{
    "identifiers": [
        "streamlit",
        "st",
        "os",
        "langchain_nvidia_ai_endpoints",
        "NVIDIAEmbeddings",
        "ChatNVIDIA",
        "langchain_community",
        "document_loaders",
        "WebBaseLoader",
        "langchain",
        "embeddings",
        "OllamaEmbeddings",
        "langchain",
        "text_splitter",
        "RecursiveCharacterTextSplitter",
        "langchain",
        "chains",
        "combine_documents",
        "create_stuff_documents_chain",
        "langchain_core",
        "prompts",
        "ChatPromptTemplate",
        "langchain_core",
        "output_parsers",
        "StrOutputParser",
        "langchain",
        "chains",
        "create_retrieval_chain",
        "langchain_community",
        "vectorstores",
        "FAISS",
        "langchain_community",
        "document_loaders",
        "PyPDFDirectoryLoader",
        "time",
        "dotenv",
        "load_dotenv",
        "load_dotenv",
        "os",
        "environ",
        "os",
        "getenv",
        "st",
        "session_state",
        "st",
        "session_state",
        "NVIDIAEmbeddings",
        "st",
        "session_state",
        "PyPDFDirectoryLoader",
        "st",
        "session_state",
        "st",
        "session_state",
        "loader",
        "load",
        "st",
        "session_state",
        "RecursiveCharacterTextSplitter",
        "chunk_size",
        "chunk_overlap",
        "st",
        "session_state",
        "st",
        "session_state",
        "text_splitter",
        "split_documents",
        "st",
        "session_state",
        "docs",
        "st",
        "session_state",
        "FAISS",
        "from_documents",
        "st",
        "session_state",
        "final_documents",
        "st",
        "session_state",
        "embeddings",
        "st",
        "title",
        "ChatNVIDIA",
        "model",
        "ChatPromptTemplate",
        "from_template",
        "st",
        "text_input",
        "st",
        "button",
        "vector_embedding",
        "st",
        "write",
        "time",
        "prompt1",
        "create_stuff_documents_chain",
        "llm",
        "prompt",
        "st",
        "session_state",
        "vectors",
        "as_retriever",
        "create_retrieval_chain",
        "retriever",
        "document_chain",
        "time",
        "process_time",
        "retrieval_chain",
        "invoke",
        "prompt1",
        "time",
        "process_time",
        "start",
        "st",
        "write",
        "response",
        "st",
        "expander",
        "i",
        "doc",
        "response",
        "st",
        "write",
        "doc",
        "page_content",
        "st",
        "write"
    ],
    "literals": [
        "'NVIDIA_API_KEY'",
        "\"NVIDIA_API_KEY\"",
        "\"vectors\"",
        "\"./pdfs\"",
        "\"hEllo\"",
        "\"Nvidia NIM Demo\"",
        "\"meta/llama3-70b-instruct\"",
        "\"Enter Your Question From Doduments\"",
        "\"Documents Embedding\"",
        "\"Vector Store DB Is Ready\"",
        "'input'",
        "\"Response time :\"",
        "'answer'",
        "\"Document Similarity Search\"",
        "\"context\"",
        "\"--------------------------------\""
    ],
    "variables": [
        "embeddings",
        "loader",
        "docs",
        "text_splitter",
        "final_documents",
        "vectors",
        "llm",
        "prompt",
        "prompt1",
        "document_chain",
        "retriever",
        "retrieval_chain",
        "start",
        "response"
    ],
    "comments": [
        "load the Groq API key",
        "Data Ingestion",
        "Document Loading",
        "Chunk Creation",
        "splitting",
        "vector OpenAI embeddings",
        "With a streamlit expander",
        "Find the relevant chunks"
    ],
    "docstrings": [
        "\"\"\"\nAnswer the questions based on the provided context only.\nPlease provide the most accurate response based on the question\n<context>\n{context}\n<context>\nQuestions:{input}\n\n\"\"\""
    ],
    "functions": [
        "vector_embedding"
    ],
    "classes": []
}