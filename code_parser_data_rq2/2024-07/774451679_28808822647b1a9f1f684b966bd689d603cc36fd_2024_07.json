{
    "identifiers": [
        "pandas",
        "pd",
        "nest_asyncio",
        "asyncio",
        "playwright",
        "async_api",
        "async_playwright",
        "bs4",
        "BeautifulSoup",
        "requests",
        "url",
        "async_playwright",
        "p",
        "p",
        "chromium",
        "launch",
        "headless",
        "browser",
        "new_page",
        "page",
        "url",
        "page",
        "wait_for_selector",
        "page",
        "content",
        "browser",
        "close",
        "html_content",
        "url",
        "BeautifulSoup",
        "scrape_with_playwright",
        "url",
        "BeautifulSoup",
        "html_content",
        "soup",
        "soup",
        "BeautifulSoup",
        "soup",
        "find",
        "find_all",
        "row",
        "rows",
        "row",
        "find",
        "cell",
        "get_text",
        "current_page",
        "split",
        "tmp",
        "split",
        "tmp",
        "tot_elmt_now",
        "tot_elmt",
        "page",
        "recordings",
        "page",
        "asyncio",
        "get_event_loop",
        "loop",
        "run_until_complete",
        "main_playwright",
        "url",
        "soup",
        "find",
        "find_all",
        "col",
        "get_text",
        "col",
        "soup",
        "select",
        "col_names",
        "append",
        "row",
        "rows",
        "row",
        "find_all",
        "row",
        "find",
        "base_url",
        "link",
        "get",
        "name",
        "value",
        "get_text",
        "strip",
        "name",
        "value",
        "col_names",
        "cells",
        "name",
        "link_href",
        "recordings",
        "append",
        "recording",
        "is_max",
        "soup",
        "parse_MAD_one",
        "page",
        "recordings",
        "recordings",
        "pd",
        "core",
        "frame",
        "DataFrame",
        "parse_MAD_one",
        "recordings",
        "pd",
        "DataFrame",
        "data",
        "df",
        "to_csv",
        "sep",
        "quotechar",
        "index",
        "header",
        "columns",
        "df",
        "columns",
        "tolist",
        "df",
        "nest_asyncio",
        "apply",
        "parse_MAD_loop"
    ],
    "literals": [
        "\"Karine DUONG\"",
        "\"Pierre POULAIN\"",
        "\"pierre.poulain@u-paris.fr\"",
        "\"tbody\"",
        "\"html.parser\"",
        "\"tfoot\"",
        "\"tr\"",
        "\"p\"",
        "\"-\"",
        "f\"https://mad.ibcp.fr/explore?page={page}\"",
        "\"tbody\"",
        "\"tr\"",
        "\"https://mad.ibcp.fr\"",
        "\"th\"",
        "\"Lien\"",
        "\"td\"",
        "\"a\"",
        "\"href\"",
        "\"Created at\"",
        "\"Lien\"",
        "\"lipid_MAD.csv\"",
        "\",\"",
        "'\"'",
        "\"__main__\""
    ],
    "variables": [
        "__authors__",
        "__contact__",
        "browser",
        "page",
        "html_content",
        "html_content",
        "soup",
        "rows",
        "cell",
        "current_page",
        "tmp",
        "tot_elmt_now",
        "tot_elmt",
        "url",
        "loop",
        "soup",
        "rows",
        "base_url",
        "col_names",
        "cells",
        "link",
        "link_href",
        "recording",
        "recording",
        "recordings",
        "data",
        "df"
    ],
    "comments": [
        "permet de créer une autre boucle d'évent, dans un env qui en a déja un en cours d'éxécution"
    ],
    "docstrings": [
        "\"\"\"This script going to scrape information from MAD database (https://mad.ibcp.fr/explore).\nThis page contains the common name, the alias, the category and the link to the page of the lipid.\n\nUsage\n-----\n    python scrap_MAD.py\n\"\"\"",
        "\"\"\"Scrapes the HTML content of a webpage using Playwright.\n\n    Parameters\n    ----------\n        url: str\n            The URL of the webpage to be scraped.\n\n    Returns\n    -------\n        str\n            The HTML content of the specified webpage.\n    \"\"\"",
        "\"\"\"Fetches and parses the HTML content of a webpage using Playwright and BeautifulSoup.\n\n    Parameters\n    ----------\n        url: str\n            The URL of the webpage to be scraped.\n\n    Returns\n    -------\n        BeautifulSoup\n            A BeautifulSoup object representing the parsed HTML content of the webpage.\n    \"\"\"",
        "\"\"\"Check if the current page is the last page of results.\n\n    Parameters\n    ----------\n        soup: BeautifulSoup)\n            A BeautifulSoup object containing the parsed HTML\n            of the current page.\n\n    Returns\n    -------\n        bool\n            True if the current page is the last page of results, False otherwise.\n    \"\"\"",
        "\"\"\"Parse data from the MAD website for a single page.\n\n    Parameters\n    ----------\n        page: int\n            The page number to parse.\n        recordings: list[dict[str, str]]\n            A list of dictionaries containing previously parsed recordings.\n\n    Returns\n    -------\n        list[dict[str, str]]\n            The updated list of recordings after parsing the specified page.\n    \"\"\"",
        "\"\"\"Parse data from the MAD website for multiple pages using a loop.\n\n    Returns\n    -------\n        pd.core.frame.DataFrame\n            DataFrame containing the parsed data from the MAD website.\n    \"\"\""
    ],
    "functions": [
        "scrape_with_playwright",
        "main_playwright",
        "is_max",
        "parse_MAD_one",
        "parse_MAD_loop"
    ],
    "classes": []
}