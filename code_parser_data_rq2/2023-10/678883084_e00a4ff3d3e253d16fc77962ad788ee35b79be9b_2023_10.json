{
    "identifiers": [
        "pandas",
        "pd",
        "json",
        "os",
        "datasets",
        "datasets",
        "Dataset",
        "DatasetDict",
        "random",
        "tqdm",
        "tqdm",
        "warnings",
        "warnings",
        "filterwarnings",
        "action",
        "category",
        "pd",
        "errors",
        "PerformanceWarning",
        "dask",
        "dataframe",
        "dd",
        "dask",
        "diagnostics",
        "ProgressBar",
        "input_csv",
        "output_csv",
        "pd",
        "read_csv",
        "input_csv",
        "df",
        "fillna",
        "index",
        "row",
        "df",
        "iterrows",
        "row",
        "iloc",
        "to_dict",
        "json",
        "dumps",
        "row_dict",
        "json_string",
        "endswith",
        "json_strings",
        "append",
        "json_string",
        "json_strings",
        "append",
        "json_strings",
        "df",
        "dropna",
        "subset",
        "pd",
        "DataFrame",
        "df",
        "iloc",
        "df",
        "df_new",
        "to_csv",
        "output_csv",
        "index",
        "input_csv",
        "output_csv",
        "pd",
        "read_csv",
        "input_csv",
        "df",
        "fillna",
        "index",
        "row",
        "df",
        "iterrows",
        "row",
        "iloc",
        "to_dict",
        "json",
        "dumps",
        "row_dict",
        "json_string",
        "endswith",
        "json_strings",
        "append",
        "json_string",
        "json_strings",
        "append",
        "join",
        "v",
        "v",
        "row_dict",
        "values",
        "row_text",
        "split",
        "random",
        "shuffle",
        "parts",
        "join",
        "parts",
        "shuffled_texts",
        "append",
        "shuffled_text",
        "json_strings",
        "df",
        "dropna",
        "subset",
        "pd",
        "DataFrame",
        "shuffled_texts",
        "df",
        "df_new",
        "to_csv",
        "output_csv",
        "index",
        "input_csv",
        "output_csv",
        "pd",
        "read_csv",
        "input_csv",
        "df",
        "fillna",
        "index",
        "row",
        "df",
        "iterrows",
        "row",
        "iloc",
        "to_dict",
        "json",
        "dumps",
        "row_dict",
        "json_string",
        "endswith",
        "json_strings",
        "append",
        "json_string",
        "json_strings",
        "append",
        "join",
        "v",
        "v",
        "row_dict",
        "values",
        "row_text",
        "split",
        "random",
        "shuffle",
        "parts",
        "join",
        "parts",
        "shuffled_texts",
        "append",
        "shuffled_text",
        "json_strings",
        "df",
        "dropna",
        "subset",
        "pd",
        "DataFrame",
        "shuffled_texts",
        "df",
        "df_new",
        "to_csv",
        "output_csv",
        "index",
        "input_csv",
        "output_csv",
        "chunksize",
        "pd",
        "DataFrame",
        "columns",
        "pd",
        "read_csv",
        "input_csv",
        "sep",
        "chunksize",
        "chunksize",
        "dtype",
        "low_memory",
        "on_bad_lines",
        "sum",
        "row",
        "open",
        "input_csv",
        "total_size",
        "chunksize",
        "df",
        "tqdm",
        "chunk_reader",
        "total",
        "total_chunks",
        "df",
        "fillna",
        "index",
        "row",
        "df",
        "iterrows",
        "row",
        "iloc",
        "to_dict",
        "json",
        "dumps",
        "row_dict",
        "json_string",
        "endswith",
        "json_strings",
        "append",
        "json_string",
        "json_strings",
        "append",
        "join",
        "v",
        "v",
        "row_dict",
        "values",
        "row_text",
        "split",
        "random",
        "shuffle",
        "parts",
        "join",
        "parts",
        "shuffled_texts",
        "append",
        "shuffled_text",
        "json_strings",
        "df",
        "dropna",
        "subset",
        "pd",
        "DataFrame",
        "shuffled_texts",
        "df",
        "pd",
        "concat",
        "df_new",
        "df_chunk",
        "ignore_index",
        "df_new",
        "to_csv",
        "output_csv",
        "index",
        "df",
        "df",
        "fillna",
        "index",
        "row",
        "df",
        "iterrows",
        "row",
        "iloc",
        "to_dict",
        "json",
        "dumps",
        "row_dict",
        "json_string",
        "endswith",
        "json_strings",
        "append",
        "json_string",
        "json_strings",
        "append",
        "join",
        "v",
        "v",
        "row_dict",
        "values",
        "row_text",
        "split",
        "random",
        "shuffle",
        "parts",
        "join",
        "parts",
        "shuffled_texts",
        "append",
        "shuffled_text",
        "json_strings",
        "df",
        "dropna",
        "subset",
        "pd",
        "DataFrame",
        "shuffled_texts",
        "df",
        "df_chunk",
        "input_csv",
        "output_csv",
        "dd",
        "read_csv",
        "input_csv",
        "sep",
        "dtype",
        "on_bad_lines",
        "ddf",
        "map_partitions",
        "process_chunk",
        "ProgressBar",
        "ddf_new",
        "compute",
        "scheduler",
        "num_workers",
        "ddf_new",
        "to_csv",
        "output_csv",
        "index",
        "path_csv_in",
        "path_csv_out",
        "hug_name",
        "version",
        "version",
        "save_rows_as_json",
        "path_csv_in",
        "path_csv_out",
        "version",
        "save_rows_as_json_shuffle_cells",
        "path_csv_in",
        "path_csv_out",
        "version",
        "save_rows_as_json_shuffle_words",
        "path_csv_in",
        "path_csv_out",
        "version",
        "save_txt_rows_as_json_shuffle_cells",
        "path_csv_in",
        "path_csv_out",
        "pd",
        "read_csv",
        "path_csv_out",
        "Dataset",
        "from_pandas",
        "df",
        "dataset",
        "push_to_hub",
        "hug_name",
        "path_csv_out",
        "hug_name",
        "pd",
        "read_csv",
        "path_csv_out",
        "Dataset",
        "from_pandas",
        "df",
        "dataset",
        "push_to_hub",
        "hug_name",
        "push_dataset_from_scripted_csv",
        "scripted_version_txt_shuffle",
        "create_and_push_dataset",
        "bench_mich_50",
        "bench_mich_50_out"
    ],
    "literals": [
        "'ignore'",
        "''",
        "'}'",
        "'transcription'",
        "'transcription'",
        "'specimen'",
        "'transcription'",
        "'transcription'",
        "''",
        "'}'",
        "' '",
        "' '",
        "' '",
        "'transcription'",
        "'transcription'",
        "'text'",
        "'transcription'",
        "'transcription'",
        "''",
        "'}'",
        "'||'",
        "'||'",
        "' '",
        "'transcription'",
        "'transcription'",
        "'text'",
        "'transcription'",
        "'transcription'",
        "'text'",
        "'transcription'",
        "'\\t'",
        "'skip'",
        "'r'",
        "''",
        "'}'",
        "'||'",
        "'||'",
        "' '",
        "'transcription'",
        "'transcription'",
        "'text'",
        "'transcription'",
        "'transcription'",
        "''",
        "'}'",
        "'||'",
        "'||'",
        "' '",
        "'transcription'",
        "'transcription'",
        "'text'",
        "'transcription'",
        "'transcription'",
        "'\\t'",
        "'skip'",
        "'processes'",
        "'catalog'",
        "'shuffle_cells'",
        "'shuffle_words'",
        "'txt_shuffle_cells'",
        "'__main__'",
        "\"HLT-GBIF-DwC-random-order\"",
        "''",
        "''",
        "\"SLTP-B50-MICH-MIpost2000\"",
        "'txt_shuffle_cells'"
    ],
    "variables": [
        "df",
        "df",
        "json_strings",
        "row_dict",
        "json_string",
        "df",
        "df",
        "df_new",
        "df",
        "df",
        "json_strings",
        "shuffled_texts",
        "row_dict",
        "json_string",
        "row_text",
        "parts",
        "shuffled_text",
        "df",
        "df",
        "df_new",
        "df",
        "df",
        "json_strings",
        "shuffled_texts",
        "row_dict",
        "json_string",
        "row_text",
        "parts",
        "shuffled_text",
        "df",
        "df",
        "df_new",
        "df_new",
        "chunk_reader",
        "total_size",
        "total_chunks",
        "df",
        "json_strings",
        "shuffled_texts",
        "row_dict",
        "json_string",
        "row_text",
        "parts",
        "shuffled_text",
        "df",
        "df",
        "df_chunk",
        "df_new",
        "df",
        "json_strings",
        "shuffled_texts",
        "row_dict",
        "json_string",
        "row_text",
        "parts",
        "shuffled_text",
        "df",
        "df",
        "df_chunk",
        "ddf",
        "ddf_new",
        "ddf_new",
        "df",
        "dataset",
        "df",
        "dataset",
        "bench_mich_50",
        "bench_mich_50_out"
    ],
    "comments": [
        "Read the dataframe from the csv file",
        "Fill NaN values with an empty string",
        "Initialize a list to store the JSON strings",
        "Iterate over the rows in the dataframe",
        "Convert the row (excluding the first column) to a dictionary",
        "Convert the dictionary to a JSON string",
        "Only add the JSON string to the list if it ends with a '}'",
        "Add the JSON strings as a new column in the original dataframe",
        "Remove rows where the JSON string did not end with a '}'",
        "Create a new dataframe with the specimen column and the JSON strings",
        "Save the new dataframe to a CSV file",
        "Read the dataframe from the csv file",
        "Fill NaN values with an empty string",
        "Initialize lists to store the JSON strings and shuffled texts",
        "Iterate over the rows in the dataframe",
        "Convert the row (excluding the first column) to a dictionary",
        "Convert the dictionary to a JSON string",
        "Only add the JSON string to the list if it ends with a '}'",
        "Create a single string from all cells in the row, excluding the first cell",
        "Split the row text by spaces, shuffle the parts, and then re-join with a single space",
        "Add the JSON strings as a new column in the original dataframe",
        "Remove rows where the JSON string did not end with a '}'",
        "Create a new dataframe with the shuffled text and the JSON strings",
        "Save the new dataframe to a CSV file",
        "Read the dataframe from the csv file",
        "Fill NaN values with an empty string",
        "Initialize lists to store the JSON strings and shuffled texts",
        "Iterate over the rows in the dataframe",
        "Convert the row (excluding the first column) to a dictionary",
        "Convert the dictionary to a JSON string",
        "Only add the JSON string to the list if it ends with a '}'",
        "Create a single string from all cells in the row, excluding the first cell",
        "Split the row text by spaces, shuffle the parts, and then re-join with a single space",
        "Add the JSON strings as a new column in the original dataframe",
        "Remove rows where the JSON string did not end with a '}'",
        "Create a new dataframe with the shuffled text and the JSON strings",
        "Save the new dataframe to a CSV file",
        "Initialize a DataFrame to store the results",
        "Initialize the csv reader",
        "Get the total number of chunks",
        "Iterate over the chunks",
        "Fill NaN values with an empty string",
        "Initialize lists to store the JSON strings and shuffled texts",
        "Iterate over the rows in the dataframe",
        "Convert the row (excluding the first column) to a dictionary",
        "Convert the dictionary to a JSON string",
        "Only add the JSON string to the list if it ends with a '}'",
        "Create a single string from all cells in the row, excluding the first cell",
        "Split the row text by spaces, shuffle the parts, and then re-join with a single space",
        "Add the JSON strings as a new column in the original dataframe",
        "Remove rows where the JSON string did not end with a '}'",
        "Create a new dataframe with the shuffled text and the JSON strings",
        "print(df_chunk.head(20))",
        "Append the new dataframe to the results dataframe",
        "Save the new dataframe to a CSV file",
        "Fill NaN values with an empty string",
        "Initialize lists to store the JSON strings and shuffled texts",
        "Iterate over the rows in the dataframe",
        "Convert the row (excluding the first column) to a dictionary",
        "Convert the dictionary to a JSON string",
        "Only add the JSON string to the list if it ends with a '}'",
        "Create a single string from all cells in the row, excluding the first cell",
        "Split the row text by spaces, shuffle the parts, and then re-join with a single space",
        "Add the JSON strings as a new column in the original dataframe",
        "Remove rows where the JSON string did not end with a '}'",
        "Create a new dataframe with the shuffled text and the JSON strings",
        "Read the dataframe using Dask",
        "Apply your function to each partition",
        "Compute the results and write to CSV",
        "To upload it to the hub",
        "To upload it to the hub",
        "os.system(\"huggingface-cli login\")",
        "herbarium_version = 'D:/Dropbox/LeafMachine2/leafmachine2/transcription/domain_knowledge/AllAsiaMinimalasof25May2023_2__TRIMMED.csv'",
        "scripted_version = 'D:/Dropbox/LeafMachine2/leafmachine2/transcription/domain_knowledge/scripted__AllAsiaMinimalasof25May2023_2__TRIMMED.csv' # (new file)",
        "scripted_version_ba = 'D:/Dropbox/LeafMachine2/leafmachine2/transcription/domain_knowledge/scripted-ba__AllAsiaMinimalasof25May2023_2__TRIMMEDtiny.csv' # (new file)",
        "scripted_version_ba_shuffle = 'D:/Dropbox/LeafMachine2/leafmachine2/transcription/domain_knowledge/scripted-ba-shuffle__AllAsiaMinimalasof25May2023_2__TRIMMEDtiny.csv' # (new file)",
        "create_and_push_dataset(herbarium_version, scripted_version, \"HLT-test-trimmed\", 'shuffle_cells')",
        "create_and_push_dataset(herbarium_version, scripted_version_ba, \"HLT-test-shuffle-cells\", 'shuffle_cells')",
        "create_and_push_dataset(herbarium_version, scripted_version_ba_shuffle, \"HLT-test-shuffle-words\", 'shuffle_words')",
        "'''All Asia, 21 columns'''",
        "herbarium_version = '/home/brlab/Dropbox/LeafMachine2/leafmachine2/transcription/domain_knowledge/AllAsiaMinimalasof25May2023_2__TRIMMED.csv'",
        "scripted_version = '/home/brlab/Dropbox/LeafMachine2/leafmachine2/transcription/domain_knowledge/scripted__HLT-AA-C21-v1.csv' # (new file)",
        "create_and_push_dataset(herbarium_version, scripted_version, \"HLT-AA-C21-v1\", 'shuffle_cells')",
        "herbarium_version = '/home/brlab/Dropbox/LM2_Env/Image_Datasets/GBIF_Ingest/GBIF/occurrence.txt'",
        "scripted_version_txt_shuffle = '/home/brlab/data/HLT_Datasets/GBIF_DwC-random_order/scripted_HLT-GBIF-DwC-random-order.csv' # (new file)",
        "create_and_push_dataset(herbarium_version, scripted_version_txt_shuffle, \"HLT-GBIF-DwC-random-order\", 'txt_shuffle_cells')",
        "",
        "(new file)",
        "(new file)"
    ],
    "docstrings": [
        "'''\nhttps://huggingface.co/docs/datasets/upload_dataset\n'''",
        "'''GBIF from 5 million records'''",
        "'''BENCHMARK MICH 50'''"
    ],
    "functions": [
        "save_rows_as_json",
        "save_rows_as_json_shuffle_words",
        "save_rows_as_json_shuffle_cells",
        "save_txt_rows_as_json_shuffle_cells2",
        "process_chunk",
        "save_txt_rows_as_json_shuffle_cells",
        "create_and_push_dataset",
        "push_dataset_from_scripted_csv"
    ],
    "classes": []
}