{
    "identifiers": [
        "math",
        "torch",
        "torch",
        "nn",
        "nn",
        "compress_weight",
        "CompressWeight",
        "general_pack_on_row",
        "general_unpack_on_row",
        "torch",
        "autograd",
        "staticmethod",
        "ctx",
        "qweight",
        "scales",
        "qzeros",
        "groupsize",
        "bits",
        "in_features",
        "scales",
        "reshape",
        "scales",
        "shape",
        "qzeros",
        "reshape",
        "qzeros",
        "shape",
        "bits",
        "torch",
        "tensor",
        "bits",
        "dtype",
        "torch",
        "int32",
        "device",
        "qweight",
        "device",
        "unsqueeze",
        "torch",
        "bitwise_right_shift",
        "torch",
        "unsqueeze",
        "qweight",
        "wf",
        "unsqueeze",
        "to",
        "torch",
        "int16",
        "bits",
        "torch",
        "int8",
        "torch",
        "bitwise_and",
        "weight",
        "bits",
        "weight",
        "torch",
        "zeros",
        "in_features",
        "qweight",
        "shape",
        "dtype",
        "torch",
        "int32",
        "device",
        "qweight",
        "device",
        "general_unpack_on_row",
        "qweight",
        "weight",
        "bits",
        "qzeros",
        "scales",
        "weight",
        "reshape",
        "groupsize",
        "weight",
        "shape",
        "scales",
        "weight",
        "scale_zeros",
        "half",
        "weight",
        "reshape",
        "weight",
        "shape",
        "weight",
        "torch",
        "autograd",
        "staticmethod",
        "ctx",
        "inputs",
        "qweight",
        "scales",
        "qzeros",
        "groupsize",
        "bits",
        "in_features",
        "torch",
        "onnx",
        "is_in_onnx_export",
        "torch",
        "zeros",
        "inputs",
        "shape",
        "qweight",
        "size",
        "dtype",
        "inputs",
        "dtype",
        "device",
        "inputs",
        "device",
        "DequantAndUnpack",
        "apply",
        "qweight",
        "scales",
        "qzeros",
        "groupsize",
        "bits",
        "in_features",
        "torch",
        "matmul",
        "inputs",
        "weight",
        "nn",
        "Module",
        "CompressWeight",
        "bits",
        "groupsize",
        "infeatures",
        "outfeatures",
        "bias",
        "bits",
        "NotImplementedError",
        "infeatures",
        "outfeatures",
        "bits",
        "groupsize",
        "groupsize",
        "infeatures",
        "torch",
        "tensor",
        "i",
        "groupsize",
        "i",
        "infeatures",
        "dtype",
        "torch",
        "int32",
        "register_buffer",
        "torch",
        "zeros",
        "infeatures",
        "bits",
        "outfeatures",
        "dtype",
        "torch",
        "int32",
        "register_buffer",
        "torch",
        "zeros",
        "math",
        "ceil",
        "infeatures",
        "groupsize",
        "outfeatures",
        "dtype",
        "torch",
        "float16",
        "register_buffer",
        "torch",
        "zeros",
        "math",
        "ceil",
        "infeatures",
        "groupsize",
        "outfeatures",
        "dtype",
        "torch",
        "float16",
        "bias",
        "register_buffer",
        "torch",
        "zeros",
        "outfeatures",
        "dtype",
        "torch",
        "float16",
        "intzeros",
        "device",
        "intzeros",
        "contiguous",
        "cpu",
        "intzeros",
        "device",
        "intzeros",
        "contiguous",
        "cpu",
        "x",
        "QuantLinearTorchFunction",
        "apply",
        "x",
        "qweight",
        "scales",
        "qzeros",
        "groupsize",
        "bits",
        "infeatures",
        "bias",
        "bias"
    ],
    "literals": [
        "\"Only 2,4,5,6,7,8 bits are supported.\"",
        "\"HQQ\"",
        "'qweight'",
        "'qzeros'",
        "'scales'",
        "'bias'"
    ],
    "variables": [
        "scales",
        "qzeros",
        "wf",
        "weight",
        "weight",
        "scale_zeros",
        "weight",
        "weight",
        "weight",
        "weight",
        "infeatures",
        "outfeatures",
        "bits",
        "groupsize",
        "pack_mode",
        "orig_fp_weight",
        "g_idx",
        "bias",
        "qzeros",
        "qzeros"
    ],
    "comments": [
        "weight = (scales * (weight - zeros))"
    ],
    "docstrings": [],
    "functions": [
        "forward",
        "forward",
        "pack_qzeros_even",
        "pack_qzeros_odd",
        "forward"
    ],
    "classes": [
        "DequantAndUnpack",
        "QuantLinearTorchFunction",
        "QuantLinearHQQ"
    ]
}