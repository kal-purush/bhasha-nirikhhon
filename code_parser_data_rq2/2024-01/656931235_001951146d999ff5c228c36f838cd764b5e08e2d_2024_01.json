{
    "identifiers": [
        "OpenAI",
        "OpenAIStream",
        "StreamingTextResponse",
        "OpenAI",
        "process",
        "req",
        "req",
        "perplexity",
        "OpenAIStream",
        "response",
        "StreamingTextResponse",
        "stream"
    ],
    "literals": [
        "'openai'",
        "'ai'",
        "''",
        "'https://api.perplexity.ai/'",
        "'edge'",
        "'pplx-70b-online'"
    ],
    "variables": [
        "perplexity",
        "runtime",
        "response",
        "stream"
    ],
    "comments": [
        "Create an OpenAI API client (that's edge friendly!)",
        "but configure it to point to perplexity.ai",
        "IMPORTANT! Set the runtime to edge",
        "Extract the `messages` from the body of the request",
        "Ask Perplexity for a streaming chat completion using PPLX 70B online model",
        "@see https://blog.perplexity.ai/blog/introducing-pplx-online-llms",
        "Convert the response into a friendly text-stream.",
        "Respond with the stream"
    ],
    "docstrings": [],
    "functions": [
        "POST"
    ],
    "classes": []
}