{
    "identifiers": [
        "langchain",
        "llms",
        "LLM",
        "typing",
        "Any",
        "Optional",
        "langchain",
        "callbacks",
        "manager",
        "CallbackManagerForLLMRun",
        "transformers",
        "AutoTokenizer",
        "AutoModelForCausalLM",
        "torch",
        "LLM",
        "AutoTokenizer",
        "AutoModelForCausalLM",
        "model_path",
        "AutoTokenizer",
        "from_pretrained",
        "model_path",
        "trust_remote_code",
        "AutoModelForCausalLM",
        "from_pretrained",
        "model_path",
        "trust_remote_code",
        "to",
        "torch",
        "bfloat16",
        "cuda",
        "model",
        "eval",
        "prompt",
        "stop",
        "Optional",
        "run_manager",
        "Optional",
        "CallbackManagerForLLMRun",
        "kwargs",
        "Any",
        "model",
        "chat",
        "tokenizer",
        "prompt",
        "history",
        "response",
        "property",
        "InternLM_LLM",
        "model_path",
        "llm",
        "predict"
    ],
    "literals": [
        "\"loading model...\"",
        "\"loaded model\"",
        "\"InternLM\"",
        "\"main\"",
        "\"/root/data/model/Shanghai_AI_Laboratory/internlm-chat-7b\"",
        "\"你是谁\""
    ],
    "variables": [
        "tokenizer",
        "model",
        "tokenizer",
        "model",
        "model",
        "response",
        "history",
        "llm"
    ],
    "comments": [
        "基于本地 InternLM 自定义 LLM 类",
        "model_path: InternLM 模型路径",
        "从本地初始化模型",
        "重写调用函数",
        "测试代码"
    ],
    "docstrings": [],
    "functions": [
        "_call",
        "_llm_type"
    ],
    "classes": [
        "InternLM_LLM"
    ]
}