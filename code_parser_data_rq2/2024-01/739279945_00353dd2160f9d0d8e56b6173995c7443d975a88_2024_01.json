{
    "identifiers": [
        "vscode",
        "APIProvider",
        "Ollama",
        "APIProvider",
        "vscode",
        "context",
        "vscode",
        "context",
        "callbacks",
        "initialRecentPrompt",
        "codellamaInitialRecentPrompt",
        "initialRecentPrompt",
        "Ollama",
        "customPrompts",
        "chunk",
        "stream",
        "chunk",
        "gptMessage",
        "chunk",
        "callbacks",
        "callbacks",
        "gptMessage",
        "error",
        "error",
        "callbacks",
        "gptMessage",
        "error",
        "error",
        "error"
    ],
    "literals": [
        "\"vscode\"",
        "\"./apiProvider\"",
        "\"langchain/llms/ollama\"",
        "string",
        "string",
        "ollama initialized!!",
        "\"http://localhost:11434\"",
        "\"content\"",
        "\"Give me only code block about subsequent requests with triple backticks. \"",
        "\"codellama\"",
        "\"ollama API is not initialized.\"",
        "\"\"",
        "\"\"",
        "\"Error parsing message:\"",
        "\"Error fetching stream:\""
    ],
    "variables": [
        "initialRecentPrompt",
        "codellamaInitialRecentPrompt",
        "customPrompts",
        "stream",
        "buffer",
        "gptMessage"
    ],
    "comments": [
        "max_tokens: number;",
        "stream: boolean;",
        "Default value"
    ],
    "docstrings": [],
    "functions": [
        "init",
        "completeStream"
    ],
    "classes": [
        "ollamaLLMProvider"
    ]
}