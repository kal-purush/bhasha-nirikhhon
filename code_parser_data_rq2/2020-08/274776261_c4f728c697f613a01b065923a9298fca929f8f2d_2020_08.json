{
    "identifiers": [
        "torch",
        "advtrain",
        "load_dataset",
        "load_dataset",
        "matplotlib",
        "pyplot",
        "plt",
        "advtrain",
        "attack_framework",
        "multi_lib_attacks",
        "attack_wrapper",
        "advtrain",
        "utils",
        "preprocess",
        "preprocess",
        "PreProcess",
        "advtrain",
        "framework",
        "Framework",
        "os",
        "framework",
        "net",
        "model_name",
        "dataset",
        "normalize",
        "preprocess",
        "epochs",
        "optimizer",
        "loss",
        "learning_rate",
        "device",
        "net",
        "framework",
        "dataset",
        "lower",
        "normalize",
        "framework",
        "train_batch_size",
        "framework",
        "test_batch_size",
        "framework",
        "val_split",
        "framework",
        "epochs",
        "model_name",
        "optimizer",
        "learning_rate",
        "device",
        "framework",
        "device",
        "device",
        "get_optimizer",
        "optimizer",
        "learning_rate",
        "val_split",
        "torch",
        "optim",
        "lr_scheduler",
        "ReduceLROnPlateau",
        "optimizer",
        "torch",
        "optim",
        "lr_scheduler",
        "MultiStepLR",
        "optimizer",
        "milestones",
        "gamma",
        "get_criterion_for_loss_function",
        "loss",
        "framework",
        "dataset_info",
        "dataset_info",
        "train_loader",
        "dataset_info",
        "validation_loader",
        "dataset_info",
        "test_loader",
        "len",
        "train_loader",
        "len",
        "val_loader",
        "len",
        "test_loader",
        "normalize",
        "dataset_info",
        "normalization",
        "dataset_info",
        "image_channels",
        "dataset_info",
        "num_classes",
        "dataset_info",
        "image_dimensions",
        "preprocess",
        "PreProcess",
        "preprocess",
        "os",
        "makedirs",
        "exist_ok",
        "os",
        "makedirs",
        "dataset",
        "exist_ok",
        "os",
        "makedirs",
        "dataset",
        "exist_ok",
        "framework",
        "adversarial_training",
        "framework",
        "attack_info",
        "attack_wrapper",
        "net",
        "device",
        "attack_info",
        "new_net",
        "new_model_name",
        "new_net",
        "new_model_name",
        "get_optimizer",
        "optimizer_name",
        "learning_rate",
        "loss",
        "loss",
        "lower",
        "loss",
        "loss",
        "torch",
        "nn",
        "CrossEntropyLoss",
        "loss",
        "torch",
        "nn",
        "MSELoss",
        "ValueError",
        "optimizer",
        "learning_rate",
        "optimizer",
        "lower",
        "optimizer",
        "torch",
        "optim",
        "SGD",
        "net",
        "parameters",
        "lr",
        "learning_rate",
        "momentum",
        "weight_decay",
        "optimizer",
        "torch",
        "optim",
        "Adagrad",
        "net",
        "parameters",
        "lr",
        "learning_rate",
        "optimizer",
        "torch",
        "optim",
        "Adam",
        "net",
        "parameters",
        "lr",
        "learning_rate",
        "ValueError",
        "net",
        "to",
        "device",
        "net",
        "eval",
        "torch",
        "cuda",
        "empty_cache",
        "torch",
        "zeros",
        "num_classes",
        "num_classes",
        "batch_idx",
        "data",
        "labels",
        "test_loader",
        "data",
        "to",
        "device",
        "labels",
        "to",
        "device",
        "current_batch_data",
        "data",
        "current_batch_data",
        "labels",
        "attack",
        "generate_adversary",
        "data",
        "labels",
        "adv_train_model",
        "net",
        "targeted",
        "targeted",
        "target_class",
        "target",
        "L2",
        "torch",
        "sum",
        "torch",
        "norm",
        "data",
        "un_norm_perturbed_data",
        "p",
        "dim",
        "Linf",
        "torch",
        "sum",
        "torch",
        "norm",
        "data",
        "un_norm_perturbed_data",
        "p",
        "dim",
        "preprocess",
        "perturbed_data",
        "to",
        "device",
        "framework",
        "net",
        "data",
        "torch",
        "max",
        "dim",
        "torch",
        "nn",
        "functional",
        "softmax",
        "dim",
        "sort",
        "dim",
        "sorted_output",
        "num_classes",
        "sorted_output",
        "num_classes",
        "correct",
        "pred",
        "labels",
        "sum",
        "item",
        "confidence_correct",
        "torch",
        "where",
        "pred",
        "labels",
        "confidence",
        "torch",
        "zeros_like",
        "confidence",
        "sum",
        "item",
        "confidence_incorrect",
        "torch",
        "where",
        "pred",
        "labels",
        "confidence",
        "torch",
        "zeros_like",
        "confidence",
        "sum",
        "item",
        "total",
        "labels",
        "size",
        "ground_truth",
        "predicted",
        "labels",
        "cpu",
        "argmax",
        "axis",
        "cpu",
        "confusion_matrix",
        "ground_truth",
        "predicted",
        "correct",
        "confidence_correct",
        "correct",
        "total",
        "correct",
        "confidence_incorrect",
        "total",
        "correct",
        "correct",
        "total",
        "L2",
        "item",
        "total",
        "Linf",
        "item",
        "total",
        "correct",
        "total",
        "accuracy",
        "norm_2",
        "norm_inf",
        "net",
        "to",
        "device",
        "net",
        "eval",
        "torch",
        "zeros",
        "num_classes",
        "num_classes",
        "torch",
        "cuda",
        "empty_cache",
        "torch",
        "no_grad",
        "batch_idx",
        "data",
        "labels",
        "test_loader",
        "data",
        "to",
        "device",
        "labels",
        "to",
        "device",
        "current_batch_data",
        "data",
        "current_batch_data",
        "labels",
        "preprocess",
        "normalize",
        "data",
        "net",
        "data",
        "torch",
        "max",
        "dim",
        "torch",
        "nn",
        "functional",
        "softmax",
        "dim",
        "sort",
        "dim",
        "sorted_output",
        "num_classes",
        "sorted_output",
        "num_classes",
        "correct",
        "pred",
        "labels",
        "sum",
        "item",
        "confidence_correct",
        "torch",
        "where",
        "pred",
        "labels",
        "confidence",
        "torch",
        "zeros_like",
        "confidence",
        "sum",
        "item",
        "confidence_incorrect",
        "torch",
        "where",
        "pred",
        "labels",
        "confidence",
        "torch",
        "zeros_like",
        "confidence",
        "sum",
        "item",
        "total",
        "labels",
        "size",
        "ground_truth",
        "predicted",
        "labels",
        "cpu",
        "argmax",
        "axis",
        "cpu",
        "confusion_matrix",
        "ground_truth",
        "predicted",
        "correct",
        "confidence_correct",
        "correct",
        "total",
        "correct",
        "confidence_incorrect",
        "total",
        "correct",
        "correct",
        "total",
        "correct",
        "total",
        "accuracy",
        "net",
        "to",
        "device",
        "net",
        "eval",
        "torch",
        "cuda",
        "empty_cache",
        "torch",
        "no_grad",
        "batch_idx",
        "data",
        "labels",
        "val_loader",
        "data",
        "to",
        "device",
        "labels",
        "to",
        "device",
        "current_batch_data",
        "data",
        "current_batch_data",
        "labels",
        "net",
        "preprocess",
        "normalize",
        "data",
        "framework",
        "net",
        "framework",
        "preprocess",
        "framework",
        "normalize",
        "data",
        "criterion",
        "target",
        "running_loss",
        "loss",
        "item",
        "batches",
        "torch",
        "max",
        "dim",
        "correct",
        "pred",
        "labels",
        "sum",
        "item",
        "total",
        "labels",
        "size",
        "correct",
        "total",
        "running_loss",
        "batches",
        "correct",
        "total",
        "accuracy",
        "average_loss",
        "resume_training",
        "batch_hook",
        "epoch_hook",
        "parallel",
        "parallel_devices_ids",
        "visualize",
        "net",
        "to",
        "device",
        "net",
        "train",
        "resume_training",
        "torch",
        "load",
        "dataset",
        "model_name",
        "saved_training_state",
        "optimizer",
        "load_state_dict",
        "saved_training_state",
        "net",
        "load_state_dict",
        "saved_training_state",
        "saved_training_state",
        "saved_training_state",
        "parallel",
        "nn",
        "DataParallel",
        "net",
        "device_ids",
        "parallel_device_ids",
        "net",
        "to",
        "device",
        "epoch",
        "start_epoch",
        "num_epochs",
        "epoch",
        "net",
        "train",
        "batch_idx",
        "data",
        "labels",
        "train_loader",
        "batch_idx",
        "data",
        "to",
        "device",
        "labels",
        "to",
        "device",
        "current_batch_data",
        "data",
        "current_batch_data",
        "labels",
        "visualize",
        "index",
        "plt",
        "figure",
        "num_channels",
        "plt",
        "imshow",
        "data",
        "index",
        "cpu",
        "numpy",
        "cmap",
        "vmin",
        "vmax",
        "plt",
        "imshow",
        "data",
        "index",
        "cpu",
        "numpy",
        "transpose",
        "plt",
        "show",
        "plt",
        "close",
        "optimizer",
        "zero_grad",
        "net",
        "preprocess",
        "normalize",
        "data",
        "framework",
        "net",
        "framework",
        "preprocess",
        "framework",
        "normalize",
        "data",
        "criterion",
        "target",
        "loss",
        "backward",
        "optimizer",
        "step",
        "train_correct",
        "max",
        "labels",
        "sum",
        "item",
        "train_total",
        "labels",
        "size",
        "train_correct",
        "train_total",
        "loss",
        "item",
        "train_accuracy",
        "batch_hook",
        "batch_hook",
        "val_split",
        "validate",
        "scheduler",
        "step",
        "val_loss",
        "val_accuracy",
        "best_val_accuracy",
        "val_accuracy",
        "val_loss",
        "scheduler",
        "step",
        "current_epoch",
        "parallel",
        "current_epoch",
        "optimizer",
        "state_dict",
        "net",
        "state_dict",
        "best_val_accuracy",
        "best_val_loss",
        "current_epoch",
        "optimizer",
        "state_dict",
        "net",
        "state_dict",
        "best_val_accuracy",
        "best_val_loss",
        "torch",
        "save",
        "saved_training_state",
        "dataset",
        "model_name",
        "save_ckpt",
        "saves",
        "append",
        "current_epoch",
        "parallel",
        "torch",
        "save",
        "net",
        "state_dict",
        "dataset",
        "model_name",
        "torch",
        "save",
        "net",
        "state_dict",
        "dataset",
        "model_name",
        "test",
        "test_accuracy",
        "epoch_hook",
        "epoch_hook",
        "num_epochs",
        "torch",
        "load",
        "dataset",
        "model_name",
        "net",
        "load_state_dict",
        "saved_training_state"
    ],
    "literals": [
        "'cifar10'",
        "'sgd'",
        "'crossentropy'",
        "'./pretrained/'",
        "'./pretrained/'",
        "'/'",
        "'./pretrained/'",
        "'/temp/'",
        "'crossentropy'",
        "'xentropy'",
        "'mse'",
        "\"Unsupported loss function\"",
        "'sgd'",
        "'adagrad'",
        "'adam'",
        "\"Unsupported Optimizer\"",
        "'data'",
        "'labels'",
        "'inf'",
        "'data'",
        "'labels'",
        "'data'",
        "'labels'",
        "'./pretrained/'",
        "'/temp/'",
        "'.temp_tfr'",
        "'epoch'",
        "'optimizer'",
        "'model'",
        "'best_val_accuracy'",
        "'best_val_loss'",
        "'inf'",
        "'data'",
        "'labels'",
        "'gray'",
        "'inf'",
        "'epoch'",
        "'optimizer'",
        "'model'",
        "'best_val_accuracy'",
        "'best_val_loss'",
        "'epoch'",
        "'optimizer'",
        "'model'",
        "'best_val_accuracy'",
        "'best_val_loss'",
        "'./pretrained/'",
        "'/temp/'",
        "'.temp_tfr'",
        "'./pretrained/'",
        "'/'",
        "'.ckpt_tfr'",
        "'./pretrained/'",
        "'/'",
        "'.ckpt_tfr'",
        "'./pretrained/'",
        "'/temp/'",
        "'.temp_tfr'",
        "'model'"
    ],
    "variables": [
        "net",
        "dataset",
        "normalize",
        "train_batch_size",
        "test_batch_size",
        "val_split",
        "framework",
        "num_epochs",
        "model_name",
        "optimizer_name",
        "learning_rate",
        "device",
        "device",
        "optimizer",
        "scheduler",
        "scheduler",
        "criterion",
        "dataset_info",
        "train_loader",
        "val_loader",
        "test_loader",
        "train_len",
        "val_len",
        "test_len",
        "normalize",
        "num_channels",
        "num_classes",
        "img_size",
        "preprocess",
        "preprocess",
        "attack_info",
        "attack",
        "best_val_accuracy",
        "best_val_loss",
        "current_train_loss",
        "current_train_acc",
        "current_epoch",
        "current_batch",
        "saves",
        "current_batch_data",
        "current_test_acc",
        "net",
        "model_name",
        "optimizer",
        "best_val_accuracy",
        "best_val_loss",
        "current_train_loss",
        "current_train_acc",
        "current_epoch",
        "current_batch",
        "saves",
        "current_batch_data",
        "loss",
        "optimizer",
        "net",
        "correct",
        "total",
        "L2",
        "Linf",
        "confidence_correct",
        "confidence_incorrect",
        "confusion_matrix",
        "data",
        "labels",
        "perturbed_data",
        "un_norm_perturbed_data",
        "data",
        "_",
        "pred",
        "sorted_output",
        "confidence",
        "confidence_correct",
        "confidence_incorrect",
        "accuracy",
        "norm_2",
        "norm_inf",
        "net",
        "correct",
        "total",
        "confidence_correct",
        "confidence_incorrect",
        "confusion_matrix",
        "data",
        "labels",
        "data",
        "_",
        "pred",
        "sorted_output",
        "confidence",
        "confidence_correct",
        "confidence_incorrect",
        "accuracy",
        "net",
        "correct",
        "total",
        "running_loss",
        "batches",
        "data",
        "labels",
        "target",
        "loss",
        "_",
        "pred",
        "accuracy",
        "average_loss",
        "net",
        "saved_training_state",
        "start_epoch",
        "best_val_accuracy",
        "best_val_loss",
        "start_epoch",
        "best_val_accuracy",
        "best_val_loss",
        "net",
        "net",
        "train_correct",
        "train_total",
        "save_ckpt",
        "current_epoch",
        "current_batch",
        "data",
        "labels",
        "target",
        "loss",
        "train_accuracy",
        "current_train_loss",
        "current_train_acc",
        "val_correct",
        "val_total",
        "val_accuracy",
        "val_loss",
        "best_val_accuracy",
        "best_val_loss",
        "save_ckpt",
        "val_accuracy",
        "save_ckpt",
        "saved_training_state",
        "saved_training_state",
        "test_correct",
        "test_total",
        "test_accuracy",
        "current_test_acc",
        "saved_training_state"
    ],
    "comments": [
        "Optimizer",
        "Training parameters exposed for hooks to access them",
        "Saves the current test accuracy for the parameters obtained or the best validation accuracy",
        "Generate adversarial image",
        "Generate adversarial image",
        "Testing on the validation set puts this into eval, so make sure to",
        "put it into train mode each epoch",
        "Clears gradients of all the parameter tensors",
        "Update internal local variables",
        "Update object attributes accessible outside",
        "Call batch hook after batch updates",
        "Update lr",
        "Load the most optimum weights found during training"
    ],
    "docstrings": [
        "\"\"\"\"\"\"",
        "\"\"\"\n@authors: Sangamesh Kodge\n@copyright: Nanoelectronics Research Laboratory\n\"\"\"",
        "\"\"\"\"\"\"",
        "\"\"\"This is a framework to train and evaluate a network, when training it uses mean and std normalization\n        \n        Args:\n            net (nn.Module): network to be trained\n            dataset (str): CIFAR10, CIFAR100, TinyImageNet, ImageNet\n            preprocess (object): a callable object, lambda or nn.Module whose forward implements the preprocessing step\n            train_batch_size (int): batch size for training dataset\n            test_batch_size (int): batch size for testing dataset\n            val_split (float): percentage of training data split as validation dataset\n            augment (bool): bool flag for Random horizontal flip and shift with padding\n            padding_crop (int): units of pixel shift (i.e. used only when augment is True), specifed in the input transformation\n            shuffle (bool): bool flag for shuffling the training and validation dataset\n            random_seed (int): Fixes the shuffle seed for reproducing the results\n            optimizer (str): Name of the optimizer to use\n            loss (str): Name of the loss to use for training\n            adversarial_training (bool): True for adversarial training\n            lib (str): select the implementing library custom, advertorch or foolbox\n            attack(str): select the attack type PGD,CW,...\n            iterations(int): Number of iterations for the attack\n            epsilon(float) : attack strength\n            stepsize(float) : step size for the attack\n            use_bpda : Backward propagation through differential approximation\n            target(int): None for non targeted attack. class label for targeted attack\n            random(bool) : False for deterministic implementation\n            device (str): cpu/cuda device to perform the evaluation on, if left to None picks up the CPU if available\n        Returns:\n            Returns an object of the framework\n        \"\"\"",
        "'''\n        Updates all the internal states to make sure new model can be trained correctly \n        Args:\n            new_net (nn.Module): New netwrok to train\n            new_model_name (str): name of new model to save\n        \n        Returns:\n            No return data \n        '''",
        "'''\n        Args:\n            loss (str): name of loss\n        \n        Returns:\n            Returns the loss_criteria from torch \n        '''",
        "'''\n        Args:\n            optimizer (str): name of optimizer\n            learning_rate (float): learning rate of optimizer\n        \n        Returns:\n            Returns the corresponding torch optimizer\n        '''",
        "\"\"\"Adversarial Inference function\n\n        Returns:\n            correct, total, accuracy.\n            correct (int), the number of correctly classifed images\n            total (int), the total number of images in the test set\n            accuracy (float), accuracy in %\n        \"\"\"",
        "\"\"\"Evaluates network performance and returns the accuracy of the network\n\n        Returns:\n            correct, total, accuracy.\n            correct (int), the number of correctly classifed images\n            total (int), the total number of images in the test set\n            accuracy (float), accuracy in %\n        \"\"\"",
        "\"\"\"Evaluates network performance on the validation set and returns the accuracy of the network\n\n        Returns:\n            correct, total, accuracy, loss\n            correct (int), the number of correctly classifed images\n            total (int), the total number of images in the test set\n            accuracy (float), accuracy in %\n            loss (float), average loss over the validation set\n        \"\"\"",
        "\"\"\"Trains the network for the specifed number of epochs\n        \n        Args:\n            resume_training (bool): Resumes traning from previous epoch, optimizer state and net parameters\n            batch_hook (function pointer): function called at end of every batch\n            epoch_hook (function pointer): function called at end of every epoch\n            parallel (bool): Use dataparallel on the devices\n            parallel_devices_ids (list of int): the device id's to use\n            visualize(bool) : see the image in the dataset.\n        \"\"\""
    ],
    "functions": [
        "update_network",
        "get_criterion_for_loss_function",
        "get_optimizer",
        "adversarial_attack",
        "test",
        "validate",
        "train"
    ],
    "classes": [
        "Blackbox_extention"
    ]
}