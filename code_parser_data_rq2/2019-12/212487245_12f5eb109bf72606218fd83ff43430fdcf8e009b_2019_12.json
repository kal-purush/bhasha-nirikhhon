{
    "identifiers": [
        "x",
        "y",
        "x",
        "np",
        "random",
        "rand",
        "input",
        "shape",
        "np",
        "random",
        "rand",
        "y",
        "np",
        "zeros",
        "y",
        "shape",
        "sigmoid",
        "np",
        "dot",
        "input",
        "weights1",
        "sigmoid",
        "np",
        "dot",
        "layer1",
        "weights2",
        "np",
        "dot",
        "layer1",
        "T",
        "y",
        "output",
        "sigmoid_derivative",
        "output",
        "np",
        "dot",
        "input",
        "T",
        "np",
        "dot",
        "y",
        "output",
        "sigmoid_derivative",
        "output",
        "weights2",
        "T",
        "sigmoid_derivative",
        "layer1",
        "weights2",
        "d_weights2",
        "weights1",
        "d_weights1"
    ],
    "literals": [],
    "variables": [
        "input",
        "weights1",
        "weights2",
        "y",
        "output",
        "layer1",
        "output",
        "d_weights2",
        "d_weights1"
    ],
    "comments": [
        "Copied from tutorial",
        "application of the chain rule to find derivative of the loss function with respect to weights2 and weights1",
        "update the weights with the derivative (slope) of the loss function"
    ],
    "docstrings": [],
    "functions": [
        "feedforward",
        "backprop"
    ],
    "classes": [
        "NeuralNetwork"
    ]
}