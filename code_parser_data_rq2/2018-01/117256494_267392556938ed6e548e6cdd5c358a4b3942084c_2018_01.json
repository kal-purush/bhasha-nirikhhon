{
    "identifiers": [
        "numpy",
        "np",
        "tensorflow",
        "tf",
        "hidden_states",
        "state_size",
        "window_size",
        "dim_hlayer",
        "batch_size",
        "activation",
        "L",
        "sketches_num",
        "discount_factor",
        "temperature",
        "tf",
        "variable_scope",
        "reuse",
        "tf",
        "AUTO_REUSE",
        "tf",
        "get_variable",
        "name",
        "shape",
        "state_size",
        "window_size",
        "dim_hlayer",
        "initializer",
        "tf",
        "contrib",
        "layers",
        "xavier_initializer",
        "uniform",
        "dtype",
        "tf",
        "float32",
        "tf",
        "get_variable",
        "name",
        "shape",
        "dim_hlayer",
        "initializer",
        "tf",
        "random_uniform_initializer",
        "dtype",
        "tf",
        "float32",
        "tf",
        "get_variable",
        "name",
        "shape",
        "dim_hlayer",
        "initializer",
        "tf",
        "random_uniform_initializer",
        "dtype",
        "tf",
        "float32",
        "tf",
        "get_variable",
        "name",
        "shape",
        "state_size",
        "window_size",
        "state_size",
        "initializer",
        "tf",
        "contrib",
        "layers",
        "xavier_initializer",
        "uniform",
        "dtype",
        "tf",
        "float32",
        "tf",
        "get_variable",
        "name",
        "shape",
        "state_size",
        "initializer",
        "tf",
        "random_uniform_initializer",
        "dtype",
        "tf",
        "float32",
        "padded_matrix",
        "r",
        "tf",
        "transpose",
        "padded_matrix",
        "j",
        "np",
        "arange",
        "r",
        "L",
        "r",
        "time_major_matrix",
        "j",
        "r",
        "j",
        "r",
        "tf",
        "reshape",
        "context_j",
        "r",
        "state_size",
        "batch_size",
        "contexts",
        "append",
        "context_j",
        "tf",
        "stack",
        "contexts",
        "tf",
        "transpose",
        "contexts",
        "batch_major_contexts",
        "hidstates",
        "sk",
        "padding_col",
        "tf",
        "concat",
        "hidstates",
        "sk",
        "tf",
        "pad",
        "hs",
        "padding_col",
        "name",
        "conv_r",
        "hs",
        "window_size",
        "hs",
        "tensor",
        "cum_attention",
        "temper",
        "input_tensor",
        "b",
        "temp",
        "tf",
        "reduce_sum",
        "tf",
        "exp",
        "input_tensor",
        "temp",
        "axis",
        "keep_dims",
        "tf",
        "exp",
        "input_tensor",
        "temp",
        "b",
        "temp",
        "z",
        "tf",
        "ones_like",
        "b",
        "b",
        "tf",
        "to_float",
        "tf",
        "less_equal",
        "a",
        "u",
        "tf",
        "to_float",
        "tf",
        "less",
        "u",
        "a",
        "a",
        "t_mask",
        "u",
        "f_mask",
        "A",
        "U",
        "csoftmax",
        "t",
        "activation",
        "tf",
        "matmul",
        "t",
        "W_hsz",
        "w_z",
        "tf",
        "matmul",
        "before_att",
        "v",
        "att",
        "tf",
        "transpose",
        "tensor",
        "tf",
        "map_fn",
        "attention",
        "tensor",
        "dtype",
        "tf",
        "float32",
        "tf",
        "reshape",
        "attentions",
        "batch_size",
        "L",
        "cum_attention",
        "discount_factor",
        "constrained_softmax",
        "attentions",
        "cum_attention",
        "temper",
        "tf",
        "transpose",
        "tensor",
        "tf",
        "reduce_sum",
        "tensor",
        "tf",
        "expand_dims",
        "constrained_weights",
        "axis",
        "tf",
        "reshape",
        "cn",
        "batch_size",
        "state_size",
        "window_size",
        "activation",
        "tf",
        "matmul",
        "cn",
        "W_hh",
        "w_h",
        "tf",
        "matmul",
        "tf",
        "expand_dims",
        "constrained_weights",
        "tf",
        "expand_dims",
        "s",
        "s",
        "constrained_weights",
        "tf",
        "zeros",
        "shape",
        "batch_size",
        "L",
        "state_size",
        "dtype",
        "tf",
        "float32",
        "tf",
        "zeros",
        "shape",
        "batch_size",
        "L",
        "tf",
        "constant",
        "window_size",
        "window_size",
        "name",
        "tf",
        "constant",
        "temperature",
        "dtype",
        "tf",
        "float32",
        "name",
        "i",
        "sketches_num",
        "sketch_step",
        "prepare_tensor",
        "hidden_states",
        "sketch",
        "padding_hs_col",
        "cum_att",
        "temperature",
        "sketch",
        "sketch_",
        "cum_att",
        "cum_att_",
        "sketches",
        "append",
        "sketch_",
        "cum_attentions",
        "append",
        "cum_att_",
        "sketches",
        "cum_attentions",
        "tf",
        "placeholder",
        "dtype",
        "tf",
        "float32",
        "shape",
        "tf",
        "nn",
        "tanh",
        "np",
        "random",
        "randn",
        "batch_size",
        "L",
        "state_size",
        "attention_block",
        "hidden_states",
        "state_size",
        "window_size",
        "dim_hlayer",
        "batch_size",
        "activation",
        "L",
        "sketches_num",
        "discount_factor",
        "temperature",
        "tf",
        "Session",
        "sess",
        "sess",
        "run",
        "tf",
        "global_variables_initializer",
        "sess",
        "run",
        "sketch_list",
        "cum_attention",
        "feed_dict",
        "hidden_states",
        "input_tensor",
        "cum_att",
        "sketchs",
        "shape",
        "len",
        "sketchs"
    ],
    "literals": [
        "'loop_matrices'",
        "\"W_hsz\"",
        "\"w_z\"",
        "\"v\"",
        "\"W_hh\"",
        "\"w_h\"",
        "\"CONSTANT\"",
        "\"HS_padded\"",
        "\"padding_hs_col\"",
        "'attention_temperature'"
    ],
    "variables": [
        "W_hsz",
        "w_z",
        "v",
        "W_hh",
        "w_h",
        "time_major_matrix",
        "contexts",
        "context_j",
        "context_j",
        "contexts",
        "batch_major_contexts",
        "hs",
        "hs",
        "hs",
        "z",
        "a",
        "u",
        "t_mask",
        "f_mask",
        "A",
        "U",
        "csoftmax",
        "before_att",
        "att",
        "tensor",
        "attentions",
        "attentions",
        "constrained_weights",
        "tensor",
        "cn",
        "cn",
        "s",
        "s",
        "sketch",
        "cum_att",
        "padding_hs_col",
        "temperature",
        "sketches",
        "cum_attentions",
        "sketch_",
        "cum_att_",
        "hidden_states",
        "state_size",
        "dim_hlayer",
        "window_size",
        "batch_size",
        "activation",
        "L",
        "sketches_num",
        "discount_factor",
        "temperature",
        "input_tensor",
        "sketch_list",
        "cum_attention",
        "sketchs",
        "cum_att"
    ],
    "comments": [
        "sess = tf.InteractiveSession()",
        "Attention block",
        "gather indices of padded",
        "time-major  -> L x 2*state_size x batch_size",
        "extract 2r+1 rows around i for each batch",
        "2*r+1 x 2*state_size x batch_size",
        "concatenate",
        "(2*r+1)*(state_size) x batch_size",
        "L x (2*r+1)* 2*(state_size) x batch_size",
        "switch back: batch_size x L x (2*r+1)*2(state_size) (batch-major)",
        "add column on right and left, and add context window",
        "[batch_size, L, 2*state*(2*window_size + 1)]",
        "input_tensor = tf.reduce_mean(input_tensor)",
        "a = tf.exp(input_tensor/temp) * b / z",
        "[batch_size, 1]",
        "[batch_size, 1, L]",
        "[batch_size, L]",
        "[batch_size, L]",
        "[batch_size,",
        "2*state_size*(2*window_size + 1)]",
        "[batch_size,",
        "2*state_size*(2*window_size + 1)]",
        "[batch_size, state_size]",
        "[batch_size, L,",
        "state_size]",
        "sketch tenzor",
        "cumulative attention",
        "print(cum_att_.eval(session=sess))",
        "list of tensors with shape [batch_size, L, state_size]",
        "list of tensors with shape [batch_size, L]",
        "print(input_tensor)"
    ],
    "docstrings": [
        "\"\"\"\n        Extract r context columns around each column and concatenate\n        :param padded_matrix: batch_size x L+(2*r) x 2*state_size\n        :param r: context size\n        :return:\n        \"\"\"",
        "\"\"\"\n            Compute the constrained softmax (csoftmax);\n            See paper \"Learning What's Easy: Fully Differentiable Neural Easy-First Taggers\"\n            on https://andre-martins.github.io/docs/emnlp2017_final.pdf (page 4)\n\n            :param input_tensor: input tensor\n            :param b: cumulative attention see paper\n            :param temp: softmax temperature\n            :return: distribution\n            \"\"\""
    ],
    "functions": [
        "attention_block",
        "conv_r",
        "prepare_tensor",
        "sketch_step",
        "constrained_softmax",
        "attention"
    ],
    "classes": []
}