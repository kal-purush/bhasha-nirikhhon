{
    "identifiers": [
        "openai",
        "os",
        "tqdm",
        "tqdm",
        "networkx",
        "nx",
        "numpy",
        "np",
        "argparse",
        "time",
        "datetime",
        "datetime",
        "timedelta",
        "timezone",
        "tenacity",
        "retry",
        "stop_after_attempt",
        "wait_random_exponential",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "parse_args",
        "args",
        "prompt",
        "m",
        "q",
        "array",
        "args",
        "array",
        "m",
        "array",
        "m",
        "args",
        "prompt",
        "open",
        "args",
        "prompt",
        "f",
        "f",
        "read",
        "Q",
        "exemplar",
        "Q",
        "i",
        "m",
        "Q",
        "edge",
        "i",
        "edge",
        "i",
        "Q",
        "args",
        "prompt",
        "Q",
        "Q",
        "i",
        "q",
        "Q",
        "question",
        "i",
        "question",
        "i",
        "args",
        "prompt",
        "Q_i",
        "Q_i",
        "Q_i",
        "Q_list",
        "append",
        "Q_i",
        "Q_list",
        "retry",
        "wait",
        "wait_random_exponential",
        "min",
        "max",
        "stop",
        "stop_after_attempt",
        "Q",
        "args",
        "Q",
        "args",
        "T",
        "args",
        "SC",
        "args",
        "model",
        "text",
        "input",
        "openai",
        "ChatCompletion",
        "create",
        "model",
        "args",
        "model",
        "messages",
        "text",
        "temperature",
        "temperature",
        "max_tokens",
        "args",
        "token",
        "Answer_list",
        "append",
        "response",
        "Answer_list",
        "openai",
        "Completion",
        "create",
        "model",
        "args",
        "model",
        "prompt",
        "input",
        "temperature",
        "temperature",
        "max_tokens",
        "args",
        "token",
        "i",
        "len",
        "input",
        "Answer_list",
        "append",
        "response",
        "i",
        "Answer_list",
        "Q_list",
        "res",
        "answer",
        "args",
        "datetime",
        "utcnow",
        "replace",
        "tzinfo",
        "timezone",
        "utc",
        "utc_dt",
        "astimezone",
        "timezone",
        "timedelta",
        "hours",
        "bj_dt",
        "now",
        "strftime",
        "args",
        "model",
        "args",
        "mode",
        "time",
        "args",
        "prompt",
        "args",
        "SC",
        "newpath",
        "os",
        "path",
        "exists",
        "newpath",
        "os",
        "makedirs",
        "newpath",
        "newpath",
        "np",
        "save",
        "newpath",
        "res",
        "np",
        "save",
        "newpath",
        "answer",
        "open",
        "newpath",
        "f",
        "f",
        "write",
        "Q_list",
        "f",
        "write",
        "f",
        "write",
        "res",
        "sum",
        "len",
        "res",
        "args",
        "file",
        "f",
        "os",
        "environ",
        "os",
        "environ",
        "os",
        "environ",
        "os",
        "environ",
        "args",
        "mode",
        "i",
        "tqdm",
        "g_num",
        "open",
        "args",
        "mode",
        "i",
        "f",
        "x",
        "x",
        "next",
        "f",
        "split",
        "line",
        "f",
        "array",
        "append",
        "x",
        "x",
        "line",
        "split",
        "array",
        "m",
        "translate",
        "m",
        "q",
        "array",
        "args",
        "args",
        "SC",
        "args",
        "SC_num",
        "k",
        "sc",
        "predict",
        "Q_list",
        "args",
        "sc_list",
        "append",
        "answer_list",
        "j",
        "q",
        "k",
        "sc",
        "sc_list",
        "k",
        "j",
        "lower",
        "answer",
        "append",
        "ans",
        "ans",
        "qt",
        "j",
        "qt",
        "j",
        "ans",
        "vote",
        "vote",
        "sc",
        "res",
        "append",
        "res",
        "append",
        "j",
        "q",
        "k",
        "sc",
        "sc_list",
        "k",
        "j",
        "q",
        "lower",
        "answer",
        "append",
        "ans",
        "ans",
        "qt",
        "q",
        "j",
        "qt",
        "q",
        "j",
        "ans",
        "vote",
        "vote",
        "sc",
        "res",
        "append",
        "res",
        "append",
        "np",
        "array",
        "res",
        "np",
        "array",
        "answer",
        "res",
        "sum",
        "log",
        "Q_list",
        "res",
        "answer",
        "args",
        "main"
    ],
    "literals": [
        "\"text-davinci-003\"",
        "\"code-davinci-002\"",
        "\"gpt-3.5-turbo\"",
        "\"gpt-4\"",
        "\"connectivity\"",
        "'--model'",
        "\"text-davinci-003\"",
        "'name of LM (default: text-davinci-003)'",
        "'--mode'",
        "\"easy\"",
        "'mode (default: easy)'",
        "'--prompt'",
        "\"none\"",
        "'prompting techniques (default: none)'",
        "'--T'",
        "'temprature (default: 0)'",
        "'--token'",
        "'max token (default: 256)'",
        "'--SC'",
        "'self-consistency (default: 0)'",
        "'--SC_num'",
        "'number of cases for SC (default: 5)'",
        "\"CoT\"",
        "\"none\"",
        "\"0-CoT\"",
        "\"LTM\"",
        "\"PROGRAM\"",
        "\"k-shot\"",
        "\"Algorithm\"",
        "\"Instruct\"",
        "''",
        "\"CoT\"",
        "\"k-shot\"",
        "\"Algorithm\"",
        "\"Instruct\"",
        "\"NLGraph/connectivity/prompt/\"",
        "\"-prompt.txt\"",
        "\"r\"",
        "\"\\n\\n\\n\"",
        "\"Determine if there is a path between two nodes in the graph. Note that (i,j) means that node i and node j are connected with an undirected edge.\\nGraph:\"",
        "' ('",
        "','",
        "')'",
        "\"\\n\"",
        "\"Instruct\"",
        "\"Let's construct a graph with the nodes and edges first.\\n\"",
        "\"Q: Is there a path between \"",
        "\"node \"",
        "\" and node \"",
        "\"?\\nA:\"",
        "\"0-CoT\"",
        "\" Let's think step by step:\"",
        "\"LTM\"",
        "\" Let's break down this problem:\"",
        "\"PROGRAM\"",
        "\" Let's solve the problem by a Python program:\"",
        "'gpt'",
        "\"role\"",
        "\"system\"",
        "\"content\"",
        "\"You are a helpful assistant.\"",
        "\"role\"",
        "\"user\"",
        "\"content\"",
        "\"choices\"",
        "\"message\"",
        "\"content\"",
        "\"choices\"",
        "\"text\"",
        "\"%Y%m%d---%H-%M\"",
        "'log/connectivity/'",
        "'-'",
        "'-'",
        "'-'",
        "\"+SC\"",
        "\"/\"",
        "\"res.npy\"",
        "\"answer.npy\"",
        "\"prompt.txt\"",
        "\"w\"",
        "\"\\n\"",
        "\"Acc: \"",
        "'/'",
        "'\\n'",
        "'OPENAI_API_KEY'",
        "'OPENAI_KEY'",
        "\"Missing openai key!\"",
        "'OPENAI_ORGANIZATION'",
        "'OPENAI_ORGANIZATION'",
        "\"easy\"",
        "\"medium\"",
        "\"hard\"",
        "\"NLgraph/connectivity/graph/\"",
        "\"/standard/graph\"",
        "\".txt\"",
        "\"r\"",
        "\"the answer is yes\"",
        "\"there is a path between node \"",
        "\" and node \"",
        "\"the answer is yes\"",
        "\"there is a path between node \"",
        "\" and node \"",
        "\"__main__\""
    ],
    "variables": [
        "model_list",
        "parser",
        "args",
        "edge",
        "question",
        "Q",
        "exemplar",
        "Q",
        "Q",
        "Q",
        "Q",
        "Q",
        "Q",
        "Q_list",
        "Q_i",
        "Q_i",
        "Q_i",
        "Q_i",
        "input",
        "temperature",
        "temperature",
        "Answer_list",
        "response",
        "response",
        "Answer_list",
        "utc_dt",
        "bj_dt",
        "time",
        "newpath",
        "newpath",
        "newpath",
        "openai",
        "api_key",
        "openai",
        "organization",
        "res",
        "answer",
        "g_num",
        "g_num",
        "g_num",
        "n",
        "m",
        "q",
        "array",
        "qt",
        "Q_list",
        "sc",
        "sc",
        "sc_list",
        "answer_list",
        "vote",
        "ans",
        "vote",
        "ans",
        "res",
        "answer"
    ],
    "comments": [
        "for exponential backoff",
        "read rest of lines",
        "ans = os.linesep.join([s for s in ans.splitlines() if s]).replace(' ', '')",
        "ans = os.linesep.join([s for s in ans.splitlines() if s]).replace(' ', '')"
    ],
    "docstrings": [],
    "functions": [
        "translate",
        "predict",
        "log",
        "main"
    ],
    "classes": []
}