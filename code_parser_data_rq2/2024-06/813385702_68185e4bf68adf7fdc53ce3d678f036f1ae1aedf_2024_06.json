{
    "identifiers": [
        "instructlab",
        "eval",
        "mt_bench_answers",
        "mt_bench_branch_generator",
        "mt_bench_judgment",
        "evaluator",
        "Evaluator",
        "Evaluator",
        "model_name",
        "judge_model_name",
        "output_dir",
        "max_workers",
        "model_name",
        "judge_model_name",
        "output_dir",
        "max_workers",
        "server_url",
        "mt_bench_answers",
        "generate_answers",
        "model_name",
        "model_api_base",
        "server_url",
        "output_dir",
        "output_dir",
        "max_workers",
        "max_workers",
        "server_url",
        "mt_bench_judgment",
        "generate_judgment",
        "model_name",
        "judge_model_name",
        "max_workers",
        "max_workers",
        "model_api_base",
        "server_url",
        "output_dir",
        "output_dir",
        "Evaluator",
        "model_name",
        "judge_model_name",
        "taxonomy_git_repo_path",
        "branch",
        "output_dir",
        "max_workers",
        "model_name",
        "judge_model_name",
        "taxonomy_git_repo_path",
        "branch",
        "output_dir",
        "max_workers",
        "server_url",
        "mt_bench_branch_generator",
        "generate",
        "judge_model_name",
        "branch",
        "taxonomy_git_repo_path",
        "output_dir",
        "mt_bench_answers",
        "generate_answers",
        "model_name",
        "branch",
        "branch",
        "model_api_base",
        "server_url",
        "output_dir",
        "output_dir",
        "data_dir",
        "output_dir",
        "max_workers",
        "max_workers",
        "bench_name",
        "server_url",
        "mt_bench_judgment",
        "generate_judgment",
        "model_name",
        "judge_model_name",
        "branch",
        "branch",
        "max_workers",
        "max_workers",
        "model_api_base",
        "server_url",
        "output_dir",
        "output_dir",
        "data_dir",
        "output_dir",
        "bench_name",
        "qa_pairs"
    ],
    "literals": [
        "\"eval_output\"",
        "\"eval_output\"",
        "\"mt_bench_branch\"",
        "\"mt_bench_branch\""
    ],
    "variables": [
        "model_name",
        "judge_model_name",
        "output_dir",
        "max_workers",
        "model_name",
        "judge_model_name",
        "taxonomy_git_repo_path",
        "branch",
        "output_dir",
        "max_workers",
        "_",
        "qa_pairs",
        "_"
    ],
    "comments": [
        "SPDX-License-Identifier: Apache-2.0",
        "First Party",
        "Local"
    ],
    "docstrings": [
        "\"\"\"\n    Child class of an Evaluator for Multi-turn Benchmark (MT-Bench)\n\n    Attributes\n        model_name          Name of the model to evaluate\n        judge_model_name    Name of the judge model\n        output_dir          The directory to use for evaluation output\n        max_workers         Max parallel workers to run the evaluation with\n    \"\"\"",
        "\"\"\"\n        Asks questions to model\n\n        Attributes\n            server_url      Model server endpoint (Ex: http://localhost:8000/v1) for the model being evaluated\n        \"\"\"",
        "\"\"\"\n        Runs MT-Bench judgment\n\n        Attributes\n            server_url      Model server endpoint (Ex: http://localhost:8000/v1) for the judge model\n\n        Returns:\n            overall_score   MT-Bench score for the overall model evaluation\n            qa_pairs        Question and answer pairs (with scores) from the evaluation\n            turn_scores     A list of indexed turn scores\n        \"\"\"",
        "\"\"\"\n    Child class of an Evaluator for MT-Bench-Branch Benchmark\n\n    Attributes\n        model_name              Name of the model to evaluate\n        judge_model_name        Name of the judge model\n        taxonomy_git_repo_path  Taxonomy git repo path\n        branch                  Branch of taxonomy repo to eval QNAs against model\n        output_dir              The directory to use for evaluation output\n        max_workers             Max parallel workers to run the evaluation with\n    \"\"\"",
        "\"\"\"\n        Asks questions to model\n\n        Attributes\n            server_url  Model server endpoint (Ex: http://localhost:8000/v1) for the model being evaluated\n        \"\"\"",
        "\"\"\"\n        Runs MT-Bench-Branch judgment.  Judgments can be compared across runs with consistent question_id -> qna file name.\n\n        Attributes\n            server_url      Model server endpoint (Ex: http://localhost:8000/v1) for the judge model\n\n        Returns:\n            qa_pairs        Question and answer pairs (with scores) from the evaluation\n        \"\"\""
    ],
    "functions": [
        "gen_answers",
        "judge_answers",
        "gen_answers",
        "judge_answers"
    ],
    "classes": [
        "MTBenchEvaluator",
        "MTBenchBranchEvaluator"
    ]
}