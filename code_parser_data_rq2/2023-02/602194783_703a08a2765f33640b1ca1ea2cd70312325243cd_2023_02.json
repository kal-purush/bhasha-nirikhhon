{
    "identifiers": [
        "spacy",
        "re",
        "sys",
        "csv",
        "spacy",
        "language",
        "Language",
        "x",
        "lower",
        "x",
        "EXCLUDE",
        "label",
        "start",
        "end",
        "text",
        "len",
        "text",
        "len",
        "text",
        "lstrip",
        "label",
        "start",
        "soff",
        "text",
        "strip",
        "start_char",
        "len",
        "text",
        "ents",
        "text",
        "ents",
        "text",
        "ents",
        "e",
        "ents",
        "e",
        "label_",
        "e",
        "start_char",
        "e",
        "end_char",
        "e",
        "text",
        "text",
        "lower",
        "strip",
        "EXCLUDE",
        "len",
        "text",
        "re",
        "match",
        "text",
        "label",
        "re",
        "match",
        "PATTERN_DATA",
        "text",
        "re",
        "match",
        "PATTERN_DATA",
        "text",
        "group",
        "start",
        "len",
        "text",
        "new_list",
        "append",
        "FakeEntity",
        "label",
        "start",
        "end",
        "text",
        "new_list",
        "append",
        "FakeEntity",
        "label",
        "start",
        "end",
        "text",
        "new_list",
        "ents",
        "e",
        "ents",
        "e",
        "label_",
        "e",
        "start_char",
        "e",
        "end_char",
        "e",
        "text",
        "text",
        "startswith",
        "len",
        "text",
        "new_list",
        "append",
        "FakeEntity",
        "label",
        "start",
        "end",
        "text",
        "text",
        "startswith",
        "len",
        "text",
        "new_list",
        "append",
        "FakeEntity",
        "label",
        "start",
        "end",
        "text",
        "text",
        "startswith",
        "len",
        "text",
        "new_list",
        "append",
        "FakeEntity",
        "label",
        "start",
        "end",
        "text",
        "new_list",
        "append",
        "FakeEntity",
        "label",
        "start",
        "end",
        "text",
        "new_list",
        "ents",
        "text",
        "pattern",
        "label",
        "re",
        "compile",
        "pattern",
        "m",
        "p",
        "finditer",
        "text",
        "m",
        "span",
        "e",
        "ents",
        "start_pos",
        "e",
        "start_char",
        "start_pos",
        "e",
        "end_char",
        "end_pos",
        "e",
        "start_char",
        "end_pos",
        "e",
        "end_char",
        "go",
        "ents",
        "append",
        "FakeEntity",
        "label",
        "start_pos",
        "end_pos",
        "text",
        "start_pos",
        "end_pos",
        "ents",
        "p",
        "ents",
        "e",
        "ents",
        "p",
        "match",
        "e",
        "text",
        "new_list",
        "append",
        "e",
        "new_list",
        "Language",
        "component",
        "doc",
        "ent",
        "doc",
        "ents",
        "word",
        "ent",
        "text",
        "lower",
        "word",
        "excluded_words",
        "entities",
        "append",
        "ent",
        "entities",
        "doc",
        "Language",
        "component",
        "doc",
        "i",
        "token",
        "doc",
        "token",
        "text",
        "token",
        "text",
        "token",
        "text",
        "endswith",
        "doc",
        "i",
        "doc",
        "text",
        "spacy",
        "load",
        "spacy_model",
        "snlp",
        "add_pipe",
        "before",
        "snlp",
        "pipe_names",
        "snlp",
        "text",
        "ent",
        "excude_manual",
        "doc",
        "ents",
        "ents",
        "append",
        "ent",
        "open",
        "csvfd",
        "csv",
        "DictReader",
        "csvfd",
        "delimiter",
        "r",
        "reader",
        "add_ent_by_pattern",
        "ents",
        "text",
        "r",
        "r",
        "correct_ent",
        "ents",
        "open",
        "csvfd",
        "csv",
        "DictReader",
        "csvfd",
        "delimiter",
        "r",
        "reader",
        "re",
        "compile",
        "r",
        "remove_pattern",
        "p",
        "ents",
        "sorted",
        "ents",
        "key",
        "x",
        "x",
        "start_char",
        "FakeDoc",
        "ents",
        "doc",
        "text",
        "open",
        "f",
        "read",
        "nlp",
        "text",
        "ent",
        "doc",
        "ents",
        "ent",
        "text",
        "ent",
        "label_"
    ],
    "literals": [
        "\"./model-best\"",
        "\"[A-Z0-9]{2}-[A-Z0-9]{2}-[A-Z0-9]{2}\"",
        "r\"\\d+(-|\\.|_|\\s|\\/)\\d{1,2}(\\.)[A-Z0-9]+(-|\\.)[A-Z0-9]+(\\.)*[A-Z0-9]*\"",
        "r\"\\d{1,2}(-|\\.|/)\\d{1,2}(-|\\.|/)\\d{4}\"",
        "'Tribunal'",
        "'Réu'",
        "'Reu'",
        "'Ré'",
        "'Supremo Tribunal de Justiça'",
        "\"STJ\"",
        "\"Supremo Tribunal\"",
        "'Requerida'",
        "'Autora'",
        "'Instância'",
        "'Relação'",
        "'Supremo'",
        "'Recorrente'",
        "'Recorrida'",
        "'Tribunal da Relação'",
        "'artº'",
        "'Exª'",
        "'Exº'",
        "'nº'",
        "r\"^\\d+(º|ª)$\"",
        "'DAT'",
        "\"Ré \"",
        "\"Réu \"",
        "\"Autora \"",
        "\"remove_entities_with_excluded_words\"",
        "\"john richard\"",
        "\"frigocar\"",
        "\"OLAaaaaaaa\"",
        "\"new_line_segmenter\"",
        "\"\\n\"",
        "\"\\n\\n\"",
        "\".\"",
        "\"new_line_segmenter\"",
        "\"ner\"",
        "'../patterns.csv'",
        "'r'",
        "\"\\t\"",
        "'Pattern'",
        "'Label'",
        "'../exclude.csv'",
        "'r'",
        "\"\\t\"",
        "'Pattern'",
        "\"__main__\"",
        "\"teste.txt\"",
        "\"r\""
    ],
    "variables": [
        "spacy_model",
        "PATTERN_MATRICULA",
        "PATTERN_PROCESSO",
        "PATTERN_DATA",
        "EXCLUDE",
        "EXCLUDE",
        "soff",
        "label_",
        "start_char",
        "text",
        "end_char",
        "ents",
        "text",
        "new_list",
        "label",
        "start",
        "end",
        "text",
        "text",
        "end",
        "new_list",
        "label",
        "start",
        "end",
        "text",
        "p",
        "go",
        "start_pos",
        "end_pos",
        "go",
        "new_list",
        "excluded_words",
        "entities",
        "doc",
        "ents",
        "is_sent_start",
        "snlp",
        "doc",
        "ents",
        "reader",
        "ents",
        "reader",
        "p",
        "ents",
        "ents",
        "f",
        "text",
        "doc"
    ],
    "comments": [
        "print(token.text)",
        "Check if the current token is a newline character",
        "If it is, treat the next token as the start of a new sentence",
        "snlp.add_pipe(\"remove_entities_with_excluded_words\", last=True)",
        "def nlp_pipe(texts):",
        "snlp = spacy.load(spacy_model)",
        "for doc in snlp.pipe(texts):",
        "ents = []",
        "for ent in excude_manual(doc.ents):",
        "ents.append(ent)",
        "with open('patterns.csv', 'r') as csvfd:",
        "reader = csv.DictReader(csvfd, delimiter=\"\\t\")",
        "for r in reader:",
        "add_ent_by_pattern(ents, text, r['Pattern'], r['Label'])",
        "ents = correct_ent(ents)",
        "with open('exclude.csv', 'r') as csvfd:",
        "reader = csv.DictReader(csvfd, delimiter=\"\\t\")",
        "for r in reader:",
        "p = re.compile(r['Pattern'])",
        "ents = remove_pattern(p, ents)",
        "ents = sorted(ents,key=lambda x: x.start_char)",
        "yield FakeDoc(ents, doc.text)",
        "print(text)"
    ],
    "docstrings": [],
    "functions": [
        "excude_manual",
        "correct_ent",
        "add_ent_by_pattern",
        "remove_pattern",
        "remove_entities_with_excluded_words",
        "new_line_segmenter",
        "nlp"
    ],
    "classes": [
        "FakeEntity",
        "FakeDoc"
    ]
}