{
    "identifiers": [
        "torch",
        "torch",
        "nn",
        "torch",
        "Tensor",
        "typing",
        "Any",
        "Dict",
        "Optional",
        "Union",
        "cast",
        "constants",
        "CATEGORICAL",
        "LABEL",
        "LOGITS",
        "FEATURES",
        "ft_transformer",
        "_TokenInitialization",
        "CLSToken",
        "FT_Transformer",
        "nn",
        "Module",
        "num_categories",
        "d_token",
        "bias",
        "Optional",
        "initialization",
        "Optional",
        "num_categories",
        "torch",
        "tensor",
        "num_categories",
        "cumsum",
        "register_buffer",
        "category_offsets",
        "persistent",
        "nn",
        "Embedding",
        "sum",
        "num_categories",
        "d_token",
        "nn",
        "Parameter",
        "Tensor",
        "len",
        "num_categories",
        "d_token",
        "bias",
        "_TokenInitialization",
        "from_str",
        "initialization",
        "parameter",
        "embeddings",
        "weight",
        "bias",
        "parameter",
        "initialization_",
        "apply",
        "parameter",
        "d_token",
        "property",
        "len",
        "num_categories",
        "property",
        "embeddings",
        "embedding_dim",
        "x",
        "Tensor",
        "Tensor",
        "embeddings",
        "x",
        "category_offsets",
        "bias",
        "x",
        "bias",
        "x",
        "nn",
        "Module",
        "prefix",
        "num_categories",
        "d_token",
        "cls_token",
        "Optional",
        "out_features",
        "Optional",
        "num_classes",
        "Optional",
        "token_bias",
        "Optional",
        "token_initialization",
        "Optional",
        "n_blocks",
        "Optional",
        "attention_n_heads",
        "Optional",
        "attention_initialization",
        "Optional",
        "attention_normalization",
        "Optional",
        "attention_dropout",
        "Optional",
        "residual_dropout",
        "Optional",
        "ffn_activation",
        "Optional",
        "ffn_normalization",
        "Optional",
        "ffn_d_hidden",
        "Optional",
        "ffn_dropout",
        "Optional",
        "prenormalization",
        "Optional",
        "first_prenormalization",
        "Optional",
        "kv_compression_ratio",
        "Optional",
        "kv_compression_sharing",
        "Optional",
        "head_activation",
        "Optional",
        "head_normalization",
        "Optional",
        "num_categories",
        "d_token",
        "n_blocks",
        "attention_n_heads",
        "token_initialization",
        "num_categories",
        "prefix",
        "out_features",
        "CategoricalFeatureTokenizer",
        "num_categories",
        "num_categories",
        "d_token",
        "d_token",
        "bias",
        "token_bias",
        "initialization",
        "token_initialization",
        "CLSToken",
        "d_token",
        "d_token",
        "initialization",
        "token_initialization",
        "cls_token",
        "kv_compression_ratio",
        "categorical_feature_tokenizer",
        "n_tokens",
        "FT_Transformer",
        "d_token",
        "d_token",
        "n_blocks",
        "n_blocks",
        "attention_n_heads",
        "attention_n_heads",
        "attention_dropout",
        "attention_dropout",
        "attention_initialization",
        "attention_initialization",
        "attention_normalization",
        "attention_normalization",
        "ffn_d_hidden",
        "ffn_d_hidden",
        "ffn_dropout",
        "ffn_dropout",
        "ffn_activation",
        "ffn_activation",
        "ffn_normalization",
        "ffn_normalization",
        "residual_dropout",
        "residual_dropout",
        "prenormalization",
        "prenormalization",
        "first_prenormalization",
        "first_prenormalization",
        "last_layer_query_idx",
        "n_tokens",
        "n_tokens",
        "kv_compression_ratio",
        "kv_compression_ratio",
        "kv_compression_sharing",
        "kv_compression_sharing",
        "head_activation",
        "head_activation",
        "head_normalization",
        "head_normalization",
        "d_out",
        "out_features",
        "FT_Transformer",
        "Head",
        "d_in",
        "d_token",
        "d_out",
        "num_classes",
        "bias",
        "activation",
        "head_activation",
        "normalization",
        "head_normalization",
        "prenormalization",
        "get_layer_ids",
        "property",
        "prefix",
        "CATEGORICAL",
        "property",
        "prefix",
        "LABEL",
        "batch",
        "categorical_feature",
        "batch",
        "categorical_key",
        "categorical_features",
        "append",
        "categorical_feature",
        "torch",
        "stack",
        "categorical_features",
        "dim",
        "categorical_feature_tokenizer",
        "categorical_features",
        "cls_token",
        "cls_token",
        "features",
        "transformer",
        "features",
        "head",
        "features",
        "prefix",
        "LOGITS",
        "logits",
        "FEATURES",
        "features",
        "n",
        "_",
        "named_parameters",
        "name_to_id"
    ],
    "literals": [
        "'normal'",
        "'category_offsets'",
        "'normal'",
        "'kaiming'",
        "'layer_norm'",
        "'reglu'",
        "'layer_norm'",
        "'relu'",
        "'layer_norm'",
        "'num_categories must be non-empty'",
        "'d_token must be positive'",
        "'n_blocks must be non-negative'",
        "'attention_n_heads must be postive'",
        "'uniform'",
        "'normal'",
        "'initialization must be uniform or normal'",
        "'Identity'",
        "f\"{self.prefix}_{CATEGORICAL}\"",
        "f\"{self.prefix}_{LABEL}\""
    ],
    "variables": [
        "num_categories",
        "category_offsets",
        "embeddings",
        "bias",
        "initialization_",
        "x",
        "x",
        "num_categories",
        "prefix",
        "out_features",
        "categorical_feature_tokenizer",
        "cls_token",
        "n_tokens",
        "n_tokens",
        "transformer",
        "head",
        "name_to_id",
        "categorical_features",
        "categorical_features",
        "features",
        "features",
        "features",
        "logits",
        "name_to_id",
        "name_to_id",
        "n"
    ],
    "comments": [],
    "docstrings": [
        "\"\"\"\n    Feature tokenizer for categorical features in tabular data. \n    It transforms the input categorical features to tokens (embeddings).\n\n    The categorical features usually refers to discrete features.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        num_categories: \n            A list of integers. Each one is the number of categories in one categorical column.\n        d_token: \n            The size of one token.\n        bias: \n            If `True`, for each feature, an additional trainable vector will be added to the\n            embedding regardless of feature value. Notablly, the bias are not shared between features.\n        initialization: \n            Initialization policy for parameters. Must be one of `['uniform', 'normal']`. \n\n        References\n        ----------\n        Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, Artem Babenko, \n        \"Revisiting Deep Learning Models for Tabular Data\", 2021\n        https://arxiv.org/pdf/2106.11959.pdf\n        \"\"\"",
        "\"\"\"The number of tokens.\"\"\"",
        "\"\"\"The size of one token.\"\"\"",
        "\"\"\"\n    FT-Transformer for categorical tabular features. \n    The input dimension is automatically computed based on\n    the number of categories in each categorical column.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        prefix\n            The model prefix.\n        num_categories\n            A list of integers. Each one is the number of categories in one categorical column.\n        d_token\n            The size of one token for `_CategoricalFeatureTokenizer`.\n        cls_token\n            If `True`, cls token will be added to the token embeddings.\n        out_features\n            Dimension of output features.\n        num_classes\n            Number of classes. 1 for a regression task.\n        token_bias\n            If `True`, for each feature, an additional trainable vector will be added in `_CategoricalFeatureTokenizer` \n            to the embedding regardless of feature value. Notablly, the bias are not shared between features.\n        token_initialization\n            Initialization policy for parameters in `_CategoricalFeatureTokenizer` and `_CLSToke`. \n            Must be one of `['uniform', 'normal']`. \n        n_blocks\n            Number of the `FT_Transformer` blocks, which should be non-negative.\n        attention_n_heads\n            Number of attention heads in each `FT_Transformer` block, which should be postive.\n        attention_initialization\n            Weights initalization scheme for Multi Headed Attention module.\n        attention_dropout\n            Dropout ratio for the Multi Headed Attention module.\n        residual_dropout\n            Dropout ratio for the linear layers in FT_Transformer block.\n        ffn_activation\n            Activation function type for the Feed-Forward Network module.\n        ffn_normalization\n            Normalization scheme of the Feed-Forward Network module.\n        ffn_d_hidden\n            Number of the hidden nodes of the linaer layers in the Feed-Forward Network module.\n        ffn_dropout\n            Dropout ratio of the hidden nodes of the linaer layers in the Feed-Forward Network module.\n        prenormalization, first_prenormalization\n            Prenormalization to stablize the training.\n        kv_compression_ratio\n            The compression ration to reduce the input sequence length.\n        kv_compression_sharing\n            If `true` the projections will share weights.\n        head_activation\n            Activation function type of the MLP layer.\n        head_normalization\n            Normalization scheme of the MLP layer.\n\n        References\n        ----------\n        Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, Artem Babenko, \n        \"Revisiting Deep Learning Models for Tabular Data\", 2021\n        https://arxiv.org/pdf/2106.11959.pdf\n        \"\"\"",
        "\"\"\"\n\n        Parameters\n        ----------\n        batch\n            A dictionary containing the input mini-batch data.\n            We need to use the keys with the model prefix to index required data.\n\n        Returns\n        -------\n            A dictionary with logits and features.\n        \"\"\"",
        "\"\"\"\n        All layers have the same id 0 since there is no pre-trained models used here.\n\n        Returns\n        -------\n        A dictionary mapping the layer names (keys) to their ids (values).\n        \"\"\""
    ],
    "functions": [
        "n_tokens",
        "d_token",
        "forward",
        "categorical_key",
        "label_key",
        "forward",
        "get_layer_ids"
    ],
    "classes": [
        "CategoricalFeatureTokenizer",
        "CategoricalTransformer"
    ]
}