{
    "identifiers": [
        "torch",
        "torch",
        "nn",
        "nn",
        "torch",
        "nn",
        "functional",
        "F",
        "nn",
        "KLDivLoss",
        "reduction",
        "torch",
        "tensor",
        "F",
        "log_softmax",
        "x",
        "dim",
        "torch",
        "tensor",
        "F",
        "kl_div",
        "x",
        "y",
        "reduction",
        "criterion",
        "x",
        "y",
        "nn",
        "Module",
        "size",
        "padding_idx",
        "smoothing",
        "LabelSmoothing",
        "nn",
        "KLDivLoss",
        "reduction",
        "padding_idx",
        "smoothing",
        "smoothing",
        "size",
        "x",
        "target",
        "x",
        "size",
        "size",
        "x",
        "data",
        "clone",
        "true_dist",
        "fill_",
        "smoothing",
        "size",
        "true_dist",
        "scatter_",
        "target",
        "data",
        "unsqueeze",
        "confidence",
        "true_dist",
        "criterion",
        "x",
        "true_dist",
        "requires_grad_",
        "nn",
        "Module",
        "label_smoothing",
        "tgt_vocab_size",
        "ignore_index",
        "label_smoothing",
        "ignore_index",
        "LabelSmoothingLoss",
        "label_smoothing",
        "tgt_vocab_size",
        "torch",
        "full",
        "tgt_vocab_size",
        "smoothing_value",
        "register_buffer",
        "one_hot",
        "unsqueeze",
        "label_smoothing",
        "output",
        "target",
        "one_hot",
        "repeat",
        "target",
        "size",
        "model_prob",
        "scatter_",
        "target",
        "unsqueeze",
        "confidence",
        "to",
        "F",
        "kl_div",
        "output",
        "model_prob",
        "reduction"
    ],
    "literals": [
        "'batchmean'",
        "'mean'",
        "\"Implement label smoothing.\"",
        "'batchmean'",
        "'one_hot'",
        "'sum'"
    ],
    "variables": [
        "criterion",
        "x",
        "x",
        "y",
        "criterion",
        "padding_idx",
        "confidence",
        "smoothing",
        "size",
        "true_dist",
        "true_dist",
        "true_dist",
        "ignore_index",
        "smoothing_value",
        "one_hot",
        "confidence",
        "model_prob"
    ],
    "comments": [
        "true_dist[:, self.padding_idx] = 0",
        "mask = torch.nonzero(target.data == self.padding_idx)",
        "if mask.dim() > 0:",
        "true_dist.index_fill_(0, mask.squeeze(), 0.0)",
        "one_hot[self.ignore_index] = 0",
        "model_prob.masked_fill_((target == self.ignore_index).unsqueeze(1), 0)",
        "if __name__ == \"__main__\":",
        "crit = LabelSmoothing(size=5, padding_idx=0, smoothing=0.1)",
        "crit1 = LabelSmoothingLoss(0.1, 5, None)",
        "# predict.shape 3 5",
        "predict = torch.FloatTensor([[0, 0.7, 0.1, 0, 0.1],",
        "[0, 0.9, 0.2, 0.1, 0],",
        "[1, 0.2, 0.7, 0.1, 0]])",
        "# v = crit(Variable(predict.log()), torch.tensor([1, 1, 0]))",
        "# preprecess = torch.nn.LogSoftmax(dim=1)",
        "v = crit(F.log_softmax(predict, dim=1), torch.tensor([1, 1, 0]))",
        "v1 = crit1(F.log_softmax(predict), torch.tensor([1, 1, 0]))",
        "print(v)",
        "print(v1)"
    ],
    "docstrings": [
        "\"\"\"\n    With label smoothing,\n    KL-divergence between q_{smoothed ground truth prob.}(w)\n    and p_{prob. computed by model}(w) is minimized.\n    \"\"\"",
        "\"\"\"\n        output (FloatTensor): batch_size x n_classes\n        target (LongTensor): batch_size\n        \"\"\""
    ],
    "functions": [
        "forward",
        "forward"
    ],
    "classes": [
        "LabelSmoothing",
        "LabelSmoothingLoss"
    ]
}