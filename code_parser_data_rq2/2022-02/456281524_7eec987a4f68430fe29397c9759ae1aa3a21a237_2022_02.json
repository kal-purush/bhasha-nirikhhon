{
    "identifiers": [
        "numpy",
        "np",
        "pandas",
        "pd",
        "matplotlib",
        "pyplot",
        "plt",
        "matplotlib",
        "figure",
        "fig",
        "seaborn",
        "sns",
        "sns",
        "style",
        "nltk",
        "nltk",
        "download",
        "nltk",
        "tokenize",
        "sent_tokenize",
        "word_tokenize",
        "nltk",
        "corpus",
        "stopwords",
        "nltk",
        "download",
        "sklearn",
        "model_selection",
        "train_test_split",
        "sklearn",
        "tree",
        "DecisionTreeClassifier",
        "sklearn",
        "svm",
        "SVC",
        "sklearn",
        "metrics",
        "classification_report",
        "dataset_path",
        "debug",
        "dataset_path",
        "debug",
        "word",
        "word",
        "vowels",
        "syllable_count",
        "index",
        "len",
        "word",
        "word",
        "index",
        "vowels",
        "word",
        "index",
        "vowels",
        "syllable_count",
        "word",
        "endswith",
        "syllable_count",
        "word",
        "endswith",
        "len",
        "word",
        "word",
        "vowels",
        "syllable_count",
        "syllable_count",
        "syllable_count",
        "syllable_count",
        "X",
        "y",
        "test_size",
        "validate_size",
        "random_state",
        "train_test_split",
        "X",
        "y",
        "stratify",
        "y",
        "test_size",
        "test_size",
        "random_state",
        "random_state",
        "validate_size",
        "test_size",
        "train_test_split",
        "X_train",
        "y_train",
        "stratify",
        "y_train",
        "test_size",
        "new_validate_size",
        "random_state",
        "random_state",
        "X_train",
        "X_test",
        "X_val",
        "y_train",
        "y_test",
        "y_val",
        "pd",
        "read_csv",
        "np",
        "array",
        "df",
        "level",
        "np",
        "array",
        "df",
        "drop",
        "columns",
        "stratified_split",
        "X",
        "y",
        "random_state",
        "debug",
        "X_train",
        "shape",
        "y_train",
        "shape",
        "X_val",
        "shape",
        "y_val",
        "shape",
        "X_test",
        "shape",
        "y_test",
        "shape",
        "DecisionTreeClassifier",
        "dt",
        "fit",
        "X_train",
        "y_train",
        "debug",
        "format",
        "dt",
        "score",
        "X_train",
        "y_train",
        "format",
        "dt",
        "score",
        "X_val",
        "y_val",
        "format",
        "dt",
        "score",
        "X_test",
        "y_test",
        "df",
        "drop",
        "columns",
        "columns",
        "pd",
        "DataFrame",
        "data",
        "feature_names",
        "dt",
        "feature_importances_",
        "columns",
        "fdf",
        "head",
        "sns",
        "barplot",
        "y",
        "x",
        "data",
        "fdf",
        "color",
        "saturation",
        "plt",
        "show",
        "dt",
        "predict",
        "X_val",
        "classification_report",
        "y_val",
        "DT_predictionsValidate",
        "dt",
        "dt",
        "input_sentence",
        "input_sentence",
        "user",
        "translate",
        "maketrans",
        "punctuation",
        "sent_tokenize",
        "user_string",
        "word_tokenize",
        "user_string",
        "word",
        "word",
        "user_words",
        "word",
        "stopwords",
        "words",
        "len",
        "user_list",
        "word",
        "user_list",
        "user_char_count",
        "len",
        "word",
        "word",
        "user_list",
        "user_sly_count",
        "_syllables",
        "word",
        "user_word_count",
        "user_char_count",
        "user_sly_count",
        "pd",
        "DataFrame",
        "user_data",
        "columns",
        "model",
        "predict",
        "X",
        "MyPrediction"
    ],
    "literals": [
        "\"darkgrid\"",
        "'punkt'",
        "\"stopwords\"",
        "'aeiouy'",
        "'e'",
        "'le'",
        "\"data_to_train.csv\"",
        "'level'",
        "\"Training (X_train and y_train): \\t\"",
        "\" \\t\"",
        "\"Validation (X_val and y_val): \\t\\t\"",
        "\" \\t\"",
        "\"Testing (X_test and y_test): \\t\\t\"",
        "\"  \\t\"",
        "\"Decision Tree Performance:\"",
        "\"\\tTRAIN Accuracy: {:.2f}\"",
        "\"\\tVALIDATION Accuracy: {:.2f}\"",
        "\"\\tTEST Accuracy: {:.2f}\"",
        "'level'",
        "\"Feature Names\"",
        "\"Feature Importances\"",
        "\"Feature Names\"",
        "\"Feature Importances\"",
        "\"salmon\"",
        "''",
        "''",
        "'word_count'",
        "'char_count'",
        "'sly_count'"
    ],
    "variables": [
        "path",
        "debug",
        "model",
        "syllable_count",
        "vowels",
        "X_train",
        "X_test",
        "y_train",
        "y_test",
        "new_validate_size",
        "X_train",
        "X_val",
        "y_train",
        "y_val",
        "df",
        "y",
        "X",
        "X_train",
        "X_test",
        "X_val",
        "y_train",
        "y_test",
        "y_val",
        "dt",
        "feature_names",
        "fdf",
        "DT_predictionsValidate",
        "model",
        "user",
        "user_string",
        "user_words",
        "user_list",
        "user_word_count",
        "user_char_count",
        "user_char_count",
        "user_sly_count",
        "user_sly_count",
        "user_data",
        "X",
        "MyPrediction"
    ],
    "comments": [
        "foundational modules",
        "visualization",
        "NLP",
        "data preparation for model learning",
        "classification metrics",
        "instance vars",
        "need to calculate new split size.",
        "let's assume we had 100 samples and we don't do this",
        "then the split will be 20 + (20% of 80) + (80% of 80).",
        "But we want 20 + 20 + 60",
        "### Step-2: Split Data into Train, Validation, and Test Data Sets",
        "Split data into training, validation, and testing data sets",
        "Set-up and Build Decision Tree classifier model",
        "Decision Tree model performance",
        "enter user vocab list here, calculate percentage of words understood"
    ],
    "docstrings": [],
    "functions": [
        "_syllables",
        "stratified_split",
        "train",
        "predict"
    ],
    "classes": [
        "Understandability"
    ]
}