{
    "identifiers": [
        "absolute_import",
        "division",
        "print_function",
        "argparse",
        "os",
        "sys",
        "itertools",
        "random",
        "numpy",
        "np",
        "tensorflow",
        "tf",
        "tf",
        "reset_default_graph",
        "argparse",
        "ArgumentParser",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "choices",
        "help",
        "np",
        "load",
        "test_images_file",
        "np",
        "reshape",
        "test_images",
        "test_images",
        "shape",
        "np",
        "load",
        "test_flows_file",
        "test_binaries",
        "shape",
        "np",
        "load",
        "train_images_file",
        "np",
        "reshape",
        "train_images",
        "train_images",
        "shape",
        "np",
        "load",
        "train_flows_file",
        "train_binaries",
        "shape",
        "test_images",
        "train_images",
        "is_training",
        "images_filename",
        "flows_filename",
        "batch_size",
        "num_epochs",
        "i",
        "itertools",
        "count",
        "i",
        "random",
        "randint",
        "random",
        "randint",
        "images_filename",
        "i",
        "np",
        "expand_dims",
        "image",
        "axis",
        "image",
        "a",
        "a",
        "b",
        "b",
        "flows_filename",
        "i",
        "np",
        "expand_dims",
        "labels",
        "axis",
        "labels",
        "a",
        "a",
        "b",
        "b",
        "image",
        "labels",
        "tf",
        "data",
        "Dataset",
        "from_generator",
        "gen",
        "tf",
        "float32",
        "tf",
        "float32",
        "tf",
        "TensorShape",
        "tf",
        "TensorShape",
        "dataset",
        "make_one_shot_iterator",
        "get_next",
        "images",
        "flows",
        "inputs",
        "mode",
        "data_format",
        "tf",
        "reshape",
        "inputs",
        "data_format",
        "tf",
        "test",
        "is_built_with_cuda",
        "data_format",
        "tf",
        "transpose",
        "inputs",
        "tf",
        "layers",
        "conv2d",
        "inputs",
        "inputs",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "maximum",
        "conv1",
        "tf",
        "scalar_mul",
        "tf",
        "constant",
        "conv1",
        "tf",
        "layers",
        "conv2d",
        "inputs",
        "conv1",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "maximum",
        "conv2",
        "tf",
        "scalar_mul",
        "tf",
        "constant",
        "conv2",
        "tf",
        "layers",
        "conv2d",
        "inputs",
        "conv2",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "maximum",
        "conv3",
        "tf",
        "scalar_mul",
        "tf",
        "constant",
        "conv3",
        "tf",
        "layers",
        "conv2d",
        "inputs",
        "conv3",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "transpose",
        "pred1",
        "tf",
        "image",
        "resize_images",
        "pred1",
        "method",
        "tf",
        "image",
        "ResizeMethod",
        "BILINEAR",
        "align_corners",
        "tf",
        "transpose",
        "upsample1",
        "tf",
        "layers",
        "conv2d_transpose",
        "inputs",
        "conv3",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "maximum",
        "upconv1",
        "tf",
        "scalar_mul",
        "tf",
        "constant",
        "upconv1",
        "tf",
        "concat",
        "upconv1",
        "conv2",
        "upsample1",
        "tf",
        "layers",
        "conv2d",
        "inputs",
        "concat1",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "transpose",
        "pred2",
        "tf",
        "image",
        "resize_images",
        "pred2",
        "method",
        "tf",
        "image",
        "ResizeMethod",
        "BILINEAR",
        "align_corners",
        "tf",
        "transpose",
        "upsample2",
        "tf",
        "layers",
        "conv2d_transpose",
        "inputs",
        "upconv1",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "maximum",
        "upconv2",
        "tf",
        "scalar_mul",
        "tf",
        "constant",
        "upconv2",
        "tf",
        "concat",
        "upconv2",
        "conv1",
        "upsample2",
        "tf",
        "layers",
        "conv2d",
        "inputs",
        "concat2",
        "filters",
        "kernel_size",
        "strides",
        "padding",
        "activation",
        "data_format",
        "data_format",
        "tf",
        "transpose",
        "pred3",
        "tf",
        "image",
        "resize_images",
        "pred3",
        "method",
        "tf",
        "image",
        "ResizeMethod",
        "BILINEAR",
        "align_corners",
        "upsample3",
        "features",
        "labels",
        "mode",
        "flow_model",
        "features",
        "mode",
        "upsample2",
        "mode",
        "tf",
        "estimator",
        "ModeKeys",
        "PREDICT",
        "tf",
        "estimator",
        "EstimatorSpec",
        "mode",
        "mode",
        "predictions",
        "predictions",
        "tf",
        "subtract",
        "labels",
        "upsample2",
        "tf",
        "nn",
        "l2_loss",
        "diff",
        "mode",
        "tf",
        "estimator",
        "ModeKeys",
        "TRAIN",
        "tf",
        "train",
        "AdamOptimizer",
        "learning_rate",
        "optimizer",
        "minimize",
        "loss",
        "tf",
        "train",
        "get_or_create_global_step",
        "tf",
        "metrics",
        "mean_absolute_error",
        "labels",
        "upsample2",
        "accuracy",
        "tf",
        "identity",
        "accuracy",
        "name",
        "tf",
        "summary",
        "scalar",
        "accuracy",
        "tf",
        "estimator",
        "EstimatorSpec",
        "mode",
        "mode",
        "predictions",
        "predictions",
        "loss",
        "loss",
        "train_op",
        "train_op",
        "eval_metric_ops",
        "metrics",
        "unused_argv",
        "tf",
        "estimator",
        "Estimator",
        "model_fn",
        "flow_model_fn",
        "model_dir",
        "FLAGS",
        "model_dir",
        "FLAGS",
        "data_format",
        "tf",
        "train",
        "LoggingTensorHook",
        "tensors",
        "tensors_to_log",
        "every_n_iter",
        "flow_classifier",
        "train",
        "input_fn",
        "input_fn",
        "train_images",
        "train_binaries",
        "FLAGS",
        "batch_size",
        "FLAGS",
        "train_epochs",
        "steps",
        "hooks",
        "logging_hook",
        "flow_classifier",
        "evaluate",
        "input_fn",
        "input_fn",
        "test_images",
        "test_binaries",
        "FLAGS",
        "batch_size",
        "steps",
        "eval_results",
        "tf",
        "logging",
        "set_verbosity",
        "tf",
        "logging",
        "INFO",
        "parser",
        "parse_known_args",
        "tf",
        "app",
        "run",
        "main",
        "main",
        "argv",
        "sys",
        "argv",
        "unparsed"
    ],
    "literals": [
        "'--batch_size'",
        "'Number of images to process in a batch'",
        "'--data_dir'",
        "'/home/cvgl_ros/Documents/parth/'",
        "'Path to the MNIST data directory.'",
        "'--model_dir'",
        "'/home/cvgl_ros/Documents/parth/'",
        "'The directory where the model will be stored.'",
        "'--train_epochs'",
        "'Number of epochs to train.'",
        "'--data_format'",
        "'channels_first'",
        "'channels_last'",
        "'A flag to override the data format used in the model. channels_first '",
        "'provides a performance boost on GPU but is not always compatible '",
        "'with CPU. If left unspecified, the data format will be chosen '",
        "'automatically based on whether TensorFlow was built for CPU or GPU.'",
        "'train'",
        "'validation'",
        "\"data_images_test.npz\"",
        "\"arr_0\"",
        "\"data_binaries_test.npz\"",
        "\"arr_0\"",
        "\"data_images_train.npz\"",
        "\"arr_0\"",
        "\"data_binaries_train.npz\"",
        "\"arr_0\"",
        "'channels_first'",
        "'channels_last'",
        "'channels_first'",
        "'same'",
        "'same'",
        "'same'",
        "'same'",
        "'same'",
        "'same'",
        "'same'",
        "'same'",
        "'data_format'",
        "\"results\"",
        "'AEE'",
        "'train_accuracy'",
        "'train_accuracy'",
        "'data_format'",
        "'train_accuracy'",
        "'train_accuracy'",
        "'Evaluation results:\\n\\t%s'",
        "'__main__'"
    ],
    "variables": [
        "parser",
        "_NUM_IMAGES",
        "test_images_file",
        "test_images",
        "test_images",
        "test_flows_file",
        "test_binaries",
        "train_images_file",
        "train_images",
        "train_images",
        "train_flows_file",
        "train_binaries",
        "test_images",
        "train_images",
        "i",
        "a",
        "b",
        "image",
        "image",
        "image",
        "labels",
        "labels",
        "labels",
        "dataset",
        "images",
        "flows",
        "inputs",
        "data_format",
        "inputs",
        "conv1",
        "conv1",
        "conv2",
        "conv2",
        "conv3",
        "conv3",
        "pred1",
        "pred1",
        "upsample1",
        "upsample1",
        "upconv1",
        "upconv1",
        "concat1",
        "pred2",
        "pred2",
        "upsample2",
        "upsample2",
        "upconv2",
        "upconv2",
        "concat2",
        "pred3",
        "pred3",
        "upsample3",
        "upsample2",
        "predictions",
        "diff",
        "loss",
        "optimizer",
        "train_op",
        "train_op",
        "accuracy",
        "metrics",
        "flow_classifier",
        "tensors_to_log",
        "logging_hook",
        "eval_results",
        "FLAGS",
        "unparsed"
    ],
    "comments": [
        "Basic model parameters.",
        "sess = tf.Session()",
        "def gen(images, flows):",
        "for i in itertools.count(0):",
        "yield images[i], flows[i]",
        "dataset = tf.data.Dataset.from_generator(",
        "gen, (tf.float32, tf.float32))",
        "value = dataset.make_one_shot_iterator().get_next()",
        "sess.run(value)",
        "sess.run(value)",
        "",
        "sess = tf.Session()",
        "dataset = tf.data.Dataset.from_tensor_slices(",
        "(images_filename, flows_filename))",
        "# Apply dataset transformations",
        "if is_training:",
        "# When choosing shuffle buffer sizes, larger sizes result in better",
        "# randomness, while smaller sizes have better performance. Because MNIST is",
        "# a small dataset, we can easily shuffle the full epoch.",
        "dataset = dataset.shuffle(buffer_size=_NUM_IMAGES['train'])",
        "# We call repeat after shuffling, rather than before, to prevent separate",
        "# epochs from blending together.",
        "dataset = dataset.repeat(num_epochs)",
        "# Map example_parser over dataset, and batch results by up to batch_size",
        "#dataset = dataset.map(example_parser).prefetch(batch_size)",
        "dataset = dataset.batch(batch_size)",
        "#iterator = dataset.make_one_shot_iterator()",
        "iterator = datalset_make_initalizeable_iterator()",
        "_images = tf.placeholder(tf.float32, [None, 480, 640, 6])",
        "_flows = tf.placeholder(tf.float32, [None, 480, 640, 2])",
        "sess.run(iterator.initializer, feed_dict={_data: images_filename,",
        "_flows: flows_filename})",
        "images, flows = iterator.get_next()",
        "",
        "Input Layer",
        "Reshape X to 4-D tensor: [batch_size, width, height, channels]",
        "MNIST images are 28x28 pixels, and have one color channel",
        "When running on GPU, transpose the data from channels_last (NHWC) to",
        "channels_first (NCHW) to improve performance.",
        "See https://www.tensorflow.org/performance/performance_guide#data_formats",
        "Convolutional Layer #1",
        "Computes 64 features using a 5x5 filter with stride of 2x2.",
        "Activation simulates a leaky ReLU layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 240, 320, 6]",
        "Output Tensor Shape: [batch_size, 120, 160, 64]",
        "Convolutional Layer #2",
        "Computes 128 features using a 3x3 filter with stride of 2x2.",
        "Activation simulates a leaky ReLU layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 120, 160, 64]",
        "Output Tensor Shape: [batch_size, 60, 80, 128]",
        "Convolutional Layer #3",
        "Computes 256 features using a 3x3 filter with stride of 2x2.",
        "Activation simulates a leaky ReLU layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 60, 80, 128]",
        "Output Tensor Shape: [batch_size, 30, 40, 256]",
        "Predict Flow #1",
        "Computes 2 features using a 3x3 filter with stride of 1x1.",
        "No activation layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 30, 40, 256]",
        "Output Tensor Shape: [batch_size, 30, 40, 2]",
        "Upsample #1",
        "Increases image dimensions by double.",
        "Input Tensor Shape: [batch_size, 30, 40, 2]",
        "Output Tensor Shape: [batch_size, 60, 80, 2]",
        "Upconvolutional Layer #1",
        "Computes 128 features using a 5x5 filter with stride of 2x2.",
        "Activation simulates a leaky ReLU layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 30, 40, 256]",
        "Output Tensor Shape: [batch_size, 60, 80, 128]",
        "Predict Flow #2",
        "Computes 2 features using a 3x3 filter with stride of 1x1.",
        "No activation layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 60, 80, 258]",
        "Output Tensor Shape: [batch_size, 60, 80, 2]",
        "Upsample #2",
        "Increases image dimensions by double.",
        "Input Tensor Shape: [batch_size, 60, 80, 2]",
        "Output Tensor Shape: [batch_size, 120, 160, 2]",
        "Upconvolutional Layer #2",
        "Computes 64 features using a 5x5 filter with stride of 2x2.",
        "Activation simulates a leaky ReLU layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 60, 80, 128]",
        "Output Tensor Shape: [batch_size, 120, 160, 64]",
        "Predict Flow #3",
        "Computes 2 features using a 3x3 filter with stride of 1x1.",
        "No activation layer.",
        "Padding is added to preserve width and height.",
        "Input Tensor Shape: [batch_size, 120, 160, 130]",
        "Output Tensor Shape: [batch_size, 120, 160, 2]",
        "Upsample #3",
        "Increases image dimensions by double.",
        "Input Tensor Shape: [batch_size, 120, 160, 2]",
        "Output Tensor Shape: [batch_size, 240, 320, 2]",
        "THIS FUNCTION BELOW NEEDS TO BE MODIFIED ######################",
        "CHANGE PREDICTIONS",
        "CHANGE LOSS",
        "CHANGE ACCURACRY AND METRICS? NOT EXACT MATCH BUT CLOSENESS?",
        "predictions = {",
        "'classes': tf.argmax(input=logits, axis=1),",
        "'probabilities': tf.nn.softmax(logits, name='softmax_tensor')",
        "}",
        "loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)",
        "Configure the training op",
        "accuracy = tf.metrics.accuracy(",
        "tf.argmax(labels, axis=1), predictions['classes'])",
        "metrics = {'accuracy': accuracy}",
        "AEE = tf.scalar_mul(tf.constant(1.0/(640*480)), loss)",
        "metrics = {'AEE': AEE}",
        "Create a tensor named train_accuracy for logging purposes",
        "",
        "Make sure that training and testing data have been converted.",
        "train_file = os.path.join(FLAGS.data_dir, 'data_images_train.txt')",
        "test_file = os.path.join(FLAGS.data_dir, 'data_images_test.txt')",
        "train_binaries_file = os.path.join(FLAGS.data_dir, 'data_binaries_train.txt')",
        "test_binaries_file = os.path.join(FLAGS.data_dir, 'data_binaries_test.txt')",
        "assert (tf.gfile.Exists(train_file) and tf.gfile.Exists(test_file)), (",
        "'Run convert_to_records.py first to convert the MNIST data to TFRecord '",
        "'file format.')",
        "Create the Estimator",
        "Set up training hook that logs the training accuracy every 100 steps.",
        "FIND A WAY TO ONLY TEST INPUT FN######################",
        "LOAD DATA AND PASS IT INTO INPUT FN",
        "Train the model",
        "summary_writer = tf.train.SummaryWriter(\"/tensorflow/logdir\", sess.graph_def)",
        "Evaluate the model and print results"
    ],
    "docstrings": [
        "\"\"\"A simple input_fn using the tf.data input pipeline.\"\"\"",
        "\"\"\"Takes the image pairs as inputs and mode and outputs a 2D tensor of flows.\"\"\"",
        "\"\"\"Model function for MNIST.\"\"\""
    ],
    "functions": [
        "input_fn",
        "gen",
        "flow_model",
        "flow_model_fn",
        "main"
    ],
    "classes": []
}