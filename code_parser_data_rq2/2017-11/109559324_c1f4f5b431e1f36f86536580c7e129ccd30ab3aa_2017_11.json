{
    "identifiers": [
        "random",
        "numpy",
        "np",
        "utils",
        "net",
        "actionSet",
        "goalSet",
        "metaEpsilon",
        "defaultMetaEpsilon",
        "epsilon",
        "defaultEpsilon",
        "controllerEpsilon",
        "defaultControllerEpsilon",
        "tau",
        "defaultTau",
        "actionSet",
        "controllerEpsilon",
        "goalSet",
        "metaEpsilon",
        "defaultNSample",
        "defaultMetaNSamples",
        "defaultGamma",
        "tau",
        "net",
        "state",
        "goal",
        "utils",
        "oneHot",
        "goal",
        "utils",
        "reshape",
        "state",
        "np",
        "concatenate",
        "stateVec",
        "goalVec",
        "axis",
        "controllerEpsilon",
        "goal",
        "random",
        "random",
        "np",
        "argmax",
        "net",
        "controller",
        "predict",
        "vector",
        "verbose",
        "random",
        "choice",
        "actionSet",
        "state",
        "metaEpsilon",
        "random",
        "random",
        "utils",
        "reshape",
        "state",
        "net",
        "meta_controller",
        "predict",
        "stateVec",
        "verbose",
        "pred",
        "shape",
        "np",
        "argmax",
        "pred",
        "random",
        "choice",
        "goalSet",
        "goalReached",
        "goalReached",
        "experience",
        "meta",
        "meta",
        "metaMemory",
        "append",
        "experience",
        "len",
        "metaMemory",
        "metaMemory",
        "memory",
        "append",
        "experience",
        "len",
        "memory",
        "memory",
        "random",
        "choice",
        "memory",
        "_",
        "nSamples",
        "np",
        "squeeze",
        "np",
        "asarray",
        "np",
        "concatenate",
        "exp",
        "state",
        "exp",
        "goal",
        "axis",
        "exp",
        "exps",
        "np",
        "squeeze",
        "np",
        "asarray",
        "np",
        "concatenate",
        "exp",
        "next_state",
        "exp",
        "goal",
        "axis",
        "exp",
        "exps",
        "net",
        "controller",
        "predict",
        "stateVectors",
        "verbose",
        "net",
        "targetController",
        "predict",
        "nextStateVectors",
        "verbose",
        "i",
        "exp",
        "exps",
        "rewardVectors",
        "i",
        "exp",
        "action",
        "exp",
        "reward",
        "exp",
        "done",
        "rewardVectors",
        "i",
        "exp",
        "action",
        "gamma",
        "max",
        "nextStateRewardVectors",
        "i",
        "np",
        "asarray",
        "rewardVectors",
        "net",
        "controller",
        "fit",
        "stateVectors",
        "rewardVectors",
        "verbose",
        "net",
        "controller",
        "get_weights",
        "net",
        "targetController",
        "get_weights",
        "i",
        "len",
        "controllerWeights",
        "targetTau",
        "controllerWeights",
        "i",
        "targetTau",
        "controllerTargetWeights",
        "i",
        "net",
        "targetController",
        "set_weights",
        "controllerTargetWeights",
        "len",
        "metaMemory",
        "random",
        "choice",
        "metaMemory",
        "_",
        "metaNSamples",
        "np",
        "squeeze",
        "np",
        "asarray",
        "exp",
        "state",
        "exp",
        "exps",
        "np",
        "squeeze",
        "np",
        "asarray",
        "exp",
        "next_state",
        "exp",
        "exps",
        "net",
        "meta",
        "predict",
        "stateVectors",
        "verbose",
        "net",
        "metaTarget",
        "predict",
        "nextStateVectors",
        "verbose",
        "i",
        "exp",
        "exps",
        "rewardVectors",
        "i",
        "np",
        "argmax",
        "exp",
        "goal",
        "exp",
        "reward",
        "exp",
        "done",
        "rewardVectors",
        "i",
        "np",
        "argmax",
        "exp",
        "goal",
        "gamma",
        "max",
        "nextStateRewardVectors",
        "i",
        "net",
        "meta",
        "fit",
        "stateVectors",
        "rewardVectors",
        "verbose",
        "net",
        "meta",
        "get_weights",
        "net",
        "metaTarget",
        "get_weights",
        "i",
        "len",
        "metaWeights",
        "targetTau",
        "metaWeights",
        "i",
        "targetTau",
        "metaTargetWeights",
        "i",
        "net",
        "metaTarget",
        "set_weights",
        "metaTargetWeights",
        "meta",
        "meta",
        "_update_meta",
        "_update",
        "stepCount",
        "defaultEndEpsilon",
        "defaultMetaEpsilon",
        "defaultEndEpsilon",
        "defaultAnnealSteps",
        "max",
        "stepCount",
        "defaultRandomPlaySteps",
        "defaultAnnealSteps",
        "stepCount",
        "goal",
        "ControllerEpsilon",
        "defaultEndEpsilon",
        "defaultControllerEpsilon",
        "goal",
        "defaultEndEpsilon",
        "defaultAnnealSteps",
        "max",
        "stepCount",
        "defaultRandomPlaySteps",
        "defaultAnnealSteps"
    ],
    "literals": [
        "\"pred shape: \"",
        "\"Exploring\""
    ],
    "variables": [
        "defaultNSample",
        "defaultGamma",
        "defaultEpsilon",
        "defaultControllerEpsilon",
        "defaultTau",
        "defaultAnnealSteps",
        "defaultEndEpsilon",
        "defaultRandomPlaySteps",
        "defaultMetaEpsilon",
        "defaultMetaNSamples",
        "actionSet",
        "controllerEpsilon",
        "goalSet",
        "metaEpsilon",
        "nSamples",
        "metaNSamples",
        "gamma",
        "targetTau",
        "net",
        "memory",
        "metaMemory",
        "goalVec",
        "stateVec",
        "vector",
        "stateVec",
        "pred",
        "metaMemory",
        "memory",
        "exps",
        "stateVectors",
        "nextStateVectors",
        "rewardVectors",
        "nextStateRewardVectors",
        "rewardVectors",
        "controllerWeights",
        "controllerTargetWeights",
        "controllerTargetWeights",
        "i",
        "exps",
        "stateVectors",
        "nextStateVectors",
        "rewardVectors",
        "nextStateRewardVectors",
        "metaWeights",
        "metaTargetWeights",
        "metaTargetWeights",
        "i",
        "metaEpsilon",
        "goal"
    ],
    "comments": [
        "Default architectures for the lower level controller/actor",
        "",
        "",
        "",
        "predict action",
        "predict action",
        "-100????",
        "Update target network",
        "Update target network"
    ],
    "docstrings": [],
    "functions": [
        "selectMove",
        "selectGoal",
        "criticize",
        "store",
        "_update",
        "_update_meta",
        "update",
        "annealMetaEpsilon",
        "annealControllerEpsilon"
    ],
    "classes": [
        "Agent"
    ]
}