{
    "identifiers": [
        "sequence",
        "lowercase",
        "text1",
        "text2",
        "filename1",
        "filename2",
        "lowercase",
        "text1",
        "text2",
        "unittest",
        "numpy",
        "np",
        "unittest",
        "TestCase",
        "assertEqual",
        "argmax",
        "assertEqual",
        "argmax",
        "tokenize",
        "assertIn",
        "words",
        "assertIn",
        "words",
        "tokenize",
        "assertIn",
        "words",
        "assertIn",
        "words",
        "text2wordfreq",
        "assertEqual",
        "counts",
        "assertEqual",
        "counts",
        "assertIn",
        "counts",
        "assertNotIn",
        "counts",
        "assertEqual",
        "shared_words",
        "os",
        "path",
        "join",
        "os",
        "path",
        "dirname",
        "os",
        "path",
        "join",
        "data_dir",
        "os",
        "path",
        "join",
        "data_dir",
        "shared_words_from_filenames",
        "filename1",
        "filename2",
        "assertGreater",
        "len",
        "words",
        "assertIn",
        "words",
        "assertAlmostEqual",
        "lexical_density",
        "assertAlmostEqual",
        "lexical_density",
        "assertEqual",
        "len",
        "hashtags",
        "tweet",
        "assertAlmostEqual",
        "jaccard_similarity",
        "text1",
        "text2",
        "assertEqual",
        "len",
        "hashtags",
        "tweet",
        "unittest",
        "main"
    ],
    "literals": [
        "'Colorless green ideas sleep furiously.'",
        "'green'",
        "'colorless'",
        "'The rain  in spain is  mainly in the plain.'",
        "'The'",
        "'rain'",
        "'Colorless green ideas sleep furiously. Green ideas in trees.'",
        "'green'",
        "'sleep'",
        "'colorless'",
        "'hello'",
        "'the hat'",
        "'red hat'",
        "'hat'",
        "'data'",
        "'1984-chp01.txt'",
        "'animal-farm-chp01.txt'",
        "'already'",
        "\"The cat\"",
        "\"The cat in the hat.\"",
        "\"Eight million Americans\"",
        "\"Americans in the South\"",
        "'__main__'"
    ],
    "variables": [
        "words",
        "words",
        "counts",
        "data_dir",
        "filename1",
        "filename2",
        "words",
        "tweet",
        "text1",
        "text2",
        "tweet"
    ],
    "comments": [
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "YOUR CODE HERE",
        "DO NOT EDIT CODE BELOW THIS LINE",
        "the use of the os.path functions is required so that filenames work",
        "on Windows and Unix/Linux systems."
    ],
    "docstrings": [
        "'''Assignment 2\n\nPlease add your code where indicated. You may conduct a superficial test of\nyour code by executing this file in a python interpreter.\n\nThe documentation strings (\"docstrings\") for each function tells you what the\nfunction should accomplish. If docstrings are unfamiliar to you, consult the\nPython Tutorial section on \"Documentation Strings\".\n\n'''",
        "\"\"\"Return the index of the highest value in a list.\n\n    This is a warmup exercise.\n\n    Remember that Python uses zero-based numbering of indexes.\n\n    Args:\n        sequence (list): A list of numeric values.\n\n    Returns:\n        int: The index of the highest value in `sequence`.\n\n    \"\"\"",
        "\"\"\"Extract words from a string containing English words.\n\n    Handling of hyphenation, contractions, and numbers is left to your\n    discretion.\n\n    Tip: you may want to look into the `re` module.\n\n    Args:\n        string (str): A string containing English.\n        lowercase (bool, optional): Convert words to lowercase.\n\n    Returns:\n        list: A list of words.\n\n    \"\"\"",
        "\"\"\"Identify shared words in two texts written in English.\n\n    Your function must make use of the `tokenize` function above. You should\n    considering using Python `set`s to solve the problem.\n\n    Args:\n        text1 (str): A string containing English.\n        text2 (str): A string containing English.\n\n    Returns:\n        set: A set with words appearing in both `text1` and `text2`.\n\n    \"\"\"",
        "\"\"\"Identify shared words in two texts stored on disk.\n\n    Your function must make use of the `tokenize` function above. You should\n    considering using Python `set`s to solve the problem.\n\n    For each filename you will need to `open` file and read the file's\n    contents.\n\n    There are two sample text files in the `data/` directory which you can use\n    to practice on.\n\n    Args:\n        filename1 (str): A string containing English.\n        filename2 (str): A string containing English.\n\n    Returns:\n        set: A set with words appearing in both texts.\n\n    \"\"\"",
        "\"\"\"Calculate word frequencies for a text written in English.\n\n    Handling of hyphenation and contractions is left to your discretion.\n\n    Your function must make use of the `tokenize` function above.\n\n    Args:\n        string (str): A string containing English.\n        lowercase (bool, optional): Convert words to lowercase before calculating their\n            frequency.\n\n    Returns:\n        dict: A dictionary with words as keys and frequencies as values.\n\n    \"\"\"",
        "\"\"\"Calculate the lexical density of a string containing English words.\n\n    The lexical density of a sequence is defined to be the number of\n    unique words divided by the number of total words. The lexical\n    density of the sentence \"The dog ate the hat.\" is 4/5.\n\n    Ignore capitalization. For example, \"The\" should be counted as the same\n    type as \"the\".\n\n    This function should use the `text2wordfreq` function.\n\n    Args:\n        string (str): A string containing English.\n\n    Returns:\n        float: Lexical density.\n\n    \"\"\"",
        "\"\"\"Extract hashtags from a string.\n\n    For example, the string `\"RT @HouseGOP: The #StateOfTheUnion is strong.\"`\n    contains the hashtag `#StateOfTheUnion`.\n\n    Args:\n        string (str): A string containing English.\n\n    Returns:\n        list: A list, possibly empty, containing hashtags.\n\n    \"\"\"",
        "\"\"\"Calculate Jaccard Similarity between two texts.\n\n    The Jaccard similarity (coefficient) or Jaccard index is defined to be the\n    ratio between the size of the intersection between two sets and the size of\n    the union between two sets. In this case, the two sets we consider are the\n    set of words extracted from `text1` and `text2` respectively.\n\n    This function should ignore capitalization. A word with a capital\n    letter should be treated the same as a word without a capital letter.\n\n    Args:\n        text1 (str): A string containing English words.\n        text2 (str): A string containing English words.\n\n    Returns:\n        float: Jaccard similarity\n\n    \"\"\"",
        "\"\"\"RT @HouseGOP: The #StateOfTheUnion isn't strong for the 8.7 million Americans out of work. #SOTU http://t.co/aa7FWRCdyn\"\"\"",
        "\"\"\"RT @HouseGOP: The #StateOfTheUnion isn't strong for the 8.7 million Americans out of work. #SOTU http://t.co/aa7FWRCdyn\"\"\""
    ],
    "functions": [
        "argmax",
        "tokenize",
        "shared_words",
        "shared_words_from_filenames",
        "text2wordfreq",
        "lexical_density",
        "hashtags",
        "jaccard_similarity",
        "test_argmax",
        "test_tokenize",
        "test_text2wordfreq",
        "test_shared_words",
        "test_shared_words_from_filenames",
        "test_lexical_density",
        "test_jaccard_similarity",
        "test_hashtags"
    ],
    "classes": [
        "TestAssignment2"
    ]
}