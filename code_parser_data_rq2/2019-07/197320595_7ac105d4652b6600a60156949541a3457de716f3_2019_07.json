{
    "identifiers": [
        "io",
        "os",
        "sys",
        "subprocess",
        "wave",
        "aifc",
        "math",
        "audioop",
        "collections",
        "json",
        "base64",
        "threading",
        "platform",
        "stat",
        "hashlib",
        "hmac",
        "time",
        "uuid",
        "urllib",
        "urlencode",
        "urllib2",
        "Request",
        "urlopen",
        "URLError",
        "HTTPError",
        "ImportError",
        "urllib",
        "parse",
        "urlencode",
        "urllib",
        "request",
        "Request",
        "urlopen",
        "urllib",
        "error",
        "URLError",
        "HTTPError",
        "NotImplementedError",
        "NotImplementedError",
        "exc_type",
        "exc_value",
        "traceback",
        "NotImplementedError",
        "AudioSource",
        "device_index",
        "sample_rate",
        "chunk_size",
        "device_index",
        "isinstance",
        "device_index",
        "sample_rate",
        "isinstance",
        "sample_rate",
        "sample_rate",
        "isinstance",
        "chunk_size",
        "chunk_size",
        "get_pyaudio",
        "pyaudio_module",
        "PyAudio",
        "audio",
        "get_device_count",
        "device_index",
        "device_index",
        "count",
        "format",
        "count",
        "count",
        "sample_rate",
        "audio",
        "get_device_info_by_index",
        "device_index",
        "device_index",
        "audio",
        "get_default_input_device_info",
        "isinstance",
        "device_info",
        "get",
        "device_info",
        "format",
        "device_info",
        "device_info",
        "audio",
        "terminate",
        "device_index",
        "pyaudio_module",
        "paInt16",
        "pyaudio_module",
        "get_sample_size",
        "format",
        "sample_rate",
        "chunk_size",
        "staticmethod",
        "pyaudio",
        "ImportError",
        "AttributeError",
        "distutils",
        "version",
        "LooseVersion",
        "LooseVersion",
        "pyaudio",
        "__version__",
        "LooseVersion",
        "AttributeError",
        "format",
        "pyaudio",
        "__version__",
        "pyaudio",
        "staticmethod",
        "Microphone",
        "get_pyaudio",
        "PyAudio",
        "i",
        "audio",
        "get_device_count",
        "audio",
        "get_device_info_by_index",
        "i",
        "result",
        "append",
        "device_info",
        "get",
        "audio",
        "terminate",
        "result",
        "staticmethod",
        "Microphone",
        "get_pyaudio",
        "pyaudio_module",
        "PyAudio",
        "device_index",
        "audio",
        "get_device_count",
        "audio",
        "get_device_info_by_index",
        "device_index",
        "device_info",
        "get",
        "isinstance",
        "device_info",
        "get",
        "device_info",
        "format",
        "device_info",
        "audio",
        "open",
        "input_device_index",
        "device_index",
        "channels",
        "format",
        "pyaudio_module",
        "paInt16",
        "rate",
        "device_info",
        "input",
        "pyaudio_stream",
        "read",
        "pyaudio_stream",
        "is_stopped",
        "pyaudio_stream",
        "stop_stream",
        "pyaudio_stream",
        "close",
        "audioop",
        "rms",
        "buffer",
        "chr",
        "energy",
        "chr",
        "energy",
        "energy",
        "energy",
        "audioop",
        "rms",
        "audioop",
        "add",
        "buffer",
        "energy_bytes",
        "len",
        "buffer",
        "debiased_energy",
        "device_name",
        "audio",
        "terminate",
        "result",
        "stream",
        "pyaudio_module",
        "PyAudio",
        "Microphone",
        "MicrophoneStream",
        "audio",
        "open",
        "input_device_index",
        "device_index",
        "channels",
        "format",
        "format",
        "rate",
        "SAMPLE_RATE",
        "frames_per_buffer",
        "CHUNK",
        "input",
        "audio",
        "terminate",
        "exc_type",
        "exc_value",
        "traceback",
        "stream",
        "close",
        "audio",
        "terminate",
        "pyaudio_stream",
        "pyaudio_stream",
        "size",
        "pyaudio_stream",
        "read",
        "size",
        "exception_on_overflow",
        "pyaudio_stream",
        "is_stopped",
        "pyaudio_stream",
        "stop_stream",
        "pyaudio_stream",
        "close",
        "AudioSource",
        "filename_or_fileobject",
        "isinstance",
        "filename_or_fileobject",
        "hasattr",
        "filename_or_fileobject",
        "filename_or_fileobject",
        "stream",
        "wave",
        "open",
        "filename_or_fileobject",
        "wave",
        "EOFError",
        "aifc",
        "open",
        "filename_or_fileobject",
        "aifc",
        "EOFError",
        "hasattr",
        "filename_or_fileobject",
        "filename_or_fileobject",
        "read",
        "open",
        "filename_or_fileobject",
        "f",
        "f",
        "read",
        "get_flac_converter",
        "os",
        "name",
        "subprocess",
        "STARTUPINFO",
        "startup_info",
        "dwFlags",
        "subprocess",
        "STARTF_USESHOWWINDOW",
        "subprocess",
        "SW_HIDE",
        "subprocess",
        "Popen",
        "flac_converter",
        "stdin",
        "subprocess",
        "PIPE",
        "stdout",
        "subprocess",
        "PIPE",
        "startupinfo",
        "startup_info",
        "process",
        "communicate",
        "flac_data",
        "io",
        "BytesIO",
        "aiff_data",
        "aifc",
        "open",
        "aiff_file",
        "aifc",
        "EOFError",
        "ValueError",
        "audio_reader",
        "getnchannels",
        "audio_reader",
        "getsampwidth",
        "SAMPLE_WIDTH",
        "audioop",
        "bias",
        "SAMPLE_WIDTH",
        "audioop",
        "error",
        "audio_reader",
        "getframerate",
        "audio_reader",
        "getnframes",
        "FRAME_COUNT",
        "SAMPLE_RATE",
        "AudioFile",
        "AudioFileStream",
        "audio_reader",
        "little_endian",
        "samples_24_bit_pretending_to_be_32_bit",
        "exc_type",
        "exc_value",
        "traceback",
        "hasattr",
        "filename_or_fileobject",
        "audio_reader",
        "close",
        "audio_reader",
        "little_endian",
        "samples_24_bit_pretending_to_be_32_bit",
        "audio_reader",
        "little_endian",
        "samples_24_bit_pretending_to_be_32_bit",
        "size",
        "audio_reader",
        "readframes",
        "audio_reader",
        "getnframes",
        "size",
        "size",
        "isinstance",
        "buffer",
        "audio_reader",
        "getsampwidth",
        "little_endian",
        "hasattr",
        "audioop",
        "audioop",
        "byteswap",
        "buffer",
        "sample_width",
        "buffer",
        "sample_width",
        "join",
        "buffer",
        "i",
        "sample_width",
        "i",
        "i",
        "sample_width",
        "len",
        "buffer",
        "sample_width",
        "samples_24_bit_pretending_to_be_32_bit",
        "join",
        "buffer",
        "i",
        "i",
        "sample_width",
        "i",
        "len",
        "buffer",
        "sample_width",
        "audio_reader",
        "getnchannels",
        "audioop",
        "tomono",
        "buffer",
        "sample_width",
        "buffer",
        "frame_data",
        "sample_rate",
        "sample_width",
        "sample_rate",
        "sample_width",
        "sample_width",
        "frame_data",
        "sample_rate",
        "sample_width",
        "start_ms",
        "end_ms",
        "start_ms",
        "start_ms",
        "end_ms",
        "end_ms",
        "start_ms",
        "start_ms",
        "start_ms",
        "start_ms",
        "sample_rate",
        "sample_width",
        "end_ms",
        "len",
        "frame_data",
        "end_ms",
        "sample_rate",
        "sample_width",
        "AudioData",
        "frame_data",
        "start_byte",
        "end_byte",
        "sample_rate",
        "sample_width",
        "convert_rate",
        "convert_width",
        "convert_rate",
        "convert_rate",
        "convert_width",
        "convert_width",
        "convert_width",
        "frame_data",
        "sample_width",
        "audioop",
        "bias",
        "raw_data",
        "convert_rate",
        "sample_rate",
        "convert_rate",
        "audioop",
        "ratecv",
        "raw_data",
        "sample_width",
        "sample_rate",
        "convert_rate",
        "convert_width",
        "sample_width",
        "convert_width",
        "convert_width",
        "audioop",
        "lin2lin",
        "raw_data",
        "sample_width",
        "audioop",
        "bias",
        "audioop",
        "error",
        "join",
        "raw_data",
        "i",
        "i",
        "i",
        "len",
        "raw_data",
        "audioop",
        "lin2lin",
        "raw_data",
        "sample_width",
        "convert_width",
        "audioop",
        "lin2lin",
        "raw_data",
        "sample_width",
        "convert_width",
        "convert_width",
        "audioop",
        "bias",
        "raw_data",
        "raw_data",
        "convert_rate",
        "convert_width",
        "get_raw_data",
        "convert_rate",
        "convert_width",
        "sample_rate",
        "convert_rate",
        "convert_rate",
        "sample_width",
        "convert_width",
        "convert_width",
        "io",
        "BytesIO",
        "wav_file",
        "wave",
        "open",
        "wav_file",
        "wav_writer",
        "setframerate",
        "sample_rate",
        "wav_writer",
        "setsampwidth",
        "sample_width",
        "wav_writer",
        "setnchannels",
        "wav_writer",
        "writeframes",
        "raw_data",
        "wav_file",
        "getvalue",
        "wav_writer",
        "close",
        "wav_data",
        "convert_rate",
        "convert_width",
        "get_raw_data",
        "convert_rate",
        "convert_width",
        "sample_rate",
        "convert_rate",
        "convert_rate",
        "sample_width",
        "convert_width",
        "convert_width",
        "hasattr",
        "audioop",
        "audioop",
        "byteswap",
        "raw_data",
        "sample_width",
        "raw_data",
        "sample_width",
        "join",
        "raw_data",
        "i",
        "sample_width",
        "i",
        "i",
        "sample_width",
        "len",
        "raw_data",
        "sample_width",
        "io",
        "BytesIO",
        "aiff_file",
        "aifc",
        "open",
        "aiff_file",
        "aiff_writer",
        "setframerate",
        "sample_rate",
        "aiff_writer",
        "setsampwidth",
        "sample_width",
        "aiff_writer",
        "setnchannels",
        "aiff_writer",
        "writeframes",
        "raw_data",
        "aiff_file",
        "getvalue",
        "aiff_writer",
        "close",
        "aiff_data",
        "convert_rate",
        "convert_width",
        "convert_width",
        "convert_width",
        "convert_width",
        "sample_width",
        "convert_width",
        "get_wav_data",
        "convert_rate",
        "convert_width",
        "get_flac_converter",
        "os",
        "name",
        "subprocess",
        "STARTUPINFO",
        "startup_info",
        "dwFlags",
        "subprocess",
        "STARTF_USESHOWWINDOW",
        "subprocess",
        "SW_HIDE",
        "subprocess",
        "Popen",
        "flac_converter",
        "stdin",
        "subprocess",
        "PIPE",
        "stdout",
        "subprocess",
        "PIPE",
        "startupinfo",
        "startup_info",
        "process",
        "communicate",
        "wav_data",
        "flac_data",
        "AudioSource",
        "source",
        "duration",
        "offset",
        "isinstance",
        "source",
        "AudioSource",
        "source",
        "stream",
        "io",
        "BytesIO",
        "source",
        "CHUNK",
        "source",
        "SAMPLE_RATE",
        "offset",
        "offset_reached",
        "offset_time",
        "seconds_per_buffer",
        "offset_time",
        "offset",
        "source",
        "stream",
        "read",
        "source",
        "CHUNK",
        "len",
        "buffer",
        "offset_reached",
        "offset",
        "elapsed_time",
        "seconds_per_buffer",
        "duration",
        "elapsed_time",
        "duration",
        "frames",
        "write",
        "buffer",
        "frames",
        "getvalue",
        "frames",
        "close",
        "AudioData",
        "frame_data",
        "source",
        "SAMPLE_RATE",
        "source",
        "SAMPLE_WIDTH",
        "source",
        "duration",
        "isinstance",
        "source",
        "AudioSource",
        "source",
        "stream",
        "pause_threshold",
        "non_speaking_duration",
        "source",
        "CHUNK",
        "source",
        "SAMPLE_RATE",
        "elapsed_time",
        "seconds_per_buffer",
        "elapsed_time",
        "duration",
        "source",
        "stream",
        "read",
        "source",
        "CHUNK",
        "audioop",
        "rms",
        "buffer",
        "source",
        "SAMPLE_WIDTH",
        "dynamic_energy_adjustment_damping",
        "seconds_per_buffer",
        "energy",
        "dynamic_energy_ratio",
        "energy_threshold",
        "damping",
        "target_energy",
        "damping",
        "snowboy_location",
        "snowboy_hot_word_files",
        "source",
        "timeout",
        "sys",
        "path",
        "append",
        "snowboy_location",
        "snowboydetect",
        "sys",
        "path",
        "pop",
        "snowboydetect",
        "SnowboyDetect",
        "resource_filename",
        "os",
        "path",
        "join",
        "snowboy_location",
        "encode",
        "model_str",
        "join",
        "snowboy_hot_word_files",
        "encode",
        "detector",
        "SetAudioGain",
        "detector",
        "SetSensitivity",
        "join",
        "len",
        "snowboy_hot_word_files",
        "encode",
        "detector",
        "SampleRate",
        "source",
        "CHUNK",
        "source",
        "SAMPLE_RATE",
        "math",
        "ceil",
        "seconds_per_buffer",
        "math",
        "ceil",
        "seconds_per_buffer",
        "collections",
        "deque",
        "maxlen",
        "five_seconds_buffer_count",
        "collections",
        "deque",
        "maxlen",
        "half_second_buffer_count",
        "time",
        "time",
        "elapsed_time",
        "seconds_per_buffer",
        "timeout",
        "elapsed_time",
        "timeout",
        "WaitTimeoutError",
        "source",
        "stream",
        "read",
        "source",
        "CHUNK",
        "len",
        "buffer",
        "frames",
        "append",
        "buffer",
        "audioop",
        "ratecv",
        "buffer",
        "source",
        "SAMPLE_WIDTH",
        "source",
        "SAMPLE_RATE",
        "snowboy_sample_rate",
        "resampling_state",
        "resampled_frames",
        "append",
        "resampled_buffer",
        "time",
        "time",
        "last_check",
        "check_interval",
        "detector",
        "RunDetection",
        "join",
        "resampled_frames",
        "snowboy_result",
        "snowboy_result",
        "resampled_frames",
        "clear",
        "time",
        "time",
        "join",
        "frames",
        "elapsed_time",
        "source",
        "timeout",
        "phrase_time_limit",
        "snowboy_configuration",
        "isinstance",
        "source",
        "AudioSource",
        "source",
        "stream",
        "pause_threshold",
        "non_speaking_duration",
        "snowboy_configuration",
        "os",
        "path",
        "isfile",
        "os",
        "path",
        "join",
        "snowboy_configuration",
        "hot_word_file",
        "snowboy_configuration",
        "os",
        "path",
        "isfile",
        "hot_word_file",
        "source",
        "CHUNK",
        "source",
        "SAMPLE_RATE",
        "math",
        "ceil",
        "pause_threshold",
        "seconds_per_buffer",
        "math",
        "ceil",
        "phrase_threshold",
        "seconds_per_buffer",
        "math",
        "ceil",
        "non_speaking_duration",
        "seconds_per_buffer",
        "collections",
        "deque",
        "snowboy_configuration",
        "elapsed_time",
        "seconds_per_buffer",
        "timeout",
        "elapsed_time",
        "timeout",
        "WaitTimeoutError",
        "source",
        "stream",
        "read",
        "source",
        "CHUNK",
        "len",
        "buffer",
        "frames",
        "append",
        "buffer",
        "len",
        "frames",
        "non_speaking_buffer_count",
        "frames",
        "popleft",
        "audioop",
        "rms",
        "buffer",
        "source",
        "SAMPLE_WIDTH",
        "energy",
        "energy_threshold",
        "dynamic_energy_threshold",
        "dynamic_energy_adjustment_damping",
        "seconds_per_buffer",
        "energy",
        "dynamic_energy_ratio",
        "energy_threshold",
        "damping",
        "target_energy",
        "damping",
        "snowboy_configuration",
        "snowboy_wait_for_hot_word",
        "snowboy_location",
        "snowboy_hot_word_files",
        "source",
        "timeout",
        "elapsed_time",
        "delta_time",
        "len",
        "buffer",
        "frames",
        "append",
        "buffer",
        "elapsed_time",
        "elapsed_time",
        "seconds_per_buffer",
        "phrase_time_limit",
        "elapsed_time",
        "phrase_start_time",
        "phrase_time_limit",
        "source",
        "stream",
        "read",
        "source",
        "CHUNK",
        "len",
        "buffer",
        "frames",
        "append",
        "buffer",
        "phrase_count",
        "audioop",
        "rms",
        "buffer",
        "source",
        "SAMPLE_WIDTH",
        "energy",
        "energy_threshold",
        "pause_count",
        "pause_count",
        "pause_buffer_count",
        "phrase_count",
        "pause_count",
        "phrase_count",
        "phrase_buffer_count",
        "len",
        "buffer",
        "i",
        "pause_count",
        "non_speaking_buffer_count",
        "frames",
        "pop",
        "join",
        "frames",
        "AudioData",
        "frame_data",
        "source",
        "SAMPLE_RATE",
        "source",
        "SAMPLE_WIDTH",
        "source",
        "callback",
        "phrase_time_limit",
        "isinstance",
        "source",
        "AudioSource",
        "source",
        "s",
        "running",
        "listen",
        "s",
        "phrase_time_limit",
        "WaitTimeoutError",
        "running",
        "callback",
        "audio",
        "wait_for_stop",
        "wait_for_stop",
        "listener_thread",
        "join",
        "threading",
        "target",
        "threaded_listen",
        "listener_thread",
        "start",
        "stopper",
        "audio_data",
        "language",
        "keyword_entries",
        "grammar",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "language",
        "isinstance",
        "language",
        "len",
        "language",
        "keyword_entries",
        "all",
        "isinstance",
        "keyword",
        "sensitivity",
        "keyword",
        "sensitivity",
        "keyword_entries",
        "pocketsphinx",
        "pocketsphinx",
        "Jsgf",
        "FsgModel",
        "ImportError",
        "RequestError",
        "ValueError",
        "RequestError",
        "hasattr",
        "pocketsphinx",
        "hasattr",
        "pocketsphinx",
        "Decoder",
        "RequestError",
        "isinstance",
        "language",
        "os",
        "path",
        "join",
        "os",
        "path",
        "dirname",
        "os",
        "path",
        "realpath",
        "language",
        "os",
        "path",
        "isdir",
        "language_directory",
        "RequestError",
        "format",
        "language_directory",
        "os",
        "path",
        "join",
        "language_directory",
        "os",
        "path",
        "join",
        "language_directory",
        "os",
        "path",
        "join",
        "language_directory",
        "language",
        "os",
        "path",
        "isdir",
        "acoustic_parameters_directory",
        "RequestError",
        "format",
        "acoustic_parameters_directory",
        "os",
        "path",
        "isfile",
        "language_model_file",
        "RequestError",
        "format",
        "language_model_file",
        "os",
        "path",
        "isfile",
        "phoneme_dictionary_file",
        "RequestError",
        "format",
        "phoneme_dictionary_file",
        "pocketsphinx",
        "Decoder",
        "default_config",
        "config",
        "set_string",
        "acoustic_parameters_directory",
        "config",
        "set_string",
        "language_model_file",
        "config",
        "set_string",
        "phoneme_dictionary_file",
        "config",
        "set_string",
        "os",
        "devnull",
        "pocketsphinx",
        "Decoder",
        "config",
        "audio_data",
        "get_raw_data",
        "convert_rate",
        "convert_width",
        "keyword_entries",
        "PortableNamedTemporaryFile",
        "f",
        "f",
        "writelines",
        "format",
        "keyword",
        "sensitivity",
        "keyword",
        "sensitivity",
        "keyword_entries",
        "f",
        "flush",
        "decoder",
        "set_kws",
        "f",
        "name",
        "decoder",
        "set_search",
        "grammar",
        "os",
        "path",
        "exists",
        "grammar",
        "ValueError",
        "format",
        "grammar",
        "os",
        "path",
        "abspath",
        "os",
        "path",
        "dirname",
        "grammar",
        "os",
        "path",
        "splitext",
        "os",
        "path",
        "basename",
        "grammar",
        "format",
        "grammar_path",
        "grammar_name",
        "os",
        "path",
        "exists",
        "fsg_path",
        "Jsgf",
        "grammar",
        "jsgf",
        "get_rule",
        "format",
        "grammar_name",
        "jsgf",
        "build_fsg",
        "rule",
        "decoder",
        "get_logmath",
        "fsg",
        "writefile",
        "fsg_path",
        "FsgModel",
        "fsg_path",
        "decoder",
        "get_logmath",
        "decoder",
        "set_fsg",
        "grammar_name",
        "fsg",
        "decoder",
        "set_search",
        "grammar_name",
        "decoder",
        "start_utt",
        "decoder",
        "process_raw",
        "raw_data",
        "decoder",
        "end_utt",
        "show_all",
        "decoder",
        "decoder",
        "hyp",
        "hypothesis",
        "hypothesis",
        "hypstr",
        "UnknownValueError",
        "audio_data",
        "key",
        "language",
        "pfilter",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "key",
        "isinstance",
        "key",
        "isinstance",
        "language",
        "audio_data",
        "get_flac_data",
        "convert_rate",
        "audio_data",
        "sample_rate",
        "convert_width",
        "key",
        "format",
        "urlencode",
        "language",
        "key",
        "pfilter",
        "Request",
        "url",
        "data",
        "flac_data",
        "headers",
        "format",
        "audio_data",
        "sample_rate",
        "urlopen",
        "request",
        "timeout",
        "operation_timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "line",
        "response_text",
        "split",
        "line",
        "json",
        "loads",
        "line",
        "len",
        "result",
        "result",
        "show_all",
        "actual_result",
        "isinstance",
        "actual_result",
        "len",
        "actual_result",
        "get",
        "UnknownValueError",
        "actual_result",
        "max",
        "actual_result",
        "key",
        "alternative",
        "alternative",
        "actual_result",
        "best_hypothesis",
        "UnknownValueError",
        "best_hypothesis",
        "audio_data",
        "credentials_json",
        "language",
        "preferred_phrases",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "credentials_json",
        "os",
        "environ",
        "get",
        "isinstance",
        "language",
        "preferred_phrases",
        "all",
        "isinstance",
        "preferred_phrases",
        "preferred_phrases",
        "preferred_phrases",
        "socket",
        "google",
        "cloud",
        "speech",
        "google",
        "cloud",
        "speech",
        "enums",
        "google",
        "cloud",
        "speech",
        "types",
        "google",
        "api_core",
        "exceptions",
        "GoogleAPICallError",
        "ImportError",
        "RequestError",
        "credentials_json",
        "speech",
        "SpeechClient",
        "from_service_account_json",
        "credentials_json",
        "speech",
        "SpeechClient",
        "audio_data",
        "get_flac_data",
        "convert_rate",
        "audio_data",
        "sample_rate",
        "max",
        "min",
        "audio_data",
        "sample_rate",
        "convert_width",
        "types",
        "RecognitionAudio",
        "content",
        "flac_data",
        "enums",
        "RecognitionConfig",
        "AudioEncoding",
        "FLAC",
        "audio_data",
        "sample_rate",
        "language",
        "preferred_phrases",
        "types",
        "SpeechContext",
        "phrases",
        "preferred_phrases",
        "show_all",
        "operation_timeout",
        "socket",
        "getdefaulttimeout",
        "operation_timeout",
        "types",
        "RecognitionConfig",
        "config",
        "client",
        "recognize",
        "config",
        "audio",
        "opts",
        "GoogleAPICallError",
        "e",
        "RequestError",
        "e",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "show_all",
        "response",
        "len",
        "response",
        "results",
        "UnknownValueError",
        "result",
        "response",
        "results",
        "transcript",
        "result",
        "alternatives",
        "transcript",
        "strip",
        "transcript",
        "audio_data",
        "key",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "key",
        "audio_data",
        "get_wav_data",
        "convert_rate",
        "audio_data",
        "sample_rate",
        "convert_width",
        "Request",
        "url",
        "data",
        "wav_data",
        "headers",
        "format",
        "key",
        "urlopen",
        "request",
        "timeout",
        "operation_timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "json",
        "loads",
        "response_text",
        "show_all",
        "result",
        "result",
        "result",
        "UnknownValueError",
        "result",
        "audio_data",
        "key",
        "language",
        "result_format",
        "profanity",
        "location",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "key",
        "isinstance",
        "result_format",
        "isinstance",
        "language",
        "getattr",
        "getattr",
        "time",
        "monotonic",
        "ImportError",
        "monotonic",
        "monotonic",
        "ImportError",
        "RuntimeError",
        "expire_time",
        "monotonic",
        "expire_time",
        "location",
        "Request",
        "credential_url",
        "data",
        "headers",
        "key",
        "allow_caching",
        "monotonic",
        "urlopen",
        "credential_request",
        "timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "credential_response",
        "read",
        "decode",
        "allow_caching",
        "access_token",
        "start_time",
        "audio_data",
        "get_wav_data",
        "convert_rate",
        "convert_width",
        "location",
        "format",
        "urlencode",
        "language",
        "result_format",
        "profanity",
        "sys",
        "version_info",
        "Request",
        "url",
        "data",
        "io",
        "BytesIO",
        "wav_data",
        "headers",
        "format",
        "access_token",
        "format",
        "len",
        "wav_data",
        "encode",
        "ascii_hex_data_length",
        "wav_data",
        "Request",
        "url",
        "data",
        "chunked_transfer_encoding_data",
        "headers",
        "format",
        "access_token",
        "urlopen",
        "request",
        "timeout",
        "operation_timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "json",
        "loads",
        "response_text",
        "show_all",
        "result",
        "result",
        "result",
        "result",
        "UnknownValueError",
        "result",
        "audio_data",
        "key",
        "language",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "key",
        "isinstance",
        "language",
        "getattr",
        "getattr",
        "time",
        "monotonic",
        "ImportError",
        "monotonic",
        "monotonic",
        "ImportError",
        "RuntimeError",
        "expire_time",
        "monotonic",
        "expire_time",
        "Request",
        "credential_url",
        "data",
        "headers",
        "key",
        "allow_caching",
        "monotonic",
        "urlopen",
        "credential_request",
        "timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "credential_response",
        "read",
        "decode",
        "allow_caching",
        "access_token",
        "start_time",
        "audio_data",
        "get_wav_data",
        "convert_rate",
        "convert_width",
        "format",
        "urlencode",
        "language",
        "language",
        "uuid",
        "uuid4",
        "sys",
        "version_info",
        "Request",
        "url",
        "data",
        "io",
        "BytesIO",
        "wav_data",
        "headers",
        "format",
        "access_token",
        "format",
        "len",
        "wav_data",
        "encode",
        "ascii_hex_data_length",
        "wav_data",
        "Request",
        "url",
        "data",
        "chunked_transfer_encoding_data",
        "headers",
        "format",
        "access_token",
        "urlopen",
        "request",
        "timeout",
        "operation_timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "json",
        "loads",
        "response_text",
        "show_all",
        "result",
        "result",
        "result",
        "result",
        "UnknownValueError",
        "result",
        "audio_data",
        "bot_name",
        "bot_alias",
        "user_id",
        "content_type",
        "access_key_id",
        "secret_access_key",
        "region",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "bot_name",
        "isinstance",
        "bot_alias",
        "isinstance",
        "user_id",
        "isinstance",
        "content_type",
        "access_key_id",
        "isinstance",
        "access_key_id",
        "secret_access_key",
        "isinstance",
        "secret_access_key",
        "region",
        "isinstance",
        "region",
        "boto3",
        "ImportError",
        "RequestError",
        "boto3",
        "client",
        "aws_access_key_id",
        "access_key_id",
        "aws_secret_access_key",
        "secret_access_key",
        "region_name",
        "region",
        "audio_data",
        "get_raw_data",
        "convert_rate",
        "convert_width",
        "client",
        "post_content",
        "botName",
        "bot_name",
        "botAlias",
        "bot_alias",
        "userId",
        "user_id",
        "contentType",
        "content_type",
        "accept",
        "accept",
        "inputStream",
        "raw_data",
        "response",
        "audio_data",
        "client_id",
        "client_key",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "client_id",
        "isinstance",
        "client_key",
        "audio_data",
        "get_wav_data",
        "convert_rate",
        "audio_data",
        "sample_rate",
        "convert_width",
        "uuid",
        "uuid4",
        "uuid",
        "uuid4",
        "time",
        "time",
        "base64",
        "urlsafe_b64encode",
        "hmac",
        "base64",
        "urlsafe_b64decode",
        "client_key",
        "user_id",
        "encode",
        "request_id",
        "encode",
        "request_time",
        "encode",
        "hashlib",
        "sha256",
        "digest",
        "decode",
        "Request",
        "url",
        "data",
        "wav_data",
        "headers",
        "json",
        "dumps",
        "client_id",
        "user_id",
        "format",
        "user_id",
        "request_id",
        "format",
        "client_id",
        "request_time",
        "request_signature",
        "urlopen",
        "request",
        "timeout",
        "operation_timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "json",
        "loads",
        "response_text",
        "show_all",
        "result",
        "result",
        "result",
        "UnknownValueError",
        "result",
        "audio_data",
        "username",
        "password",
        "language",
        "show_all",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "username",
        "isinstance",
        "password",
        "audio_data",
        "get_flac_data",
        "convert_rate",
        "audio_data",
        "sample_rate",
        "convert_width",
        "audio_data",
        "sample_width",
        "format",
        "urlencode",
        "format",
        "language",
        "Request",
        "url",
        "data",
        "flac_data",
        "headers",
        "base64",
        "standard_b64encode",
        "format",
        "username",
        "password",
        "encode",
        "decode",
        "request",
        "add_header",
        "format",
        "authorization_value",
        "urlopen",
        "request",
        "timeout",
        "operation_timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "json",
        "loads",
        "response_text",
        "show_all",
        "result",
        "result",
        "len",
        "result",
        "result",
        "UnknownValueError",
        "utterance",
        "result",
        "utterance",
        "UnknownValueError",
        "hypothesis",
        "utterance",
        "hypothesis",
        "transcription",
        "append",
        "hypothesis",
        "join",
        "transcription",
        "audio_data",
        "tensor_graph",
        "tensor_label",
        "isinstance",
        "audio_data",
        "AudioData",
        "isinstance",
        "tensor_graph",
        "isinstance",
        "tensor_label",
        "tensorflow",
        "tf",
        "ImportError",
        "RequestError",
        "tensor_graph",
        "lasttfgraph",
        "tensor_graph",
        "tf",
        "gfile",
        "FastGFile",
        "tensor_graph",
        "f",
        "tf",
        "GraphDef",
        "graph_def",
        "ParseFromString",
        "f",
        "read",
        "tf",
        "import_graph_def",
        "graph_def",
        "name",
        "line",
        "rstrip",
        "line",
        "tf",
        "gfile",
        "GFile",
        "tensor_label",
        "audio_data",
        "get_wav_data",
        "convert_rate",
        "convert_width",
        "tf",
        "Session",
        "sess",
        "sess",
        "graph",
        "get_tensor_by_name",
        "output_layer_name",
        "sess",
        "run",
        "softmax_tensor",
        "input_layer_name",
        "wav_data",
        "predictions",
        "argsort",
        "node_id",
        "top_k",
        "tflabels",
        "node_id",
        "human_string",
        "shutil_which",
        "flac_converter",
        "os",
        "path",
        "dirname",
        "os",
        "path",
        "abspath",
        "platform",
        "system",
        "platform",
        "machine",
        "system",
        "machine",
        "os",
        "path",
        "join",
        "base_path",
        "system",
        "machine",
        "os",
        "path",
        "join",
        "base_path",
        "system",
        "machine",
        "os",
        "path",
        "join",
        "base_path",
        "system",
        "machine",
        "os",
        "path",
        "join",
        "base_path",
        "OSError",
        "os",
        "access",
        "flac_converter",
        "os",
        "X_OK",
        "os",
        "stat",
        "flac_converter",
        "os",
        "chmod",
        "flac_converter",
        "stat_info",
        "st_mode",
        "stat",
        "S_IEXEC",
        "platform",
        "system",
        "os",
        "sync",
        "sys",
        "version_info",
        "os",
        "system",
        "OSError",
        "flac_converter",
        "pgm",
        "os",
        "getenv",
        "p",
        "path",
        "split",
        "os",
        "path",
        "pathsep",
        "os",
        "path",
        "join",
        "p",
        "pgm",
        "os",
        "path",
        "exists",
        "p",
        "os",
        "access",
        "p",
        "os",
        "X_OK",
        "p",
        "mode",
        "mode",
        "tempfile",
        "tempfile",
        "mkstemp",
        "os",
        "fdopen",
        "file_descriptor",
        "mode",
        "file_path",
        "exc_type",
        "exc_value",
        "traceback",
        "_file",
        "close",
        "os",
        "remove",
        "name",
        "args",
        "kwargs",
        "_file",
        "write",
        "args",
        "kwargs",
        "args",
        "kwargs",
        "_file",
        "writelines",
        "args",
        "kwargs",
        "args",
        "kwargs",
        "_file",
        "flush",
        "args",
        "kwargs",
        "AudioFile",
        "audio_data",
        "client_access_token",
        "language",
        "session_id",
        "show_all",
        "audio_data",
        "get_wav_data",
        "convert_rate",
        "convert_width",
        "uuid",
        "uuid4",
        "hex",
        "boundary",
        "encode",
        "wav_data",
        "session_id",
        "uuid",
        "uuid4",
        "hex",
        "boundary",
        "encode",
        "session_id",
        "encode",
        "language",
        "encode",
        "boundary",
        "encode",
        "wav_data",
        "boundary",
        "encode",
        "Request",
        "url",
        "data",
        "data",
        "headers",
        "format",
        "client_access_token",
        "len",
        "data",
        "format",
        "boundary",
        "urlopen",
        "request",
        "timeout",
        "HTTPError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "URLError",
        "e",
        "RequestError",
        "format",
        "e",
        "reason",
        "response",
        "read",
        "decode",
        "json",
        "loads",
        "response_text",
        "show_all",
        "result",
        "result",
        "result",
        "result",
        "UnknownValueError",
        "result",
        "classmethod",
        "recognize_api"
    ],
    "literals": [
        "\"Anthony Zhang (Uberi)\"",
        "\"3.8.1\"",
        "\"BSD\"",
        "\"this is an abstract class\"",
        "\"this is an abstract class\"",
        "\"this is an abstract class\"",
        "\"Device index must be None or an integer\"",
        "\"Sample rate must be None or a positive integer\"",
        "\"Chunk size must be a positive integer\"",
        "\"Device index out of range ({} devices available; device index should be between 0 and {} inclusive)\"",
        "\"defaultSampleRate\"",
        "\"defaultSampleRate\"",
        "\"Invalid device info returned from PyAudio: {}\"",
        "\"defaultSampleRate\"",
        "\"Could not find PyAudio; check installation\"",
        "\"0.2.11\"",
        "\"PyAudio 0.2.11 or later is required (found version {})\"",
        "\"name\"",
        "\"name\"",
        "\"defaultSampleRate\"",
        "\"defaultSampleRate\"",
        "\"Invalid device info returned from PyAudio: {}\"",
        "\"defaultSampleRate\"",
        "\"This audio source is already inside a context manager\"",
        "\"\"",
        "u\"\"",
        "\"read\"",
        "\"Given audio file must be a filename string or a file-like object\"",
        "\"This audio source is already inside a context manager\"",
        "\"rb\"",
        "\"rb\"",
        "\"read\"",
        "\"rb\"",
        "\"nt\"",
        "\"--stdout\"",
        "\"--totally-silent\"",
        "\"--decode\"",
        "\"--force-aiff-format\"",
        "\"-\"",
        "\"rb\"",
        "\"Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\"",
        "\"Audio must be mono or stereo\"",
        "b\"\"",
        "\"read\"",
        "b\"\"",
        "\"byteswap\"",
        "b\"\"",
        "b\"\"",
        "b\"\\x00\"",
        "\"Sample rate must be a positive integer\"",
        "\"Sample width must be between 1 and 4 inclusive\"",
        "\"``start_ms`` must be a non-negative number\"",
        "\"``end_ms`` must be a non-negative number greater or equal to ``start_ms``\"",
        "\"Sample rate to convert to must be a positive integer\"",
        "\"Sample width to convert to must be between 1 and 4 inclusive\"",
        "b\"\"",
        "b\"\"",
        "\"wb\"",
        "\"byteswap\"",
        "b\"\"",
        "\"wb\"",
        "\"Sample width to convert to must be between 1 and 3 inclusive\"",
        "\"nt\"",
        "\"--stdout\"",
        "\"--totally-silent\"",
        "\"--best\"",
        "\"-\"",
        "\"Source must be an audio source\"",
        "\"Audio source must be entered before recording, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?\"",
        "\"Source must be an audio source\"",
        "\"Audio source must be entered before adjusting, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?\"",
        "\"resources\"",
        "\"common.res\"",
        "\",\"",
        "\",\"",
        "\"0.4\"",
        "\"listening timed out while waiting for hotword to be said\"",
        "b\"\"",
        "\"Error initializing streams or reading audio data\"",
        "b\"\"",
        "\"Source must be an audio source\"",
        "\"Audio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?\"",
        "\"snowboydetect.py\"",
        "\"``snowboy_configuration[0]`` must be a Snowboy root directory containing ``snowboydetect.py``\"",
        "\"``snowboy_configuration[1]`` must be a list of Snowboy hot word configuration files\"",
        "b\"\"",
        "\"listening timed out while waiting for phrase to start\"",
        "b\"\"",
        "\"Source must be an audio source\"",
        "\"en-US\"",
        "\"``audio_data`` must be audio data\"",
        "\"``language`` must be a string or 3-tuple of Sphinx data file paths of the form ``(acoustic_parameters, language_model, phoneme_dictionary)``\"",
        "\"\"",
        "u\"\"",
        "\"``keyword_entries`` must be ``None`` or a list of pairs of strings and numbers between 0 and 1\"",
        "\"missing PocketSphinx module: ensure that PocketSphinx is set up correctly.\"",
        "\"bad PocketSphinx installation; try reinstalling PocketSphinx version 0.0.9 or better.\"",
        "\"Decoder\"",
        "\"default_config\"",
        "\"outdated PocketSphinx installation; ensure you have PocketSphinx version 0.0.9 or better.\"",
        "\"pocketsphinx-data\"",
        "\"missing PocketSphinx language data directory: \\\"{}\\\"\"",
        "\"acoustic-model\"",
        "\"language-model.lm\"",
        "\"pronounciation-dictionary.dic\"",
        "\"missing PocketSphinx language model parameters directory: \\\"{}\\\"\"",
        "\"missing PocketSphinx language model file: \\\"{}\\\"\"",
        "\"missing PocketSphinx phoneme dictionary file: \\\"{}\\\"\"",
        "\"-hmm\"",
        "\"-lm\"",
        "\"-dict\"",
        "\"-logfn\"",
        "\"w\"",
        "\"{} /1e{}/\\n\"",
        "\"keywords\"",
        "\"keywords\"",
        "\"Grammar '{0}' does not exist.\"",
        "\"{0}/{1}.fsg\"",
        "\"{0}.{0}\"",
        "\"en-US\"",
        "\"``audio_data`` must be audio data\"",
        "\"``key`` must be ``None`` or a string\"",
        "\"``language`` must be a string\"",
        "\"AIzaSyBOti4mM-6x9WDnZIjIeyEU21OpBXqWBgw\"",
        "\"http://www.google.com/speech-api/v2/recognize?{}\"",
        "\"client\"",
        "\"chromium\"",
        "\"lang\"",
        "\"key\"",
        "\"pFilter\"",
        "\"Content-Type\"",
        "\"audio/x-flac; rate={}\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"\\n\"",
        "\"result\"",
        "\"alternative\"",
        "\"confidence\"",
        "\"alternative\"",
        "\"alternative\"",
        "\"confidence\"",
        "\"alternative\"",
        "\"transcript\"",
        "\"transcript\"",
        "\"en-US\"",
        "\"``audio_data`` must be audio data\"",
        "'GOOGLE_APPLICATION_CREDENTIALS'",
        "\"``language`` must be a string\"",
        "\"\"",
        "u\"\"",
        "\"``preferred_phrases`` must be a list of strings\"",
        "'missing google-cloud-speech module: ensure that google-cloud-speech is set up correctly.'",
        "'encoding'",
        "'sample_rate_hertz'",
        "'language_code'",
        "'speechContexts'",
        "'enableWordTimeOffsets'",
        "'timeout'",
        "\"recognition connection failed: {0}\"",
        "''",
        "' '",
        "\"Data must be audio data\"",
        "\"``key`` must be a string\"",
        "\"https://api.wit.ai/speech?v=20170307\"",
        "\"Authorization\"",
        "\"Bearer {}\"",
        "\"Content-Type\"",
        "\"audio/wav\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"_text\"",
        "\"_text\"",
        "\"_text\"",
        "\"en-US\"",
        "\"simple\"",
        "\"masked\"",
        "\"westus\"",
        "\"Data must be audio data\"",
        "\"``key`` must be a string\"",
        "\"``format`` must be a string\"",
        "\"``language`` must be a string\"",
        "\"azure_cached_access_token\"",
        "\"azure_cached_access_token_expiry\"",
        "\"https://\"",
        "\".api.cognitive.microsoft.com/sts/v1.0/issueToken\"",
        "b\"\"",
        "\"Content-type\"",
        "\"application/x-www-form-urlencoded\"",
        "\"Content-Length\"",
        "\"0\"",
        "\"Ocp-Apim-Subscription-Key\"",
        "\"credential request failed: {}\"",
        "\"credential connection failed: {}\"",
        "\"utf-8\"",
        "\"https://\"",
        "\".stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?{}\"",
        "\"language\"",
        "\"format\"",
        "\"profanity\"",
        "\"Authorization\"",
        "\"Bearer {}\"",
        "\"Content-type\"",
        "\"audio/wav; codec=\\\"audio/pcm\\\"; samplerate=16000\"",
        "\"Transfer-Encoding\"",
        "\"chunked\"",
        "\"{:X}\"",
        "\"utf-8\"",
        "b\"\\r\\n\"",
        "b\"\\r\\n0\\r\\n\\r\\n\"",
        "\"Authorization\"",
        "\"Bearer {}\"",
        "\"Content-type\"",
        "\"audio/wav; codec=\\\"audio/pcm\\\"; samplerate=16000\"",
        "\"Transfer-Encoding\"",
        "\"chunked\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"RecognitionStatus\"",
        "\"RecognitionStatus\"",
        "\"Success\"",
        "\"DisplayText\"",
        "\"DisplayText\"",
        "\"en-US\"",
        "\"Data must be audio data\"",
        "\"``key`` must be a string\"",
        "\"``language`` must be a string\"",
        "\"bing_cached_access_token\"",
        "\"bing_cached_access_token_expiry\"",
        "\"https://api.cognitive.microsoft.com/sts/v1.0/issueToken\"",
        "b\"\"",
        "\"Content-type\"",
        "\"application/x-www-form-urlencoded\"",
        "\"Content-Length\"",
        "\"0\"",
        "\"Ocp-Apim-Subscription-Key\"",
        "\"credential request failed: {}\"",
        "\"credential connection failed: {}\"",
        "\"utf-8\"",
        "\"https://speech.platform.bing.com/speech/recognition/interactive/cognitiveservices/v1?{}\"",
        "\"language\"",
        "\"locale\"",
        "\"requestid\"",
        "\"Authorization\"",
        "\"Bearer {}\"",
        "\"Content-type\"",
        "\"audio/wav; codec=\\\"audio/pcm\\\"; samplerate=16000\"",
        "\"Transfer-Encoding\"",
        "\"chunked\"",
        "\"{:X}\"",
        "\"utf-8\"",
        "b\"\\r\\n\"",
        "b\"\\r\\n0\\r\\n\\r\\n\"",
        "\"Authorization\"",
        "\"Bearer {}\"",
        "\"Content-type\"",
        "\"audio/wav; codec=\\\"audio/pcm\\\"; samplerate=16000\"",
        "\"Transfer-Encoding\"",
        "\"chunked\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"RecognitionStatus\"",
        "\"RecognitionStatus\"",
        "\"Success\"",
        "\"DisplayText\"",
        "\"DisplayText\"",
        "\"audio/l16; rate=16000; channels=1\"",
        "\"Data must be audio data\"",
        "\"``bot_name`` must be a string\"",
        "\"``bot_alias`` must be a string\"",
        "\"``user_id`` must be a string\"",
        "\"``content_type`` must be a string\"",
        "\"``access_key_id`` must be a string\"",
        "\"``secret_access_key`` must be a string\"",
        "\"``region`` must be a string\"",
        "\"missing boto3 module: ensure that boto3 is set up correctly.\"",
        "'lex-runtime'",
        "\"text/plain; charset=utf-8\"",
        "\"inputTranscript\"",
        "\"Data must be audio data\"",
        "\"``client_id`` must be a string\"",
        "\"``client_key`` must be a string\"",
        "\"https://api.houndify.com/v1/audio\"",
        "\"utf-8\"",
        "b\";\"",
        "\"utf-8\"",
        "\"utf-8\"",
        "\"utf-8\"",
        "\"Content-Type\"",
        "\"application/json\"",
        "\"Hound-Request-Info\"",
        "\"ClientID\"",
        "\"UserID\"",
        "\"Hound-Request-Authentication\"",
        "\"{};{}\"",
        "\"Hound-Client-Authentication\"",
        "\"{};{};{}\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"Disambiguation\"",
        "\"Disambiguation\"",
        "'Disambiguation'",
        "'ChoiceData'",
        "'Transcription'",
        "\"en-US\"",
        "\"Data must be audio data\"",
        "\"``username`` must be a string\"",
        "\"``password`` must be a string\"",
        "\"https://stream.watsonplatform.net/speech-to-text/api/v1/recognize?{}\"",
        "\"profanity_filter\"",
        "\"false\"",
        "\"model\"",
        "\"{}_BroadbandModel\"",
        "\"inactivity_timeout\"",
        "\"Content-Type\"",
        "\"audio/x-flac\"",
        "\"X-Watson-Learning-Opt-Out\"",
        "\"true\"",
        "\"{}:{}\"",
        "\"utf-8\"",
        "\"utf-8\"",
        "\"Authorization\"",
        "\"Basic {}\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"results\"",
        "\"results\"",
        "\"alternatives\"",
        "\"results\"",
        "\"results\"",
        "\"alternatives\"",
        "\"alternatives\"",
        "\"transcript\"",
        "\"transcript\"",
        "\"\\n\"",
        "''",
        "'tensorflow-data/conv_actions_frozen.pb'",
        "'tensorflow-data/conv_actions_labels.txt'",
        "\"Data must be audio data\"",
        "\"``tensor_graph`` must be a string\"",
        "\"``tensor_label`` must be a string\"",
        "\"missing tensorflow module: ensure that tensorflow is set up correctly.\"",
        "'rb'",
        "''",
        "'wav_data:0'",
        "'labels_softmax:0'",
        "\"flac\"",
        "\"Windows\"",
        "\"i686\"",
        "\"i786\"",
        "\"x86\"",
        "\"x86_64\"",
        "\"AMD64\"",
        "\"flac-win32.exe\"",
        "\"Darwin\"",
        "\"i686\"",
        "\"i786\"",
        "\"x86\"",
        "\"x86_64\"",
        "\"AMD64\"",
        "\"flac-mac\"",
        "\"Linux\"",
        "\"i686\"",
        "\"i786\"",
        "\"x86\"",
        "\"flac-linux-x86\"",
        "\"Linux\"",
        "\"x86_64\"",
        "\"AMD64\"",
        "\"flac-linux-x86_64\"",
        "\"FLAC conversion utility not available - consider installing the FLAC command line application by running `apt-get install flac` or your operating system's equivalent\"",
        "'Linux'",
        "'sync'",
        "'PATH'",
        "\"w+b\"",
        "\"en\"",
        "\"https://api.api.ai/v1/query\"",
        "\"utf-8\"",
        "b\"--\"",
        "\"utf-8\"",
        "b\"\\r\\n\"",
        "b\"Content-Disposition: form-data; name=\\\"request\\\"\\r\\n\"",
        "b\"Content-Type: application/json\\r\\n\"",
        "b\"\\r\\n\"",
        "b\"{\\\"v\\\": \\\"20150910\\\", \\\"sessionId\\\": \\\"\"",
        "\"utf-8\"",
        "b\"\\\", \\\"lang\\\": \\\"\"",
        "\"utf-8\"",
        "b\"\\\"}\\r\\n\"",
        "b\"--\"",
        "\"utf-8\"",
        "b\"\\r\\n\"",
        "b\"Content-Disposition: form-data; name=\\\"voiceData\\\"; filename=\\\"audio.wav\\\"\\r\\n\"",
        "b\"Content-Type: audio/wav\\r\\n\"",
        "b\"\\r\\n\"",
        "b\"\\r\\n\"",
        "b\"--\"",
        "\"utf-8\"",
        "b\"--\\r\\n\"",
        "\"Authorization\"",
        "\"Bearer {}\"",
        "\"Content-Length\"",
        "\"Expect\"",
        "\"100-continue\"",
        "\"Content-Type\"",
        "\"multipart/form-data; boundary={}\"",
        "\"recognition request failed: {}\"",
        "\"recognition connection failed: {}\"",
        "\"utf-8\"",
        "\"status\"",
        "\"errorType\"",
        "\"status\"",
        "\"status\"",
        "\"errorType\"",
        "\"success\"",
        "\"result\"",
        "\"resolvedQuery\""
    ],
    "variables": [
        "__author__",
        "__version__",
        "__license__",
        "pyaudio_module",
        "audio",
        "count",
        "device_info",
        "sample_rate",
        "device_index",
        "format",
        "SAMPLE_WIDTH",
        "SAMPLE_RATE",
        "CHUNK",
        "audio",
        "stream",
        "audio",
        "result",
        "device_info",
        "pyaudio_module",
        "audio",
        "result",
        "device_info",
        "device_name",
        "pyaudio_stream",
        "buffer",
        "energy",
        "energy_bytes",
        "debiased_energy",
        "result",
        "device_index",
        "audio",
        "stream",
        "stream",
        "pyaudio_stream",
        "filename_or_fileobject",
        "stream",
        "DURATION",
        "audio_reader",
        "little_endian",
        "SAMPLE_RATE",
        "CHUNK",
        "FRAME_COUNT",
        "audio_reader",
        "little_endian",
        "audio_reader",
        "little_endian",
        "flac_data",
        "flac_data",
        "flac_converter",
        "startup_info",
        "startup_info",
        "wShowWindow",
        "startup_info",
        "process",
        "aiff_data",
        "_",
        "aiff_file",
        "audio_reader",
        "little_endian",
        "SAMPLE_WIDTH",
        "samples_24_bit_pretending_to_be_32_bit",
        "samples_24_bit_pretending_to_be_32_bit",
        "SAMPLE_WIDTH",
        "SAMPLE_RATE",
        "CHUNK",
        "FRAME_COUNT",
        "DURATION",
        "stream",
        "stream",
        "DURATION",
        "audio_reader",
        "little_endian",
        "samples_24_bit_pretending_to_be_32_bit",
        "buffer",
        "buffer",
        "sample_width",
        "buffer",
        "buffer",
        "buffer",
        "sample_width",
        "buffer",
        "frame_data",
        "sample_rate",
        "sample_width",
        "start_byte",
        "start_byte",
        "end_byte",
        "end_byte",
        "raw_data",
        "raw_data",
        "raw_data",
        "_",
        "raw_data",
        "raw_data",
        "raw_data",
        "raw_data",
        "raw_data",
        "raw_data",
        "sample_rate",
        "sample_width",
        "wav_writer",
        "wav_data",
        "raw_data",
        "sample_rate",
        "sample_width",
        "raw_data",
        "raw_data",
        "aiff_writer",
        "aiff_data",
        "convert_width",
        "wav_data",
        "flac_converter",
        "startup_info",
        "startup_info",
        "wShowWindow",
        "startup_info",
        "process",
        "flac_data",
        "stderr",
        "energy_threshold",
        "dynamic_energy_threshold",
        "dynamic_energy_adjustment_damping",
        "dynamic_energy_ratio",
        "pause_threshold",
        "operation_timeout",
        "phrase_threshold",
        "non_speaking_duration",
        "frames",
        "seconds_per_buffer",
        "elapsed_time",
        "offset_time",
        "offset_reached",
        "offset_reached",
        "buffer",
        "frame_data",
        "seconds_per_buffer",
        "elapsed_time",
        "buffer",
        "energy",
        "damping",
        "target_energy",
        "energy_threshold",
        "detector",
        "snowboy_sample_rate",
        "elapsed_time",
        "seconds_per_buffer",
        "resampling_state",
        "five_seconds_buffer_count",
        "half_second_buffer_count",
        "frames",
        "resampled_frames",
        "check_interval",
        "last_check",
        "buffer",
        "resampled_buffer",
        "resampling_state",
        "snowboy_result",
        "last_check",
        "seconds_per_buffer",
        "pause_buffer_count",
        "phrase_buffer_count",
        "non_speaking_buffer_count",
        "elapsed_time",
        "buffer",
        "frames",
        "buffer",
        "energy",
        "damping",
        "target_energy",
        "energy_threshold",
        "snowboy_location",
        "snowboy_hot_word_files",
        "buffer",
        "delta_time",
        "pause_count",
        "phrase_count",
        "phrase_start_time",
        "buffer",
        "energy",
        "pause_count",
        "frame_data",
        "running",
        "audio",
        "running",
        "listener_thread",
        "listener_thread",
        "daemon",
        "language_directory",
        "acoustic_parameters_directory",
        "language_model_file",
        "phoneme_dictionary_file",
        "acoustic_parameters_directory",
        "language_model_file",
        "phoneme_dictionary_file",
        "config",
        "decoder",
        "raw_data",
        "grammar_path",
        "grammar_name",
        "fsg_path",
        "jsgf",
        "rule",
        "fsg",
        "fsg",
        "hypothesis",
        "flac_data",
        "key",
        "url",
        "request",
        "response",
        "response_text",
        "actual_result",
        "result",
        "actual_result",
        "best_hypothesis",
        "best_hypothesis",
        "client",
        "client",
        "flac_data",
        "audio",
        "config",
        "config",
        "config",
        "opts",
        "opts",
        "config",
        "response",
        "transcript",
        "wav_data",
        "url",
        "request",
        "response",
        "response_text",
        "result",
        "access_token",
        "expire_time",
        "allow_caching",
        "expire_time",
        "allow_caching",
        "credential_url",
        "credential_request",
        "start_time",
        "credential_response",
        "access_token",
        "azure_cached_access_token",
        "azure_cached_access_token_expiry",
        "wav_data",
        "url",
        "request",
        "ascii_hex_data_length",
        "chunked_transfer_encoding_data",
        "request",
        "response",
        "response_text",
        "result",
        "access_token",
        "expire_time",
        "allow_caching",
        "expire_time",
        "allow_caching",
        "credential_url",
        "credential_request",
        "start_time",
        "credential_response",
        "access_token",
        "bing_cached_access_token",
        "bing_cached_access_token_expiry",
        "wav_data",
        "url",
        "request",
        "ascii_hex_data_length",
        "chunked_transfer_encoding_data",
        "request",
        "response",
        "response_text",
        "result",
        "client",
        "raw_data",
        "accept",
        "response",
        "wav_data",
        "url",
        "user_id",
        "request_id",
        "request_time",
        "request_signature",
        "request",
        "response",
        "response_text",
        "result",
        "flac_data",
        "url",
        "request",
        "authorization_value",
        "response",
        "response_text",
        "result",
        "transcription",
        "lasttfgraph",
        "tflabels",
        "lasttfgraph",
        "graph_def",
        "tflabels",
        "wav_data",
        "input_layer_name",
        "output_layer_name",
        "softmax_tensor",
        "predictions",
        "top_k",
        "human_string",
        "flac_converter",
        "base_path",
        "system",
        "machine",
        "flac_converter",
        "flac_converter",
        "flac_converter",
        "flac_converter",
        "stat_info",
        "path",
        "p",
        "mode",
        "file_descriptor",
        "file_path",
        "_file",
        "name",
        "WavFile",
        "wav_data",
        "url",
        "boundary",
        "session_id",
        "data",
        "request",
        "response",
        "response_text",
        "result",
        "Recognizer",
        "recognize_api"
    ],
    "comments": [
        "!/usr/bin/env python3",
        "attempt to use the Python 2 modules",
        "use the Python 3 modules",
        "set up PyAudio",
        "obtain device count",
        "ensure device index is in range",
        "automatically set the sample rate to the hardware's default sample rate if not specified",
        "16-bit int sampling",
        "size of each sample",
        "sampling rate in Hertz",
        "number of frames stored in each buffer",
        "read audio",
        "compute RMS of debiased audio",
        "Python 2 compatibility",
        "probably actually audio",
        "sometimes, if the stream isn't stopped, closing the stream throws an exception",
        "attempt to read the file as WAV",
        "RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)",
        "attempt to read the file as AIFF",
        "AIFF is a big-endian format",
        "attempt to read the file as FLAC",
        "run the FLAC converter with the FLAC data to get the AIFF data",
        "on Windows, specify that the process is to be started without showing a console window",
        "specify that the wShowWindow field of `startup_info` contains a value",
        "specify that the console window should be hidden",
        "default startupinfo",
        "put the resulting AIFF file in stdout, and make sure it's not mixed with any program output",
        "decode the FLAC file into an AIFF file",
        "the input FLAC file contents will be given in stdin",
        "AIFF is a big-endian format",
        "24-bit audio needs some special handling for old Python versions (workaround for https://bugs.python.org/issue12866)",
        "24-bit audio",
        "test whether this sample width is supported (for example, ``audioop`` in Python 3.3 and below don't support sample width 3, while Python 3.4+ do)",
        "this version of audioop doesn't support 24-bit audio (probably Python 3.3 or less)",
        "while the ``AudioFile`` instance will outwardly appear to be 32-bit, it will actually internally be 24-bit",
        "the ``AudioFile`` instance should present itself as a 32-bit stream now, since we'll be converting into 32-bit on the fly when reading",
        "only close the file if it was opened by this class in the first place (if the file was originally given as a path)",
        "an audio file object (e.g., a `wave.Wave_read` instance)",
        "whether the audio data is little-endian (when working with big-endian things, we'll have to convert it to little-endian before we process it)",
        "this is true if the audio is 24-bit audio, but 24-bit audio isn't supported, so we have to pretend that this is 32-bit audio and convert it on the fly",
        "workaround for https://bugs.python.org/issue24608",
        "big endian format, convert to little endian on the fly",
        "``audioop.byteswap`` was only added in Python 3.4 (incidentally, that also means that we don't need to worry about 24-bit audio being unsupported, since Python 3.4+ always has that functionality)",
        "manually reverse the bytes of each sample, which is slower but works well enough as a fallback",
        "workaround for https://bugs.python.org/issue12866",
        "we need to convert samples from 24-bit to 32-bit before we can process them with ``audioop`` functions",
        "since we're in little endian, we prepend a zero byte to each 24-bit sample to get a 32-bit sample",
        "make sure we thread the buffer as 32-bit audio now, after converting it from 24-bit audio",
        "stereo audio",
        "convert stereo audio data to mono",
        "make sure unsigned 8-bit audio (which uses unsigned samples) is handled like higher sample width audio (which uses signed samples)",
        "subtract 128 from every sample to make them act like signed samples",
        "resample audio at the desired rate if specified",
        "convert samples to desired sample width if specified",
        "we're converting the audio into 24-bit (workaround for https://bugs.python.org/issue12866)",
        "convert audio into 32-bit first, which is always supported",
        "test whether 24-bit audio is supported (for example, ``audioop`` in Python 3.3 and below don't support sample width 3, while Python 3.4+ do)",
        "this version of audioop doesn't support 24-bit audio (probably Python 3.3 or less)",
        "since we're in little endian, we discard the first byte from each 32-bit sample to get a 24-bit sample",
        "24-bit audio fully supported, we don't need to shim anything",
        "if the output is 8-bit audio with unsigned samples, convert the samples we've been treating as signed to unsigned again",
        "add 128 to every sample to make them act like unsigned samples again",
        "generate the WAV file contents",
        "note that we can't use context manager, since that was only added in Python 3.4",
        "make sure resources are cleaned up",
        "the AIFF format is big-endian, so we need to covnert the little-endian raw data to big-endian",
        "``audioop.byteswap`` was only added in Python 3.4",
        "manually reverse the bytes of each sample, which is slower but works well enough as a fallback",
        "generate the AIFF-C file contents",
        "note that we can't use context manager, since that was only added in Python 3.4",
        "make sure resources are cleaned up",
        "resulting WAV data would be 32-bit, which is not convertable to FLAC using our encoder",
        "the largest supported sample width is 24-bit, so we'll limit the sample width to that",
        "run the FLAC converter with the WAV data to get the FLAC data",
        "on Windows, specify that the process is to be started without showing a console window",
        "specify that the wShowWindow field of `startup_info` contains a value",
        "specify that the console window should be hidden",
        "default startupinfo",
        "put the resulting FLAC file in stdout, and make sure it's not mixed with any program output",
        "highest level of compression available",
        "the input FLAC file contents will be given in stdin",
        "minimum audio energy to consider for recording",
        "seconds of non-speaking audio before a phrase is considered complete",
        "seconds after an internal operation (e.g., an API request) starts before it times out, or ``None`` for no timeout",
        "minimum seconds of speaking audio before we consider the speaking audio a phrase - values below this are ignored (for filtering out clicks and pops)",
        "seconds of non-speaking audio to keep on both sides of the recording",
        "loop for the total number of chunks needed",
        "adjust energy threshold until a phrase starts",
        "energy of the audio signal",
        "dynamically adjust the energy threshold using asymmetric weighted average",
        "account for different chunk sizes and rates",
        "load snowboy library (NOT THREAD SAFE)",
        "buffers capable of holding 5 seconds of original audio",
        "buffers capable of holding 0.5 seconds of resampled audio",
        "snowboy check interval",
        "reached end of the stream",
        "resample audio to the required sample rate",
        "run Snowboy on the resampled audio",
        "wake word found",
        "number of buffers of non-speaking audio during a phrase, before the phrase should be considered complete",
        "minimum number of buffers of speaking audio before we consider the speaking audio a phrase",
        "maximum number of buffers of non-speaking audio to retain before and after a phrase",
        "read audio input for phrases until there is a phrase that is long enough",
        "number of seconds of audio read",
        "an empty buffer means that the stream has ended and there is no data left to read",
        "store audio input until the phrase starts",
        "handle waiting too long for phrase by raising an exception",
        "reached end of the stream",
        "ensure we only keep the needed amount of non-speaking buffers",
        "detect whether speaking has started on audio input",
        "energy of the audio signal",
        "dynamically adjust the energy threshold using asymmetric weighted average",
        "account for different chunk sizes and rates",
        "read audio input until the hotword is said",
        "reached end of the stream",
        "read audio input until the phrase ends",
        "handle phrase being too long by cutting off the audio",
        "reached end of the stream",
        "check if speaking has stopped for longer than the pause threshold on the audio input",
        "unit energy of the audio signal within the buffer",
        "end of the phrase",
        "check how long the detected phrase is, and retry listening if the phrase is too short",
        "exclude the buffers for the pause before the phrase",
        "phrase is long enough or we've reached the end of the stream, so stop listening",
        "obtain frame data",
        "remove extra non-speaking frames at the end",
        "print(\"type of frame data\")",
        "print(type(frame_data))",
        "listen for 1 second, then check again if the stop function has been called",
        "listening timed out, just try again",
        "block until the background thread is done, which can take around 1 second",
        "import the PocketSphinx speech recognition module",
        "directory containing language data",
        "3-tuple of Sphinx data file paths",
        "create decoder object",
        "set the path of the hidden Markov model (HMM) parameter files",
        "disable logging (logging causes unwanted output in terminal)",
        "obtain audio data",
        "the included language models require audio to be 16-bit mono 16 kHz in little-endian format",
        "obtain recognition results",
        "explicitly specified set of keywords",
        "generate a keywords file - Sphinx documentation recommendeds sensitivities between 1e-50 and 1e-5",
        "perform the speech recognition with the keywords file (this is inside the context manager so the file isn;t deleted until we're done)",
        "a path to a FSG or JSGF grammar",
        "create FSG grammar if not available",
        "begin utterance processing",
        "process audio data with recognition enabled (no_search = False), as a full utterance (full_utt = True)",
        "stop utterance processing",
        "return results",
        "no transcriptions available",
        "audio samples must be at least 8 kHz",
        "audio samples must be 16-bit",
        "obtain audio transcription results",
        "ignore any blank blocks",
        "return results",
        "return alternative with highest confidence score",
        "when there is no confidence available, we arbitrarily choose the first hypothesis.",
        "audio sample rate must be between 8 kHz and 48 kHz inclusive - clamp sample rate into this range",
        "audio samples must be 16-bit",
        "some useful extra options for when we want all the output",
        "audio samples must be at least 8 kHz",
        "audio samples should be 16-bit",
        "return results",
        "we need monotonic time to avoid being affected by system clock changes, but this is only available in Python 3.3+",
        "use time.monotonic backport for Python 2 if available (from https://pypi.python.org/pypi/monotonic)",
        "monotonic time not available, don't cache access tokens",
        "don't allow caching, since monotonic time isn't available",
        "caching not enabled, first credential request, or the access token from the previous one expired",
        "get an access token using OAuth",
        "credential response can take longer, use longer timeout instead of default one",
        "save the token for the duration it is valid for",
        "according to https://docs.microsoft.com/en-us/azure/cognitive-services/Speech-Service/rest-apis#authentication, the token expires in exactly 10 minutes",
        "audio samples must be 8kHz or 16 kHz",
        "audio samples should be 16-bit",
        "chunked-transfer requests are only supported in the standard library as of Python 3.6+, use it if possible",
        "fall back on manually formatting the POST body as a chunked request",
        "return results",
        "we need monotonic time to avoid being affected by system clock changes, but this is only available in Python 3.3+",
        "use time.monotonic backport for Python 2 if available (from https://pypi.python.org/pypi/monotonic)",
        "monotonic time not available, don't cache access tokens",
        "don't allow caching, since monotonic time isn't available",
        "caching not enabled, first credential request, or the access token from the previous one expired",
        "get an access token using OAuth",
        "credential response can take longer, use longer timeout instead of default one",
        "save the token for the duration it is valid for",
        "according to https://docs.microsoft.com/en-us/azure/cognitive-services/speech/api-reference-rest/bingvoicerecognition, the token expires in exactly 10 minutes",
        "audio samples must be 8kHz or 16 kHz",
        "audio samples should be 16-bit",
        "chunked-transfer requests are only supported in the standard library as of Python 3.6+, use it if possible",
        "fall back on manually formatting the POST body as a chunked request",
        "return results",
        "audio samples must be 8 kHz or 16 kHz",
        "audio samples should be 16-bit",
        "get the HMAC digest as bytes",
        "return results",
        "audio samples should be at least 16 kHz",
        "audio samples should be at least 16-bit",
        "don't stop recognizing when the audio stream activity stops",
        "prevent requests from being logged, for improved privacy",
        "return results",
        "load graph",
        "load labels",
        "Sort labels in order of confidence",
        "check for installed version first",
        "flac utility is not installed",
        "directory of the current module file, where all the FLAC bundled binaries are stored",
        "no FLAC converter available",
        "mark FLAC converter as executable if possible",
        "handle known issue when running on docker:",
        "run executable right after chmod() may result in OSError \"Text file busy\"",
        "fix: flush FS with sync",
        "create the temporary file and open it",
        "the name property is a public field",
        "===============================",
        "backwards compatibility shims",
        "===============================",
        "WavFile was renamed to AudioFile in 3.4.1",
        "API.AI Speech Recognition is deprecated/not recommended as of 3.5.0, and currently is only optionally available for paid plans"
    ],
    "docstrings": [
        "\"\"\"Library for performing speech recognition, with support for several engines and APIs, online and offline.\"\"\"",
        "\"\"\"\n    Creates a new ``Microphone`` instance, which represents a physical microphone on the computer. Subclass of ``AudioSource``.\n\n    This will throw an ``AttributeError`` if you don't have PyAudio 0.2.11 or later installed.\n\n    If ``device_index`` is unspecified or ``None``, the default microphone is used as the audio source. Otherwise, ``device_index``\n    should be the index of the device to use for audio input.\n\n    A device index is an integer between 0 and ``pyaudio.get_device_count() - 1`` (assume we have used ``import pyaudio`` beforehand) inclusive.\n    It represents an audio device such as a microphone or speaker. See the `PyAudio documentation <http://people.csail.mit.edu/hubert/pyaudio/docs/>`__ for more details.\n\n    The microphone audio is recorded in chunks of ``chunk_size`` samples, at a rate of ``sample_rate`` samples per second (Hertz).\n    If not specified, the value of ``sample_rate`` is determined automatically from the system's microphone settings.\n\n    Higher ``sample_rate`` values result in better audio quality, but also more bandwidth (and therefore, slower recognition).\n    Additionally, some CPUs, such as those in older Raspberry Pi models, can't keep up if this value is too high.\n\n    Higher ``chunk_size`` values help avoid triggering on rapidly changing ambient noise, but also makes detection less sensitive.\n    This value, generally, should be left at its default.\n    \"\"\"",
        "\"\"\"\n        Imports the pyaudio module and checks its version. Throws exceptions if pyaudio can't be found or a wrong version is installed\n        \"\"\"",
        "\"\"\"\n        Returns a list of the names of all available microphones. For microphones where the name can't be retrieved, the list entry contains ``None`` instead.\n\n        The index of each microphone's name in the returned list is the same as its device index when creating a ``Microphone`` instance - if you want to use the microphone at index 3 in the returned list, use ``Microphone(device_index=3)``.\n        \"\"\"",
        "\"\"\"\n        Returns a dictionary mapping device indices to microphone names, for microphones that are currently hearing sounds. When using this function, ensure that your microphone is unmuted and make some noise at it to ensure it will be detected as working.\n\n        Each key in the returned dictionary can be passed to the ``Microphone`` constructor to use that microphone. For example, if the return value is ``{3: \"HDA Intel PCH: ALC3232 Analog (hw:1,0)\"}``, you can do ``Microphone(device_index=3)`` to use that microphone.\n        \"\"\"",
        "\"\"\"\n    Creates a new ``AudioFile`` instance given a WAV/AIFF/FLAC audio file ``filename_or_fileobject``. Subclass of ``AudioSource``.\n\n    If ``filename_or_fileobject`` is a string, then it is interpreted as a path to an audio file on the filesystem. Otherwise, ``filename_or_fileobject`` should be a file-like object such as ``io.BytesIO`` or similar.\n\n    Note that functions that read from the audio (such as ``recognizer_instance.record`` or ``recognizer_instance.listen``) will move ahead in the stream. For example, if you execute ``recognizer_instance.record(audiofile_instance, duration=10)`` twice, the first time it will return the first 10 seconds of audio, and the second time it will return the 10 seconds of audio right after that. This is always reset to the beginning when entering an ``AudioFile`` context.\n\n    WAV files must be in PCM/LPCM format; WAVE_FORMAT_EXTENSIBLE and compressed WAV are not supported and may result in undefined behaviour.\n\n    Both AIFF and AIFF-C (compressed AIFF) formats are supported.\n\n    FLAC files must be in native FLAC format; OGG-FLAC is not supported and may result in undefined behaviour.\n    \"\"\"",
        "\"\"\"\n    Creates a new ``AudioData`` instance, which represents mono audio data.\n\n    The raw audio data is specified by ``frame_data``, which is a sequence of bytes representing audio samples. This is the frame data structure used by the PCM WAV format.\n\n    The width of each sample, in bytes, is specified by ``sample_width``. Each group of ``sample_width`` bytes represents a single audio sample.\n\n    The audio data is assumed to have a sample rate of ``sample_rate`` samples per second (Hertz).\n\n    Usually, instances of this class are obtained from ``recognizer_instance.record`` or ``recognizer_instance.listen``, or in the callback for ``recognizer_instance.listen_in_background``, rather than instantiating them directly.\n    \"\"\"",
        "\"\"\"\n        Returns a new ``AudioData`` instance, trimmed to a given time interval. In other words, an ``AudioData`` instance with the same audio data except starting at ``start_ms`` milliseconds in and ending ``end_ms`` milliseconds in.\n\n        If not specified, ``start_ms`` defaults to the beginning of the audio, and ``end_ms`` defaults to the end.\n        \"\"\"",
        "\"\"\"\n        Returns a byte string representing the raw frame data for the audio represented by the ``AudioData`` instance.\n\n        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n\n        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n\n        Writing these bytes directly to a file results in a valid `RAW/PCM audio file <https://en.wikipedia.org/wiki/Raw_audio_format>`__.\n        \"\"\"",
        "\"\"\"\n        Returns a byte string representing the contents of a WAV file containing the audio represented by the ``AudioData`` instance.\n\n        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n\n        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n\n        Writing these bytes directly to a file results in a valid `WAV file <https://en.wikipedia.org/wiki/WAV>`__.\n        \"\"\"",
        "\"\"\"\n        Returns a byte string representing the contents of an AIFF-C file containing the audio represented by the ``AudioData`` instance.\n\n        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n\n        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n\n        Writing these bytes directly to a file results in a valid `AIFF-C file <https://en.wikipedia.org/wiki/Audio_Interchange_File_Format>`__.\n        \"\"\"",
        "\"\"\"\n        Returns a byte string representing the contents of a FLAC file containing the audio represented by the ``AudioData`` instance.\n\n        Note that 32-bit FLAC is not supported. If the audio data is 32-bit and ``convert_width`` is not specified, then the resulting FLAC will be a 24-bit FLAC.\n\n        If ``convert_rate`` is specified and the audio sample rate is not ``convert_rate`` Hz, the resulting audio is resampled to match.\n\n        If ``convert_width`` is specified and the audio samples are not ``convert_width`` bytes each, the resulting audio is converted to match.\n\n        Writing these bytes directly to a file results in a valid `FLAC file <https://en.wikipedia.org/wiki/FLAC>`__.\n        \"\"\"",
        "\"\"\"\n        Creates a new ``Recognizer`` instance, which represents a collection of speech recognition functionality.\n        \"\"\"",
        "\"\"\"\n        Records up to ``duration`` seconds of audio from ``source`` (an ``AudioSource`` instance) starting at ``offset`` (or at the beginning if not specified) into an ``AudioData`` instance, which it returns.\n\n        If ``duration`` is not specified, then it will record until there is no more audio input.\n        \"\"\"",
        "\"\"\"\n        Adjusts the energy threshold dynamically using audio from ``source`` (an ``AudioSource`` instance) to account for\n        ambient noise.\n\n        Intended to calibrate the energy threshold with the ambient energy level. Should be used on periods of audio without\n        speech - will stop early if any speech is detected.\n\n        The ``duration`` parameter is the maximum number of seconds that it will dynamically adjust the threshold for before\n        returning. This value should be at least 0.5 in order to get a representative sample of the ambient noise.\n        \"\"\"",
        "\"\"\"\n        Records a single phrase from ``source`` (an ``AudioSource`` instance) into an ``AudioData`` instance, which it returns.\n\n        This is done by waiting until the audio has an energy above ``recognizer_instance.energy_threshold``\n        (the user has started speaking), and then recording until it encounters ``recognizer_instance.pause_threshold``\n        seconds of non-speaking or there is no more audio input. The ending silence is not included.\n\n\n        The ``timeout`` parameter is the maximum number of seconds that this will wait for a phrase to start before\n        giving up and throwing an ``speech_recognition.WaitTimeoutError`` exception.\n        If ``timeout`` is ``None``, there will be no wait timeout.\n\n\n        The ``phrase_time_limit`` parameter is the maximum number of seconds that this will allow a phrase to continue\n        before stopping and returning the part of the phrase processed before the time limit was reached.The resulting\n        audio will be the phrase cut off at the time limit. If ``phrase_timeout`` is ``None``, there will be no phrase time limit.\n\n\n        The ``snowboy_configuration`` parameter allows integration with `Snowboy <https://snowboy.kitt.ai/>`__, an offline,\n        high-accuracy, power-efficient hotword recognition engine. When used,this function will pause until Snowboy detects\n        a hotword, after which it will unpause. This parameter should either be ``None`` to turn off Snowboy support, or a\n        tuple of the form ``(SNOWBOY_LOCATION, LIST_OF_HOT_WORD_FILES)``, where ``SNOWBOY_LOCATION`` is the path to the\n        Snowboy root directory, and ``LIST_OF_HOT_WORD_FILES`` is a list of paths to Snowboy hotword\n        configuration files (`*.pmdl` or `*.umdl` format).\n\n\n        This operation will always complete within ``timeout + phrase_timeout`` seconds if both are numbers, either by\n        returning the audio data, or by raising a ``speech_recognition.WaitTimeoutError`` exception.\n        \"\"\"",
        "\"\"\"\n        Spawns a thread to repeatedly record phrases from ``source`` (an ``AudioSource`` instance) into an ``AudioData`` instance and call ``callback`` with that ``AudioData`` instance as soon as each phrase are detected.\n\n        Returns a function object that, when called, requests that the background listener thread stop. The background thread is a daemon and will not stop the program from exiting if there are no other non-daemon threads. The function accepts one parameter, ``wait_for_stop``: if truthy, the function will wait for the background listener to stop before returning, otherwise it will return immediately and the background listener thread might still be running for a second or two afterwards. Additionally, if you are using a truthy value for ``wait_for_stop``, you must call the function from the same thread you originally called ``listen_in_background`` from.\n\n        Phrase recognition uses the exact same mechanism as ``recognizer_instance.listen(source)``. The ``phrase_time_limit`` parameter works in the same way as the ``phrase_time_limit`` parameter for ``recognizer_instance.listen(source)``, as well.\n\n        The ``callback`` parameter is a function that should accept two parameters - the ``recognizer_instance``, and an ``AudioData`` instance representing the captured audio. Note that ``callback`` function will be called from a non-main thread.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using CMU Sphinx.\n\n        The recognition language is determined by ``language``, an RFC5646 language tag like ``\"en-US\"`` or ``\"en-GB\"``, defaulting to US English.\n        Out of the box, only ``en-US`` is supported. See `Notes on using `PocketSphinx <https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst>`__\n        for information about installing other languages. This document is also included under ``reference/pocketsphinx.rst``. The ``language`` parameter can also be a tuple of\n        filesystem paths, of the form ``(acoustic_parameters_directory, language_model_file, phoneme_dictionary_file)`` - this allows you to load arbitrary Sphinx models.\n\n\n        If specified, the keywords to search for are determined by ``keyword_entries``, an iterable of tuples of the form ``(keyword, sensitivity)``, where ``keyword``\n        is a phrase, and ``sensitivity`` is how sensitive to this phrase the recognizer should be, on a scale of 0 (very insensitive, more false negatives) to 1\n        (very sensitive, more false positives) inclusive. If not specified or ``None``, no keywords are used and Sphinx will simply transcribe whatever words it recognizes.\n        Specifying ``keyword_entries`` is more accurate than just looking for those same keywords in non-keyword-based transcriptions, because Sphinx knows specifically\n        what sounds to look for.\n\n\n        Sphinx can also handle FSG or JSGF grammars. The parameter ``grammar`` expects a path to the grammar file. Note that if a JSGF grammar is passed, an FSG grammar\n        will be created at the same location to speed up execution in the next run. If ``keyword_entries`` are passed, content of ``grammar`` will be ignored.\n\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the Sphinx ``pocketsphinx.pocketsphinx.Decoder``\n        object resulting from the recognition.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception\n        if there are any issues with the Sphinx installation.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Google Speech Recognition API.\n\n        The Google Speech Recognition API key is specified by ``key``. If not specified, it uses a generic key that works\n        out of the box. This should generally be used for personal or testing purposes only, as it **may be revoked by Google at any time**.\n\n        To obtain your own API key, simply following the steps on the `API Keys <http://www.chromium.org/developers/how-tos/api-keys>`__ page\n        at the Chromium Developers site. In the Google Developers Console, Google Speech Recognition is listed as \"Speech API\".\n\n        The recognition language is determined by ``language``, an RFC5646 language tag like ``\"en-US\"`` (US English) or ``\"fr-FR\"``\n         (International French), defaulting to US English. A list of supported language tags can be found in this\n         `StackOverflow answer <http://stackoverflow.com/a/14302134>`__.\n\n        The profanity filter level can be adjusted with ``pfilter``: 0 - No filter, 1 - Only shows the first character\n        and replaces the rest with asterisks. The default is level 0.\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the raw API response as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible.\n        Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Google Cloud Speech API.\n\n        This function requires a Google Cloud Platform account; see the `Google Cloud Speech API Quickstart <https://cloud.google.com/speech/docs/getting-started>`__ for details and instructions. Basically, create a project, enable billing for the project, enable the Google Cloud Speech API for the project, and set up Service Account Key credentials for the project. The result is a JSON file containing the API credentials. The text content of this JSON file is specified by ``credentials_json``. If not specified, the library will try to automatically `find the default API credentials JSON file <https://developers.google.com/identity/protocols/application-default-credentials>`__.\n\n        The recognition language is determined by ``language``, which is a BCP-47 language tag like ``\"en-US\"`` (US English). A list of supported language tags can be found in the `Google Cloud Speech API documentation <https://cloud.google.com/speech/docs/languages>`__.\n\n        If ``preferred_phrases`` is an iterable of phrase strings, those given phrases will be more likely to be recognized over similar-sounding alternatives. This is useful for things like keyword/command recognition or adding new phrases that aren't in Google's vocabulary. Note that the API imposes certain `restrictions on the list of phrase strings <https://cloud.google.com/speech/limits#content>`__.\n\n        Returns the most likely transcription if ``show_all`` is False (the default). Otherwise, returns the raw API response as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the credentials aren't valid, or if there is no Internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Wit.ai API.\n\n        The Wit.ai API key is specified by ``key``. Unfortunately, these are not available without `signing up for an account <https://wit.ai/>`__ and creating an app. You will need to add at least one intent to the app before you can see the API key, though the actual intent settings don't matter.\n\n        To get the API key for a Wit.ai app, go to the app's overview page, go to the section titled \"Make an API request\", and look for something along the lines of ``Authorization: Bearer XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX``; ``XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX`` is the API key. Wit.ai API keys are 32-character uppercase alphanumeric strings.\n\n        The recognition language is configured in the Wit.ai app settings.\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the `raw API response <https://wit.ai/docs/http/20141022#get-intent-via-text-link>`__ as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Microsoft Azure Speech API.\n\n        The Microsoft Azure Speech API key is specified by ``key``. Unfortunately, these are not available without `signing up for an account <https://azure.microsoft.com/en-ca/pricing/details/cognitive-services/speech-api/>`__ with Microsoft Azure.\n\n        To get the API key, go to the `Microsoft Azure Portal Resources <https://portal.azure.com/>`__ page, go to \"All Resources\" > \"Add\" > \"See All\" > Search \"Speech > \"Create\", and fill in the form to make a \"Speech\" resource. On the resulting page (which is also accessible from the \"All Resources\" page in the Azure Portal), go to the \"Show Access Keys\" page, which will have two API keys, either of which can be used for the `key` parameter. Microsoft Azure Speech API keys are 32-character lowercase hexadecimal strings.\n\n        The recognition language is determined by ``language``, a BCP-47 language tag like ``\"en-US\"`` (US English) or ``\"fr-FR\"`` (International French), defaulting to US English. A list of supported language values can be found in the `API documentation <https://docs.microsoft.com/en-us/azure/cognitive-services/speech/api-reference-rest/bingvoicerecognition#recognition-language>`__ under \"Interactive and dictation mode\".\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the `raw API response <https://docs.microsoft.com/en-us/azure/cognitive-services/speech/api-reference-rest/bingvoicerecognition#sample-responses>`__ as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Microsoft Bing Speech API.\n\n        The Microsoft Bing Speech API key is specified by ``key``. Unfortunately, these are not available without `signing up for an account <https://azure.microsoft.com/en-ca/pricing/details/cognitive-services/speech-api/>`__ with Microsoft Azure.\n\n        To get the API key, go to the `Microsoft Azure Portal Resources <https://portal.azure.com/>`__ page, go to \"All Resources\" > \"Add\" > \"See All\" > Search \"Bing Speech API > \"Create\", and fill in the form to make a \"Bing Speech API\" resource. On the resulting page (which is also accessible from the \"All Resources\" page in the Azure Portal), go to the \"Show Access Keys\" page, which will have two API keys, either of which can be used for the `key` parameter. Microsoft Bing Speech API keys are 32-character lowercase hexadecimal strings.\n\n        The recognition language is determined by ``language``, a BCP-47 language tag like ``\"en-US\"`` (US English) or ``\"fr-FR\"`` (International French), defaulting to US English. A list of supported language values can be found in the `API documentation <https://docs.microsoft.com/en-us/azure/cognitive-services/speech/api-reference-rest/bingvoicerecognition#recognition-language>`__ under \"Interactive and dictation mode\".\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the `raw API response <https://docs.microsoft.com/en-us/azure/cognitive-services/speech/api-reference-rest/bingvoicerecognition#sample-responses>`__ as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Amazon Lex API.\n\n        If access_key_id or secret_access_key is not set it will go through the list in the link below\n        http://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Houndify API.\n\n        The Houndify client ID and client key are specified by ``client_id`` and ``client_key``, respectively. Unfortunately, these are not available without `signing up for an account <https://www.houndify.com/signup>`__. Once logged into the `dashboard <https://www.houndify.com/dashboard>`__, you will want to select \"Register a new client\", and fill in the form as necessary. When at the \"Enable Domains\" page, enable the \"Speech To Text Only\" domain, and then select \"Save & Continue\".\n\n        To get the client ID and client key for a Houndify client, go to the `dashboard <https://www.houndify.com/dashboard>`__ and select the client's \"View Details\" link. On the resulting page, the client ID and client key will be visible. Client IDs and client keys are both Base64-encoded strings.\n\n        Currently, only English is supported as a recognition language.\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the raw API response as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the IBM Speech to Text API.\n\n        The IBM Speech to Text username and password are specified by ``username`` and ``password``, respectively. Unfortunately, these are not available without `signing up for an account <https://console.ng.bluemix.net/registration/>`__. Once logged into the Bluemix console, follow the instructions for `creating an IBM Watson service instance <https://www.ibm.com/watson/developercloud/doc/getting_started/gs-credentials.shtml>`__, where the Watson service is \"Speech To Text\". IBM Speech to Text usernames are strings of the form XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX, while passwords are mixed-case alphanumeric strings.\n\n        The recognition language is determined by ``language``, an RFC5646 language tag with a dialect like ``\"en-US\"`` (US English) or ``\"zh-CN\"`` (Mandarin Chinese), defaulting to US English. The supported language values are listed under the ``model`` parameter of the `audio recognition API documentation <https://www.ibm.com/watson/developercloud/speech-to-text/api/v1/#sessionless_methods>`__, in the form ``LANGUAGE_BroadbandModel``, where ``LANGUAGE`` is the language value.\n\n        Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the `raw API response <https://www.ibm.com/watson/developercloud/speech-to-text/api/v1/#sessionless_methods>`__ as a JSON dictionary.\n\n        Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n        \"\"\"",
        "\"\"\"\n        Performs speech recognition on ``audio_data`` (an ``AudioData`` instance).\n\n        Path to Tensor loaded from ``tensor_graph``. You can download a model here: http://download.tensorflow.org/models/speech_commands_v0.01.zip\n\n        Path to Tensor Labels file loaded from ``tensor_label``.\n        \"\"\"",
        "\"\"\"Returns the absolute path of a FLAC converter executable, or raises an OSError if none can be found.\"\"\"",
        "\"\"\"Python 2 compatibility: backport of ``shutil.which()`` from Python 3\"\"\"",
        "\"\"\"Limited replacement for ``tempfile.NamedTemporaryFile``, except unlike ``tempfile.NamedTemporaryFile``, the file can be opened again while it's currently open, even on Windows.\"\"\""
    ],
    "functions": [
        "__enter__",
        "__exit__",
        "get_pyaudio",
        "list_microphone_names",
        "list_working_microphones",
        "__enter__",
        "__exit__",
        "read",
        "close",
        "__enter__",
        "__exit__",
        "read",
        "get_segment",
        "get_raw_data",
        "get_wav_data",
        "get_aiff_data",
        "get_flac_data",
        "record",
        "adjust_for_ambient_noise",
        "snowboy_wait_for_hot_word",
        "listen",
        "listen_in_background",
        "threaded_listen",
        "stopper",
        "recognize_sphinx",
        "recognize_google",
        "recognize_google_cloud",
        "recognize_wit",
        "recognize_azure",
        "recognize_bing",
        "recognize_lex",
        "recognize_houndify",
        "recognize_ibm",
        "recognize_tensorflow",
        "get_flac_converter",
        "shutil_which",
        "__enter__",
        "__exit__",
        "write",
        "writelines",
        "flush",
        "recognize_api"
    ],
    "classes": [
        "WaitTimeoutError",
        "RequestError",
        "UnknownValueError",
        "AudioSource",
        "Microphone",
        "MicrophoneStream",
        "AudioFile",
        "AudioFileStream",
        "AudioData",
        "Recognizer",
        "PortableNamedTemporaryFile"
    ]
}