{
    "identifiers": [
        "org",
        "apache",
        "nutch",
        "util",
        "java",
        "io",
        "java",
        "net",
        "URL",
        "java",
        "text",
        "SimpleDateFormat",
        "java",
        "util",
        "Collection",
        "java",
        "util",
        "java",
        "util",
        "Random",
        "org",
        "apache",
        "hadoop",
        "conf",
        "Configuration",
        "org",
        "apache",
        "hadoop",
        "conf",
        "Configured",
        "org",
        "apache",
        "hadoop",
        "fs",
        "FileSystem",
        "org",
        "apache",
        "hadoop",
        "fs",
        "Path",
        "org",
        "apache",
        "hadoop",
        "io",
        "Text",
        "org",
        "apache",
        "hadoop",
        "io",
        "Writable",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "Job",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "Mapper",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "Reducer",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "lib",
        "input",
        "KeyValueTextInputFormat",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "lib",
        "input",
        "MultipleInputs",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "lib",
        "input",
        "SequenceFileInputFormat",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "lib",
        "MultithreadedMapper",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "lib",
        "output",
        "FileOutputFormat",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "lib",
        "output",
        "MapFileOutputFormat",
        "org",
        "apache",
        "hadoop",
        "util",
        "StringUtils",
        "org",
        "apache",
        "hadoop",
        "util",
        "Tool",
        "org",
        "apache",
        "hadoop",
        "util",
        "ToolRunner",
        "org",
        "apache",
        "nutch",
        "crawl",
        "CrawlDatum",
        "org",
        "apache",
        "nutch",
        "hostdb",
        "HostDatum",
        "org",
        "apache",
        "nutch",
        "net",
        "URLFilters",
        "org",
        "apache",
        "nutch",
        "net",
        "URLNormalizers",
        "org",
        "apache",
        "nutch",
        "protocol",
        "Content",
        "org",
        "apache",
        "nutch",
        "protocol",
        "Protocol",
        "org",
        "apache",
        "nutch",
        "protocol",
        "ProtocolFactory",
        "org",
        "apache",
        "nutch",
        "protocol",
        "ProtocolOutput",
        "org",
        "apache",
        "nutch",
        "protocol",
        "ProtocolStatus",
        "org",
        "slf4j",
        "Logger",
        "org",
        "slf4j",
        "LoggerFactory",
        "crawlercommons",
        "robots",
        "BaseRobotRules",
        "crawlercommons",
        "sitemaps",
        "AbstractSiteMap",
        "crawlercommons",
        "sitemaps",
        "SiteMap",
        "crawlercommons",
        "sitemaps",
        "SiteMapIndex",
        "crawlercommons",
        "sitemaps",
        "SiteMapParser",
        "crawlercommons",
        "sitemaps",
        "SiteMapURL",
        "LOG",
        "LoggerFactory",
        "getLogger",
        "sdf",
        "CURRENT_NAME",
        "LOCK_NAME",
        "SITEMAP_STRICT_PARSING",
        "SITEMAP_URL_FILTERING",
        "SITEMAP_URL_NORMALIZING",
        "SITEMAP_ALWAYS_TRY_SITEMAPXML_ON_ROOT",
        "SITEMAP_OVERWRITE_EXISTING",
        "protocolFactory",
        "strict",
        "normalize",
        "tryDefaultSitemapXml",
        "filters",
        "normalizers",
        "datum",
        "parser",
        "context",
        "conf",
        "context",
        "getConfiguration",
        "protocolFactory",
        "conf",
        "conf",
        "getBoolean",
        "SITEMAP_URL_FILTERING",
        "normalize",
        "conf",
        "getBoolean",
        "SITEMAP_URL_NORMALIZING",
        "strict",
        "conf",
        "getBoolean",
        "SITEMAP_STRICT_PARSING",
        "tryDefaultSitemapXml",
        "conf",
        "getBoolean",
        "SITEMAP_ALWAYS_TRY_SITEMAPXML_ON_ROOT",
        "parser",
        "strict",
        "filters",
        "conf",
        "normalize",
        "normalizers",
        "conf",
        "URLNormalizers",
        "SCOPE_DEFAULT",
        "key",
        "value",
        "context",
        "url",
        "value",
        "context",
        "write",
        "key",
        "value",
        "value",
        "host",
        "key",
        "toString",
        "url",
        "filterNormalize",
        "host",
        "url",
        "filterNormalize",
        "host",
        "url",
        "filterNormalize",
        "host",
        "url",
        "filterNormalize",
        "host",
        "context",
        "getCounter",
        "increment",
        "rules",
        "protocolFactory",
        "getProtocol",
        "url",
        "getRobotRules",
        "url",
        "datum",
        "sitemaps",
        "rules",
        "getSitemaps",
        "tryDefaultSitemapXml",
        "sitemaps",
        "size",
        "sitemaps",
        "add",
        "url",
        "sitemap",
        "sitemaps",
        "context",
        "getCounter",
        "increment",
        "generateSitemapUrlDatum",
        "protocolFactory",
        "getProtocol",
        "sitemap",
        "sitemap",
        "context",
        "value",
        "url",
        "filterNormalize",
        "key",
        "toString",
        "context",
        "getCounter",
        "increment",
        "context",
        "getCounter",
        "increment",
        "generateSitemapUrlDatum",
        "protocolFactory",
        "getProtocol",
        "url",
        "url",
        "context",
        "e",
        "LOG",
        "warn",
        "key",
        "toString",
        "StringUtils",
        "stringifyException",
        "e",
        "url",
        "normalizers",
        "url",
        "normalizers",
        "normalize",
        "url",
        "URLNormalizers",
        "SCOPE_DEFAULT",
        "filters",
        "url",
        "filters",
        "url",
        "e",
        "url",
        "protocol",
        "url",
        "context",
        "output",
        "protocol",
        "getProtocolOutput",
        "url",
        "datum",
        "status",
        "output",
        "getStatus",
        "content",
        "output",
        "getContent",
        "output",
        "getStatus",
        "isSuccess",
        "output",
        "getStatus",
        "isRedirect",
        "stuff",
        "output",
        "getStatus",
        "getArgs",
        "url",
        "stuff",
        "normalizers",
        "url",
        "normalizers",
        "normalize",
        "url",
        "URLNormalizers",
        "SCOPE_DEFAULT",
        "output",
        "protocol",
        "getProtocolOutput",
        "url",
        "datum",
        "status",
        "output",
        "getStatus",
        "content",
        "output",
        "getContent",
        "status",
        "getCode",
        "ProtocolStatus",
        "SUCCESS",
        "context",
        "getCounter",
        "increment",
        "LOG",
        "error",
        "status",
        "getCode",
        "url",
        "asm",
        "parser",
        "parseSiteMap",
        "content",
        "getContentType",
        "content",
        "getContent",
        "url",
        "asm",
        "sm",
        "asm",
        "sitemapUrls",
        "sm",
        "getSiteMapUrls",
        "sitemapUrl",
        "sitemapUrls",
        "strict",
        "sitemapUrl",
        "isValid",
        "key",
        "filterNormalize",
        "sitemapUrl",
        "getUrl",
        "toString",
        "key",
        "sitemapUrlDatum",
        "sitemapUrlDatum",
        "setStatus",
        "CrawlDatum",
        "STATUS_INJECTED",
        "sitemapUrlDatum",
        "setScore",
        "sitemapUrl",
        "getPriority",
        "sitemapUrl",
        "getChangeFrequency",
        "fetchInterval",
        "sitemapUrl",
        "getChangeFrequency",
        "ALWAYS",
        "fetchInterval",
        "HOURLY",
        "fetchInterval",
        "DAILY",
        "fetchInterval",
        "WEEKLY",
        "fetchInterval",
        "MONTHLY",
        "fetchInterval",
        "YEARLY",
        "fetchInterval",
        "NEVER",
        "fetchInterval",
        "MAX_VALUE",
        "sitemapUrlDatum",
        "setFetchInterval",
        "fetchInterval",
        "sitemapUrl",
        "getLastModified",
        "sitemapUrlDatum",
        "setModifiedTime",
        "sitemapUrl",
        "getLastModified",
        "getTime",
        "context",
        "write",
        "key",
        "sitemapUrlDatum",
        "asm",
        "index",
        "asm",
        "sitemapUrls",
        "index",
        "getSitemaps",
        "sitemap",
        "sitemapUrls",
        "sitemap",
        "isIndex",
        "generateSitemapUrlDatum",
        "protocol",
        "sitemap",
        "getUrl",
        "toString",
        "context",
        "sitemapDatum",
        "originalDatum",
        "overwriteExisting",
        "context",
        "conf",
        "context",
        "getConfiguration",
        "overwriteExisting",
        "conf",
        "getBoolean",
        "SITEMAP_OVERWRITE_EXISTING",
        "key",
        "values",
        "context",
        "sitemapDatum",
        "originalDatum",
        "curr",
        "values",
        "curr",
        "getStatus",
        "CrawlDatum",
        "STATUS_INJECTED",
        "sitemapDatum",
        "sitemapDatum",
        "curr",
        "originalDatum",
        "originalDatum",
        "curr",
        "originalDatum",
        "sitemapDatum",
        "overwriteExisting",
        "originalDatum",
        "setScore",
        "sitemapDatum",
        "getScore",
        "originalDatum",
        "setFetchInterval",
        "sitemapDatum",
        "getFetchInterval",
        "originalDatum",
        "setModifiedTime",
        "sitemapDatum",
        "getModifiedTime",
        "context",
        "getCounter",
        "increment",
        "context",
        "write",
        "key",
        "originalDatum",
        "sitemapDatum",
        "context",
        "getCounter",
        "increment",
        "sitemapDatum",
        "setStatus",
        "CrawlDatum",
        "STATUS_DB_UNFETCHED",
        "context",
        "write",
        "key",
        "sitemapDatum",
        "crawldb",
        "hostdb",
        "sitemapUrlDir",
        "strict",
        "normalize",
        "threads",
        "start",
        "currentTimeMillis",
        "LOG",
        "isInfoEnabled",
        "LOG",
        "info",
        "sdf",
        "format",
        "start",
        "fs",
        "FileSystem",
        "get",
        "getConf",
        "old",
        "crawldb",
        "current",
        "crawldb",
        "tempCrawlDb",
        "crawldb",
        "toString",
        "nextInt",
        "MAX_VALUE",
        "crawldb",
        "LOCK_NAME",
        "fs",
        "exists",
        "current",
        "fs",
        "mkdirs",
        "current",
        "LockUtil",
        "createLockFile",
        "fs",
        "conf",
        "getConf",
        "conf",
        "setBoolean",
        "SITEMAP_STRICT_PARSING",
        "strict",
        "conf",
        "setBoolean",
        "SITEMAP_URL_FILTERING",
        "conf",
        "setBoolean",
        "SITEMAP_URL_NORMALIZING",
        "normalize",
        "conf",
        "setBoolean",
        "job",
        "Job",
        "getInstance",
        "conf",
        "crawldb",
        "toString",
        "job",
        "setJarByClass",
        "MultipleInputs",
        "addInputPath",
        "job",
        "current",
        "sitemapUrlDir",
        "MultipleInputs",
        "addInputPath",
        "job",
        "sitemapUrlDir",
        "hostdb",
        "MultipleInputs",
        "addInputPath",
        "job",
        "hostdb",
        "CURRENT_NAME",
        "FileOutputFormat",
        "setOutputPath",
        "job",
        "tempCrawlDb",
        "job",
        "setOutputFormatClass",
        "job",
        "setOutputKeyClass",
        "job",
        "setOutputValueClass",
        "job",
        "setMapperClass",
        "MultithreadedMapper",
        "setMapperClass",
        "job",
        "MultithreadedMapper",
        "setNumberOfThreads",
        "job",
        "threads",
        "job",
        "setReducerClass",
        "job",
        "waitForCompletion",
        "preserveBackup",
        "conf",
        "getBoolean",
        "preserveBackup",
        "fs",
        "exists",
        "old",
        "fs",
        "old",
        "FSUtils",
        "replace",
        "fs",
        "old",
        "current",
        "FSUtils",
        "replace",
        "fs",
        "current",
        "tempCrawlDb",
        "LockUtil",
        "removeLockFile",
        "fs",
        "LOG",
        "isInfoEnabled",
        "filteredRecords",
        "job",
        "getCounters",
        "findCounter",
        "getValue",
        "fromHostDb",
        "job",
        "getCounters",
        "findCounter",
        "getValue",
        "fromSeeds",
        "job",
        "getCounters",
        "findCounter",
        "getValue",
        "failedFetches",
        "job",
        "getCounters",
        "findCounter",
        "getValue",
        "newSitemapEntries",
        "job",
        "getCounters",
        "findCounter",
        "getValue",
        "LOG",
        "info",
        "filteredRecords",
        "LOG",
        "info",
        "fromHostDb",
        "LOG",
        "info",
        "fromSeeds",
        "LOG",
        "info",
        "failedFetches",
        "LOG",
        "info",
        "newSitemapEntries",
        "end",
        "currentTimeMillis",
        "LOG",
        "info",
        "sdf",
        "format",
        "end",
        "TimingUtil",
        "elapsedTime",
        "start",
        "end",
        "e",
        "fs",
        "exists",
        "tempCrawlDb",
        "fs",
        "tempCrawlDb",
        "LockUtil",
        "removeLockFile",
        "fs",
        "e",
        "args",
        "res",
        "ToolRunner",
        "run",
        "NutchConfiguration",
        "create",
        "args",
        "exit",
        "res",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "args",
        "args",
        "length",
        "usage",
        "crawlDb",
        "args",
        "hostDb",
        "urlDir",
        "strict",
        "normalize",
        "threads",
        "getConf",
        "getInt",
        "i",
        "i",
        "args",
        "length",
        "i",
        "args",
        "i",
        "equals",
        "hostDb",
        "args",
        "i",
        "LOG",
        "info",
        "hostDb",
        "args",
        "i",
        "equals",
        "urlDir",
        "args",
        "i",
        "LOG",
        "info",
        "urlDir",
        "args",
        "i",
        "equals",
        "threads",
        "valueOf",
        "args",
        "i",
        "LOG",
        "info",
        "threads",
        "args",
        "i",
        "equals",
        "LOG",
        "info",
        "strict",
        "args",
        "i",
        "equals",
        "LOG",
        "info",
        "args",
        "i",
        "equals",
        "LOG",
        "info",
        "normalize",
        "LOG",
        "info",
        "args",
        "i",
        "usage",
        "sitemap",
        "crawlDb",
        "hostDb",
        "urlDir",
        "strict",
        "normalize",
        "threads",
        "e",
        "LOG",
        "error",
        "StringUtils",
        "stringifyException",
        "e"
    ],
    "literals": [
        "\"yyyy-MM-dd HH:mm:ss\"",
        "\"current\"",
        "\".locked\"",
        "\"sitemap.strict.parsing\"",
        "\"sitemap.url.filter\"",
        "\"sitemap.url.normalize\"",
        "\"sitemap.url.default.sitemap.xml\"",
        "\"sitemap.url.overwrite.existing\"",
        "\"http://\"",
        "\"/\"",
        "\"https://\"",
        "\"/\"",
        "\"ftp://\"",
        "\"/\"",
        "\"file:/\"",
        "\"/\"",
        "\"Sitemap\"",
        "\"filtered_records\"",
        "\"sitemap.xml\"",
        "\"Sitemap\"",
        "\"sitemaps_from_hostdb\"",
        "\"Sitemap\"",
        "\"filtered_records\"",
        "\"Sitemap\"",
        "\"sitemap_seeds\"",
        "\"Exception for record {} : {}\"",
        "\"Sitemap\"",
        "\"failed_fetches\"",
        "\"Error while fetching the sitemap. Status code: {} for {}\"",
        "\"Sitemap\"",
        "\"existing_sitemap_entries\"",
        "\"Sitemap\"",
        "\"new_sitemap_entries\"",
        "\"SitemapProcessor: Starting at {}\"",
        "\"old\"",
        "\"current\"",
        "\"crawldb-\"",
        "\"mapreduce.fileoutputcommitter.marksuccessfuljobs\"",
        "\"SitemapProcessor_\"",
        "\"db.preserve.backup\"",
        "\"Sitemap\"",
        "\"filtered_records\"",
        "\"Sitemap\"",
        "\"sitemaps_from_hostdb\"",
        "\"Sitemap\"",
        "\"sitemap_seeds\"",
        "\"Sitemap\"",
        "\"failed_fetches\"",
        "\"Sitemap\"",
        "\"new_sitemap_entries\"",
        "\"SitemapProcessor: Total records rejected by filters: {}\"",
        "\"SitemapProcessor: Total sitemaps from HostDb: {}\"",
        "\"SitemapProcessor: Total sitemaps from seed urls: {}\"",
        "\"SitemapProcessor: Total failed sitemap fetches: {}\"",
        "\"SitemapProcessor: Total new sitemap entries added: {}\"",
        "\"SitemapProcessor: Finished at {}, elapsed: {}\"",
        "\"Usage:\\n SitemapProcessor <crawldb> [-hostdb <hostdb>] [-sitemapUrls <url_dir>] \"",
        "\"[-threads <threads>] [-force] [-noStrict] [-noFilter] [-noNormalize]\\n\"",
        "\"\\t<crawldb>\\t\\tpath to crawldb where the sitemap urls would be injected\"",
        "\"\\t-hostdb <hostdb>\\tpath of a hostdb. Sitemap(s) from these hosts would be downloaded\"",
        "\"\\t-sitemapUrls <url_dir>\\tpath to sitemap urls directory\"",
        "\"\\t-threads <threads>\\tNumber of threads created per mapper to fetch sitemap urls\"",
        "\"\\t-force\\t\\t\\tforce update even if CrawlDb appears to be locked (CAUTION advised)\"",
        "\"\\t-noStrict\\t\\tBy default Sitemap parser rejects invalid urls. '-noStrict' disables that.\"",
        "\"\\t-noFilter\\t\\tturn off URLFilters on urls (optional)\"",
        "\"\\t-noNormalize\\t\\tturn off URLNormalizer on urls (optional)\"",
        "\"mapred.map.multithreadedrunner.threads\"",
        "\"-hostdb\"",
        "\"SitemapProcessor: hostdb: {}\"",
        "\"-sitemapUrls\"",
        "\"SitemapProcessor: sitemap urls dir: {}\"",
        "\"-threads\"",
        "\"SitemapProcessor: threads: {}\"",
        "\"-noStrict\"",
        "\"SitemapProcessor: 'strict' parsing disabled\"",
        "\"-noFilter\"",
        "\"SitemapProcessor: filtering disabled\"",
        "\"-noNormalize\"",
        "\"SitemapProcessor: normalizing disabled\"",
        "\"SitemapProcessor: Found invalid argument \\\"{}\\\"\\n\"",
        "\"SitemapProcessor: {}\""
    ],
    "variables": [
        "url"
    ],
    "comments": [
        "If its an entry from CrawlDb, emit it. It will be merged in the reducer",
        "For entry from hostdb, get sitemap url(s) from robots.txt, fetch the sitemap,",
        "extract urls and emit those",
        "try different combinations of schemes one by one till we get rejection in all cases",
        "We may wish to use the robots.txt content as the third parameter for .getRobotRules",
        "For entry from sitemap urls file, fetch the sitemap, extract urls and emit those",
        "Following redirects http > https",
        "try again",
        "If there were any problems fetching the sitemap, log the error and let it go. Not sure how often",
        "sitemaps are redirected. In future we might have to handle redirects.",
        "If 'strict' is ON, only allow valid urls. Else allow all urls",
        "60*60",
        "60*60*24",
        "60*60*24*7",
        "60*60*24*30",
        "60*60*24*365",
        "Loose \"NEVER\" contract",
        "DO NOT ENABLE!!",
        "The url was already present in crawldb. If we got the same url from sitemap too, save",
        "the information from sitemap to the original datum. Emit the original crawl datum",
        "For the newly discovered links via sitemap, set the status as unfetched and emit",
        "lock an existing crawldb to prevent multiple simultaneous updates",
        "add crawlDb, sitemap url directory and hostDb to input paths"
    ],
    "docstrings": [
        "* Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.",
        "* <p>Performs Sitemap processing by fetching sitemap links, parsing the content and merging\n * the urls from Sitemap (with the metadata) with the existing crawldb.</p>\n *\n * <p>There are two use cases supported in Nutch's Sitemap processing:</p>\n * <ol>\n *  <li>Sitemaps are considered as \"remote seed lists\". Crawl administrators can prepare a\n *     list of sitemap links and get only those sitemap pages. This suits well for targeted\n *     crawl of specific hosts.</li>\n *  <li>For open web crawl, it is not possible to track each host and get the sitemap links\n *     manually. Nutch would automatically get the sitemaps for all the hosts seen in the\n *     crawls and inject the urls from sitemap to the crawldb.</li>\n * </ol>\n *\n * <p>For more details see:\n *      https://wiki.apache.org/nutch/SitemapFeature </p>",
        "Filters and or normalizes the input URL"
    ],
    "functions": [
        "setup",
        "filterNormalize",
        "generateSitemapUrlDatum",
        "setup",
        "reduce",
        "sitemap",
        "main",
        "usage",
        "run"
    ],
    "classes": [
        "SitemapProcessor",
        "SitemapMapper",
        "SitemapReducer"
    ]
}