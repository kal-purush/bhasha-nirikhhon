{
    "identifiers": [
        "numpy",
        "np",
        "tensorflow",
        "tf",
        "data",
        "load_data",
        "convert_1d_to_3d",
        "dim_x",
        "dim_y",
        "dim_z",
        "predictions",
        "labels",
        "np",
        "sum",
        "np",
        "argmax",
        "predictions",
        "np",
        "argmax",
        "labels",
        "predictions",
        "shape",
        "image_size_x",
        "image_size_y",
        "image_size_x",
        "image_size_y",
        "dataset",
        "dataset",
        "reshape",
        "image_size_x",
        "image_size_y",
        "num_channels",
        "astype",
        "np",
        "float32",
        "dim",
        "data",
        "labels",
        "data",
        "shape",
        "dim",
        "num_total_data",
        "num_train_offset",
        "num_total_data",
        "num_valid_offset",
        "num_total_data",
        "reformat",
        "data",
        "num_train_offset",
        "labels",
        "num_train_offset",
        "reformat",
        "data",
        "num_train_offset",
        "num_valid_offset",
        "labels",
        "num_train_offset",
        "num_valid_offset",
        "reformat",
        "data",
        "num_valid_offset",
        "labels",
        "num_valid_offset",
        "train_dataset",
        "shape",
        "train_labels",
        "shape",
        "valid_dataset",
        "shape",
        "valid_labels",
        "shape",
        "test_dataset",
        "shape",
        "test_labels",
        "shape",
        "tf",
        "Graph",
        "graph",
        "as_default",
        "tf",
        "placeholder",
        "tf",
        "float32",
        "shape",
        "batch_size",
        "image_size_x",
        "image_size_y",
        "num_channels",
        "tf",
        "placeholder",
        "tf",
        "float32",
        "shape",
        "batch_size",
        "num_labels",
        "tf",
        "constant",
        "valid_dataset",
        "tf",
        "constant",
        "test_dataset",
        "tf",
        "Variable",
        "tf",
        "truncated_normal",
        "patch_size",
        "patch_size",
        "num_channels",
        "depth",
        "stddev",
        "tf",
        "Variable",
        "tf",
        "zeros",
        "depth",
        "tf",
        "Variable",
        "tf",
        "truncated_normal",
        "patch_size",
        "patch_size",
        "depth",
        "depth",
        "stddev",
        "tf",
        "Variable",
        "tf",
        "constant",
        "shape",
        "depth",
        "tf",
        "Variable",
        "tf",
        "truncated_normal",
        "image_size_x",
        "image_size_y",
        "depth",
        "num_hidden",
        "stddev",
        "tf",
        "Variable",
        "tf",
        "constant",
        "shape",
        "num_hidden",
        "tf",
        "Variable",
        "tf",
        "truncated_normal",
        "num_hidden",
        "num_labels",
        "stddev",
        "tf",
        "Variable",
        "tf",
        "constant",
        "shape",
        "num_labels",
        "data",
        "tf",
        "nn",
        "conv2d",
        "data",
        "layer1_weights",
        "padding",
        "tf",
        "nn",
        "relu",
        "conv",
        "layer1_biases",
        "tf",
        "nn",
        "conv2d",
        "hidden",
        "layer2_weights",
        "padding",
        "tf",
        "nn",
        "relu",
        "conv",
        "layer2_biases",
        "hidden",
        "get_shape",
        "as_list",
        "tf",
        "reshape",
        "hidden",
        "shape",
        "shape",
        "shape",
        "shape",
        "tf",
        "nn",
        "relu",
        "tf",
        "matmul",
        "reshape",
        "layer3_weights",
        "layer3_biases",
        "tf",
        "matmul",
        "hidden",
        "layer4_weights",
        "layer4_biases",
        "model",
        "tf_train_dataset",
        "tf",
        "reduce_mean",
        "tf",
        "nn",
        "softmax_cross_entropy_with_logits",
        "logits",
        "tf_train_labels",
        "tf",
        "train",
        "GradientDescentOptimizer",
        "minimize",
        "loss",
        "tf",
        "nn",
        "softmax",
        "logits",
        "tf",
        "nn",
        "softmax",
        "model",
        "tf_valid_dataset",
        "tf",
        "nn",
        "softmax",
        "model",
        "tf_test_dataset",
        "tf",
        "Session",
        "graph",
        "graph",
        "session",
        "tf",
        "initialize_all_variables",
        "run",
        "step",
        "num_steps",
        "step",
        "batch_size",
        "train_labels",
        "shape",
        "batch_size",
        "train_dataset",
        "offset",
        "offset",
        "batch_size",
        "train_labels",
        "offset",
        "offset",
        "batch_size",
        "tf_train_dataset",
        "batch_data",
        "tf_train_labels",
        "batch_labels",
        "session",
        "run",
        "optimizer",
        "loss",
        "train_prediction",
        "feed_dict",
        "feed_dict",
        "step",
        "step",
        "l",
        "accuracy",
        "predictions",
        "batch_labels",
        "accuracy",
        "valid_prediction",
        "eval",
        "valid_labels",
        "accuracy",
        "test_prediction",
        "eval",
        "test_labels",
        "load_data",
        "convert_1d_to_3d",
        "data",
        "labels",
        "ConvolutionalNetwork",
        "dim_z",
        "dim_y",
        "convX",
        "set_datasets",
        "dim_x",
        "data_dim_x",
        "data_dim_x_label"
    ],
    "literals": [
        "'Training set'",
        "'Validation set'",
        "'Test set'",
        "'SAME'",
        "'SAME'",
        "'Initialized'",
        "'Minibatch loss at step %d: %f'",
        "'Minibatch accuracy: %.1f%%'",
        "'Validation accuracy: %.1f%%'",
        "'Test accuracy: %.1f%%'",
        "\"__main__\""
    ],
    "variables": [
        "num_labels",
        "num_channels",
        "num_steps",
        "batch_size",
        "patch_size",
        "depth",
        "num_hidden",
        "image_size_x",
        "image_size_y",
        "num_total_data",
        "num_train_offset",
        "num_valid_offset",
        "num_test_offset",
        "train_dataset",
        "train_labels",
        "valid_dataset",
        "valid_labels",
        "test_dataset",
        "test_labels",
        "graph",
        "tf_train_dataset",
        "tf_train_labels",
        "tf_valid_dataset",
        "tf_test_dataset",
        "layer1_weights",
        "layer1_biases",
        "layer2_weights",
        "layer2_biases",
        "layer3_weights",
        "layer3_biases",
        "layer4_weights",
        "layer4_biases",
        "conv",
        "hidden",
        "conv",
        "hidden",
        "shape",
        "reshape",
        "hidden",
        "logits",
        "loss",
        "optimizer",
        "train_prediction",
        "valid_prediction",
        "test_prediction",
        "offset",
        "batch_data",
        "batch_labels",
        "feed_dict",
        "_",
        "l",
        "predictions",
        "data",
        "labels",
        "data_dim_x",
        "data_dim_x_label",
        "data_dim_y",
        "data_dim_y_label",
        "data_dim_z",
        "data_dim_z_label",
        "convX"
    ],
    "comments": [
        "grayscale",
        "Input data.",
        "Variables.",
        "Model.",
        "Training computation.",
        "Optimizer.",
        "Predictions for the training, validation, and test data.",
        "convX.train()"
    ],
    "docstrings": [
        "\"\"\"\n        Reformat into a TensorFlow-friendly shape:\n          - convolutions need the image data formatted as a cube (width by height by #channels)\n          - labels as float 1-hot encodings.\n        \"\"\"",
        "\"\"\"\n        Two convolutional layers, followed by one fully connected layer, with stride of 2.\n        \"\"\""
    ],
    "functions": [
        "accuracy",
        "reformat",
        "set_datasets",
        "train",
        "model"
    ],
    "classes": [
        "ConvolutionalNetwork"
    ]
}