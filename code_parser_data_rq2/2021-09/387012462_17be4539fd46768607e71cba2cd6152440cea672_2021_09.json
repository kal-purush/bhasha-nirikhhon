{
    "identifiers": [
        "os",
        "re",
        "codecs",
        "unicodedata",
        "numpy",
        "np",
        "pandas",
        "pd",
        "torch",
        "utils",
        "data",
        "Dataset",
        "idx",
        "idx",
        "vocab",
        "idx",
        "idx",
        "vocab",
        "text",
        "join",
        "unicodedata",
        "normalize",
        "text",
        "unicodedata",
        "category",
        "text",
        "lower",
        "re",
        "sub",
        "format",
        "vocab",
        "text",
        "re",
        "sub",
        "text",
        "text",
        "csv_file",
        "subset",
        "pd",
        "read_csv",
        "csv_file",
        "subset",
        "df",
        "df",
        "df",
        "subset",
        "index",
        "row",
        "subset_df",
        "iterrows",
        "fnames",
        "append",
        "row",
        "row",
        "text_normalize",
        "text",
        "char2idx",
        "text",
        "text_lengths",
        "append",
        "len",
        "text",
        "texts",
        "append",
        "np",
        "array",
        "text",
        "np",
        "fnames",
        "text_lengths",
        "texts",
        "sentences",
        "max_n",
        "text_normalize",
        "line",
        "strip",
        "line",
        "sentences",
        "np",
        "zeros",
        "len",
        "normalized_sentences",
        "max_n",
        "np",
        "i",
        "sent",
        "normalized_sentences",
        "len",
        "sent",
        "char2idx",
        "sent",
        "texts",
        "Dataset",
        "keys",
        "dir_name",
        "keys",
        "os",
        "path",
        "join",
        "os",
        "path",
        "dirname",
        "os",
        "path",
        "realpath",
        "dir_name",
        "fnames",
        "text_lengths",
        "texts",
        "read_metadata",
        "os",
        "path",
        "join",
        "path",
        "start",
        "end",
        "fnames",
        "start",
        "end",
        "text_lengths",
        "start",
        "end",
        "texts",
        "start",
        "end",
        "len",
        "fnames",
        "index",
        "keys",
        "texts",
        "index",
        "keys",
        "np",
        "load",
        "os",
        "path",
        "join",
        "path",
        "fnames",
        "index",
        "keys",
        "np",
        "load",
        "os",
        "path",
        "join",
        "path",
        "fnames",
        "index",
        "keys",
        "np",
        "ones",
        "data",
        "shape",
        "dtype",
        "np",
        "keys",
        "np",
        "ones",
        "data",
        "shape",
        "dtype",
        "np",
        "data"
    ],
    "literals": [
        "\"PE abcdefghijklmnopqrstuvwxyz'.?\"",
        "''",
        "'NFD'",
        "'Mn'",
        "\"[^{}]\"",
        "\" \"",
        "\"[ ]+\"",
        "\" \"",
        "'*'",
        "'*'",
        "'subset'",
        "'file'",
        "'text'",
        "\"E\"",
        "\"E\"",
        "'EmotionalSpeechDataset'",
        "'ESD.csv'",
        "'texts'",
        "'texts'",
        "'mels'",
        "'mels'",
        "'mels'",
        "\"%s.npy\"",
        "'mags'",
        "'mags'",
        "'mags'",
        "\"%s.npy\"",
        "'mel_gates'",
        "'mel_gates'",
        "'mels'",
        "'mag_gates'",
        "'mag_gates'",
        "'mags'"
    ],
    "variables": [
        "vocab",
        "char2idx",
        "idx2char",
        "text",
        "text",
        "text",
        "text",
        "df",
        "subset_df",
        "subset_df",
        "fnames",
        "text_lengths",
        "texts",
        "text",
        "text",
        "text",
        "normalized_sentences",
        "texts",
        "texts",
        "i",
        "keys",
        "path",
        "fnames",
        "text_lengths",
        "texts",
        "data",
        "data",
        "data",
        "data",
        "data",
        "data"
    ],
    "comments": [
        "P: Padding, E: EOS.",
        "Strip accents",
        "def read_metadata(metadata_file):",
        "fnames, text_lengths, texts = [], [], []",
        "transcript = os.path.join(metadata_file)",
        "lines = codecs.open(transcript, 'r', 'utf-8').readlines()",
        "for line in lines:",
        "fname, _, text = line.strip().split(\"|\")",
        "",
        "fnames.append(fname)",
        "",
        "text = text_normalize(text) + \"E\"  # E: EOS",
        "text = [char2idx[char] for char in text]",
        "text_lengths.append(len(text))",
        "texts.append(np.array(text, np.long))",
        "",
        "return fnames, text_lengths, texts",
        "E: EOS",
        "text normalization, E: EOS",
        "self.fnames, self.text_lengths, self.texts = read_metadata(os.path.join(self.path, 'metadata.csv'))",
        "(39, 80)",
        "(39, 80)",
        "TODO: because pre processing!",
        "TODO: because pre processing!"
    ],
    "docstrings": [
        "\"\"\"Data loader for the LJSpeech dataset. See: https://keithito.com/LJ-Speech-Dataset/\"\"\""
    ],
    "functions": [
        "text_normalize",
        "read_metadata",
        "get_test_data",
        "__len__",
        "__getitem__"
    ],
    "classes": [
        "ESDSpeech"
    ]
}