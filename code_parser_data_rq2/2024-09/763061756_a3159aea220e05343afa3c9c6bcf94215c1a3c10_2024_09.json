{
    "identifiers": [
        "numbers",
        "warnings",
        "warn",
        "copy",
        "deepcopy",
        "numpy",
        "np",
        "numpy",
        "float32",
        "DTYPE",
        "numpy",
        "float64",
        "DOUBLE",
        "scipy",
        "sparse",
        "issparse",
        "joblib",
        "Parallel",
        "delayed",
        "sklearn",
        "clone",
        "sklearn",
        "ensemble",
        "RandomForestClassifier",
        "sklearn",
        "ensemble",
        "_base",
        "_set_random_states",
        "sklearn",
        "ensemble",
        "_forest",
        "_get_n_samples_bootstrap",
        "sklearn",
        "ensemble",
        "_forest",
        "_parallel_build_trees",
        "sklearn",
        "ensemble",
        "_forest",
        "_generate_unsampled_indices",
        "sklearn",
        "exceptions",
        "DataConversionWarning",
        "sklearn",
        "tree",
        "DecisionTreeClassifier",
        "sklearn",
        "utils",
        "check_array",
        "sklearn",
        "utils",
        "check_random_state",
        "sklearn",
        "utils",
        "_safe_indexing",
        "sklearn",
        "utils",
        "validation",
        "_check_sample_weight",
        "imblearn",
        "pipeline",
        "make_pipeline",
        "imblearn",
        "over_sampling",
        "SMOTE",
        "imblearn",
        "under_sampling",
        "RandomUnderSampler",
        "imblearn",
        "over_sampling",
        "BaseOverSampler",
        "imblearn",
        "BaseSampler",
        "imblearn",
        "utils",
        "Substitution",
        "imblearn",
        "utils",
        "_docstring",
        "_n_jobs_docstring",
        "imblearn",
        "utils",
        "_docstring",
        "_random_state_docstring",
        "imblearn",
        "utils",
        "_validation",
        "check_sampling_strategy",
        "imblearn",
        "utils",
        "_validation",
        "_deprecate_positional_args",
        "np",
        "iinfo",
        "np",
        "int32",
        "max",
        "sklearn",
        "utils",
        "check_X_y",
        "imblearn",
        "BaseSampler",
        "imblearn",
        "BaseCleaningSampler",
        "imblearn",
        "over_sampling",
        "SMOTE",
        "imblearn",
        "over_sampling",
        "BaseOverSampler",
        "imblearn",
        "under_sampling",
        "EditedNearestNeighbours",
        "imblearn",
        "under_sampling",
        "CondensedNearestNeighbour",
        "imblearn",
        "under_sampling",
        "NeighbourhoodCleaningRule",
        "imblearn",
        "under_sampling",
        "RandomUnderSampler",
        "imblearn",
        "utils",
        "check_target_type",
        "imblearn",
        "utils",
        "Substitution",
        "imblearn",
        "utils",
        "_docstring",
        "_n_jobs_docstring",
        "imblearn",
        "utils",
        "_docstring",
        "_random_state_docstring",
        "imblearn",
        "utils",
        "_validation",
        "_deprecate_positional_args",
        "Substitution",
        "sampling_strategy",
        "BaseOverSampler",
        "_sampling_strategy_docstring",
        "n_jobs",
        "_n_jobs_docstring",
        "random_state",
        "_random_state_docstring",
        "BaseSampler",
        "_deprecate_positional_args",
        "sampling_strategy",
        "random_state",
        "smote",
        "rus",
        "nc",
        "n_jobs",
        "sampling_strategy",
        "random_state",
        "smote",
        "rus",
        "nc",
        "n_jobs",
        "smote",
        "isinstance",
        "smote",
        "SMOTE",
        "clone",
        "smote",
        "ValueError",
        "smote",
        "SMOTE",
        "sampling_strategy",
        "sampling_strategy",
        "random_state",
        "random_state",
        "n_jobs",
        "n_jobs",
        "rus",
        "isinstance",
        "rus",
        "RandomUnderSampler",
        "clone",
        "rus",
        "ValueError",
        "rus",
        "RandomUnderSampler",
        "sampling_strategy",
        "n_jobs",
        "n_jobs",
        "nc",
        "isinstance",
        "nc",
        "NeighbourhoodCleaningRule",
        "clone",
        "nc",
        "ValueError",
        "rus",
        "NeighbourhoodCleaningRule",
        "sampling_strategy",
        "n_jobs",
        "n_jobs",
        "X",
        "y",
        "_validate_estimator",
        "check_target_type",
        "y",
        "check_X_y",
        "X",
        "y",
        "accept_sparse",
        "sampling_strategy",
        "nc_",
        "fit_resample",
        "X",
        "y",
        "rus_",
        "fit_resample",
        "X_res",
        "y_res",
        "smote_",
        "fit_resample",
        "X_res",
        "y_res",
        "sampler",
        "tree",
        "forest",
        "X",
        "y",
        "sample_weight",
        "tree_idx",
        "n_trees",
        "verbose",
        "class_weight",
        "n_samples_bootstrap",
        "sampler",
        "fit_resample",
        "X",
        "y",
        "sample_weight",
        "_safe_indexing",
        "sample_weight",
        "sampler",
        "sample_indices_",
        "_get_n_samples_bootstrap",
        "min",
        "n_samples_bootstrap",
        "X_resampled",
        "shape",
        "_parallel_build_trees",
        "tree",
        "forest",
        "X_resampled",
        "y_resampled",
        "sample_weight",
        "tree_idx",
        "n_trees",
        "verbose",
        "verbose",
        "class_weight",
        "class_weight",
        "n_samples_bootstrap",
        "n_samples_bootstrap",
        "sampler",
        "tree",
        "Substitution",
        "sampling_strategy",
        "BaseOverSampler",
        "_sampling_strategy_docstring",
        "n_jobs",
        "_n_jobs_docstring",
        "random_state",
        "_random_state_docstring",
        "RandomForestClassifier",
        "_deprecate_positional_args",
        "n_estimators",
        "criterion",
        "max_depth",
        "min_samples_split",
        "min_samples_leaf",
        "min_weight_fraction_leaf",
        "max_features",
        "max_leaf_nodes",
        "min_impurity_decrease",
        "bootstrap",
        "oob_score",
        "sampling_strategy",
        "replacement",
        "n_jobs",
        "random_state",
        "verbose",
        "warm_start",
        "class_weight",
        "ccp_alpha",
        "max_samples",
        "k_neighbors",
        "smote",
        "rus",
        "nc",
        "criterion",
        "criterion",
        "max_depth",
        "max_depth",
        "n_estimators",
        "n_estimators",
        "bootstrap",
        "bootstrap",
        "oob_score",
        "oob_score",
        "n_jobs",
        "n_jobs",
        "random_state",
        "random_state",
        "verbose",
        "verbose",
        "warm_start",
        "warm_start",
        "class_weight",
        "class_weight",
        "min_samples_split",
        "min_samples_split",
        "min_samples_leaf",
        "min_samples_leaf",
        "min_weight_fraction_leaf",
        "min_weight_fraction_leaf",
        "max_features",
        "max_features",
        "max_leaf_nodes",
        "max_leaf_nodes",
        "min_impurity_decrease",
        "min_impurity_decrease",
        "ccp_alpha",
        "ccp_alpha",
        "max_samples",
        "max_samples",
        "sampling_strategy",
        "random_state",
        "k_neighbors",
        "n_jobs",
        "replacement",
        "smote",
        "rus",
        "nc",
        "DecisionTreeClassifier",
        "isinstance",
        "n_estimators",
        "numbers",
        "Integral",
        "np",
        "integer",
        "ValueError",
        "n_estimators",
        "n_estimators",
        "ValueError",
        "n_estimators",
        "base_estimator",
        "clone",
        "base_estimator",
        "clone",
        "SMOTENCRUS",
        "sampling_strategy",
        "_sampling_strategy",
        "random_state",
        "random_state",
        "smote",
        "smote",
        "rus",
        "rus",
        "nc",
        "nc",
        "n_jobs",
        "n_jobs",
        "random_state",
        "clone",
        "base_estimator_",
        "estimator",
        "set_params",
        "p",
        "getattr",
        "p",
        "p",
        "estimator_params",
        "clone",
        "base_sampler_",
        "random_state",
        "_set_random_states",
        "estimator",
        "random_state",
        "_set_random_states",
        "sampler",
        "random_state",
        "estimator",
        "sampler",
        "X",
        "y",
        "sample_weight",
        "issparse",
        "y",
        "ValueError",
        "_validate_data",
        "X",
        "y",
        "multi_output",
        "accept_sparse",
        "dtype",
        "DTYPE",
        "sample_weight",
        "_check_sample_weight",
        "sample_weight",
        "X",
        "X",
        "shape",
        "issparse",
        "X",
        "X",
        "sort_indices",
        "np",
        "atleast_1d",
        "y",
        "y",
        "ndim",
        "y",
        "shape",
        "warn",
        "DataConversionWarning",
        "stacklevel",
        "y",
        "ndim",
        "np",
        "reshape",
        "y",
        "y",
        "shape",
        "_validate_y_class_weight",
        "y",
        "getattr",
        "y",
        "DOUBLE",
        "y",
        "flags",
        "contiguous",
        "np",
        "ascontiguousarray",
        "y_encoded",
        "dtype",
        "DOUBLE",
        "isinstance",
        "sampling_strategy",
        "np",
        "where",
        "classes_",
        "key",
        "value",
        "key",
        "value",
        "check_sampling_strategy",
        "sampling_strategy",
        "y",
        "items",
        "sampling_strategy",
        "expanded_class_weight",
        "sample_weight",
        "sample_weight",
        "expanded_class_weight",
        "expanded_class_weight",
        "_get_n_samples_bootstrap",
        "n_samples",
        "X",
        "shape",
        "max_samples",
        "max_samples",
        "_validate_estimator",
        "bootstrap",
        "oob_score",
        "ValueError",
        "check_random_state",
        "random_state",
        "warm_start",
        "hasattr",
        "n_estimators",
        "len",
        "estimators_",
        "n_more_estimators",
        "ValueError",
        "n_estimators",
        "len",
        "estimators_",
        "n_more_estimators",
        "warn",
        "warm_start",
        "len",
        "estimators_",
        "random_state",
        "randint",
        "MAX_INT",
        "size",
        "len",
        "estimators_",
        "_",
        "n_more_estimators",
        "_make_sampler_estimator",
        "random_state",
        "random_state",
        "trees",
        "append",
        "tree",
        "samplers",
        "append",
        "sampler",
        "Parallel",
        "n_jobs",
        "n_jobs",
        "verbose",
        "verbose",
        "delayed",
        "_local_parallel_build_trees",
        "s",
        "t",
        "X",
        "y_encoded",
        "sample_weight",
        "i",
        "len",
        "trees",
        "verbose",
        "verbose",
        "class_weight",
        "class_weight",
        "n_samples_bootstrap",
        "n_samples_bootstrap",
        "i",
        "s",
        "t",
        "samplers",
        "trees",
        "samplers_trees",
        "estimators_",
        "extend",
        "trees",
        "samplers_",
        "extend",
        "samplers",
        "pipelines_",
        "extend",
        "make_pipeline",
        "deepcopy",
        "s",
        "deepcopy",
        "t",
        "s",
        "t",
        "samplers",
        "trees",
        "oob_score",
        "_set_oob_score",
        "X",
        "y_encoded",
        "hasattr",
        "n_outputs_",
        "n_classes_",
        "classes_",
        "X",
        "y",
        "check_array",
        "X",
        "dtype",
        "DTYPE",
        "accept_sparse",
        "n_classes_",
        "y",
        "shape",
        "np",
        "zeros",
        "n_samples",
        "n_classes_",
        "k",
        "k",
        "n_outputs_",
        "sampler",
        "estimator",
        "samplers_",
        "estimators_",
        "X",
        "sampler",
        "sample_indices_",
        "y",
        "sampler",
        "sample_indices_",
        "y_resample",
        "shape",
        "_get_n_samples_bootstrap",
        "n_sample_subset",
        "max_samples",
        "_generate_unsampled_indices",
        "estimator",
        "random_state",
        "n_sample_subset",
        "n_samples_bootstrap",
        "estimator",
        "predict_proba",
        "X_resample",
        "unsampled_indices",
        "check_input",
        "n_outputs_",
        "p_estimator",
        "k",
        "n_outputs_",
        "sampler",
        "sample_indices_",
        "unsampled_indices",
        "predictions",
        "k",
        "indices",
        "p_estimator",
        "k",
        "k",
        "n_outputs_",
        "predictions",
        "k",
        "sum",
        "axis",
        "warn",
        "np",
        "errstate",
        "invalid",
        "divide",
        "predictions",
        "k",
        "predictions",
        "k",
        "sum",
        "axis",
        "np",
        "newaxis",
        "np",
        "isnan",
        "np",
        "sum",
        "decision",
        "axis",
        "oob_decision_function",
        "append",
        "decision",
        "oob_score",
        "np",
        "mean",
        "y",
        "mask_scores",
        "k",
        "np",
        "argmax",
        "predictions",
        "k",
        "mask_scores",
        "axis",
        "axis",
        "n_outputs_",
        "oob_decision_function",
        "oob_decision_function",
        "oob_score",
        "n_outputs_",
        "property",
        "getattr",
        "n_features_in_",
        "_n_features"
    ],
    "literals": [
        "\"over-sampling\"",
        "\"auto\"",
        "f\"smote needs to be a SMOTE object.\"",
        "f\"Got {type(self.smote)} instead.\"",
        "f\"enn needs to be an RUS.\"",
        "f\" Got {type(self.rus)} instead.\"",
        "\"auto\"",
        "f\"enn needs to be an NeighbourhoodCleaningRule.\"",
        "f\" Got {type(self.rus)} instead.\"",
        "\"auto\"",
        "\"csr\"",
        "\"csc\"",
        "\"gini\"",
        "\"auto\"",
        "\"auto\"",
        "f\"n_estimators must be an integer, \"",
        "f\"got {type(self.n_estimators)}.\"",
        "f\"n_estimators must be greater than zero, \"",
        "f\"got {self.n_estimators}.\"",
        "\"sparse multilabel-indicator for y is not supported.\"",
        "\"csc\"",
        "\"A column-vector y was passed when a 1d array was\"",
        "\" expected. Please change the shape of y to \"",
        "\"(n_samples,), for example using ravel().\"",
        "\"dtype\"",
        "\"under-sampling\"",
        "\"Out of bag estimation only available if bootstrap=True\"",
        "\"estimators_\"",
        "\"n_estimators=%d must be larger or equal to \"",
        "\"len(estimators_)=%d when warm_start==True\"",
        "\"Warm-start fitting without increasing n_estimators does not \"",
        "\"fit new trees.\"",
        "\"classes_\"",
        "\"csr\"",
        "\"Some inputs do not have OOB scores. \"",
        "\"This probably means too few trees were used \"",
        "\"to compute any reliable oob estimates.\"",
        "\"ignore\"",
        "\"ignore\"",
        "\"n_features_\"",
        "\"multioutput\"",
        "\"multilabel\""
    ],
    "variables": [
        "MAX_INT",
        "_sampling_type",
        "sampling_strategy",
        "random_state",
        "smote",
        "rus",
        "nc",
        "n_jobs",
        "smote_",
        "smote_",
        "rus_",
        "rus_",
        "nc_",
        "nc_",
        "y",
        "X",
        "y",
        "sampling_strategy_",
        "X_res",
        "y_res",
        "X_res",
        "y_res",
        "X_resampled",
        "y_resampled",
        "sample_weight",
        "n_samples_bootstrap",
        "tree",
        "sampling_strategy",
        "random_state",
        "k_neighbors",
        "n_jobs",
        "replacement",
        "smote",
        "rus",
        "nc",
        "base_estimator_",
        "base_estimator_",
        "base_sampler_",
        "estimator",
        "sampler",
        "X",
        "y",
        "sample_weight",
        "_n_features",
        "y",
        "y",
        "n_outputs_",
        "y_encoded",
        "expanded_class_weight",
        "y_encoded",
        "_sampling_strategy",
        "_sampling_strategy",
        "sample_weight",
        "sample_weight",
        "n_samples_bootstrap",
        "random_state",
        "estimators_",
        "samplers_",
        "pipelines_",
        "n_more_estimators",
        "trees",
        "samplers",
        "tree",
        "sampler",
        "samplers_trees",
        "samplers",
        "trees",
        "n_classes_",
        "classes_",
        "X",
        "n_classes_",
        "n_samples",
        "oob_decision_function",
        "oob_score",
        "predictions",
        "X_resample",
        "y_resample",
        "n_sample_subset",
        "n_samples_bootstrap",
        "unsampled_indices",
        "p_estimator",
        "p_estimator",
        "indices",
        "decision",
        "mask_scores",
        "oob_decision_function_",
        "oob_decision_function_",
        "oob_score_"
    ],
    "comments": [
        "-*- coding: utf-8 -*-",
        "The code is written using the original implementation of the BRF classier from the imblearn library.",
        "from sklearn.utils.fixes import _joblib_parallel_args",
        "from imblearn.under_sampling import EditedNearestNeighbours",
        "from smote_nc import SMOTENC",
        "from smote_rus import SMOTERUS",
        "Otherwise create a default SMOTE",
        "Otherwise create a default RUS",
        "Otherwise create a default NC",
        "Creating the forest",
        "resample before to fit the tree",
        "Validate or convert input data",
        "Pre-sort indices to avoid that each individual tree of the",
        "ensemble sorts the indices.",
        "reshape is necessary to preserve the data contiguity against vs",
        "[:, np.newaxis] that does not.",
        "Get bootstrap sample size",
        "Check parameters",
        "Free allocated memory, if any",
        "We draw from the random state to get the random state we",
        "would have got if we hadn't used a warm_start.",
        "Parallel loop: we prefer the threading backend as the Cython code",
        "for fitting the trees is internally releasing the Python GIL",
        "making threading more efficient than multiprocessing in",
        "that case. However, we respect any parallel_backend contexts set",
        "at a higher level, since correctness does not rely on using",
        "threads.",
        "Collect newly grown trees",
        "Create pipeline with the fitted samplers and trees",
        "Decapsulate classes_ attributes",
        "with the resampling, we are likely to have rows not included",
        "for the OOB score leading to division by zero"
    ],
    "docstrings": [
        "\"\"\"\nCreated on Sat Sep 14 13:47:53 2024\n\n@author: asifn\n\"\"\"",
        "\"\"\"Proposed Algorithm: iBRF\"\"\"",
        "\"\"\"Over-sampling using SMOTE, undersampling using RUS and cleaning using NC.\n    \n    Parameters\n    ----------\n    {sampling_strategy}\n    {random_state}\n    \n    smote : sampler object, default=None\n        The :class:`~imblearn.over_sampling.SMOTE` object to use. If not given,\n        a :class:`~imblearn.over_sampling.SMOTE` object with default parameters\n        will be given.\n    Attributes\n    ----------\n    sampling_strategy_ : dict\n        Dictionary containing the information to sample the dataset. The keys\n        corresponds to the class labels from which to sample and the values\n        are the number of samples to sample.\n    smote_ : sampler object\n        The validated :class:`~imblearn.over_sampling.SMOTE` instance.\n    nc_ : sampler object\n        The validated :class:`~imblearn.under_sampling.NeighbourhoodCleaningRule`\n        instance.\n    rus_ : sampler object\n        The validated :class:`~imblearn.under_sampling.RandomUnderSampler`\n        instance.\n    n_features_in_ : int\n        Number of features in the input dataset.\n        \n    \"\"\"",
        "\"\"\"An improved balanced random forest classifier.\n\n    A balanced random forest randomly under-samples each boostrap sample to\n    balance it. The iBRF approach uses a hybrid sampling approach to balance it.\n\n    Parameters\n    ----------\n    n_estimators : int, default=100\n        The number of trees in the forest.\n\n    criterion : {{\"gini\", \"entropy\"}}, default=\"gini\"\n        The function to measure the quality of a split. Supported criteria are\n        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n        Note: this parameter is tree-specific.\n\n    max_depth : int, default=None\n        The maximum depth of the tree. If None, then nodes are expanded until\n        all leaves are pure or until all leaves contain less than\n        min_samples_split samples.\n\n    min_samples_split : int or float, default=2\n        The minimum number of samples required to split an internal node:\n\n        - If int, then consider `min_samples_split` as the minimum number.\n        - If float, then `min_samples_split` is a percentage and\n          `ceil(min_samples_split * n_samples)` are the minimum\n          number of samples for each split.\n\n    min_samples_leaf : int or float, default=1\n        The minimum number of samples required to be at a leaf node:\n\n        - If int, then consider ``min_samples_leaf`` as the minimum number.\n        - If float, then ``min_samples_leaf`` is a fraction and\n          `ceil(min_samples_leaf * n_samples)` are the minimum\n          number of samples for each node.\n\n    min_weight_fraction_leaf : float, default=0.0\n        The minimum weighted fraction of the sum total of weights (of all\n        the input samples) required to be at a leaf node. Samples have\n        equal weight when sample_weight is not provided.\n\n    max_features : {{\"auto\", \"sqrt\", \"log2\"}}, int, float, or None, \\\n            default=\"auto\"\n        The number of features to consider when looking for the best split:\n\n        - If int, then consider `max_features` features at each split.\n        - If float, then `max_features` is a percentage and\n          `int(max_features * n_features)` features are considered at each\n          split.\n        - If \"auto\", then `max_features=sqrt(n_features)`.\n        - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n        - If \"log2\", then `max_features=log2(n_features)`.\n        - If None, then `max_features=n_features`.\n\n        Note: the search for a split does not stop until at least one\n        valid partition of the node samples is found, even if it requires to\n        effectively inspect more than ``max_features`` features.\n\n    max_leaf_nodes : int, default=None\n        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n        Best nodes are defined as relative reduction in impurity.\n        If None then unlimited number of leaf nodes.\n\n    min_impurity_decrease : float, default=0.0\n        A node will be split if this split induces a decrease of the impurity\n        greater than or equal to this value.\n        The weighted impurity decrease equation is the following::\n\n            N_t / N * (impurity - N_t_R / N_t * right_impurity\n                                - N_t_L / N_t * left_impurity)\n\n        where ``N`` is the total number of samples, ``N_t`` is the number of\n        samples at the current node, ``N_t_L`` is the number of samples in the\n        left child, and ``N_t_R`` is the number of samples in the right child.\n        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n        if ``sample_weight`` is passed.\n\n    bootstrap : bool, default=True\n        Whether bootstrap samples are used when building trees.\n\n    oob_score : bool, default=False\n        Whether to use out-of-bag samples to estimate\n        the generalization accuracy.\n\n    {sampling_strategy}\n\n    replacement : bool, default=False\n        Whether or not to sample randomly with replacement or not.\n\n    {n_jobs}\n\n    {random_state}\n\n    verbose : int, default=0\n        Controls the verbosity of the tree building process.\n\n    warm_start : bool, default=False\n        When set to ``True``, reuse the solution of the previous call to fit\n        and add more estimators to the ensemble, otherwise, just fit a whole\n        new forest.\n\n    class_weight : dict, list of dicts, {{\"balanced\", \"balanced_subsample\"}}, \\\n            default=None\n        Weights associated with classes in the form dictionary with the key\n        being the class_label and the value the weight.\n        If not given, all classes are supposed to have weight one. For\n        multi-output problems, a list of dicts can be provided in the same\n        order as the columns of y.\n        Note that for multioutput (including multilabel) weights should be\n        defined for each class of every column in its own dict. For example,\n        for four-class multilabel classification weights should be\n        [{{0: 1, 1: 1}}, {{0: 1, 1: 5}}, {{0: 1, 1: 1}}, {{0: 1, 1: 1}}]\n        instead of [{{1:1}}, {{2:5}}, {{3:1}}, {{4:1}}].\n        The \"balanced\" mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data\n        as ``n_samples / (n_classes * np.bincount(y))``\n        The \"balanced_subsample\" mode is the same as \"balanced\" except that\n        weights are computed based on the bootstrap sample for every tree\n        grown.\n        For multi-output, the weights of each column of y will be multiplied.\n        Note that these weights will be multiplied with sample_weight (passed\n        through the fit method) if sample_weight is specified.\n\n    ccp_alpha : non-negative float, default=0.0\n        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n        subtree with the largest cost complexity that is smaller than\n        ``ccp_alpha`` will be chosen. By default, no pruning is performed.\n\n        .. versionadded:: 0.6\n           Added in `scikit-learn` in 0.22\n\n    max_samples : int or float, default=None\n        If bootstrap is True, the number of samples to draw from X\n        to train each base estimator.\n            - If None (default), then draw `X.shape[0]` samples.\n            - If int, then draw `max_samples` samples.\n            - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n              `max_samples` should be in the interval `(0, 1)`.\n        Be aware that the final number samples used will be the minimum between\n        the number of samples given in `max_samples` and the number of samples\n        obtained after resampling.\n\n        .. versionadded:: 0.6\n           Added in `scikit-learn` in 0.22\n\n    Attributes\n    ----------\n    base_estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier` instance\n        The child estimator template used to create the collection of fitted\n        sub-estimators.\n\n    estimators_ : list of :class:`~sklearn.tree.DecisionTreeClassifier`\n        The collection of fitted sub-estimators.\n\n    base_sampler_ : :class:`~imblearn.under_sampling.RandomUnderSampler`\n        The base sampler used to construct the subsequent list of samplers.\n\n    samplers_ : list of :class:`~imblearn.under_sampling.RandomUnderSampler`\n        The collection of fitted samplers.\n\n    pipelines_ : list of Pipeline.\n        The collection of fitted pipelines (samplers + trees).\n\n    classes_ : ndarray of shape (n_classes,) or a list of such arrays\n        The classes labels (single output problem), or a list of arrays of\n        class labels (multi-output problem).\n\n    n_classes_ : int or list\n        The number of classes (single output problem), or a list containing the\n        number of classes for each output (multi-output problem).\n\n    n_features_ : int\n        The number of features when ``fit`` is performed.\n\n        .. deprecated:: 1.0\n           `n_features_` is deprecated in `scikit-learn` 1.0 and will be removed\n           in version 1.2. Depending of the version of `scikit-learn` installed,\n           you will get be warned or not.\n\n    n_features_in_ : int\n        Number of features in the input dataset.\n\n        .. versionadded:: 0.9\n\n    feature_names_in_ : ndarray of shape (n_features_in_,)\n        Names of features seen during `fit`. Defined only when `X` has feature\n        names that are all strings.\n\n        .. versionadded:: 0.9\n\n    n_outputs_ : int\n        The number of outputs when ``fit`` is performed.\n\n    feature_importances_ : ndarray of shape (n_features,)\n        The feature importances (the higher, the more important the feature).\n\n    oob_score_ : float\n        Score of the training dataset obtained using an out-of-bag estimate.\n\n    oob_decision_function_ : ndarray of shape (n_samples, n_classes)\n        Decision function computed with out-of-bag estimate on the training\n        set. If n_estimators is small it might be possible that a data point\n        was never left out during the bootstrap. In this case,\n        `oob_decision_function_` might contain NaN.\n\n    References\n    ----------\n    .. [1] Chen, Chao, Andy Liaw, and Leo Breiman. \"Using random forest to\n       learn imbalanced data.\" University of California, Berkeley 110 (2004):\n       1-12.\n\n\n    \"\"\"",
        "\"\"\"Check the estimator and the n_estimator attribute, set the\n        `base_estimator_` attribute.\"\"\"",
        "\"\"\"Make and configure a copy of the `base_estimator_` attribute.\n        Warning: This method should be used to properly instantiate new\n        sub-estimators.\n        \"\"\"",
        "\"\"\"Build a forest of trees from the training set (X, y).\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The training input samples. Internally, its dtype will be converted\n            to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n            converted into a sparse ``csc_matrix``.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            The target values (class labels in classification, real numbers in\n            regression).\n\n        sample_weight : array-like of shape (n_samples,)\n            Sample weights. If None, then samples are equally weighted. Splits\n            that would create child nodes with net zero or negative weight are\n            ignored while searching for a split in each node. In the case of\n            classification, splits are also ignored if they would result in any\n            single class carrying a negative weight in either child node.\n\n        Returns\n        -------\n        self : object\n            The fitted instance.\n        \"\"\"",
        "**_joblib_parallel_args(prefer=\"threads\"),",
        "\"\"\"Compute out-of-bag score.\"\"\"",
        "\"\"\"Number of features when fitting the estimator.\"\"\""
    ],
    "functions": [
        "_validate_estimator",
        "_fit_resample",
        "_local_parallel_build_trees",
        "_validate_estimator",
        "_make_sampler_estimator",
        "fit",
        "_set_oob_score",
        "n_features_",
        "_more_tags"
    ],
    "classes": [
        "SMOTENCRUS",
        "ImprovedBalancedRandomForestClassifier"
    ]
}