{
    "identifiers": [
        "os",
        "time",
        "whisperx",
        "torch",
        "tiktoken",
        "tabulate",
        "tabulate",
        "argparse",
        "gc",
        "os",
        "makedirs",
        "exist_ok",
        "os",
        "makedirs",
        "exist_ok",
        "time",
        "time",
        "script_start_time",
        "script_start_time",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "nargs",
        "choices",
        "help",
        "parser",
        "add_argument",
        "choices",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "choices",
        "help",
        "parser",
        "parse_args",
        "args",
        "model_pos",
        "args",
        "model_pos",
        "args",
        "model",
        "args",
        "batch_size",
        "batch_sizes",
        "get",
        "model_name",
        "args",
        "batch_size",
        "torch",
        "cuda",
        "is_available",
        "model_name",
        "batch_size",
        "device",
        "args",
        "compute_type",
        "torch",
        "cuda",
        "is_available",
        "torch",
        "cuda",
        "empty_cache",
        "gc",
        "collect",
        "whisperx",
        "load_model",
        "model_name",
        "device",
        "compute_type",
        "args",
        "compute_type",
        "e",
        "e",
        "exit",
        "tiktoken",
        "encoding_for_model",
        "text",
        "len",
        "encoding",
        "encode",
        "text",
        "filename",
        "os",
        "listdir",
        "audio_folder",
        "filename",
        "endswith",
        "time",
        "time",
        "os",
        "path",
        "join",
        "audio_folder",
        "filename",
        "filename",
        "whisperx",
        "load_audio",
        "input_path",
        "model",
        "transcribe",
        "audio",
        "batch_size",
        "batch_size",
        "RuntimeError",
        "e",
        "e",
        "batch_size",
        "batch_size",
        "torch",
        "cuda",
        "empty_cache",
        "gc",
        "collect",
        "model",
        "transcribe",
        "audio",
        "batch_size",
        "batch_size",
        "whisperx",
        "load_align_model",
        "language_code",
        "result",
        "device",
        "device",
        "whisperx",
        "align",
        "result",
        "model_a",
        "metadata",
        "audio",
        "device",
        "model_a",
        "torch",
        "cuda",
        "empty_cache",
        "gc",
        "collect",
        "result_aligned",
        "seg",
        "segments",
        "seg",
        "strip",
        "seg",
        "start_seconds",
        "start_seconds",
        "start_minutes",
        "start_seconds_remainder",
        "transcript_segments",
        "append",
        "start_time_formatted",
        "seg",
        "strip",
        "join",
        "transcript_segments",
        "os",
        "path",
        "splitext",
        "filename",
        "os",
        "path",
        "join",
        "output_folder",
        "base_filename",
        "os",
        "makedirs",
        "file_output_folder",
        "exist_ok",
        "os",
        "path",
        "join",
        "file_output_folder",
        "base_filename",
        "open",
        "timestamp_output_path",
        "encoding",
        "f",
        "f",
        "write",
        "transcript",
        "seg",
        "segments",
        "seg",
        "strip",
        "plain_text",
        "append",
        "seg",
        "strip",
        "join",
        "plain_text",
        "os",
        "path",
        "join",
        "file_output_folder",
        "base_filename",
        "open",
        "plain_output_path",
        "encoding",
        "f",
        "f",
        "write",
        "plain_transcript",
        "time",
        "time",
        "file_start_time",
        "os",
        "path",
        "getsize",
        "timestamp_output_path",
        "len",
        "transcript",
        "count_tokens",
        "transcript",
        "result",
        "total_length",
        "audio_length",
        "audio_length",
        "audio_length",
        "minutes",
        "minutes",
        "seconds",
        "total_size",
        "file_size",
        "total_chars",
        "char_count",
        "total_tokens",
        "token_count",
        "total_time",
        "file_time",
        "stats",
        "append",
        "os",
        "path",
        "splitext",
        "filename",
        "model_name",
        "length_formatted",
        "file_size",
        "char_count",
        "token_count",
        "file_time",
        "filename",
        "file_time",
        "e",
        "filename",
        "e",
        "torch",
        "cuda",
        "is_available",
        "torch",
        "cuda",
        "empty_cache",
        "gc",
        "collect",
        "tabulate",
        "stats",
        "headers",
        "headers",
        "tablefmt",
        "script_start_time",
        "script_start_time",
        "time",
        "time",
        "time",
        "time",
        "time",
        "time",
        "script_start_time",
        "total_length",
        "total_length",
        "total_minutes",
        "elapsed_time",
        "total_minutes",
        "total_seconds",
        "total_size",
        "total_chars",
        "total_tokens"
    ],
    "literals": [
        "\"./output/\"",
        "\"./audio_processed/\"",
        "f\"DEBUG - script_start_time type: {type(script_start_time)}, value: {script_start_time}\"",
        "'Transcribe audio files using WhisperX'",
        "'model_pos'",
        "'?'",
        "'tiny'",
        "'base'",
        "'small'",
        "'medium'",
        "'large-v2'",
        "'large-v3'",
        "'large-v3-turbo'",
        "'WhisperX model to use (shorthand)'",
        "'--model'",
        "'tiny'",
        "'base'",
        "'small'",
        "'medium'",
        "'large-v2'",
        "'large-v3-turbo'",
        "'WhisperX model to use'",
        "'large-v3-turbo'",
        "'--batch_size'",
        "'Batch size for transcription'",
        "'--compute_type'",
        "'float16'",
        "'float32'",
        "'int8'",
        "'Compute type'",
        "'float16'",
        "'tiny'",
        "'base'",
        "'small'",
        "'medium'",
        "'large-v2'",
        "'large-v3'",
        "'large-v3-turbo'",
        "\"cuda\"",
        "\"cpu\"",
        "f\"\\nðŸ¤– WhisperX Model: {model_name}\"",
        "f\"ðŸ§  Using batch size: {batch_size}\"",
        "f\"ðŸ’» Device: {device} | Compute type: {args.compute_type}\"",
        "f\"Error loading models: {str(e)}\"",
        "\"Try using a smaller model, reducing batch size, or using int8 compute type\"",
        "\"gpt-4\"",
        "\"./audio\"",
        "\"./output/\"",
        "\".mp3\"",
        "\".wav\"",
        "f\"\\nProcessing {filename}...\"",
        "\"CUDA out of memory\"",
        "f\"ðŸš¨ CUDA out of memory. Reducing batch size to {batch_size//2}...\"",
        "\"language\"",
        "\"segments\"",
        "\"segments\"",
        "\"text\"",
        "\"start\"",
        "f\"{start_minutes:02d}:{start_seconds_remainder:02d}\"",
        "f\"{start_time_formatted} > {seg['text'].strip()}\"",
        "'text'",
        "\"\\n\"",
        "f\"{base_filename}-timestamps.txt\"",
        "\"w\"",
        "\"utf-8\"",
        "\"text\"",
        "\"text\"",
        "\" \"",
        "f\"{base_filename}.txt\"",
        "\"w\"",
        "\"utf-8\"",
        "\"segments\"",
        "\"end\"",
        "f\"{minutes}:{seconds:02d}\"",
        "f\"âœ… {os.path.splitext(filename)[0]}-{model_name}.txt\"",
        "f\"{file_size:.2f}\"",
        "f\"{file_time:.2f}\"",
        "f\"âœ… Completed {filename} in {file_time:.2f}s\"",
        "f\"âŒ Error processing {filename}: {str(e)}\"",
        "\"\\nResults\"",
        "\"âœ… File\"",
        "\"Audio\"",
        "\"Size (KB)\"",
        "\"Characters\"",
        "\"Tokens\"",
        "\"Time (s)\"",
        "\"grid\"",
        "f\"DEBUG - Before elapsed_time calculation:\"",
        "f\"  - script_start_time type: {type(script_start_time)}, value: {script_start_time}\"",
        "f\"  - current time type: {type(time.time())}, value: {time.time()}\"",
        "\"\\nTotals\"",
        "f\"Time:         {elapsed_time:.2f} seconds\"",
        "f\"Transcribed:  {total_minutes}:{total_seconds:02d} minutes\"",
        "f\"Size:         {total_size:.2f} KB\"",
        "f\"Characters:   {total_chars}\"",
        "f\"Tokens:       {total_tokens}\""
    ],
    "variables": [
        "script_start_time",
        "parser",
        "args",
        "model_name",
        "batch_sizes",
        "batch_size",
        "batch_size",
        "device",
        "model",
        "encoding",
        "audio_folder",
        "output_folder",
        "stats",
        "total_size",
        "total_chars",
        "total_tokens",
        "total_time",
        "total_length",
        "file_start_time",
        "input_path",
        "audio",
        "result",
        "result",
        "model_a",
        "metadata",
        "result_aligned",
        "segments",
        "transcript_segments",
        "start_seconds",
        "start_minutes",
        "start_seconds_remainder",
        "start_time_formatted",
        "transcript",
        "base_filename",
        "file_output_folder",
        "timestamp_output_path",
        "plain_text",
        "plain_transcript",
        "plain_output_path",
        "file_time",
        "file_size",
        "char_count",
        "token_count",
        "audio_length",
        "minutes",
        "seconds",
        "length_formatted",
        "headers",
        "elapsed_time",
        "total_minutes",
        "total_seconds"
    ],
    "comments": [
        "Create directories if they don't exist",
        "Timer start - use a more specific name to avoid collisions",
        "Argument parser",
        "Process positional arguments",
        "Determine appropriate batch size based on model",
        "Default batch sizes based on model size",
        "Load WhisperX model",
        "Try to clear any existing models from GPU memory",
        "OpenAI tokenizer",
        "WhisperX transcription",
        "Use try/except with batch size reduction for OOM errors",
        "Align word-level timestamps",
        "Free up memory after alignment",
        "Process segments",
        "Format segments with MM:SS timestamps followed by > and then text",
        "Format each segment with timestamps in MM:SS format",
        "Format start time as MM:SS",
        "Format with start timestamp followed by > and then the text",
        "Save output",
        "Save with timestamps",
        "Create a version without timestamps",
        "Save without timestamps",
        "Calculate stats",
        "Try to clear memory in case of error",
        "Results",
        "Debug before calculating elapsed time",
        "Calculate elapsed time"
    ],
    "docstrings": [],
    "functions": [
        "count_tokens"
    ],
    "classes": []
}