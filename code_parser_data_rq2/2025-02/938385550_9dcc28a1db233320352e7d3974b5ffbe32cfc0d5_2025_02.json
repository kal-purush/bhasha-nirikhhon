{
    "identifiers": [
        "unicodedata",
        "time",
        "functools",
        "lru_cache",
        "concurrent",
        "futures",
        "numpy",
        "np",
        "csv",
        "maketrans",
        "punctuation",
        "whitespace",
        "replace",
        "maketrans",
        "COMBINED_TRANS",
        "NUMBER_TRANS",
        "lru_cache",
        "maxsize",
        "word",
        "unicodedata",
        "normalize",
        "word",
        "join",
        "c",
        "c",
        "word",
        "c",
        "diacritics",
        "word",
        "translate",
        "combined_trans",
        "translate",
        "number_trans",
        "lower",
        "sentence",
        "unicodedata",
        "normalize",
        "sentence",
        "lower",
        "join",
        "c",
        "c",
        "word",
        "c",
        "diacritics",
        "sentence",
        "translate",
        "combined_trans",
        "translate",
        "number_trans",
        "sentence",
        "last_char",
        "count",
        "count",
        "result",
        "append",
        "result",
        "append",
        "join",
        "result",
        "sentence",
        "split",
        "i",
        "len",
        "words",
        "words",
        "i",
        "word",
        "startswith",
        "word",
        "startswith",
        "word",
        "startswith",
        "word",
        "len",
        "prefix",
        "rest",
        "prefix",
        "rest",
        "i",
        "len",
        "words",
        "words",
        "i",
        "suffixes",
        "output",
        "append",
        "word",
        "words",
        "i",
        "i",
        "output",
        "append",
        "word",
        "i",
        "join",
        "output",
        "sentence",
        "_normalize_chunk",
        "sentence",
        "texts",
        "len",
        "texts",
        "_normalize_chunk",
        "t",
        "t",
        "texts",
        "np",
        "array",
        "texts",
        "dtype",
        "concurrent",
        "futures",
        "ThreadPoolExecutor",
        "executor",
        "executor",
        "_normalize_chunk",
        "text_array",
        "results",
        "func",
        "args",
        "kwargs",
        "func",
        "args",
        "kwargs",
        "time",
        "perf_counter_ns",
        "func",
        "args",
        "kwargs",
        "time",
        "perf_counter_ns",
        "start",
        "result",
        "elapsed",
        "wrapper",
        "TurboNormalizer",
        "twitter_dataset",
        "normalizer",
        "normalize_word",
        "normalizer",
        "normalize_sentence",
        "twitter_dataset",
        "normalizer",
        "normalize_bulk",
        "normalizer",
        "normalize_sentence",
        "open",
        "newline",
        "encoding",
        "csvfile",
        "csv",
        "writer",
        "csvfile",
        "writer",
        "writerow",
        "name",
        "data",
        "func",
        "tests",
        "items",
        "precision_timer",
        "func",
        "data",
        "name",
        "elapsed",
        "len",
        "data",
        "isinstance",
        "data",
        "len",
        "data",
        "split",
        "isinstance",
        "result",
        "writer",
        "writerow",
        "data",
        "result",
        "elapsed",
        "result",
        "len",
        "result",
        "result",
        "orig",
        "norm",
        "data",
        "result",
        "writer",
        "writerow",
        "orig",
        "norm",
        "elapsed",
        "len",
        "data",
        "result",
        "len",
        "result",
        "result"
    ],
    "literals": [
        "''",
        "''",
        "'\\u200c'",
        "''",
        "'@#'",
        "'0123456789'",
        "'۰۱۲۳۴۵۶۷۸۹'",
        "'\\u064b\\u064c\\u064d\\u064e\\u064f\\u0650\\u0651\\u0652'",
        "'ها'",
        "'ای'",
        "'تر'",
        "'تری'",
        "'ترین'",
        "'NFKC'",
        "''",
        "'NFKC'",
        "''",
        "''",
        "''",
        "'می'",
        "'نمی'",
        "'می'",
        "'می'",
        "'نمی'",
        "'\\u200c'",
        "'\\u200c'",
        "' '",
        "\"سلام چطوری؟ امروز خیلی هوا خوبه!\"",
        "\"این فیلم جدید رو دیدم واقعا عالی بود!!!\"",
        "\"چرا انقدر ترافیک زیاده؟؟؟ خسته شدم\"",
        "\"کاش یه روز بدون استرس داشته باشیم...\"",
        "\"دیروز یه کتاب خوندم خیلی جالب بود #کتاب\"",
        "\"__main__\"",
        "\"تک کلمه ساده\"",
        "\"TEST!\"",
        "\"جمله استاندارد\"",
        "\"این یک متن TEST با علائم !@# سجاوندی و   فاصله‌های اضافه است!!!\"",
        "\"پردازش گروهی\"",
        "\"توییت نمونه\"",
        "\"سلام @ali چطوری؟ #جالب اینو ببینممم https://t.co/test 😂 ۳.۱۴\"",
        "'normalized_tweets.csv'",
        "'w'",
        "''",
        "'utf-8'",
        "'Original Text'",
        "'Normalized Text'",
        "'Execution Time (s)'",
        "f\"✅ تست {name}\"",
        "f\"⏱ زمان اجرا: {elapsed:.10f} ثانیه\"",
        "f\"📊 حجم داده: {len(data) if isinstance(data, list) else len(data.split())}\"",
        "f\"🎯 نمونه خروجی: {result[:75] + '...' if len(result) > 75 else result}\"",
        "'...'",
        "f\"🎯 نمونه خروجی: {result[0][:75] + '...' if len(result[0]) > 75 else result[0]}\"",
        "'...'",
        "\"-\"",
        "\"نتایج در فایل 'normalized_tweets.csv' ذخیره شد!\""
    ],
    "variables": [
        "COMBINED_TRANS",
        "NUMBER_TRANS",
        "combined_trans",
        "number_trans",
        "diacritics",
        "suffixes",
        "word",
        "word",
        "sentence",
        "sentence",
        "sentence",
        "result",
        "last_char",
        "count",
        "last_char",
        "count",
        "sentence",
        "words",
        "output",
        "i",
        "word",
        "prefix",
        "rest",
        "word",
        "text_array",
        "results",
        "start",
        "result",
        "elapsed",
        "twitter_dataset",
        "normalizer",
        "twitter_dataset",
        "tests",
        "writer",
        "result",
        "elapsed"
    ],
    "comments": [
        "اصلاح جدول ترجمه که نیم‌فاصله رو نگه داره",
        "کاهش تکرار حروف",
        "جدا کردن کلمات با حفظ نیم‌فاصله",
        "مدیریت \"می\" و \"نمی\"",
        "نیم‌فاصله‌گذاری پسوندها",
        "دیتاست نمونه توییتر",
        "... بقیه دیتاست همونیه که قبلاً دادم، برای کوتاه بودن فقط ۵ تا نمونه گذاشتم",
        "می‌تونی دیتاست کامل رو از پیام قبلی کپی کنی",
        "دیتاست کامل رو اینجا کپی کن یا همون ۵ تا رو تست کن",
        "جایگزین با دیتاست کامل اگه خواستی"
    ],
    "docstrings": [],
    "functions": [
        "normalize_word",
        "_normalize_chunk",
        "normalize_sentence",
        "normalize_bulk",
        "precision_timer",
        "wrapper"
    ],
    "classes": [
        "TurboNormalizer"
    ]
}