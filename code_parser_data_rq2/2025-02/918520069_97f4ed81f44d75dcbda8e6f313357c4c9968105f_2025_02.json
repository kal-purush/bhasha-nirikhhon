{
    "identifiers": [
        "time",
        "os",
        "vllm",
        "LLM",
        "SamplingParams",
        "vllm",
        "assets",
        "audio",
        "AudioAsset",
        "os",
        "environ",
        "input",
        "LLM",
        "model",
        "model",
        "max_model_len",
        "max_num_seqs",
        "limit_mm_per_prompt",
        "kv_cache_dtype",
        "AudioAsset",
        "audio_and_sample_rate",
        "AudioAsset",
        "audio_and_sample_rate",
        "SamplingParams",
        "temperature",
        "top_p",
        "max_tokens",
        "llm",
        "start_profile",
        "llm",
        "generate",
        "prompts",
        "sampling_params",
        "llm",
        "stop_profile",
        "output",
        "outputs",
        "output",
        "prompt",
        "output",
        "encoder_prompt",
        "output",
        "outputs",
        "text",
        "encoder_prompt",
        "prompt",
        "generated_text"
    ],
    "literals": [
        "\"VLLM_TORCH_PROFILER_DIR\"",
        "\"./vllm_profile\"",
        "'model? (tiny, small, medium, ...) > '",
        "f\"openai/whisper-{model}\"",
        "\"audio\"",
        "\"fp8\"",
        "\"prompt\"",
        "\"<|startoftranscript|>\"",
        "\"multi_modal_data\"",
        "\"audio\"",
        "\"mary_had_lamb\"",
        "\"encoder_prompt\"",
        "\"prompt\"",
        "\"\"",
        "\"multi_modal_data\"",
        "\"audio\"",
        "\"winning_call\"",
        "\"decoder_prompt\"",
        "\"<|startoftranscript|>\"",
        "f\"\\nEncoder prompt: {encoder_prompt!r}, \"",
        "f\"\\nDecoder prompt: {prompt!r}, \"",
        "f\"\\nGenerated text: {generated_text!r}\""
    ],
    "variables": [
        "model",
        "llm",
        "prompts",
        "sampling_params",
        "outputs",
        "prompt",
        "encoder_prompt",
        "generated_text"
    ],
    "comments": [
        "Create a Whisper encoder/decoder model instance",
        "Test explicit encoder/decoder prompt",
        "Print the outputs."
    ],
    "docstrings": [],
    "functions": [],
    "classes": []
}