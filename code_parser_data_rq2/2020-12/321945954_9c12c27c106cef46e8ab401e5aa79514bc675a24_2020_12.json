{
    "identifiers": [
        "numpy",
        "np",
        "trax",
        "trax",
        "layers",
        "tl",
        "trax",
        "fastmath",
        "numpy",
        "fastnp",
        "trax",
        "supervised",
        "training",
        "candidate",
        "reference",
        "candidate",
        "reference",
        "can_unigram_set",
        "intersection",
        "ref_unigram_set",
        "can_unigram_set",
        "union",
        "ref_unigram_set",
        "len",
        "joint_elems",
        "len",
        "all_elems",
        "overlap",
        "similarity_fn",
        "samples",
        "log_probs",
        "index_candidate",
        "candidate",
        "samples",
        "index_sample",
        "sample",
        "logp",
        "samples",
        "log_probs",
        "index_candidate",
        "index_sample",
        "np",
        "exp",
        "logp",
        "weight_sum",
        "sample_p",
        "similarity_fn",
        "candidate",
        "sample",
        "overlap",
        "sample_p",
        "sample_overlap",
        "overlap",
        "weight_sum",
        "score",
        "scores",
        "input_encoder_fn",
        "input_encoder_fn",
        "target",
        "input_vocab_size",
        "d_model",
        "n_encoder_layers",
        "join",
        "d_model",
        "n_encoder_layers",
        "input_vocab_size",
        "d_model",
        "lstms",
        "encoder",
        "proposed",
        "replace",
        "expected",
        "replace",
        "success",
        "fails",
        "proposed",
        "expected",
        "isinstance",
        "encoder",
        "trax",
        "layers",
        "combinators",
        "Serial",
        "success",
        "len",
        "encoder",
        "sublayers",
        "n_encoder_layers",
        "success",
        "fails",
        "len",
        "encoder",
        "sublayers",
        "n_encoder_layers",
        "fails",
        "trax",
        "layers",
        "combinators",
        "Serial",
        "fails",
        "success",
        "fails",
        "pre_attention_decoder_fn",
        "pre_attention_decoder_fn",
        "target",
        "mode",
        "target_vocab_size",
        "d_model",
        "target_vocab_size",
        "d_model",
        "d_model",
        "decoder",
        "proposed",
        "replace",
        "expected",
        "replace",
        "success",
        "fails",
        "proposed",
        "expected",
        "isinstance",
        "decoder",
        "trax",
        "layers",
        "combinators",
        "Serial",
        "success",
        "len",
        "decoder",
        "sublayers",
        "success",
        "fails",
        "len",
        "decoder",
        "sublayers",
        "fails",
        "trax",
        "layers",
        "combinators",
        "Serial",
        "fails",
        "success",
        "fails",
        "prepare_attention_input",
        "prepare_attention_input",
        "fastnp",
        "array",
        "fastnp",
        "array",
        "fastnp",
        "array",
        "fastnp",
        "array",
        "enc_act",
        "target",
        "enc_act",
        "dec_act",
        "inputs",
        "fastnp",
        "allclose",
        "queries",
        "dec_act",
        "success",
        "fails",
        "fastnp",
        "allclose",
        "keys",
        "enc_act",
        "success",
        "fails",
        "fastnp",
        "allclose",
        "values",
        "enc_act",
        "success",
        "fails",
        "fastnp",
        "allclose",
        "mask",
        "exp_mask",
        "success",
        "fails",
        "exp_mask",
        "mask",
        "isinstance",
        "queries",
        "exp_type",
        "isinstance",
        "keys",
        "exp_type",
        "isinstance",
        "values",
        "exp_type",
        "isinstance",
        "mask",
        "exp_type",
        "success",
        "fails",
        "jax",
        "interpreters",
        "xla",
        "DeviceArray",
        "fails",
        "success",
        "fails",
        "NMTAttn",
        "test_case",
        "test_cases",
        "test_case",
        "test_case",
        "NMTAttn",
        "success",
        "test_case",
        "test_case",
        "len",
        "NMTAttn",
        "sublayers",
        "success",
        "test_case",
        "format",
        "len",
        "NMTAttn",
        "sublayers",
        "fails",
        "test_case",
        "NMTAttn",
        "model",
        "sublayers",
        "model",
        "sublayers",
        "i",
        "test_case",
        "i",
        "output",
        "i",
        "test_case",
        "fails",
        "check_count",
        "check_count",
        "success",
        "test_case",
        "fails",
        "fails",
        "success",
        "fails",
        "train_task",
        "train_task",
        "target",
        "_labeled_data",
        "strlabel",
        "find",
        "strlabel",
        "find",
        "success",
        "fails",
        "target",
        "_loss_layer",
        "strlabel",
        "success",
        "fails",
        "isinstance",
        "target",
        "optimizer",
        "trax",
        "optimizers",
        "adam",
        "Adam",
        "success",
        "fails",
        "isinstance",
        "target",
        "_lr_schedule",
        "trax",
        "supervised",
        "lr_schedules",
        "_BodyAndTail",
        "success",
        "fails",
        "target",
        "_n_steps_per_checkpoint",
        "success",
        "fails",
        "fails",
        "success",
        "fails",
        "next_symbol",
        "model",
        "next_symbol",
        "model",
        "np",
        "array",
        "target",
        "the_model",
        "tokens_en",
        "isinstance",
        "next_de_tokens",
        "len",
        "next_de_tokens",
        "next_de_tokens",
        "next_de_tokens",
        "success",
        "fails",
        "target",
        "the_model",
        "tokens_en",
        "np",
        "allclose",
        "next_de_tokens",
        "next_de_tokens",
        "success",
        "fails",
        "fails",
        "success",
        "fails",
        "sampling_decode",
        "model",
        "sampling_decode",
        "model",
        "target",
        "model",
        "temperature",
        "vocab_file",
        "VOCAB_FILE",
        "vocab_dir",
        "VOCAB_DIR",
        "output",
        "expected",
        "success",
        "fails",
        "target",
        "model",
        "temperature",
        "vocab_file",
        "VOCAB_FILE",
        "vocab_dir",
        "VOCAB_DIR",
        "output",
        "expected",
        "success",
        "fails",
        "fails",
        "success",
        "fails",
        "rouge1_similarity",
        "rouge1_similarity",
        "test_case",
        "test_cases",
        "test_case",
        "abs",
        "test_case",
        "target",
        "test_case",
        "success",
        "test_case",
        "fails",
        "fails",
        "success",
        "fails",
        "average_overlap",
        "average_overlap",
        "jaccard_similarity",
        "jaccard_similarity",
        "test_case",
        "test_cases",
        "test_case",
        "target",
        "test_case",
        "x",
        "output",
        "abs",
        "output",
        "x",
        "test_case",
        "x",
        "success",
        "test_case",
        "fails",
        "fails",
        "success",
        "fails",
        "mbr_decode",
        "model",
        "mbr_decode",
        "test_case",
        "test_cases",
        "target",
        "test_case",
        "weighted_avg_overlap",
        "jaccard_similarity",
        "model",
        "TEMPERATURE",
        "vocab_file",
        "VOCAB_FILE",
        "vocab_dir",
        "VOCAB_DIR",
        "result",
        "test_case",
        "output",
        "test_case",
        "success",
        "test_case",
        "fails",
        "test_cases",
        "target",
        "test_case",
        "weighted_avg_overlap",
        "jaccard_similarity",
        "model",
        "TEMPERATURE",
        "vocab_file",
        "VOCAB_FILE",
        "vocab_dir",
        "VOCAB_DIR",
        "max",
        "result",
        "key",
        "result",
        "get",
        "result",
        "success",
        "fails",
        "fails",
        "success",
        "fails"
    ],
    "literals": [
        "'ende_32k.subword'",
        "'data/'",
        "\"\\n\"",
        "f'  LSTM_{d_model}'",
        "f\"Serial[\\n  Embedding_{input_vocab_size}_{d_model}\\n{lstms}\\n]\"",
        "\" \"",
        "\"\"",
        "\" \"",
        "\"\"",
        "\"Wrong model. \\nProposed:\\n%s\"",
        "\"\\nExpected:\\n%s\"",
        "'The number of sublayers does not match %s <>'",
        "\" %s\"",
        "\"The enconder is not an object of \"",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "'train'",
        "f\"Serial[\\n  ShiftRight(1)\\n  Embedding_{target_vocab_size}_{d_model}\\n  LSTM_{d_model}\\n]\"",
        "\" \"",
        "\"\"",
        "\" \"",
        "\"\"",
        "\"Wrong model. \\nProposed:\\n%s\"",
        "\"\\nExpected:\\n%s\"",
        "'The number of sublayers does not match %s <>'",
        "\" %s\"",
        "\"The enconder is not an object of \"",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"Queries does not match the decoder activations\"",
        "\"Keys does not match the encoder activations\"",
        "\"Values does not match the encoder activations\"",
        "\"Mask does not match expected tensor. \\nExpected:\\n%s\"",
        "\"\\nOutput:\\n%s\"",
        "\"One of the output object are not of type \"",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"expected\"",
        "\"Serial_in2_out2[\\n  Select[0,1,0,1]_in2_out4\\n  Parallel_in2_out2[\\n    Serial[\\n      Embedding_33300_1024\\n      LSTM_1024\\n      LSTM_1024\\n    ]\\n    Serial[\\n      ShiftRight(1)\\n      Embedding_33300_1024\\n      LSTM_1024\\n    ]\\n  ]\\n  PrepareAttentionInput_in3_out4\\n  Serial_in4_out2[\\n    Branch_in4_out3[\\n      None\\n      Serial_in4_out2[\\n        Parallel_in3_out3[\\n          Dense_1024\\n          Dense_1024\\n          Dense_1024\\n        ]\\n        PureAttention_in4_out2\\n        Dense_1024\\n      ]\\n    ]\\n    Add_in2\\n  ]\\n  Select[0,2]_in3_out2\\n  LSTM_1024\\n  LSTM_1024\\n  Dense_33300\\n  LogSoftmax\\n]\"",
        "\"error\"",
        "\"The NMTAttn is not defined properly.\"",
        "\"name\"",
        "\"layer_len_check\"",
        "\"expected\"",
        "\"error\"",
        "\"We found {} layers in your model. It should be 9.\\nCheck the LSTM stack before the dense layer\"",
        "\"name\"",
        "\"selection_layer_check\"",
        "\"expected\"",
        "\"Select[0,1,0,1]_in2_out4\"",
        "\"Select[0,2]_in3_out2\"",
        "\"error\"",
        "\"Look at your selection layers.\"",
        "'name'",
        "\"simple_test_check\"",
        "\"expected\"",
        "'name'",
        "\"layer_len_check\"",
        "\"expected\"",
        "\"error\"",
        "'name'",
        "\"selection_layer_check\"",
        "\"expected\"",
        "\"error\"",
        "'error'",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"generator\"",
        "'add_loss_weights'",
        "\"Wrong labeled data parameter\"",
        "\"CrossEntropyLoss_in3\"",
        "\"Wrong loss functions. CrossEntropyLoss_in3 was expected\"",
        "\"Wrong optimizer\"",
        "\"Wrong learning rate schedule type\"",
        "\"Wrong checkpoint step frequency\"",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"Output must be a tuple of size 2 containing a integer and a float number\"",
        "\"Expected output: \"",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"I eat soup.\"",
        "'Ich iss Suppe.'",
        "\"Test 1 fails\"",
        "\"I like your shoes.\"",
        "'Ich mag Ihre Schuhe.'",
        "\"Test 2 fails\"",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "\"expected\"",
        "\"error\"",
        "\"Expected similarity: 0.8571428571428571\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "\"expected\"",
        "\"error\"",
        "\"Expected similarity: 0.5\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "\"expected\"",
        "\"error\"",
        "\"Expected similarity: 0\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "\"expected\"",
        "\"error\"",
        "\"Expected similarity: 0.5\"",
        "'name'",
        "\"simple_test_check\"",
        "\"expected\"",
        "'input'",
        "'error'",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"name\"",
        "\"dict_test_check\"",
        "\"input\"",
        "\"expected\"",
        "\"error\"",
        "\"Expected output does not match\"",
        "\"name\"",
        "\"dict_test_check\"",
        "\"input\"",
        "\"expected\"",
        "\"error\"",
        "\"Expected output does not match\"",
        "'name'",
        "\"dict_test_check\"",
        "'input'",
        "'expected'",
        "'error'",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "\"I am hungry\"",
        "\"expected\"",
        "\"Ich bin hungrig.\"",
        "\"error\"",
        "\"Expected output does not match\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "'Congratulations!'",
        "\"expected\"",
        "'Herzlichen Gl√ºckwunsch!'",
        "\"error\"",
        "\"Expected output does not match\"",
        "\"name\"",
        "\"simple_test_check\"",
        "\"input\"",
        "'You have completed the assignment!'",
        "\"expected\"",
        "'Sie haben die Abtretung abgeschlossen!'",
        "\"error\"",
        "\"Expected output does not match\"",
        "'input'",
        "'name'",
        "\"simple_test_check\"",
        "'expected'",
        "'error'",
        "'input'",
        "'Use max function to select max_index'",
        "\"\\033[92m All tests passed\"",
        "'\\033[92m'",
        "\" Tests passed\"",
        "'\\033[91m'",
        "\" Tests failed\""
    ],
    "variables": [
        "VOCAB_FILE",
        "VOCAB_DIR",
        "can_unigram_set",
        "ref_unigram_set",
        "joint_elems",
        "all_elems",
        "overlap",
        "scores",
        "overlap",
        "weight_sum",
        "sample_p",
        "sample_overlap",
        "score",
        "scores",
        "index_candidate",
        "target",
        "success",
        "fails",
        "input_vocab_size",
        "d_model",
        "n_encoder_layers",
        "encoder",
        "lstms",
        "expected",
        "proposed",
        "target",
        "success",
        "fails",
        "mode",
        "target_vocab_size",
        "d_model",
        "decoder",
        "expected",
        "proposed",
        "target",
        "success",
        "fails",
        "enc_act",
        "dec_act",
        "inputs",
        "exp_mask",
        "exp_type",
        "queries",
        "keys",
        "values",
        "mask",
        "test_cases",
        "success",
        "fails",
        "model",
        "output",
        "check_count",
        "target",
        "success",
        "fails",
        "strlabel",
        "strlabel",
        "target",
        "the_model",
        "success",
        "fails",
        "tokens_en",
        "next_de_tokens",
        "next_de_tokens",
        "target",
        "the_model",
        "success",
        "fails",
        "output",
        "expected",
        "output",
        "expected",
        "target",
        "success",
        "fails",
        "n_samples",
        "test_cases",
        "target",
        "success",
        "fails",
        "test_cases",
        "output",
        "target",
        "success",
        "fails",
        "TEMPERATURE",
        "test_cases",
        "result",
        "output",
        "TEMPERATURE",
        "test_case",
        "result"
    ],
    "comments": [
        "convert the lists to a set to get the unique tokens",
        "get the set of tokens common to both candidate and reference",
        "get the set of all tokens found in either candidate or reference",
        "divide the number of joint elements by the number of all elements",
        "initialize dictionary",
        "run a for loop for each sample",
        "initialize overlap and weighted sum",
        "run a for loop for each sample",
        "skip if the candidate index is the same as the sample index",
        "convert log probability to linear scale",
        "update the weighted sum",
        "get the unigram overlap between candidate and sample",
        "update the overlap",
        "get the score for the candidate",
        "save the score in the dictionary. use index as the key.",
        "UNIT TEST for UNQ_C1",
        "Test all layers are in the expected sequence",
        "Test the output type",
        "Test the number of layers",
        "Test",
        "UNIT TEST for UNQ_C2",
        "Test all layers are in the expected sequence",
        "Test the output type",
        "Test the number of layers",
        "Test",
        "UNIT TEST for UNQ_C3",
        "This unit test consider a batch size = 2, number_of_tokens = 3 and embedding_size = 4",
        "Test the output type",
        "UNIT TEST for UNQ_C4",
        "UNIT TEST for UNQ_C5",
        "Test the labeled data parameter",
        "Test the cross entropy loss data parameter",
        "Test the optimizer parameter",
        "Test the schedule parameter",
        "Test the _n_steps_per_checkpoint parameter",
        "UNIT TEST for UNQ_C6",
        "Test the type and size of output",
        "Test an output",
        "UNIT TEST for UNQ_C7",
        "UNIT TEST for UNQ_C8",
        "UNIT TEST for UNQ_C9",
        "UNIT TEST for UNQ_C10",
        "Test that function return the most likely translation"
    ],
    "docstrings": [
        "\"\"\"Returns the Jaccard similarity between two token lists\n\n    Args:\n        candidate (list of int): tokenized version of the candidate translation\n        reference (list of int): tokenized version of the reference translation\n\n    Returns:\n        float: overlap between the two token lists\n    \"\"\"",
        "\"\"\"Returns the weighted mean of each candidate sentence in the samples\n\n    Args:\n        samples (list of lists): tokenized version of the translated sentences\n        log_probs (list of float): log probability of the translated sentences\n\n    Returns:\n        dict: scores of each sample\n            key: index of the sample\n            value: score of the sample\n    \"\"\""
    ],
    "functions": [
        "jaccard_similarity",
        "weighted_avg_overlap",
        "test_input_encoder_fn",
        "test_pre_attention_decoder_fn",
        "test_prepare_attention_input",
        "test_NMTAttn",
        "test_train_task",
        "test_next_symbol",
        "test_sampling_decode",
        "test_rouge1_similarity",
        "test_average_overlap",
        "test_mbr_decode"
    ],
    "classes": []
}