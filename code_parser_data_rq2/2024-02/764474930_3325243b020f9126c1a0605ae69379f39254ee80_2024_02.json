{
    "identifiers": [
        "argparse",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "x",
        "x",
        "lower",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "x",
        "x",
        "lower",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "x",
        "x",
        "lower",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "parse_args",
        "args"
    ],
    "literals": [
        "'Punctuation restoration'",
        "'--name'",
        "'punctuation-restore'",
        "'name of run'",
        "'--cuda'",
        "'true'",
        "'use cuda if available'",
        "'--seed'",
        "'random seed'",
        "'--pretrained-model'",
        "'roberta-large'",
        "'pretrained language model'",
        "'--freeze-bert'",
        "'true'",
        "'Freeze BERT layers or not'",
        "'--lstm-dim'",
        "'hidden dimension in LSTM layer, if -1 is set equal to hidden dimension in language model'",
        "'--use-crf'",
        "'true'",
        "'whether to use CRF layer or not'",
        "'--data-path'",
        "'data/'",
        "'path to train/dev/test datasets'",
        "'--language'",
        "'bangla'",
        "'language, available options are english, bangla, english-bangla (for training with both)'",
        "'--sequence-length'",
        "'sequence length to use when preparing dataset (default 256)'",
        "'--augment-rate'",
        "'token augmentation probability'",
        "'--augment-type'",
        "'all'",
        "'which augmentation to use'",
        "'--sub-style'",
        "'unk'",
        "'replacement strategy for substitution augment'",
        "'--alpha-sub'",
        "'augmentation rate for substitution'",
        "'--alpha-del'",
        "'augmentation rate for deletion'",
        "'--lr'",
        "'learning rate'",
        "'--decay'",
        "'weight decay (default: 0)'",
        "'--gradient-clip'",
        "'gradient clipping (default: -1 i.e., none)'",
        "'--batch-size'",
        "'batch size (default: 8)'",
        "'--epoch'",
        "'total epochs (default: 10)'",
        "'--save-path'",
        "'out/'",
        "'model and log save directory'"
    ],
    "variables": [
        "parser",
        "args"
    ],
    "comments": [],
    "docstrings": [],
    "functions": [
        "parse_arguments"
    ],
    "classes": []
}