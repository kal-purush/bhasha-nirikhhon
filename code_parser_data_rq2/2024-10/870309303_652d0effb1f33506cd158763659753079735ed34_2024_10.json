{
    "identifiers": [
        "json",
        "cv2",
        "matplotlib",
        "pyplot",
        "plt",
        "pathlib",
        "Path",
        "os",
        "collections",
        "defaultdict",
        "random",
        "torch",
        "detectron2",
        "engine",
        "DefaultPredictor",
        "detectron2",
        "config",
        "get_cfg",
        "detectron2",
        "model_zoo",
        "detectron2",
        "utils",
        "visualizer",
        "Visualizer",
        "ColorMode",
        "detectron2",
        "data",
        "MetadataCatalog",
        "detectron2",
        "data",
        "datasets",
        "register_coco_instances",
        "register_coco_instances",
        "register_coco_instances",
        "annotations_json",
        "images_dir",
        "output_gt_dir",
        "output_pred_dir",
        "model_weights",
        "score_threshold",
        "filter_file",
        "Path",
        "output_gt_dir",
        "mkdir",
        "parents",
        "exist_ok",
        "Path",
        "output_pred_dir",
        "mkdir",
        "parents",
        "exist_ok",
        "open",
        "annotations_json",
        "f",
        "json",
        "load",
        "f",
        "coco",
        "coco",
        "cat",
        "cat",
        "cat",
        "coco",
        "defaultdict",
        "ann",
        "annotations",
        "img_id_to_ann",
        "ann",
        "append",
        "ann",
        "filter_file",
        "open",
        "filter_file",
        "f",
        "line",
        "strip",
        "line",
        "f",
        "line",
        "strip",
        "folder",
        "folder_names",
        "img",
        "img",
        "images",
        "folder",
        "img",
        "folder_images",
        "selected_images",
        "append",
        "random",
        "choice",
        "folder_images",
        "selected_images",
        "random",
        "choice",
        "images",
        "register_datasets",
        "model_weights",
        "get_cfg",
        "cfg",
        "merge_from_file",
        "model_zoo",
        "get_config_file",
        "cfg",
        "MODEL",
        "ROI_HEADS",
        "cfg",
        "MODEL",
        "model_weights",
        "cfg",
        "MODEL",
        "torch",
        "cuda",
        "is_available",
        "cfg",
        "MODEL",
        "ROI_HEADS",
        "score_threshold",
        "DefaultPredictor",
        "cfg",
        "img",
        "selected_images",
        "Path",
        "images_dir",
        "img",
        "cv2",
        "imread",
        "img_path",
        "image",
        "img_path",
        "cv2",
        "cvtColor",
        "image",
        "cv2",
        "COLOR_BGR2RGB",
        "ann",
        "img_id_to_ann",
        "img",
        "ann",
        "x",
        "y",
        "x",
        "w",
        "y",
        "h",
        "cv2",
        "rectangle",
        "image_rgb",
        "top_left",
        "bottom_right",
        "color",
        "thickness",
        "categories",
        "get",
        "ann",
        "cv2",
        "FONT_HERSHEY_SIMPLEX",
        "cv2",
        "getTextSize",
        "label",
        "font",
        "font_scale",
        "thickness",
        "x",
        "y",
        "y",
        "y",
        "cv2",
        "rectangle",
        "image_rgb",
        "text_origin",
        "text_origin",
        "text_size",
        "text_origin",
        "text_size",
        "text_origin",
        "color",
        "thickness",
        "cv2",
        "putText",
        "image_rgb",
        "label",
        "text_origin",
        "font",
        "font_scale",
        "color",
        "thickness",
        "thickness",
        "lineType",
        "cv2",
        "LINE_AA",
        "Path",
        "output_gt_dir",
        "img",
        "cv2",
        "imwrite",
        "gt_output_path",
        "cv2",
        "cvtColor",
        "image_rgb",
        "cv2",
        "COLOR_RGB2BGR",
        "gt_output_path",
        "predictor",
        "predictor",
        "image",
        "Visualizer",
        "image_rgb",
        "MetadataCatalog",
        "get",
        "dataset_name",
        "scale",
        "instance_mode",
        "ColorMode",
        "IMAGE",
        "outputs",
        "to",
        "instances",
        "instances",
        "scores",
        "score_threshold",
        "v",
        "draw_instance_predictions",
        "instances",
        "Path",
        "output_pred_dir",
        "img",
        "cv2",
        "imwrite",
        "pred_output_path",
        "get_image",
        "pred_output_path",
        "ValueError",
        "e",
        "e",
        "img",
        "image",
        "shape",
        "argparse",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "required",
        "help",
        "parser",
        "parse_args",
        "visualize_annotations_and_predictions",
        "annotations_json",
        "args",
        "annotations_json",
        "images_dir",
        "args",
        "images_dir",
        "output_gt_dir",
        "args",
        "output_gt_dir",
        "output_pred_dir",
        "args",
        "output_pred_dir",
        "model_weights",
        "args",
        "model_weights",
        "score_threshold",
        "args",
        "score_threshold",
        "filter_file",
        "args",
        "filter_file"
    ],
    "literals": [
        "\"custom_dataset_train\"",
        "\"dataset/annotations/train_annotations.json\"",
        "\"dataset/images\"",
        "\"custom_dataset_val\"",
        "\"dataset/annotations/val_annotations.json\"",
        "\"dataset/images\"",
        "'r'",
        "'images'",
        "'annotations'",
        "'id'",
        "'name'",
        "'categories'",
        "'image_id'",
        "'r'",
        "'file_name'",
        "\"custom_dataset_val\"",
        "\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"",
        "\"cuda\"",
        "\"cpu\"",
        "\"No model weights provided. Skipping predictions.\"",
        "'file_name'",
        "f\"Failed to load image {img_path}\"",
        "'id'",
        "'bbox'",
        "'category_id'",
        "'object'",
        "f\"gt_{img['file_name']}\"",
        "'file_name'",
        "f\"Saved ground truth image to {gt_output_path}\"",
        "\"instances\"",
        "\"cpu\"",
        "f\"pred_{img['file_name']}\"",
        "'file_name'",
        "f\"Saved prediction image to {pred_output_path}\"",
        "f\"Error processing or saving prediction image: {e}\"",
        "f\"Image file: {img['file_name']}\"",
        "'file_name'",
        "f\"Image dimensions: {image.shape}\"",
        "\"__main__\"",
        "\"Visualize Ground Truth and Model Predictions.\"",
        "\"--annotations_json\"",
        "\"data/v2-datasets-playwright/live-playwright-coco/annotations/val_annotations.json\"",
        "\"Path to the COCO annotations JSON file.\"",
        "\"--images_dir\"",
        "\"data/v2-datasets-playwright/live-playwright-coco/images\"",
        "\"Path to the directory containing images.\"",
        "\"--output_gt_dir\"",
        "\"v2-eval-final/trash\"",
        "\"Directory to save images with ground truth bounding boxes.\"",
        "\"--output_pred_dir\"",
        "\"v2-eval-final/eval\"",
        "\"Directory to save images with predicted bounding boxes.\"",
        "\"--model_weights\"",
        "\"data/v4-coco-finetune/model_final.pth\"",
        "\"Path to the trained Detectron2 model weights. If not provided, predictions are skipped.\"",
        "\"--score_threshold\"",
        "\"Minimum score for the predicted bounding boxes to be visualized.\"",
        "\"--filter_file\"",
        "\"Path to a text file containing folder names to filter image filenames.\""
    ],
    "variables": [
        "coco",
        "images",
        "annotations",
        "categories",
        "img_id_to_ann",
        "folder_names",
        "folder_names",
        "selected_images",
        "folder_images",
        "selected_images",
        "dataset_name",
        "cfg",
        "NUM_CLASSES",
        "WEIGHTS",
        "DEVICE",
        "SCORE_THRESH_TEST",
        "predictor",
        "predictor",
        "img_path",
        "image",
        "image_rgb",
        "x",
        "y",
        "w",
        "h",
        "top_left",
        "bottom_right",
        "label",
        "font",
        "font_scale",
        "thickness",
        "text_size",
        "_",
        "text_origin",
        "gt_output_path",
        "outputs",
        "v",
        "instances",
        "instances",
        "pred_output_path",
        "parser",
        "args"
    ],
    "comments": [
        "Ensure this is imported",
        "Ensure this is imported",
        "Ensure output directories exist",
        "Load annotations",
        "Create a mapping from image_id to annotations",
        "Load filter strings if filter_file is provided",
        "Filter images based on folder_names",
        "If no folder names provided, select one random image",
        "Register the datasets",
        "Ensure consistency",
        "Initialize Detectron2 predictor if model weights are provided",
        "Merge with the config file used during training",
        "Update the number of classes to match your custom dataset",
        "Change to your number of classes",
        "Set the path to your trained model weights",
        "e.g., \"output/model_final.pth\"",
        "Set the computation device",
        "Set threshold for this model",
        "=== Visualize Ground Truth with OpenCV ===",
        "Green box",
        "Draw label",
        "Draw background rectangle for text",
        "Yellow background",
        "Filled rectangle",
        "Put text",
        "=== Visualize Predictions ===",
        "Use the correct metadata",
        "Optionally filter predictions by score_threshold",
        "You might want to implement a resizing strategy here",
        "For example:",
        "max_dim = 2**16 - 1",
        "h, w = image.shape[:2]",
        "if h > max_dim or w > max_dim:",
        "scale = min(max_dim / h, max_dim / w)",
        "new_h, new_w = int(h * scale), int(w * scale)",
        "resized_image = cv2.resize(image, (new_w, new_h))",
        "# Rerun prediction and visualization on resized image",
        "..."
    ],
    "docstrings": [
        "\"\"\"\n    Register the training and validation datasets.\n    \"\"\"",
        "\"\"\"\n    Visualize ground truth annotations and model predictions on sample images.\n    \n    Args:\n        annotations_json (str): Path to the COCO annotations JSON file.\n        images_dir (str): Path to the directory containing images.\n        output_gt_dir (str): Directory to save images with ground truth bounding boxes.\n        output_pred_dir (str): Directory to save images with predicted bounding boxes.\n        model_weights (str): Path to the trained Detectron2 model weights. If None, predictions are skipped.\n        score_threshold (float): Minimum score for the predicted bounding boxes to be visualized.\n        filter_file (str): Path to a text file containing folder names to filter image filenames.\n    \"\"\""
    ],
    "functions": [
        "register_datasets",
        "visualize_annotations_and_predictions"
    ],
    "classes": []
}