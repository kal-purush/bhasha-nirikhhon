{
    "identifiers": [
        "typing",
        "Mapping",
        "Type",
        "numpy",
        "np",
        "gym",
        "spaces",
        "stable_baselines3",
        "common",
        "buffers",
        "BaseBuffer",
        "ReplayBuffer",
        "stable_baselines3",
        "common",
        "type_aliases",
        "ReplayBufferSamples",
        "imitation",
        "rewards",
        "reward_function",
        "RewardFn",
        "imitation",
        "util",
        "util",
        "samples",
        "ReplayBufferSamples",
        "Mapping",
        "np",
        "ndarray",
        "state",
        "samples",
        "observations",
        "cpu",
        "numpy",
        "action",
        "samples",
        "actions",
        "cpu",
        "numpy",
        "next_state",
        "samples",
        "next_observations",
        "cpu",
        "numpy",
        "done",
        "samples",
        "dones",
        "cpu",
        "numpy",
        "BaseBuffer",
        "buffer_size",
        "observation_space",
        "spaces",
        "Space",
        "action_space",
        "spaces",
        "Space",
        "replay_buffer_class",
        "Type",
        "ReplayBuffer",
        "reward_fn",
        "RewardFn",
        "kwargs",
        "replay_buffer_class",
        "ReplayBuffer",
        "isinstance",
        "observation_space",
        "spaces",
        "Dict",
        "replay_buffer_class",
        "buffer_size",
        "observation_space",
        "action_space",
        "kwargs",
        "reward_fn",
        "k",
        "v",
        "k",
        "v",
        "kwargs",
        "items",
        "k",
        "buffer_size",
        "observation_space",
        "action_space",
        "_base_kwargs",
        "property",
        "replay_buffer",
        "pos",
        "pos",
        "setter",
        "pos",
        "replay_buffer",
        "pos",
        "property",
        "replay_buffer",
        "full",
        "full",
        "setter",
        "full",
        "replay_buffer",
        "full",
        "args",
        "kwargs",
        "replay_buffer",
        "sample",
        "args",
        "kwargs",
        "reward_fn",
        "_samples_to_reward_fn_input",
        "samples",
        "samples",
        "rewards",
        "shape",
        "samples",
        "rewards",
        "device",
        "util",
        "safe_to_tensor",
        "rewards",
        "reshape",
        "shape",
        "to",
        "device",
        "ReplayBufferSamples",
        "samples",
        "observations",
        "samples",
        "actions",
        "samples",
        "next_observations",
        "samples",
        "dones",
        "rewards_th",
        "args",
        "kwargs",
        "replay_buffer",
        "add",
        "args",
        "kwargs",
        "NotImplementedError"
    ],
    "literals": [
        "\"only ReplayBuffer is supported\"",
        "\"device\"",
        "\"n_envs\"",
        "\"_get_samples() is intentionally not implemented.\"",
        "\"This method should not be called.\""
    ],
    "variables": [
        "replay_buffer",
        "reward_fn",
        "_base_kwargs",
        "pos",
        "full",
        "samples",
        "rewards",
        "shape",
        "device",
        "rewards_th"
    ],
    "comments": [
        "Note(yawen-d): we directly inherit ReplayBuffer and leave out the case of",
        "DictReplayBuffer because the current RewardFn only takes in NumPy array-based",
        "inputs, and SAC is the only use case for ReplayBuffer relabeling. See:",
        "https://github.com/HumanCompatibleAI/imitation/pull/459#issuecomment-1201997194"
    ],
    "docstrings": [
        "\"\"\"Wrapper for reward labeling for transitions sampled from a replay buffer.\"\"\"",
        "\"\"\"Convert a sample from a replay buffer to a numpy array.\"\"\"",
        "\"\"\"Relabel the rewards in transitions sampled from a ReplayBuffer.\"\"\"",
        "\"\"\"Builds ReplayBufferRewardWrapper.\n\n        Args:\n            buffer_size: Max number of elements in the buffer\n            observation_space: Observation space\n            action_space: Action space\n            replay_buffer_class: Class of the replay buffer.\n            reward_fn: Reward function for reward relabeling.\n            **kwargs: keyword arguments for ReplayBuffer.\n        \"\"\""
    ],
    "functions": [
        "_samples_to_reward_fn_input",
        "pos",
        "pos",
        "full",
        "full",
        "sample",
        "add",
        "_get_samples"
    ],
    "classes": [
        "ReplayBufferRewardWrapper"
    ]
}