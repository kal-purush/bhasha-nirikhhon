{
    "identifiers": [
        "com",
        "ouroboros",
        "java",
        "io",
        "org",
        "apache",
        "commons",
        "logging",
        "Log",
        "org",
        "apache",
        "commons",
        "logging",
        "LogFactory",
        "org",
        "apache",
        "hadoop",
        "conf",
        "Configuration",
        "org",
        "apache",
        "hadoop",
        "fs",
        "Path",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "Cell",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "HBaseConfiguration",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "client",
        "HTable",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "client",
        "Result",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "client",
        "Scan",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "CompareFilter",
        "CompareOp",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "Filter",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "PrefixFilter",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "RegexStringComparator",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "RowFilter",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "io",
        "ImmutableBytesWritable",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "mapreduce",
        "HFileOutputFormat2",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "mapreduce",
        "TableInputFormat",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "mapreduce",
        "TableMapReduceUtil",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "mapreduce",
        "TableMapper",
        "org",
        "apache",
        "hadoop",
        "hbase",
        "util",
        "Bytes",
        "org",
        "apache",
        "hadoop",
        "mapreduce",
        "Job",
        "org",
        "apache",
        "hadoop",
        "util",
        "GenericOptionsParser",
        "LOG",
        "LogFactory",
        "getLog",
        "NAME",
        "Override",
        "row",
        "value",
        "context",
        "cell",
        "value",
        "listCells",
        "context",
        "write",
        "row",
        "cell",
        "e",
        "LOG",
        "error",
        "e",
        "MAX_ROWS",
        "MAX_KEYS",
        "conf",
        "args",
        "s",
        "versions",
        "args",
        "length",
        "parseInt",
        "args",
        "s",
        "setMaxVersions",
        "versions",
        "startTime",
        "args",
        "length",
        "parseLong",
        "args",
        "endTime",
        "args",
        "length",
        "parseLong",
        "args",
        "MAX_VALUE",
        "s",
        "setTimeRange",
        "startTime",
        "endTime",
        "s",
        "setCacheBlocks",
        "s",
        "setCaching",
        "MAX_ROWS",
        "s",
        "setBatch",
        "MAX_KEYS",
        "conf",
        "get",
        "TableInputFormat",
        "SCAN_COLUMN_FAMILY",
        "s",
        "addFamily",
        "Bytes",
        "toBytes",
        "conf",
        "get",
        "TableInputFormat",
        "SCAN_COLUMN_FAMILY",
        "exportFilter",
        "getExportFilter",
        "args",
        "exportFilter",
        "LOG",
        "info",
        "s",
        "setFilter",
        "exportFilter",
        "LOG",
        "info",
        "versions",
        "startTime",
        "endTime",
        "s",
        "args",
        "exportFilter",
        "filterCriteria",
        "args",
        "length",
        "args",
        "filterCriteria",
        "filterCriteria",
        "startsWith",
        "regexPattern",
        "filterCriteria",
        "substring",
        "filterCriteria",
        "length",
        "exportFilter",
        "CompareOp",
        "EQUAL",
        "regexPattern",
        "exportFilter",
        "Bytes",
        "toBytes",
        "filterCriteria",
        "exportFilter",
        "conf",
        "args",
        "tableName",
        "args",
        "outputDir",
        "args",
        "job",
        "Job",
        "getInstance",
        "conf",
        "job",
        "setJobName",
        "NAME",
        "tableName",
        "job",
        "setJarByClass",
        "s",
        "getConfiguredScanForJob",
        "conf",
        "args",
        "TableMapReduceUtil",
        "initTableMapperJob",
        "tableName",
        "s",
        "job",
        "job",
        "setNumReduceTasks",
        "job",
        "setOutputFormatClass",
        "HFileOutputFormat2",
        "configureIncrementalLoad",
        "job",
        "conf",
        "tableName",
        "HFileOutputFormat2",
        "setOutputPath",
        "job",
        "outputDir",
        "job",
        "errorMsg",
        "errorMsg",
        "errorMsg",
        "length",
        "err",
        "errorMsg",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "err",
        "TableInputFormat",
        "SCAN_COLUMN_FAMILY",
        "args",
        "conf",
        "HBaseConfiguration",
        "create",
        "otherArgs",
        "conf",
        "args",
        "getRemainingArgs",
        "otherArgs",
        "length",
        "usage",
        "otherArgs",
        "length",
        "exit",
        "job",
        "createSubmittableJob",
        "conf",
        "otherArgs",
        "exit",
        "job",
        "waitForCompletion"
    ],
    "literals": [
        "\"exportToHFiles\"",
        "\"Setting Scan Filter for Export.\"",
        "\"verisons=\"",
        "\", starttime=\"",
        "\", endtime=\"",
        "\"^\"",
        "\"_\"",
        "\"ERROR: \"",
        "\"Usage: ExportToHFiles [-D <property=value>]* <tablename> <outputdir> [<versions> \"",
        "\"[<starttime> [<endtime>]] [^[regex pattern] or [Prefix] to filter]]\\n\"",
        "\"  Note: -D properties will be applied to the conf used. \"",
        "\"  For example: \"",
        "\"   -D mapred.output.compress=true\"",
        "\"   -D mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec\"",
        "\"   -D mapred.output.compression.type=BLOCK\"",
        "\"  Additionally, the following SCAN properties can be specified\"",
        "\"  to control/limit what is exported..\"",
        "\"   -D \"",
        "\"=<familyName>\"",
        "\"Wrong number of arguments: \""
    ],
    "variables": [],
    "comments": [
        "1 row per minute",
        "rows are wide!",
        "Optional arguments.",
        "Set Scan Versions",
        "Set Scan Range",
        "Set cache blocks",
        "Set Scan Column Family",
        "Set RowFilter or Prefix Filter if applicable.",
        "Set optional scan parameters",
        "No reducers. Just write straight to output files.",
        "Use configureIncrementalLoad as advised for bulk loading"
    ],
    "docstrings": [
        "* Job to export a HTable into HFiles for bulk import.\n * A modified copy of org.apache.hadoop.hbase.mapreduce.Export job, accepts the same arguments as Export.    \n * \n * After the export to HFiles, LoadIncrementalHFiles class can be used to import the HFiles into the HTable.\n * hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /user/hfiles/htable htable",
        "* @param row\n         *            The current table row key.\n         * @param value\n         *            The columns.\n         * @param context\n         *            The current context.\n         * @throws IOException\n         *             When something is broken with the data.\n         * @see org.apache.hadoop.mapreduce.Mapper#map(KEYIN, VALUEIN, org.apache.hadoop.mapreduce.Mapper.Context)"
    ],
    "functions": [
        "Scan",
        "getConfiguredScanForJob",
        "Filter",
        "getExportFilter",
        "Job",
        "createSubmittableJob",
        "usage",
        "main"
    ],
    "classes": [
        "ExportToHFiles",
        "ExporterToHFiles"
    ]
}