{
    "identifiers": [
        "typing",
        "AsyncGenerator",
        "Optional",
        "asyncio",
        "json",
        "dataclasses",
        "dataclass",
        "autogen_core",
        "CancellationToken",
        "DefaultTopicId",
        "FunctionCall",
        "message_handler",
        "MessageContext",
        "RoutedAgent",
        "TopicId",
        "autogen_core",
        "models",
        "AssistantMessage",
        "ChatCompletionClient",
        "CreateResult",
        "LLMMessage",
        "SystemMessage",
        "UserMessage",
        "FunctionExecutionResult",
        "FunctionExecutionResultMessage",
        "autogen_core",
        "tools",
        "Tool",
        "pydantic",
        "BaseModel",
        "dataclass",
        "BaseModel",
        "CreateResult",
        "AssistantMessage",
        "BaseModel",
        "UserMessage",
        "BaseModel",
        "TopicId",
        "TASK_RESULTS_TOPIC_TYPE",
        "source",
        "RoutedAgent",
        "name",
        "system_message",
        "model_client",
        "ChatCompletionClient",
        "tool_schema",
        "Tool",
        "model_client_stream",
        "reflect_on_tool_use",
        "group_chat_topic_type",
        "name",
        "SystemMessage",
        "content",
        "system_message",
        "model_client",
        "tool_schema",
        "model_client_stream",
        "reflect_on_tool_use",
        "group_chat_topic_type",
        "LLMMessage",
        "cancellation_token",
        "CancellationToken",
        "AsyncGenerator",
        "CreateResult",
        "chunk",
        "_model_client",
        "create_stream",
        "messages",
        "_system_message",
        "_chat_history",
        "tools",
        "_tools",
        "cancellation_token",
        "cancellation_token",
        "isinstance",
        "chunk",
        "CreateResult",
        "chunk",
        "isinstance",
        "chunk",
        "chunk",
        "RuntimeError",
        "chunk",
        "model_result",
        "RuntimeError",
        "model_result",
        "call",
        "FunctionCall",
        "cancellation_token",
        "CancellationToken",
        "FunctionExecutionResult",
        "next",
        "tool",
        "tool",
        "_tools",
        "tool",
        "name",
        "call",
        "name",
        "tool",
        "json",
        "loads",
        "call",
        "arguments",
        "tool",
        "run_json",
        "arguments",
        "cancellation_token",
        "FunctionExecutionResult",
        "call_id",
        "call",
        "id",
        "content",
        "tool",
        "return_value_as_string",
        "result",
        "is_error",
        "name",
        "tool",
        "name",
        "e",
        "FunctionExecutionResult",
        "call_id",
        "call",
        "id",
        "content",
        "e",
        "is_error",
        "name",
        "tool",
        "name",
        "message_handler",
        "message",
        "UserMessage",
        "ctx",
        "MessageContext",
        "Message",
        "_chat_history",
        "append",
        "message",
        "Optional",
        "CreateResult",
        "chunk",
        "_call_model_client",
        "cancellation_token",
        "ctx",
        "cancellation_token",
        "isinstance",
        "chunk",
        "CreateResult",
        "chunk",
        "isinstance",
        "chunk",
        "runtime",
        "publish_message",
        "StreamResult",
        "content",
        "chunk",
        "source",
        "id",
        "topic_id",
        "task_results_topic_id",
        "RuntimeError",
        "chunk",
        "model_result",
        "RuntimeError",
        "_chat_history",
        "append",
        "AssistantMessage",
        "content",
        "model_result",
        "content",
        "source",
        "id",
        "isinstance",
        "model_result",
        "content",
        "runtime",
        "publish_message",
        "StreamResult",
        "content",
        "model_result",
        "source",
        "id",
        "topic_id",
        "task_results_topic_id",
        "Message",
        "content",
        "model_result",
        "content",
        "isinstance",
        "model_result",
        "content",
        "all",
        "isinstance",
        "call",
        "FunctionCall",
        "call",
        "model_result",
        "content",
        "asyncio",
        "gather",
        "_execute_tool_call",
        "call",
        "ctx",
        "cancellation_token",
        "call",
        "model_result",
        "content",
        "_chat_history",
        "append",
        "FunctionExecutionResultMessage",
        "content",
        "results",
        "Optional",
        "CreateResult",
        "chunk",
        "_call_model_client",
        "cancellation_token",
        "ctx",
        "cancellation_token",
        "isinstance",
        "chunk",
        "CreateResult",
        "chunk",
        "isinstance",
        "chunk",
        "runtime",
        "publish_message",
        "StreamResult",
        "content",
        "chunk",
        "source",
        "id",
        "topic_id",
        "task_results_topic_id",
        "RuntimeError",
        "chunk",
        "model_result2",
        "RuntimeError",
        "model_result2",
        "content",
        "isinstance",
        "model_result2",
        "content",
        "runtime",
        "publish_message",
        "StreamResult",
        "content",
        "model_result2",
        "source",
        "id",
        "topic_id",
        "task_results_topic_id",
        "Message",
        "content",
        "model_result2",
        "content",
        "message_handler",
        "message",
        "GroupChatMessage",
        "ctx",
        "MessageContext",
        "_chat_history",
        "extend",
        "UserMessage",
        "content",
        "message",
        "body",
        "source",
        "source",
        "message",
        "body",
        "message_handler",
        "message",
        "RequestToSpeak",
        "ctx",
        "MessageContext",
        "_chat_history",
        "append",
        "UserMessage",
        "content",
        "id",
        "source",
        "Optional",
        "CreateResult",
        "chunk",
        "_call_model_client",
        "cancellation_token",
        "ctx",
        "cancellation_token",
        "isinstance",
        "chunk",
        "CreateResult",
        "chunk",
        "runtime",
        "publish_message",
        "StreamResult",
        "content",
        "model_result",
        "source",
        "id",
        "topic_id",
        "task_results_topic_id",
        "isinstance",
        "chunk",
        "runtime",
        "publish_message",
        "StreamResult",
        "content",
        "chunk",
        "source",
        "id",
        "topic_id",
        "task_results_topic_id",
        "RuntimeError",
        "chunk",
        "model_result",
        "RuntimeError",
        "isinstance",
        "model_result",
        "content",
        "model_result",
        "content",
        "_chat_history",
        "append",
        "AssistantMessage",
        "content",
        "model_result",
        "content",
        "source",
        "id",
        "publish_message",
        "GroupChatMessage",
        "body",
        "UserMessage",
        "content",
        "model_result",
        "content",
        "source",
        "id",
        "topic_id",
        "DefaultTopicId",
        "_group_chat_topic_type"
    ],
    "literals": [
        "\"task-results\"",
        "\"default\"",
        "\"Default\"",
        "f\"Invalid chunk type: {type(chunk)}\"",
        "\"No final model result in streaming mode.\"",
        "f\"Invalid chunk type: {type(chunk)}\"",
        "\"No final model result in streaming mode.\"",
        "f\"Invalid chunk type: {type(chunk)}\"",
        "\"No final model result in streaming mode.\"",
        "f\"Transferred to {message.body.source}\"",
        "\"system\"",
        "f\"Transferred to {self.id.type}, adopt the persona immediately.\"",
        "\"system\"",
        "f\"Invalid chunk type: {type(chunk)}\"",
        "\"No final model result in streaming mode.\""
    ],
    "variables": [
        "content",
        "content",
        "source",
        "body",
        "TASK_RESULTS_TOPIC_TYPE",
        "task_results_topic_id",
        "_system_message",
        "_model_client",
        "_tools",
        "_model_client_stream",
        "_reflect_on_tool_use",
        "_group_chat_topic_type",
        "_chat_history",
        "model_result",
        "model_result",
        "tool",
        "arguments",
        "result",
        "model_result",
        "model_result",
        "results",
        "model_result2",
        "model_result2",
        "model_result",
        "model_result"
    ],
    "comments": [
        "context: MessageContext,",
        "self._model_context = context",
        "Call the LLM model to process the message",
        "No final result in model client respons",
        "Find the tool by name.",
        "Run the tool and capture the result.",
        "Append the message to chat history.",
        "Add message to model context.",
        "await self._model_context.add_message(UserMessage(content=message.content, source=\"User\"))",
        "foward the stream tokent to the Queue",
        "No final result in model client respons",
        "Add the first model create result to the session.",
        "No tools, return the result",
        "Execute the tool calls.",
        "Add the function execution results to the session.",
        "if (not self._reflect_on_tool_use):",
        "return Message(content=model_result.content)",
        "Run the chat completion client again to reflect on the history and function execution results.",
        "model_result = None",
        "foward the stream tokent to the Queue",
        "Message handler for Group chat message. It just add the message to the agent message history.",
        "The message will be processed when the agent receives the RequestToSpeak.",
        "Message handler for request to speaker message.",
        "print(f\"### {self.id.type}: \")",
        "Run the chat completion client again to reflect on the history and function execution results.",
        "foward the stream tokent to the Queue",
        "print(model_result.content, flush=True)"
    ],
    "docstrings": [],
    "functions": [
        "_call_model_client",
        "_execute_tool_call",
        "handle_user_message",
        "handle_message",
        "handle_request_to_speak"
    ],
    "classes": [
        "Message",
        "StreamResult",
        "GroupChatMessage",
        "RequestToSpeak",
        "SimpleAssistantAgent"
    ]
}