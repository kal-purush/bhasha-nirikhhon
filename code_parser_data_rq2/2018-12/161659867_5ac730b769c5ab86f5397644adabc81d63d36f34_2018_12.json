{
    "identifiers": [
        "argparse",
        "time",
        "torch",
        "torchvision",
        "transforms",
        "transforms",
        "misc",
        "dataset",
        "CocoCaptionsRV",
        "misc",
        "evaluation",
        "eval_recall",
        "misc",
        "model",
        "joint_embedding",
        "misc",
        "utils",
        "collate_fn_padded",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "torch",
        "device",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "dest",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "dest",
        "action",
        "help",
        "parser",
        "add_argument",
        "dest",
        "action",
        "help",
        "parser",
        "parse_args",
        "args",
        "model_path",
        "torch",
        "load",
        "args",
        "model_path",
        "map_location",
        "storage",
        "loc",
        "storage",
        "joint_embedding",
        "checkpoint",
        "join_emb",
        "load_state_dict",
        "checkpoint",
        "param",
        "join_emb",
        "parameters",
        "join_emb",
        "to",
        "device",
        "join_emb",
        "eval",
        "transforms",
        "Normalize",
        "mean",
        "std",
        "transforms",
        "Compose",
        "transforms",
        "Resize",
        "transforms",
        "ToTensor",
        "normalize",
        "CocoCaptionsRV",
        "sset",
        "args",
        "dset",
        "transform",
        "prepro_val",
        "len",
        "dataset",
        "DataLoader",
        "dataset",
        "batch_size",
        "args",
        "batch_size",
        "num_workers",
        "collate_fn",
        "collate_fn_padded",
        "pin_memory",
        "time",
        "time",
        "i",
        "imgs",
        "caps",
        "lengths",
        "dataset_loader",
        "imgs",
        "to",
        "device",
        "caps",
        "to",
        "device",
        "torch",
        "no_grad",
        "join_emb",
        "input_imgs",
        "input_caps",
        "lengths",
        "imgs_enc",
        "append",
        "output_imgs",
        "cpu",
        "data",
        "numpy",
        "caps_enc",
        "append",
        "output_caps",
        "cpu",
        "data",
        "numpy",
        "i",
        "i",
        "args",
        "batch_size",
        "len",
        "dataset",
        "time",
        "time",
        "end",
        "time",
        "time",
        "args",
        "model_path",
        "args",
        "dset",
        "eval_recall",
        "imgs_enc",
        "caps_enc"
    ],
    "literals": [
        "\"cuda\"",
        "'__main__'",
        "'Evaluate the model on cross modal retrieval task'",
        "\"-p\"",
        "'--path'",
        "\"model_path\"",
        "'Path to the weights of the model to evaluate'",
        "\"-bs\"",
        "\"--batch_size\"",
        "\"The size of the batches\"",
        "'-tr'",
        "\"--train\"",
        "\"dset\"",
        "'store_const'",
        "\"train\"",
        "\"Using training dataset instead of validation\"",
        "\"val\"",
        "'-te'",
        "\"--test\"",
        "\"dset\"",
        "'store_const'",
        "\"test\"",
        "\"Using test dataset instead of validation\"",
        "\"val\"",
        "\"Loading model from:\"",
        "'args_dict'",
        "\"state_dict\"",
        "\"Dataset size: \"",
        "\"### Beginning of evaluation ###\"",
        "\"/\"",
        "\" pairs encoded - Time per batch: \"",
        "\"s\""
    ],
    "variables": [
        "device",
        "parser",
        "args",
        "checkpoint",
        "join_emb",
        "param",
        "requires_grad",
        "normalize",
        "prepro_val",
        "dataset",
        "dataset_loader",
        "imgs_enc",
        "caps_enc",
        "end",
        "input_imgs",
        "input_caps",
        "output_imgs",
        "output_caps",
        "end"
    ],
    "comments": [
        "device = torch.device(\"cpu\") # uncomment to run with cpu"
    ],
    "docstrings": [
        "\"\"\"\n****************** COPYRIGHT AND CONFIDENTIALITY INFORMATION ******************\nCopyright (c) 2018 [Thomson Licensing]\nAll Rights Reserved\nThis program contains proprietary information which is a trade secret/business \\\nsecret of [Thomson Licensing] and is protected, even if unpublished, under \\\napplicable Copyright laws (including French droit d'auteur) and/or may be \\\nsubject to one or more patent(s).\nRecipient is to retain this program in confidence and is not permitted to use \\\nor make copies thereof other than as permitted in a written agreement with \\\n[Thomson Licensing] unless otherwise expressly allowed by applicable laws or \\\nby [Thomson Licensing] under express agreement.\nThomson Licensing is a company of the group TECHNICOLOR\n*******************************************************************************\nThis scripts permits one to reproduce training and experiments of:\n    Engilberge, M., Chevallier, L., PÃ©rez, P., & Cord, M. (2018, April).\n    Finding beans in burgers: Deep semantic-visual embedding with localization.\n    In Proceedings of CVPR (pp. 3984-3993)\n\nAuthor: Martin Engilberge\n\"\"\""
    ],
    "functions": [],
    "classes": []
}