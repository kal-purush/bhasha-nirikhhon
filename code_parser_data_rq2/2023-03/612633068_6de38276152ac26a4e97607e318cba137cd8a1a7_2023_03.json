{
    "identifiers": [
        "pickle",
        "nltk",
        "stem",
        "PorterStemmer",
        "nltk",
        "stem",
        "WordNetLemmatizer",
        "nltk",
        "corpus",
        "stopwords",
        "re",
        "nltk",
        "flask",
        "Flask",
        "request",
        "render_template",
        "nltk",
        "download",
        "nltk",
        "download",
        "text",
        "re",
        "sub",
        "text",
        "re",
        "sub",
        "text",
        "join",
        "text",
        "split",
        "text",
        "lower",
        "text",
        "text",
        "stopwords",
        "words",
        "word",
        "word",
        "text",
        "split",
        "word",
        "stop_words",
        "join",
        "removedstopword",
        "text",
        "WordNetLemmatizer",
        "word",
        "text",
        "split",
        "lemma",
        "lemmatize",
        "word",
        "stemSentence",
        "stem",
        "stemSentence",
        "stemSentence",
        "strip",
        "stemSentence",
        "text",
        "PorterStemmer",
        "word",
        "text",
        "split",
        "stemmer",
        "stem",
        "word",
        "stemmed_sentence",
        "stem",
        "stemmed_sentence",
        "stemmed_sentence",
        "strip",
        "stemmed_sentence",
        "text",
        "model",
        "tfidf_vectorizer",
        "cleantext",
        "text",
        "removestopwords",
        "text",
        "lemmatizing",
        "text",
        "stemming",
        "text",
        "tfidf_vectorizer",
        "transform",
        "text",
        "model",
        "predict",
        "text_vector",
        "newmapper",
        "predicted",
        "open",
        "pickle",
        "load",
        "file",
        "file",
        "close",
        "open",
        "pickle",
        "load",
        "file1",
        "file1",
        "close",
        "Flask",
        "app",
        "route",
        "methods",
        "request",
        "method",
        "request",
        "form",
        "mydict",
        "test",
        "text",
        "model",
        "tfidf_vectorizer",
        "render_template",
        "genre",
        "prediction",
        "text",
        "text",
        "showresult",
        "render_template",
        "app",
        "run",
        "host",
        "port"
    ],
    "literals": [
        "'stopwords'",
        "'wordnet'",
        "\"'\\''\"",
        "\"\"",
        "\"[^a-zA-Z]\"",
        "\" \"",
        "' '",
        "'english'",
        "' '",
        "\"\"",
        "\" \"",
        "\"\"",
        "\" \"",
        "'Fantasy'",
        "'Science Fiction'",
        "'Crime Fiction'",
        "'Historical novel'",
        "'Horror'",
        "'Thriller'",
        "'bookgenremodel.pkl'",
        "'rb'",
        "'tfdifvector.pkl'",
        "'rb'",
        "'/'",
        "'GET'",
        "'POST'",
        "'POST'",
        "\"summary\"",
        "'index.html'",
        "'index.html'",
        "'__main__'",
        "'0.0.0.0'"
    ],
    "variables": [
        "text",
        "text",
        "text",
        "text",
        "stop_words",
        "removedstopword",
        "lemma",
        "stemSentence",
        "stem",
        "stemSentence",
        "stemmer",
        "stemmed_sentence",
        "stem",
        "stemmed_sentence",
        "text",
        "text",
        "text",
        "text",
        "text_vector",
        "predicted",
        "newmapper",
        "file",
        "model",
        "file1",
        "tfidf_vectorizer",
        "app",
        "mydict",
        "text",
        "prediction"
    ],
    "comments": [
        "cleaning the text i.e removing all unncessary characters",
        "removing the \"\\\"",
        "removing special symbols",
        "removing the whitespaces",
        "convert text to lowercase",
        "removing the stopwords",
        "lemmatizing the text",
        "stemming the text,i.e reducing the word size",
        "testing the model",
        "training once for tfdif to fit",
        "loading the model"
    ],
    "docstrings": [],
    "functions": [
        "cleantext",
        "removestopwords",
        "lemmatizing",
        "stemming",
        "test",
        "hello_world"
    ],
    "classes": []
}