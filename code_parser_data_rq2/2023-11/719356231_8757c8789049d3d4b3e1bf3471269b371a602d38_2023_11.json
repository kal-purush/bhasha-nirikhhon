{
    "identifiers": [
        "asyncio",
        "icecream",
        "ic",
        "transformers",
        "AutoTokenizer",
        "openai",
        "AsyncOpenAI",
        "sync_helpers",
        "get_length_of_chunk_in_tokens",
        "my_chunk",
        "my_config",
        "my_chunk",
        "my_config",
        "completions",
        "create",
        "model",
        "my_config",
        "prompt",
        "my_prompt",
        "max_tokens",
        "my_config",
        "completion",
        "choices",
        "text",
        "my_chunk",
        "my_config",
        "my_config",
        "split_text",
        "my_chunk",
        "my_chunks",
        "my_chunk",
        "my_depth",
        "my_config",
        "my_depth",
        "ic",
        "my_depth",
        "get_length_of_chunk_in_tokens",
        "my_chunk",
        "my_config",
        "length_of_chunk_in_tokens",
        "my_config",
        "get_async_chunking",
        "my_chunk",
        "my_config",
        "ic",
        "len",
        "chunks",
        "asyncio",
        "gather",
        "enter_recursion",
        "partial_chunk",
        "my_depth",
        "my_config",
        "partial_chunk",
        "chunks",
        "join",
        "partial_results",
        "enter_recursion",
        "my_result_string",
        "my_depth",
        "my_config",
        "get_result",
        "my_chunk",
        "my_config",
        "ic",
        "len",
        "intermediate_result",
        "intermediate_result",
        "strip",
        "my_result",
        "my_filename",
        "open",
        "my_filename",
        "encoding",
        "my_fp",
        "my_fp",
        "read",
        "my_config",
        "AutoTokenizer",
        "from_pretrained",
        "my_config",
        "use_fast",
        "my_tokenizer",
        "my_config",
        "AsyncOpenAI",
        "api_key",
        "my_config",
        "base_url",
        "my_config",
        "client"
    ],
    "literals": [
        "\"JSON\"",
        "\"JSON\"",
        "f\"\"\"BEGININPUT\n{my_chunk}\nENDINPUT\nBEGININSTRUCTION\nSummarize the input in about 130 words, focusing on characters, actions and events. Infer the appearance and personality of the characters involved in a few sentences, if they are mentioned in the text. Write confidently even if character qualities are vague or poorly-defined. Keep your response in one paragraph.\nENDINSTRUCTION\n\"\"\"",
        "\"api_client\"",
        "\"model_local_identifier\"",
        "\"max_tokens\"",
        "\"text_splitter\"",
        "\"chunk_size\"",
        "\"\\n\"",
        "\"r\"",
        "\"utf-8\"",
        "\"model_identifier\"",
        "\"api_key\"",
        "\"api_url\""
    ],
    "variables": [
        "JSONObject",
        "JSONList",
        "my_prompt",
        "completion",
        "my_chunks",
        "length_of_chunk_in_tokens",
        "chunks",
        "partial_results",
        "partial_results",
        "my_result_string",
        "intermediate_result",
        "intermediate_result",
        "my_result",
        "my_tokenizer",
        "client"
    ],
    "comments": [
        "import httpx",
        "type: ignore",
        "type: ignore",
        "my_prompt = f\"\"\"BEGININPUT",
        "{my_chunk}",
        "ENDINPUT",
        "BEGININSTRUCTION",
        "Summarize the input in about 130 words.",
        "ENDINSTRUCTION",
        "\"\"\"",
        "length_of_chunk_in_chars = get_length_of_chunk_in_chars(my_chunk)",
        "we need to split",
        "we can summarize"
    ],
    "docstrings": [],
    "functions": [
        "get_result",
        "get_async_chunking",
        "enter_recursion",
        "get_file_contents",
        "get_tokenizer",
        "get_api_client"
    ],
    "classes": []
}