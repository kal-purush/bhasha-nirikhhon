{
    "identifiers": [
        "pandas",
        "pd",
        "numpy",
        "np",
        "matplotlib",
        "pyplot",
        "plt",
        "nltk",
        "nltk",
        "tokenize",
        "WhitespaceTokenizer",
        "nltk",
        "corpus",
        "stopwords",
        "pymc",
        "pm",
        "sklearn",
        "model_selection",
        "train_test_split",
        "sklearn",
        "feature_extraction",
        "text",
        "TfidfVectorizer",
        "sklearn",
        "linear_model",
        "LinearRegression",
        "sklearn",
        "metrics",
        "root_mean_squared_error",
        "sklearn",
        "metrics",
        "r2_score",
        "WhitespaceTokenizer",
        "nltk",
        "download",
        "nltk",
        "download",
        "stopwords",
        "words",
        "pd",
        "set_option",
        "TfidfVectorizer",
        "path",
        "FILE_PATHS",
        "DATAFRAMES",
        "append",
        "pd",
        "read_csv",
        "path",
        "sep",
        "pd",
        "DataFrame",
        "columns",
        "DATAFRAMES",
        "columns",
        "tolist",
        "text",
        "text",
        "nltk",
        "word_tokenize",
        "text",
        "word",
        "lower",
        "word",
        "arr",
        "word",
        "isalpha",
        "x",
        "x",
        "arr",
        "x",
        "lower",
        "stop_words",
        "join",
        "arr",
        "text",
        "text",
        "split",
        "df",
        "DATAFRAMES",
        "df",
        "apply",
        "x",
        "get_keywords",
        "x",
        "df",
        "apply",
        "x",
        "get_month",
        "x",
        "pd",
        "concat",
        "analyze_df",
        "df",
        "analyze_df",
        "np",
        "unique",
        "analyze_df",
        "np",
        "unique",
        "analyze_df",
        "return_counts",
        "a",
        "b",
        "unique",
        "counts",
        "a",
        "b",
        "np",
        "unique",
        "analyze_df",
        "return_counts",
        "a",
        "b",
        "unique",
        "counts",
        "a",
        "b",
        "analyze_df",
        "stars",
        "words",
        "stars_to_words",
        "stars",
        "words",
        "split",
        "subset",
        "apply",
        "x",
        "gather_keywords",
        "x",
        "ratings",
        "x",
        "text",
        "axis",
        "i",
        "np",
        "unique",
        "stars_to_words",
        "i",
        "return_counts",
        "pd",
        "DataFrame",
        "unique",
        "counts",
        "tmp",
        "sort_values",
        "by",
        "ascending",
        "i",
        "tmp",
        "head",
        "analyze_df",
        "analyze_df",
        "train_test_split",
        "X",
        "y",
        "test_size",
        "random_state",
        "vectorizer",
        "fit_transform",
        "analyze_df",
        "analyze_df",
        "train_test_split",
        "X",
        "y",
        "test_size",
        "random_state",
        "LinearRegression",
        "model",
        "fit",
        "X_train",
        "y_train",
        "model",
        "predict",
        "X_test",
        "root_mean_squared_error",
        "y_test",
        "y_preds",
        "rmse",
        "r2_score",
        "y_test",
        "y_preds",
        "r2"
    ],
    "literals": [
        "'stopwords'",
        "'punkt_tab'",
        "'english'",
        "'display.max_columns'",
        "'export_harrypotter.csv'",
        "','",
        "'month'",
        "' '",
        "''",
        "'-'",
        "'text'",
        "'text'",
        "'month'",
        "'date'",
        "'ratings'",
        "'month'",
        "'text'",
        "'ratings'",
        "'ratings'",
        "\"Ratings Data: \"",
        "\": \"",
        "'\\n'",
        "'month'",
        "\"Month Data: \"",
        "\": \"",
        "'\\n'",
        "'text'",
        "'ratings'",
        "' '",
        "'word'",
        "'count'",
        "'count'",
        "\"Top 20 for\"",
        "\"- STAR\"",
        "'\\n'",
        "'text'",
        "'ratings'",
        "'*****'",
        "'PREDICT BY KEYWORD'",
        "'text'",
        "'ratings'",
        "'*****'",
        "'MODEL ACCURACY'",
        "'RMSE:'",
        "'R^2:'"
    ],
    "variables": [
        "tk",
        "stop_words",
        "vectorizer",
        "FILE_PATHS",
        "DATAFRAMES",
        "analyze_df",
        "arr",
        "arr",
        "arr",
        "df",
        "df",
        "analyze_df",
        "analyze_df",
        "unique",
        "counts",
        "unique",
        "counts",
        "subset",
        "stars_to_words",
        "unique",
        "counts",
        "tmp",
        "tmp",
        "X",
        "y",
        "X_train",
        "X_test",
        "y_train",
        "y_test",
        "X",
        "y",
        "X_train",
        "X_test",
        "y_train",
        "y_test",
        "model",
        "y_preds",
        "rmse",
        "r2"
    ],
    "comments": [
        "CLEAN DATA",
        "Helper method to extract keywords",
        "get keywords",
        "remove stopwords",
        "Append df to analyze_df",
        "print(analyze_df.head(5))",
        "Check for NaN values",
        "goal: predict star rating distribution using bayesian regression",
        "DETERMINE PRIORS",
        "Ratings distribution",
        "Result: Highly skewed left",
        "Result: Peak in winter, low in summer/fall",
        "CHECK ASSUMPTIONS",
        "Extract features using TF-IDF",
        "Extract features using TF-IDF",
        "Initialize and train the regression model",
        "Predict the demand on the test set"
    ],
    "docstrings": [
        "*** PART ONE ***",
        "**A. Get keywords (from 'text')",
        "**B. Month (from 'date')",
        "*** PART TWO ***",
        "*** PREDICT RATINGS BY MONTH ***",
        "*** PREDICT RATINGS BY KEYWORD ***",
        "*** MODEL EVALUATION ***"
    ],
    "functions": [
        "get_keywords",
        "get_month",
        "gather_keywords"
    ],
    "classes": []
}