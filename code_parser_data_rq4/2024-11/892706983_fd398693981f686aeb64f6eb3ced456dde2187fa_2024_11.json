{
    "identifiers": [
        "pandas",
        "pd",
        "random",
        "re",
        "yahoo_fin",
        "stock_info",
        "si",
        "pd",
        "read_csv",
        "output_file_path",
        "combined_score",
        "combined_score",
        "combined_score",
        "reddit_data_with_scores",
        "apply",
        "classify_sentiment",
        "si",
        "tickers_sp500",
        "si",
        "tickers_nasdaq",
        "si",
        "tickers_dow",
        "tickers_list",
        "text",
        "re",
        "findall",
        "text",
        "sorted",
        "word",
        "word",
        "words",
        "word",
        "tickers_set",
        "tickers",
        "reddit_data_with_scores",
        "apply",
        "identify_tickers",
        "text",
        "re",
        "sub",
        "text",
        "text",
        "strip",
        "reddit_data_with_scores",
        "apply",
        "clean_text",
        "df",
        "sentiment",
        "n",
        "df",
        "df",
        "sentiment",
        "len",
        "filtered_df",
        "n",
        "filtered_df",
        "sample",
        "n",
        "n",
        "random_state",
        "random",
        "randint",
        "filtered_df",
        "sample_posts_by_sentiment",
        "reddit_data_with_scores",
        "sample_posts_by_sentiment",
        "reddit_data_with_scores",
        "sample_posts_by_sentiment",
        "reddit_data_with_scores",
        "pd",
        "concat",
        "positive_posts",
        "neutral_posts",
        "negative_posts",
        "sampled_posts",
        "sampled_posts",
        "explode",
        "groupby",
        "size",
        "unstack",
        "fill_value",
        "ticker_sentiment_summary",
        "reddit_data_with_scores",
        "to_csv",
        "classified_file_path",
        "index",
        "classified_file_path"
    ],
    "literals": [
        "r'C:\\Users\\Andrew\\Desktop\\NEU\\5100 foundation for AI\\Final\\Reddit WallStreetBets Posts Sentiment Analysis\\reddit_wsb_combined_scores.csv'",
        "r'C:\\Users\\Andrew\\Desktop\\NEU\\5100 foundation for AI\\Final\\Reddit WallStreetBets Posts Sentiment Analysis\\reddit_wsb_classified.csv'",
        "'Positive'",
        "'Negative'",
        "'Neutral'",
        "'sentiment_classification'",
        "'combined_score'",
        "r'\\b[A-Z]{1,5}\\b'",
        "'tickers'",
        "'body'",
        "r'\\s+'",
        "' '",
        "'body'",
        "'body'",
        "'sentiment_classification'",
        "'Positive'",
        "'Neutral'",
        "'Negative'",
        "\"Sampled Posts with Sentiment Classification:\"",
        "'body'",
        "'tickers'",
        "'score'",
        "'comms_num'",
        "'transformer_sentiment_score'",
        "'combined_score'",
        "'sentiment_classification'",
        "'tickers'",
        "'tickers'",
        "'sentiment_classification'",
        "\"Ticker sentiment summary:\"",
        "f\"Data with sentiment classification saved to {classified_file_path}\""
    ],
    "variables": [
        "output_file_path",
        "classified_file_path",
        "reddit_data_with_scores",
        "reddit_data_with_scores",
        "tickers_list",
        "tickers_set",
        "words",
        "tickers",
        "reddit_data_with_scores",
        "text",
        "reddit_data_with_scores",
        "filtered_df",
        "positive_posts",
        "neutral_posts",
        "negative_posts",
        "sampled_posts",
        "ticker_sentiment_summary"
    ],
    "comments": [
        "Load the data with combined scores",
        "Function to classify the sentiment based on the combined score",
        "Apply the classification to the combined score",
        "Get a list of all tickers from Yahoo Finance",
        "Combine multiple sources as needed",
        "Function to identify tickers in the text and sort them alphabetically",
        "Match words that are 1-5 capital letters long",
        "Apply the identify_tickers function to each post",
        "Function to clean text by removing excess whitespace",
        "Replace multiple spaces/newlines with a single space",
        "Apply text cleaning to the body",
        "Sample 5 posts from each sentiment category for inspection",
        "Debugging: Display sampled posts and ticker sentiment summary",
        "Save the DataFrame with sentiment classification to a new CSV file"
    ],
    "docstrings": [],
    "functions": [
        "classify_sentiment",
        "identify_tickers",
        "clean_text",
        "sample_posts_by_sentiment"
    ],
    "classes": []
}