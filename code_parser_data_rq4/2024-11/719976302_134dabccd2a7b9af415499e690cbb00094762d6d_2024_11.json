{
    "identifiers": [
        "statistics",
        "mean",
        "typing",
        "Optional",
        "src",
        "Model",
        "src",
        "dtos",
        "Message",
        "Evaluation",
        "src",
        "llms",
        "OpenAI",
        "src",
        "prompts",
        "EVAL_PROMPT",
        "model",
        "Optional",
        "Model",
        "n_samples",
        "prompt",
        "EVAL_PROMPT",
        "model",
        "model",
        "OpenAI",
        "n_samples",
        "prompt",
        "trajectory",
        "Message",
        "Evaluation",
        "Message",
        "system",
        "prompt",
        "model",
        "count_message_tokens",
        "system_message",
        "max_output_tokens",
        "model",
        "truncate_messages",
        "trajectory",
        "headroom",
        "system_message",
        "messages",
        "model",
        "run_async",
        "messages",
        "max_tokens",
        "max_output_tokens",
        "response_format",
        "n",
        "n_samples",
        "n_samples",
        "Message",
        "from_response",
        "choice",
        "message",
        "choice",
        "response",
        "Message",
        "from_response",
        "response",
        "Evaluation",
        "from_message",
        "eval",
        "eval",
        "evals",
        "evals",
        "mean",
        "eval",
        "score",
        "eval",
        "evals",
        "evaluation"
    ],
    "literals": [
        "\"type\"",
        "\"json_schema\"",
        "\"json_schema\"",
        "\"name\"",
        "\"evaluation\"",
        "\"strict\"",
        "\"schema\"",
        "\"type\"",
        "\"object\"",
        "\"properties\"",
        "\"reasoning\"",
        "\"type\"",
        "\"string\"",
        "\"description\"",
        "\"Your thoughts and reasoning process. Keep it brief and concise.\"",
        "\"score\"",
        "\"type\"",
        "\"number\"",
        "\"description\"",
        "\"Score from 0-10 on the quality of the trajectory. A 10 indicates that the agent has completely succeeded in satisfying the user's intent.\"",
        "\"required\"",
        "\"reasoning\"",
        "\"score\"",
        "\"additionalProperties\""
    ],
    "variables": [
        "model",
        "n_samples",
        "prompt",
        "max_output_tokens",
        "system_message",
        "headroom",
        "messages",
        "messages",
        "response",
        "evals",
        "evals",
        "evals",
        "evaluation",
        "evaluation",
        "score"
    ],
    "comments": [
        "Standard library",
        "Local",
        "Use self-consistency"
    ],
    "docstrings": [],
    "functions": [
        "run_async"
    ],
    "classes": [
        "Evaluator"
    ]
}