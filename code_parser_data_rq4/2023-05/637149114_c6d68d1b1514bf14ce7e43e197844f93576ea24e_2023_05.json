{
    "identifiers": [
        "torch",
        "torch",
        "ones",
        "x1",
        "torch",
        "ones",
        "requires_grad",
        "x",
        "x",
        "y",
        "x",
        "grad_fn",
        "y",
        "grad_fn",
        "y",
        "y",
        "z",
        "mean",
        "z",
        "torch",
        "randn",
        "a",
        "a",
        "a",
        "requires_grad",
        "a",
        "requires_grad_",
        "a",
        "requires_grad",
        "a",
        "a",
        "sum",
        "b",
        "grad_fn",
        "backward",
        "x",
        "grad",
        "x",
        "requires_grad",
        "x",
        "requires_grad",
        "torch",
        "no_grad",
        "x",
        "requires_grad",
        "x",
        "requires_grad",
        "x",
        "detach",
        "y",
        "requires_grad",
        "x",
        "eq",
        "y",
        "all",
        "torch",
        "torch",
        "torch",
        "nn",
        "nn",
        "torch",
        "nn",
        "functional",
        "F",
        "nn",
        "Module",
        "Net",
        "nn",
        "Conv2d",
        "nn",
        "Conv2d",
        "nn",
        "Linear",
        "nn",
        "Linear",
        "nn",
        "Linear",
        "x",
        "F",
        "max_pool2d",
        "F",
        "relu",
        "conv1",
        "x",
        "F",
        "max_pool2d",
        "F",
        "relu",
        "conv2",
        "x",
        "x",
        "view",
        "num_flat_features",
        "x",
        "F",
        "relu",
        "fc1",
        "x",
        "F",
        "relu",
        "fc2",
        "x",
        "fc3",
        "x",
        "x",
        "x",
        "x",
        "size",
        "s",
        "size",
        "num_features",
        "s",
        "num_features",
        "Net",
        "net",
        "net",
        "parameters",
        "len",
        "size",
        "torch",
        "randn",
        "input",
        "input",
        "size",
        "net",
        "input",
        "size",
        "net",
        "input",
        "torch",
        "randn",
        "target",
        "target",
        "size",
        "target",
        "view",
        "target",
        "target",
        "size",
        "nn",
        "MSELoss",
        "criterion",
        "output",
        "target",
        "loss",
        "loss",
        "grad_fn",
        "loss",
        "grad_fn",
        "next_functions",
        "loss",
        "grad_fn",
        "next_functions",
        "next_functions",
        "net",
        "zero_grad",
        "net",
        "conv1",
        "bias",
        "grad",
        "loss",
        "backward",
        "net",
        "conv1",
        "bias",
        "grad",
        "torch",
        "optim",
        "optim",
        "optim",
        "SGD",
        "net",
        "parameters",
        "lr",
        "optimizer",
        "zero_grad",
        "net",
        "input",
        "criterion",
        "output",
        "target",
        "loss",
        "backward",
        "optimizer",
        "step",
        "torch",
        "torchvision",
        "torchvision",
        "transforms",
        "transforms",
        "torch",
        "nn",
        "nn",
        "torch",
        "nn",
        "functional",
        "F",
        "torch",
        "optim",
        "optim",
        "transforms",
        "Compose",
        "transforms",
        "ToTensor",
        "transforms",
        "Normalize",
        "torchvision",
        "datasets",
        "CIFAR10",
        "root",
        "train",
        "download",
        "transform",
        "transform",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "trainset",
        "batch_size",
        "shuffle",
        "torchvision",
        "datasets",
        "CIFAR10",
        "root",
        "train",
        "download",
        "transform",
        "transform",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "testset",
        "batch_size",
        "shuffle",
        "nn",
        "Module",
        "Net",
        "nn",
        "Conv2d",
        "nn",
        "MaxPool2d",
        "nn",
        "Conv2d",
        "nn",
        "Linear",
        "nn",
        "Linear",
        "nn",
        "Linear",
        "x",
        "pool",
        "F",
        "relu",
        "conv1",
        "x",
        "pool",
        "F",
        "relu",
        "conv2",
        "x",
        "x",
        "view",
        "F",
        "relu",
        "fc1",
        "x",
        "F",
        "relu",
        "fc2",
        "x",
        "fc3",
        "x",
        "x",
        "Net",
        "net",
        "nn",
        "CrossEntropyLoss",
        "optim",
        "SGD",
        "net",
        "parameters",
        "lr",
        "momentum",
        "epoch",
        "i",
        "data",
        "trainloader",
        "data",
        "optimizer",
        "zero_grad",
        "net",
        "inputs",
        "criterion",
        "outputs",
        "labels",
        "loss",
        "backward",
        "optimizer",
        "step",
        "running_loss",
        "loss",
        "item",
        "i",
        "epoch",
        "i",
        "running_loss",
        "torch",
        "save",
        "net",
        "state_dict",
        "PATH",
        "iter",
        "testloader",
        "dataiter",
        "__next__",
        "Net",
        "net",
        "load_state_dict",
        "torch",
        "load",
        "PATH",
        "net",
        "images",
        "torch",
        "max",
        "outputs",
        "join",
        "classes",
        "predicted",
        "j",
        "j",
        "torch",
        "no_grad",
        "data",
        "testloader",
        "data",
        "labels",
        "labels",
        "labels",
        "size",
        "labels",
        "size",
        "labels",
        "size",
        "labels",
        "size",
        "net",
        "images",
        "torch",
        "max",
        "outputs",
        "data",
        "total",
        "labels",
        "size",
        "correct",
        "predicted",
        "labels",
        "sum",
        "item",
        "correct",
        "total",
        "i",
        "i",
        "torch",
        "no_grad",
        "data",
        "testloader",
        "data",
        "net",
        "images",
        "torch",
        "max",
        "outputs",
        "predicted",
        "predicted",
        "size",
        "predicted",
        "labels",
        "predicted",
        "labels",
        "size",
        "predicted",
        "labels",
        "squeeze",
        "c",
        "c",
        "size",
        "i",
        "labels",
        "i",
        "class_correct",
        "label",
        "c",
        "i",
        "item",
        "class_total",
        "label",
        "i",
        "classes",
        "i",
        "class_correct",
        "i",
        "class_total",
        "i",
        "jieba",
        "hanlp",
        "hanlp",
        "utils",
        "lang",
        "en",
        "english_tokenizer",
        "tokenize_english",
        "jieba",
        "posseg",
        "pseg",
        "jieba",
        "cut",
        "content",
        "cut_all",
        "cut",
        "jieba",
        "lcut",
        "content",
        "cut_all",
        "lcut",
        "jieba",
        "lcut",
        "content",
        "cut_all",
        "jieba_lcut",
        "jieba",
        "lcut",
        "content",
        "cut_all",
        "l",
        "jieba",
        "lcut",
        "lcut1",
        "jieba",
        "load_userdict",
        "jieba",
        "lcut",
        "lcut1",
        "tokenize_english",
        "tokenizer",
        "list_list",
        "pseg",
        "lcut",
        "pseg_lcut",
        "joblib",
        "keras",
        "preprocessing",
        "text",
        "Tokenizer",
        "Tokenizer",
        "num_words",
        "char_level",
        "t",
        "fit_on_texts",
        "vocab",
        "token",
        "vocab",
        "len",
        "vocab",
        "t",
        "texts_to_sequences",
        "token",
        "token",
        "zero_list",
        "joblib",
        "dump",
        "t",
        "tokenizer_path",
        "fasttext",
        "fasttext",
        "train_unsupervised"
    ],
    "literals": [
        "\"++++++++++++++++++++++++++++++++++++++++\"",
        "\"++++++++++++++++++++++++++++++++++++++++\"",
        "\"++++++++++++++++++++++++++++++++++++++++\"",
        "\"+++++++++++++++++\"",
        "\"+++++++++++++++++\"",
        "\"+++++++++++++++++\"",
        "\"+++++++++++++++++\"",
        "\"+++++++++++++++++\"",
        "\"+++++++++++++++++\"",
        "'conv1.bias.grad before backward'",
        "'conv1.bias.grad after backward'",
        "\"hello world\"",
        "'./data'",
        "'./data'",
        "'plane'",
        "'car'",
        "'bird'",
        "'cat'",
        "'deer'",
        "'dog'",
        "'frog'",
        "'horse'",
        "'ship'",
        "'truck'",
        "'[%d, %5d] loss: %.3f'",
        "'Finished Training'",
        "'./cifar_net.pth'",
        "'Predicted: '",
        "' '",
        "'%5s'",
        "\"++++++++++++++\"",
        "\"++++++++++++++\"",
        "'Accuracy of the network on the 10000 test images: %d %%'",
        "\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"",
        "'Accuracy of %5s : %2d %%'",
        "\"工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作\"",
        "\"煩惱即是菩提，我暫且不提\"",
        "\"八一双鹿更名为八一南昌篮球队！\"",
        "\"./user_dict.txt\"",
        "\"八一双鹿更名为八一南昌篮球队！\"",
        "'Mr. Hankcs bought hankcs.com for 1.5 thousand dollars.'",
        "\"我爱北京天安门\"",
        "\"周杰伦\"",
        "\"陈奕迅\"",
        "\"王力宏\"",
        "\"李宗盛\"",
        "\"吴亦凡\"",
        "\"鹿晗\"",
        "\"的one-hot编码为:\"",
        "\"./Tokenizer\"",
        "'data1/enwik9'"
    ],
    "variables": [
        "x1",
        "x",
        "y",
        "z",
        "a",
        "a",
        "b",
        "y",
        "conv1",
        "conv2",
        "fc1",
        "fc2",
        "fc3",
        "x",
        "x",
        "x",
        "x",
        "x",
        "x",
        "size",
        "num_features",
        "net",
        "input",
        "output",
        "target",
        "target",
        "criterion",
        "loss",
        "optimizer",
        "output",
        "loss",
        "transform",
        "trainset",
        "trainloader",
        "testset",
        "testloader",
        "classes",
        "conv1",
        "pool",
        "conv2",
        "fc1",
        "fc2",
        "fc3",
        "x",
        "x",
        "x",
        "x",
        "x",
        "x",
        "net",
        "criterion",
        "optimizer",
        "running_loss",
        "inputs",
        "labels",
        "outputs",
        "loss",
        "running_loss",
        "PATH",
        "dataiter",
        "images",
        "labels",
        "net",
        "outputs",
        "_",
        "predicted",
        "correct",
        "total",
        "images",
        "labels",
        "outputs",
        "_",
        "predicted",
        "class_correct",
        "class_total",
        "images",
        "labels",
        "outputs",
        "_",
        "predicted",
        "c",
        "label",
        "content",
        "cut",
        "lcut",
        "jieba_lcut",
        "content",
        "l",
        "lcut1",
        "lcut1",
        "tokenizer",
        "list_list",
        "pseg_lcut",
        "vocab",
        "t",
        "zero_list",
        "token_index",
        "zero_list",
        "token_index",
        "tokenizer_path",
        "model"
    ],
    "comments": [
        "如果某个张量Tensor是用户自定义的, 则其对应的grad_fn is None",
        "当代码要进行反向传播的时候, 直接调用.backward()就可以自动计算所有的梯度. 在这个Tensor上的所有梯度将被累加进属性.grad中.",
        "x的requires_grad = true,则x平方的requires_grad也是true",
        "可以通过.detach()获得一个新的Tensor, 拥有相同的内容但不需要自动求导.",
        "检测x y 是否拥有相同的内容(值比较矩阵)",
        "导入若干工具包",
        "定义一个简单的网络类",
        "定义第一层卷积神经网络, 输入通道维度=1, 输出通道维度=6, 卷积核大小3*3",
        "定义第二层卷积神经网络, 输入通道维度=6, 输出通道维度=16, 卷积核大小3*3",
        "定义三层全连接网络",
        "在(2, 2)的池化窗口下执行最大池化操作",
        "计算size, 除了第0个维度上的batch_size",
        "改变target的形状为二维张量, 为了和output匹配",
        "MSELoss",
        "Linear",
        "ReLU",
        "Pytorch中执行梯度清零的代码",
        "Pytorch中执行反向传播的代码",
        "首先导入优化器的包, optim中包含若干常用的优化算法, 比如SGD, Adam等",
        "通过optim创建优化器对象",
        "将优化器执行梯度清零的操作",
        "对损失值执行反向传播的操作",
        "参数的更新通过一行标准代码来执行",
        "使用torchvision下载CIFAR10数据集",
        "利用transforms.compose进行转换，转换为tensor类型",
        "下面是标准代码，定义数据转换器",
        "num_workers=2是两个线程，多个线程加速读取数据速度",
        "测试时不需要打乱，所以shuffle=False",
        "仿照7.1节中的类来构造此处的类, 唯一的区别是此处采用3通道3-channel",
        "采用交叉熵损失函数和随机梯度下降优化器.",
        "loop over the dataset multiple times",
        "data中包含输入图像张量inputs, 标签张量labels",
        "首先将优化器梯度归零",
        "输入图像张量进网络, 得到输出张量outputs",
        "利用网络的输出outputs和标签labels计算损失值",
        "反向传播+参数更新, 是标准代码的标准流程",
        "打印轮次和损失值",
        "首先设定模型的保存路径",
        "保存模型的状态字典",
        "先拿出四张图片进行简单的测试",
        "先取出4张图片",
        "两种利用迭代器的方法",
        "images, labels = next(dataiter)",
        "首先实例化模型的类对象",
        "加载训练阶段保存好的模型的状态字典",
        "利用模型对图片进行预测",
        "共有10个类别, 采用模型计算出的概率最大的作为预测的类别",
        "dim=0表示计算每列的最大值，dim=1表示每行的最大值",
        "打印预测标签的结果",
        "在全部测试集上运行",
        "data中有四个数据",
        "范围只能是-1 到0",
        "具体原因看main.py",
        "dim=0表示计算每列的最大值，dim=1表示每行的最大值",
        "返回值有两个，取后者。取返回最大值所在的索引",
        "labels.size(0)",
        "predicted和labels都是一行四列的值。sum把其中的值为TRUE的加起来",
        "%% 字符%",
        "为了更加细致的看一下模型在哪些类别上表现更好, 在哪些类别上表现更差, 我们分类别的进行准确率计算.",
        "class_correct中有10个0.0",
        "class_total中有10个0.0",
        "把.squeeze()删除也能运行",
        "https://zhuanlan.zhihu.com/p/368920094",
        "全模式把所有能分词的都分割出来",
        "",
        "tokenizer = hanlp.load('CTB6_CONVSEG')",
        "tokenizer(\"工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作\")",
        "recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)",
        "recognizer1 = recognizer(list('上海华安工业（集团）公司董事长谭旭光和秘书张晚霞来到美国纽约现代艺术博物馆参观。'))",
        "print(recognizer1)",
        "recognizer = hanlp.load(hanlp.pretrained.ner.CONLL03_NER_BERT_BASE_UNCASED_EN))",
        "recognizer1 = recognizer([\"President\", \"Obama\", \"is\", \"speaking\", \"at\", \"the\", \"White\", \"House\"])",
        "print(recognizer1)",
        "导入用于对象保存与加载的joblib",
        "导入keras中的词汇映射器Tokenizer",
        "假定vocab为语料集所有不同词汇集合",
        "实例化一个词汇映射器对象",
        "使用映射器拟合现有文本数据",
        "使用映射器转化现有文本数据, 每个词汇对应从1开始的自然数",
        "返回样式如: [[2]], 取出其中的数字需要使用[0][0]",
        "使用joblib工具保存映射器, 以便之后使用"
    ],
    "docstrings": [
        "'''\n在整个Pytorch框架中, 所有的神经网络本质上都是一个autograd package(自动求导工具包)\nautograd package提供了一个对Tensors上所有的操作进行自动微分的功能.\ntorch.Tensor是整个package中的核心类, 如果将属性.requires_grad设置为True, 它将追踪在这个类上定义的所有操作. 当代码要进行反向传播的时候, 直接调用.backward()就可以自动计算所有的梯度. 在这个Tensor上的所有梯度将被累加进属性.grad中.\n如果想终止一个Tensor在计算图中的追踪回溯, 只需要执行.detach()就可以将该Tensor从计算图中撤下, 在未来的回溯计算中也不会再计算该Tensor.\n除了.detach(), 如果想终止对计算图的回溯, 也就是不再进行方向传播求导数的过程, 也可以采用代码块的方式with torch.no_grad():, 这种方式非常适用于对模型进行预测的时候, 因为预测阶段不再需要对梯度进行计算.\n\n关于torch.Function:\nFunction类是和Tensor类同等重要的一个核心类, 它和Tensor共同构建了一个完整的类, 每一个Tensor拥有一个.grad_fn属性, 代表引用了哪个具体的Function创建了该Tensor.\n如果某个张量Tensor是用户自定义的, 则其对应的grad_fn is None\n'''",
        "'''\n关于方法.requires_grad_(): 该方法可以原地改变Tensor的属性.requires_grad的值. 如果没有主动设定默认为False.\n'''",
        "'''\n关于torch.nn:\n使用Pytorch来构建神经网络, 主要的工具都在torch.nn包中.\nnn依赖于autograd来定义模型, 并对其自动求导.\n\n构建神经网络的典型流程:\n定义一个拥有可学习参数的神经网络\n遍历训练数据集\n处理输入数据使其流经神经网络\n计算损失值\n将网络参数的梯度进行反向传播\n以一定的规则更新网络的权重\n\n激活函数Relu，在神经网络中的作用是：通过加权的输入进行非线性组合产生非线性决策边界 简单的来说就是增加非线性作用。\n在深层卷积神经网络中使用激活函数同样也是增加非线性，主要是为了解决sigmoid函数带来的梯度消失问题。\n\n在PyTorch中对于不能整除的状况默认均为向下取整，可以选择向上取整\n'''",
        "'''\norch.randn[8, 3, 244, 244]，[batch, channel, height, width]，表示batch_size=8， 3通道（灰度图像为1），图片尺寸：224x224\n如果给的是torch.randn[1, 1, 32, 32]表示batch_size=1， 1通道（灰度图像），图片尺寸：32x32\n'''",
        "'''\ntorch.nn构建的神经网络只支持mini-batches的输入, 不支持单一样本的输入.\n比如: nn.Conv2d 需要一个4D Tensor, 形状为(nSamples, nChannels, Height, Width). 如果你的输入只有单一样本形式,\n 则需要执行input.unsqueeze(0), 主动将3D Tensor扩充成4D Tensor.\n'''",
        "'''\n损失函数的输入是一个输入的pair: (output, target), 然后计算出一个数值来评估output和target之间的差距大小.\n在torch.nn中有若干不同的损失函数可供使用, 比如nn.MSELoss就是通过计算均方差损失来评估输入和目标值之间的差距.\n'''",
        "'''\n关于方向传播的链条: 如果我们跟踪loss反向传播的方向, 使用.grad_fn属性打印, 将可以看到一张完整的计算图如下:\ninput -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n'''",
        "'''\n当调用loss.backward()时, 整张计算图将对loss进行自动求导, \n所有属性requires_grad=True的Tensors都将参与梯度求导的运算, 并将梯度累加到Tensors中的.grad属性中.\n'''",
        "'''\n反向传播(backpropagation)\n在Pytorch中执行反向传播非常简便, 全部的操作就是loss.backward().\n在执行反向传播之前, 要先将梯度清零, 否则梯度会在不同的批次数据之间被累加.\n'''",
        "'''\n下载数据集并对图片进行调整,\n因为torchvision数据集的输出是PILImage格式, 数据域在[0, 1]. 我们将其转换为标准数据域[-1, 1]的张量格式.\n'''",
        "'''\nMomentum的作用？\n主要是在训练网络时，最开始会对网络进行权值初始化，但是这个初始化不可能是最合适的；\n因此可能就会出现损失函数在训练的过程中出现局部最小值的情况，而没有达到全局最优的状态。\nmomentum的出现可以在一定程度上解决这个问题。动量来源于物理学，当momentum越大时，\n转换为势能的能量就越大，就越有可能摆脱局部凹区域，从而进入全局凹区域。momentum主要是用于权值优化。\n'''",
        "'''\n        torch.Size括号中有几个数字就是几维\n        例如：第一层（最外层）中括号里面包含了两个中括号（以逗号进行分割），这就是（2，3，4）中的2\n        第二层中括号里面包含了三个中括号（以逗号进行分割），这就是（2，3，4）中的3\n        第三层中括号里面包含了四个数（以逗号进行分割），这就是（2，3，4）中的4\n        '''"
    ],
    "functions": [
        "forward",
        "num_flat_features",
        "forward"
    ],
    "classes": [
        "Net",
        "Net"
    ]
}