{
    "identifiers": [
        "os",
        "re",
        "PyPDF2",
        "nltk",
        "tokenize",
        "word_tokenize",
        "nltk",
        "corpus",
        "stopwords",
        "wordnet",
        "collections",
        "Counter",
        "stopwords",
        "words",
        "Counter",
        "file_name",
        "os",
        "listdir",
        "folder_path",
        "file_name",
        "endswith",
        "os",
        "path",
        "join",
        "folder_path",
        "file_name",
        "open",
        "file_path",
        "file",
        "PyPDF2",
        "PdfReader",
        "file",
        "page",
        "pdf_reader",
        "pages",
        "page",
        "extract_text",
        "re",
        "findall",
        "text",
        "word",
        "lower",
        "word",
        "word_list",
        "word",
        "isalpha",
        "word",
        "lower",
        "stop_words",
        "len",
        "word",
        "word",
        "isdigit",
        "word",
        "word",
        "words",
        "wordnet",
        "synsets",
        "word",
        "word_counter",
        "update",
        "tokens",
        "sorted",
        "word_counter",
        "items",
        "key",
        "x",
        "x",
        "reverse",
        "open",
        "output_file",
        "encoding",
        "file",
        "word",
        "count",
        "sorted_words",
        "file",
        "write",
        "word",
        "count",
        "output_file"
    ],
    "literals": [
        "'D:/workspace/python/wordparse/book'",
        "\"english\"",
        "\".pdf\"",
        "\"rb\"",
        "r'\\b\\w+\\b'",
        "\"D:/workspace/python/wordparse/book/output.txt\"",
        "\"w\"",
        "\"utf-8\"",
        "f\"{word}: {count}\\n\"",
        "\"Output written to\""
    ],
    "variables": [
        "folder_path",
        "stop_words",
        "word_counter",
        "file_path",
        "pdf_reader",
        "text",
        "word_list",
        "words",
        "tokens",
        "sorted_words",
        "output_file"
    ],
    "comments": [
        "文件夹路径",
        "停用词列表",
        "单词计数器",
        "遍历文件夹中的所有PDF文件",
        "打开PDF文件",
        "遍历PDF中的每一页",
        "提取文本内容",
        "分词并去除停用词",
        "tokens = word_tokenize(text)",
        "tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]",
        "更新单词计数器",
        "将单词按出现次数排序",
        "将排序结果写入txt文件",
        "tokens_with_meaning = []",
        "synsets = wordnet.synsets(word)",
        "if synsets:",
        "meaning = [synset.lemma_names('cmn') for synset in synsets]",
        "file.write(f\"{word}: {meaning} : {count}\\n\")"
    ],
    "docstrings": [],
    "functions": [],
    "classes": []
}