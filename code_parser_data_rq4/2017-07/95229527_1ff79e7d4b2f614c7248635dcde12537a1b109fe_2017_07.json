{
    "identifiers": [
        "os",
        "math",
        "gc",
        "pandas",
        "pd",
        "itertools",
        "pickle",
        "df2",
        "a",
        "df2",
        "groupby",
        "as_index",
        "count",
        "df2",
        "groupby",
        "as_index",
        "count",
        "pd",
        "merge",
        "df2_start_end",
        "df2_start",
        "on",
        "a",
        "df",
        "df",
        "df",
        "df",
        "train",
        "os",
        "path",
        "exists",
        "path",
        "pickle",
        "load",
        "open",
        "path",
        "train",
        "groupby",
        "count",
        "reset_index",
        "pickle",
        "dump",
        "train",
        "open",
        "path",
        "train",
        "train",
        "os",
        "path",
        "exists",
        "path",
        "pickle",
        "load",
        "open",
        "path",
        "get_rating_matrix",
        "train",
        "pd",
        "DataFrame",
        "rat_mat",
        "groupby",
        "name",
        "group",
        "user_groups",
        "pair",
        "itertools",
        "combinations",
        "group",
        "values",
        "item1_list",
        "append",
        "pair",
        "item2_list",
        "append",
        "pair",
        "concur_count",
        "append",
        "item1_list",
        "item2_list",
        "concur_count",
        "sim_mat",
        "groupby",
        "as_index",
        "sum",
        "pickle",
        "dump",
        "sim_mat",
        "open",
        "path",
        "sim_mat",
        "train",
        "os",
        "path",
        "exists",
        "path",
        "pickle",
        "load",
        "open",
        "path",
        "get_concur_mat",
        "train",
        "get_rating_matrix",
        "train",
        "rat_mat",
        "groupby",
        "as_index",
        "count",
        "item_vector",
        "item_vector",
        "to_dict",
        "concur_mat",
        "apply",
        "p",
        "item_count_dict",
        "p",
        "concur_mat",
        "apply",
        "p",
        "item_count_dict",
        "p",
        "concur_mat",
        "concur_mat",
        "apply",
        "math",
        "sqrt",
        "concur_mat",
        "apply",
        "math",
        "sqrt",
        "pickle",
        "dump",
        "concur_mat",
        "open",
        "path",
        "concur_mat",
        "te",
        "pd",
        "read_csv",
        "drop_duplicates",
        "pd",
        "read_csv",
        "get_concur_sim",
        "tr",
        "sim_mat",
        "sim_mat1",
        "sim_mat1",
        "sim_mat1",
        "sim_mat",
        "append",
        "sim_mat1",
        "sim_mat1",
        "sim_mat",
        "gc",
        "collect",
        "pd",
        "merge",
        "tr",
        "sim_mat",
        "left_on",
        "right_on",
        "ss",
        "gc",
        "collect",
        "ss",
        "sort_values",
        "ascending",
        "drop_duplicates",
        "pd",
        "merge",
        "ss",
        "te",
        "on",
        "pd",
        "merge",
        "df",
        "te",
        "on",
        "how",
        "fillna",
        "df",
        "df",
        "label",
        "sort_values",
        "ascending",
        "drop_duplicates",
        "pd",
        "read_csv",
        "drop_duplicates",
        "pd",
        "read_csv",
        "get_concur_sim",
        "tr",
        "pd",
        "merge",
        "tr",
        "te",
        "on",
        "how",
        "fillna",
        "pd",
        "merge",
        "df",
        "df",
        "label",
        "sim_mat",
        "left_on",
        "right_on",
        "pd",
        "merge",
        "df",
        "df",
        "label",
        "sim_mat",
        "left_on",
        "right_on",
        "make_sub"
    ],
    "literals": [
        "'userid'",
        "'geohashed_start_loc'",
        "'geohashed_end_loc'",
        "'userid'",
        "'geohashed_start_loc'",
        "'geohashed_end_loc'",
        "'orderid'",
        "'userid'",
        "'geohashed_start_loc'",
        "'userid'",
        "'geohashed_start_loc'",
        "'orderid'",
        "'userid'",
        "'geohashed_start_loc'",
        "'prob'",
        "'orderid_x'",
        "'orderid_y'",
        "'userid'",
        "'geohashed_start_loc'",
        "'geohashed_end_loc'",
        "'prob'",
        "'../cache/rating_all_test.pkl'",
        "\"rb\"",
        "'userid'",
        "'geohashed_end_loc'",
        "'geohashed_start_loc'",
        "'orderid'",
        "'wb'",
        "\"../cache/concur_mat_test.pkl\"",
        "\"rb\"",
        "'userid'",
        "'geohashed_end_loc'",
        "'geohashed_start_loc'",
        "'item1'",
        "'item2'",
        "'count'",
        "'item1'",
        "'item2'",
        "'wb'",
        "\"cache/concur_sim_mat_test.pkl\"",
        "\"rb\"",
        "'geohashed_start_loc'",
        "'geohashed_start_loc'",
        "'userid'",
        "'geohashed_end_loc'",
        "'geohashed_start_loc'",
        "'count'",
        "'count'",
        "'item1_count'",
        "'item1'",
        "'item2_count'",
        "'item2'",
        "'sim'",
        "'count'",
        "'item1_count'",
        "'item2_count'",
        "'wb'",
        "'item1'",
        "'item2'",
        "'sim'",
        "'../data/train.csv'",
        "'userid'",
        "'geohashed_start_loc'",
        "'userid'",
        "'geohashed_start_loc'",
        "'../data/test.csv'",
        "'orderid'",
        "'userid'",
        "'geohashed_start_loc'",
        "'label'",
        "'t'",
        "'item1'",
        "'item1'",
        "'item2'",
        "'item2'",
        "'t'",
        "'t'",
        "'geohashed_start_loc'",
        "'item1'",
        "'item1'",
        "'userid'",
        "'geohashed_start_loc'",
        "'sim'",
        "'userid'",
        "'geohashed_start_loc'",
        "'userid'",
        "'geohashed_start_loc'",
        "'right'",
        "'orderid'",
        "'sim'",
        "'orderid'",
        "'../data/train.csv'",
        "'userid'",
        "'geohashed_start_loc'",
        "'userid'",
        "'geohashed_start_loc'",
        "'../data/test.csv'",
        "'userid'",
        "'geohashed_start_loc'",
        "'label'",
        "'userid'",
        "'right'",
        "'item1'",
        "'geohashed_start_loc'",
        "'orderid'",
        "'item2'",
        "'sim'",
        "'item2'",
        "'geohashed_start_loc'",
        "'orderid'",
        "'item1'",
        "'sim'"
    ],
    "variables": [
        "df2_start_end",
        "df2_start",
        "df",
        "df",
        "df",
        "path",
        "train",
        "train",
        "path",
        "sim_mat",
        "rat_mat",
        "sim_mat",
        "item1_list",
        "item2_list",
        "concur_count",
        "user_groups",
        "sim_mat",
        "sim_mat",
        "sim_mat",
        "sim_mat",
        "path",
        "concur_mat",
        "concur_mat",
        "rat_mat",
        "item_vector",
        "item_vector",
        "index",
        "item_vector",
        "columns",
        "item_count_dict",
        "concur_mat",
        "concur_mat",
        "concur_mat",
        "tr",
        "te",
        "te",
        "sim_mat",
        "sim_mat1",
        "sim_mat1",
        "sim_mat1",
        "sim_mat1",
        "sim_mat",
        "ss",
        "ss",
        "df",
        "df",
        "df",
        "tr",
        "te",
        "te",
        "sim_mat",
        "df"
    ],
    "comments": [
        "coding=utf-8",
        "dump 时如果指定了 protocol 为 True，压缩过后的文件的大小只有原来的文件的 30%",
        "print name",
        "找到一个用户测试集新地点对应的最相似/最近的订单起点",
        "prob(u,new_start) = prob(u,old_start)*sim(new_start,old_start)",
        "def make_eval(val):",
        "user_start_prob = get_user_start_prob( val,1.0 )",
        "",
        "",
        "# res = pd.DataFrame()",
        "df2 = pd.merge(val[['orderid', 'userid', 'geohashed_start_loc']], user_start_prob, on=('userid', 'geohashed_start_loc'))[['orderid', 'geohashed_end_loc', 'prob']]",
        "df3 = pd.merge(val[['orderid', 'userid', 'weekday']], user_weekday_prob, on=('userid', 'weekday'))[",
        "['orderid', 'geohashed_end_loc', 'prob']]",
        "df4 = pd.merge(val[['orderid', 'userid', 'quarter']], user_quarter_prob, on=('userid', 'quarter'))[",
        "['orderid', 'geohashed_end_loc', 'prob']]",
        "",
        "res = pd.merge( df1,df2,on=('orderid','geohashed_end_loc'),how='left' ).fillna(0.001) #保证p(end|hour)*p(end|start)大于只在end|start中出现的概率，忽略了他们的差异",
        "res['prob'] = res['prob_x']*res['prob_y']",
        "del res['prob_x']",
        "del res['prob_y']",
        "res = pd.merge( res,df3,on=('orderid','geohashed_end_loc'),how='left' ).fillna(0.001)",
        "res['prob'] = res['prob_x'] * res['prob_y']",
        "del res['prob_x']",
        "del res['prob_y']",
        "res = pd.merge(res, df4, on=('orderid', 'geohashed_end_loc'),how='left').fillna(0.001)",
        "res['prob'] = res['prob_x'] * res['prob_y']",
        "del res['prob_x']",
        "del res['prob_y']",
        "",
        "groupby = res.sort_values('prob', ascending=False).drop_duplicates( ['orderid','geohashed_end_loc'] ).groupby('orderid', as_index=False)",
        "n1 = groupby.nth(0)",
        "n1.columns = ['orderid','pred1','prob1']",
        "n2 = groupby.nth(1)",
        "n2.columns = ['orderid','pred2','prob2']",
        "n3 = groupby.nth(2)",
        "n3.columns = ['orderid','pred3','prob3']",
        "res = pd.merge(n1, n2, on=('orderid'), how='left').fillna('-1')",
        "res = pd.merge(res, n3, on=('orderid'), how='left').fillna('-1')",
        "# res = res[['orderid', 'pred1', 'pred2', 'pred3']]",
        "return res",
        "prob(u,new_start) = prob(u,old_start)*sim(new_start,old_start)",
        "if __name__ == \"__main__\":",
        "d = pd.read_csv('data/data.csv')",
        "c = make_eval(d)",
        "b = pd.merge( d,c,on='orderid' )[['orderid','userid','geohashed_end_loc','pred1','pred2','pred3']]",
        "bad_case = b[(b.geohashed_end_loc != b.pred1) & (b.geohashed_end_loc != b.pred2) & (b.geohashed_end_loc != b.pred3)]",
        "dd = pd.merge(bad_case, d, on='orderid')",
        "print b"
    ],
    "docstrings": [
        "\"\"\"\n    基于推荐的算法：\n    如果用户在训练集出现过，预测的概率公式是：\n    prob(u,new_start) = prob(u,old_start)*sim(new_start,old_start)\n    其中相似度算法一种方法是--共现矩阵算法\n\"\"\"",
        "\"\"\"\n    :param df2:\n    :param a:权重控制参数,0到1之间的浮点数\n    :return:\n    \"\"\""
    ],
    "functions": [
        "get_user_start_prob",
        "get_rating_matrix",
        "get_concur_mat",
        "get_concur_sim",
        "get_sim_start",
        "make_sub"
    ],
    "classes": []
}