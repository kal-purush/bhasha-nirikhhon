{
    "identifiers": [
        "os",
        "models",
        "kp_classifier",
        "KPClassifier",
        "utils",
        "MPDetectionStream",
        "utils",
        "normalize_landmarks",
        "commands",
        "model_path",
        "MPDetectionStream",
        "src",
        "commands",
        "default_map",
        "num",
        "command",
        "num",
        "command",
        "commands",
        "model_path",
        "ValueError",
        "os",
        "path",
        "exists",
        "model_path",
        "ValueError",
        "KPClassifier",
        "model_path",
        "draw_on_image",
        "stream",
        "read_frame",
        "draw_landmarks",
        "draw_on_image",
        "normalize_landmarks",
        "img",
        "landmarks",
        "landmark_list",
        "img",
        "kp_classifier",
        "predict",
        "landmark_list",
        "command_map",
        "label",
        "command",
        "img"
    ],
    "literals": [
        "\"LAND\"",
        "\"STOP\"",
        "\"FORWARD\"",
        "\"BACK\"",
        "\"UP\"",
        "\"LEFT\"",
        "\"RIGHT\"",
        "\"TAKEOFF\"",
        "\"model_path is None\"",
        "\"model_path is not valid\"",
        "\"\""
    ],
    "variables": [
        "default_map",
        "stream",
        "command_map",
        "command_map",
        "kp_classifier",
        "img",
        "landmarks",
        "landmark_list",
        "label",
        "command"
    ],
    "comments": [
        "if commands is not given by the user, use the default commands",
        "check the model_path is valid",
        "initialize the kp_classifier model",
        "Make mediapipe detections",
        "get the normalized landmarks",
        "if no landmarks detected, return empty string and img",
        "call kp_classifier to get the predicted labels",
        "convert command number to command string"
    ],
    "docstrings": [
        "\"\"\"\n    Class to use mediapipe hand gesture classifier model\n    to detect hand gesture from a single image\n    pass it to tensor flow model and get the labels\n    then map the labels to commands and return the command\n\n    parameters:\n\n    commands: list of commands to map the labels to them.\n    model_path: path to the keypoint classifier model.\n    \"\"\"",
        "\"\"\"\n        detect hand landmarks from a single image, normalize it,\n        then pass it to tensor flow model and get the labels,\n        map the labels to command and return the command\n\n        parameters:\n            draw_on_image: if True, draw the landmarks on the image.\n\n        returns:\n            command: the predicted command.\n            image: the image with the landmarks drawn on it.\n        \"\"\""
    ],
    "functions": [
        "detect"
    ],
    "classes": [
        "HGClassifier"
    ]
}