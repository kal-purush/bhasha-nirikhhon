{
    "identifiers": [
        "parse",
        "j",
        "j",
        "hash",
        "hash",
        "j",
        "hash",
        "body",
        "parse",
        "body",
        "isException",
        "hashesPerLabels",
        "isIcann",
        "exceptions",
        "exceptions",
        "isWildcard",
        "hashesPerLabels",
        "isIcann",
        "wildcards",
        "wildcards",
        "rule",
        "rule",
        "isNormal",
        "hashesPerLabels",
        "isIcann",
        "rules",
        "rules",
        "hashesPerLabels",
        "rule",
        "numberOfLabels",
        "hashesPerLabels",
        "rules",
        "hashesPerLabels",
        "rules",
        "maximumNumberOfLabels",
        "maximumNumberOfLabels",
        "numberOfLabels",
        "hashesPerLabels",
        "numberOfLabels",
        "hashesPerLabels",
        "numberOfLabels",
        "hashesPerLabels",
        "numberOfLabels",
        "fastHash",
        "rule",
        "pushHashes",
        "hashes",
        "chunks",
        "hashes",
        "hashes",
        "a",
        "b",
        "a",
        "b",
        "a",
        "b",
        "label",
        "maximumNumberOfLabels",
        "label",
        "pushHashes",
        "exceptions",
        "label",
        "pushHashes",
        "exceptions",
        "label",
        "pushHashes",
        "wildcards",
        "label",
        "pushHashes",
        "wildcards",
        "label",
        "pushHashes",
        "rules",
        "label",
        "pushHashes",
        "rules",
        "label",
        "Uint32Array",
        "maximumNumberOfLabels",
        "chunks"
    ],
    "literals": [
        "'../parser'",
        "string",
        "string",
        "'.'"
    ],
    "variables": [
        "hash",
        "j",
        "rules",
        "wildcards",
        "exceptions",
        "maximumNumberOfLabels",
        "hashesPerLabels",
        "numberOfLabels",
        "chunks",
        "pushHashes",
        "label"
    ],
    "comments": [
        "Keep track of maximum number of labels seen in a given rule. This allows us",
        "to make sure that all sections of the typed array (wildcards, exceptions",
        "and normal rules) have the same size and we do not need to check that while",
        "matching.",
        "Iterate on public suffix rules",
        "Select correct section to insert the rule",
        "eslint-disable-next-line no-param-reassign",
        "Count number of labels in this suffix",
        "Experimentally, we start ignoring suffixes with only one label since the",
        "fallback to '*' will yield the same result. This helps reduce the size of",
        "the bundle further and speed-up matching. One potential side-effect is",
        "that we might not accurately return the information about if a suffix is",
        "from the ICANN or PRIVATE section.",
        "Pack everything together",
        "@ts-ignore"
    ],
    "docstrings": [
        "* This builder implements a probabilistic data-structure to store the public\n * suffixes from Mozilla's 'publicsuffix' project. The goals are:\n *\n *   1. Allow storing the parsed rules in a very compact form (<30KB)\n *   2. Allow super fast load time with no parsing required (typed array)\n *   2. Super fast lookup times (~2M+ per second)\n *\n * These are achieved by hashing each available suffix as a 32bits number and\n * storing them in a typed array which is bundled in the library itself. This\n * way the only cost of loading the rules is paid by the JavaScript engine\n * loading the source and the size of the rules is ~29KB. Matching is also\n * extremely fast, at around 2M+ lookups per second.\n *\n * **WARNING**: The drawback of this structure is that, because we use hashes of\n * suffixes instead of their initial values, there can be collisions (think\n * bloom filters). Some future work involves estimating the probability of\n * collisions. Only use this structure if you are fine with this limitation and\n * need the most compact/fast data structure available.\n *\n * Data Structure\n * ==============\n *\n * The basic idea behind the packed hashes structure is that suffixes will be\n * grouped by number of labels then hashed to 32bits integers using a fast\n * hashing function. For examples:\n *\n *  1 label:\n *    com   -> hash(com)\n *    fr    -> hash(fr)\n *    gov   -> hash(gov)\n *  2 labels:\n *    co.uk -> hash(co.uk)\n *\n * Then the hashes are organized in a typed array from least number of labels to\n * most number of labels, and in each section, hashes are sorted so that we can\n * perform lookups using a binary search:\n *\n * |#1 length|suffix 1|suffix 2|...|#2 length|suffix 1|suffix 2|...|...\n *  ^                               ^ number of suffixes with 2 labels\n *  | number of suffix with 1 label\n *\n *  In the example above:\n *\n *    3|hash(com)|hash(fr)|hash(gov)|1|hash(co.uk)\n *    ^                              ^ we have on suffix with 2 labels (co.uk)\n *    | we have 3 suffixes with one label\n *\n * In practice, the data-structure is slightly more complex as we have to handle\n * the ICANN and PRIVATE sections of the list separately (which allows to pick\n * one or the other at runtime; or both, which is the default) as well as\n * wildcards and exceptions rules. The structure looks more like:\n *\n *  |icann exceptions|private exceptions|icann wildcards|private wildcards|icann rules|private rules\n *\n *  Still ordered from least number of labels to most number of labels. This\n *  allows the matching to be a forward progression from beginning to end,\n *  potentially skipping some sections (e.g.: private) by just incrementing the\n *  index.\n *\n * Finding a Match\n * ===============\n *\n * Finding a match can be done efficiently, without any string copy and by a\n * single pass over the input (from end to beginning). The algorithm is as\n * follows:\n *\n * - For each character `c` in hostname, from end to start:\n *     1. If `c` is '.' then we reached the end of a label:\n *         * Use a binary search in the section containing suffixes of the same\n *           size as our current label to check if our hash is there.\n *         * Move forward to the next section by incrementing the index by the\n *           number of suffixes in this section.\n *     2. Update the hash with the current character\n *\n * This does not account for wildcards and exceptions, but explains the general\n * idea of the matching algorithm. Have a look at the source bellow for more\n * details.\n *\n * Some nice properties of this algorithm:\n * 1. Pretty straight-forward implementation\n * 2. Matching is always going forward in the array\n * 3. Sections can be skipped by just incrementing the index\n * 4. Hash can be computed on-the-fly from end to start without any string copy",
        "* Compute 32 bits hash of `str` backward.",
        "* Build packed typed array given the raw public list as a string."
    ],
    "functions": [
        "fastHash"
    ],
    "classes": []
}