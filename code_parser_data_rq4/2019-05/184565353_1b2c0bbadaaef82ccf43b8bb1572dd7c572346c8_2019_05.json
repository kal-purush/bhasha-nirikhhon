{
    "identifiers": [
        "tensorflow",
        "tf",
        "cnn",
        "CNN",
        "transformer",
        "Transfomer",
        "EncoderDecoder",
        "hp",
        "hp",
        "CNN",
        "hp",
        "Transfomer",
        "hp",
        "xs",
        "ys",
        "encoder",
        "encode",
        "xs",
        "decoder",
        "decode",
        "ys",
        "memory",
        "training",
        "label_smoothing",
        "tf",
        "one_hot",
        "y",
        "depth",
        "hp",
        "vocab_size",
        "tf",
        "nn",
        "softmax_cross_entropy_with_logits_v2",
        "logits",
        "logits",
        "labels",
        "y_",
        "tf",
        "to_float",
        "tf",
        "not_equal",
        "y",
        "token2idx",
        "tf",
        "reduce_sum",
        "ce",
        "nonpadding",
        "tf",
        "reduce_sum",
        "nonpadding",
        "tf",
        "train",
        "get_or_create_global_step",
        "noam_scheme",
        "hp",
        "lr",
        "global_step",
        "hp",
        "warmup_steps",
        "tf",
        "train",
        "AdamOptimizer",
        "lr",
        "optimizer",
        "minimize",
        "loss",
        "global_step",
        "global_step",
        "tf",
        "summary",
        "scalar",
        "lr",
        "tf",
        "summary",
        "scalar",
        "loss",
        "tf",
        "summary",
        "scalar",
        "global_step",
        "tf",
        "summary",
        "merge_all",
        "loss",
        "train_op",
        "global_step",
        "summaries",
        "xs",
        "ys",
        "ys",
        "tf",
        "ones",
        "tf",
        "shape",
        "xs",
        "tf",
        "int32",
        "token2idx",
        "decoder_inputs",
        "y",
        "y_seqlen",
        "sents2",
        "encoder",
        "encode",
        "xs",
        "logging",
        "info",
        "_",
        "tqdm",
        "hp",
        "maxlen2",
        "decoder",
        "decode",
        "ys",
        "memory",
        "tf",
        "reduce_sum",
        "y_hat",
        "token2idx",
        "tf",
        "concat",
        "decoder_inputs",
        "y_hat",
        "_decoder_inputs",
        "y",
        "y_seqlen",
        "sents2",
        "tf",
        "random_uniform",
        "tf",
        "shape",
        "y_hat",
        "tf",
        "int32",
        "sents1",
        "n",
        "convert_idx_to_token_tensor",
        "y_hat",
        "n",
        "idx2token",
        "sents2",
        "n",
        "tf",
        "summary",
        "text",
        "sent1",
        "tf",
        "summary",
        "text",
        "pred",
        "tf",
        "summary",
        "text",
        "sent2",
        "tf",
        "summary",
        "merge_all",
        "y_hat",
        "summaries"
    ],
    "literals": [
        "\"<pad>\"",
        "'lr'",
        "\"loss\"",
        "\"global_step\"",
        "\"<s>\"",
        "\"Inference graph is being built. Please be patient.\"",
        "\"<pad>\"",
        "\"sent1\"",
        "\"pred\"",
        "\"sent2\""
    ],
    "variables": [
        "hp",
        "encoder",
        "decoder",
        "memory",
        "info",
        "logits",
        "yhat",
        "y",
        "length",
        "y_",
        "ce",
        "nonpadding",
        "loss",
        "global_step",
        "lr",
        "optimizer",
        "train_op",
        "summaries",
        "decoder_inputs",
        "y",
        "y_seqlen",
        "sents2",
        "decoder_inputs",
        "ys",
        "memory",
        "sents1",
        "logits",
        "y_hat",
        "y",
        "sents2",
        "_decoder_inputs",
        "ys",
        "n",
        "sent1",
        "pred",
        "sent2",
        "summaries"
    ],
    "comments": [
        "Load vocab",
        "Load token2idx etc.",
        "train scheme",
        "0: <pad>",
        "monitor a random sample"
    ],
    "docstrings": [
        "'''Predicts autoregressively\n        At inference, input ys is ignored.\n        Returns\n        y_hat: (N, T2)\n        '''"
    ],
    "functions": [
        "train",
        "eval"
    ],
    "classes": []
}