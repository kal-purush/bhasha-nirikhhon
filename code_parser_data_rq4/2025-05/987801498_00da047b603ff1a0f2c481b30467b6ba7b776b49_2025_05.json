{
    "identifiers": [
        "os",
        "fastapi",
        "FastAPI",
        "HTTPException",
        "pydantic",
        "BaseModel",
        "typing",
        "uvicorn",
        "langchain",
        "embeddings",
        "OpenAIEmbeddings",
        "langchain",
        "vectorstores",
        "Chroma",
        "langchain",
        "text_splitter",
        "RecursiveCharacterTextSplitter",
        "langchain",
        "llms",
        "OpenAI",
        "langchain",
        "chains",
        "RetrievalQA",
        "pdfplumber",
        "docx",
        "FastAPI",
        "title",
        "OpenAIEmbeddings",
        "RecursiveCharacterTextSplitter",
        "chunk_size",
        "chunk_overlap",
        "Chroma",
        "collection_name",
        "embedding_function",
        "embedder",
        "persist_directory",
        "PERSIST_DIR",
        "path",
        "docx",
        "Document",
        "path",
        "join",
        "p",
        "text",
        "p",
        "doc",
        "paragraphs",
        "path",
        "pdfplumber",
        "open",
        "path",
        "pdf",
        "page",
        "pdf",
        "pages",
        "page",
        "extract_text",
        "text",
        "full_text",
        "append",
        "text",
        "join",
        "full_text",
        "app",
        "post",
        "f",
        "f",
        "os",
        "listdir",
        "DATA_DIR",
        "f",
        "endswith",
        "files",
        "HTTPException",
        "status_code",
        "detail",
        "fname",
        "files",
        "os",
        "path",
        "join",
        "DATA_DIR",
        "fname",
        "fname",
        "endswith",
        "extract_text_from_pdf",
        "path",
        "extract_text_from_docx",
        "path",
        "text_splitter",
        "split_text",
        "raw",
        "texts",
        "extend",
        "chunks",
        "metadatas",
        "extend",
        "fname",
        "len",
        "chunks",
        "vectordb",
        "add_texts",
        "texts",
        "texts",
        "metadatas",
        "metadatas",
        "vectordb",
        "persist",
        "len",
        "files",
        "len",
        "texts",
        "OpenAI",
        "model_name",
        "temperature",
        "RetrievalQA",
        "from_chain_type",
        "llm",
        "llm",
        "chain_type",
        "retriever",
        "vectordb",
        "as_retriever",
        "BaseModel",
        "app",
        "post",
        "request",
        "QueryRequest",
        "request",
        "query",
        "HTTPException",
        "status_code",
        "detail",
        "qa_chain",
        "run",
        "request",
        "query",
        "results",
        "uvicorn",
        "run",
        "app",
        "host",
        "port",
        "main"
    ],
    "literals": [
        "\"./documents\"",
        "\"./vector_store\"",
        "\"RAG MVP API\"",
        "\"rag_docs\"",
        "\"\\n\"",
        "\"\\n\"",
        "\"/ingest\"",
        "'.pdf'",
        "'.docx'",
        "\"No documents found to ingest.\"",
        "'.pdf'",
        "\"source\"",
        "\"ingested_files\"",
        "\"total_chunks\"",
        "\"gpt-4o-mini\"",
        "\"stuff\"",
        "\"/query\"",
        "\"Query text is required.\"",
        "\"answer\"",
        "\"0.0.0.0\"",
        "\"__main__\""
    ],
    "variables": [
        "DATA_DIR",
        "PERSIST_DIR",
        "app",
        "embedder",
        "text_splitter",
        "vectordb",
        "doc",
        "full_text",
        "text",
        "files",
        "texts",
        "metadatas",
        "path",
        "raw",
        "raw",
        "chunks",
        "llm",
        "qa_chain",
        "query",
        "top_k",
        "results"
    ],
    "comments": [
        "--- Configuration ---",
        "Folder containing .pdf and .docx files",
        "Where Chroma will persist embeddings",
        "Initialize FastAPI",
        "Initialize components",
        "Load or create vectorstore",
        "Function to extract text",
        "Ingestion endpoint",
        "split into chunks",
        "Upsert into vectorstore",
        "Query model",
        "Query endpoint",
        "Run application"
    ],
    "docstrings": [],
    "functions": [
        "extract_text_from_docx",
        "extract_text_from_pdf",
        "ingest_documents",
        "query_docs",
        "main"
    ],
    "classes": [
        "QueryRequest"
    ]
}