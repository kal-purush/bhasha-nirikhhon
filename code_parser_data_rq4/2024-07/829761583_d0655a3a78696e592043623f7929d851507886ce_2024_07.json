{
    "identifiers": [
        "os",
        "streamlit",
        "st",
        "time",
        "langchain",
        "OpenAI",
        "langchain",
        "chains",
        "RetrievalQAWithSourcesChain",
        "langchain",
        "text_splitter",
        "RecursiveCharacterTextSplitter",
        "langchain",
        "document_loaders",
        "UnstructuredURLLoader",
        "langchain",
        "embeddings",
        "OpenAIEmbeddings",
        "langchain",
        "vectorstores",
        "FAISS",
        "dotenv",
        "load_dotenv",
        "load_dotenv",
        "st",
        "title",
        "st",
        "sidebar",
        "title",
        "i",
        "st",
        "sidebar",
        "text_input",
        "i",
        "urls",
        "append",
        "url",
        "st",
        "sidebar",
        "button",
        "st",
        "empty",
        "OpenAI",
        "temperature",
        "max_tokens",
        "process_url_clicked",
        "UnstructuredURLLoader",
        "urls",
        "urls",
        "main_placeholder",
        "text",
        "loader",
        "load",
        "RecursiveCharacterTextSplitter",
        "separators",
        "chunk_size",
        "main_placeholder",
        "text",
        "text_splitter",
        "split_documents",
        "data",
        "OpenAIEmbeddings",
        "FAISS",
        "from_documents",
        "docs",
        "embeddings",
        "main_placeholder",
        "text",
        "time",
        "sleep",
        "vectorstore_openai",
        "save_local",
        "file_path",
        "main_placeholder",
        "text_input",
        "query",
        "os",
        "path",
        "exists",
        "file_path",
        "OpenAIEmbeddings",
        "FAISS",
        "load_local",
        "file_path",
        "embeddings",
        "allow_dangerous_deserialization",
        "RetrievalQAWithSourcesChain",
        "from_llm",
        "llm",
        "llm",
        "retriever",
        "vectorstore",
        "as_retriever",
        "chain",
        "query",
        "return_only_outputs",
        "st",
        "header",
        "st",
        "write",
        "result",
        "result",
        "get",
        "sources",
        "st",
        "subheader",
        "sources",
        "split",
        "source",
        "sources_list",
        "st",
        "write",
        "source"
    ],
    "literals": [
        "\"News Research Tool ðŸ“ˆ\"",
        "\"News Article URLs\"",
        "f\"URL {i+1}\"",
        "\"Process URLs\"",
        "\"faiss_store_openai.index\"",
        "\"Data Loading...Started...âœ…âœ…âœ…\"",
        "'\\n\\n'",
        "'\\n'",
        "'.'",
        "','",
        "\"Text Splitter...Started...âœ…âœ…âœ…\"",
        "\"Embedding Vector Started Building...âœ…âœ…âœ…\"",
        "\"Question: \"",
        "\"question\"",
        "\"Answer\"",
        "\"answer\"",
        "\"sources\"",
        "\"\"",
        "\"Sources:\"",
        "\"\\n\""
    ],
    "variables": [
        "urls",
        "url",
        "process_url_clicked",
        "file_path",
        "main_placeholder",
        "llm",
        "loader",
        "data",
        "text_splitter",
        "docs",
        "embeddings",
        "vectorstore_openai",
        "query",
        "embeddings",
        "vectorstore",
        "chain",
        "result",
        "sources",
        "sources_list"
    ],
    "comments": [
        "take environment variables from .env (especially openai api key)",
        "load data",
        "split data",
        "create embeddings and save it to FAISS index",
        "Save the FAISS index",
        "result will be a dictionary of this format --> {\"answer\": \"\", \"sources\": [] }",
        "Display sources, if available",
        "Split the sources by newline"
    ],
    "docstrings": [],
    "functions": [],
    "classes": []
}