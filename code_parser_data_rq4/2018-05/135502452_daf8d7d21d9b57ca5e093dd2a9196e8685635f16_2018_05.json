{
    "identifiers": [
        "argparse",
        "argparse",
        "ArgumentParser",
        "description",
        "formatter_class",
        "argparse",
        "RawTextHelpFormatter",
        "parser",
        "add_argument",
        "metavar",
        "help",
        "parser",
        "add_argument",
        "metavar",
        "help",
        "parser",
        "add_argument",
        "metavar",
        "help",
        "parser",
        "add_argument",
        "metavar",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "parse_args",
        "args",
        "p",
        "args",
        "o",
        "args",
        "g",
        "args",
        "n",
        "args",
        "c",
        "numbases",
        "timeit",
        "timeit",
        "default_timer",
        "gzip",
        "itertools",
        "islice",
        "mygene",
        "tqdm",
        "tqdm",
        "pandas",
        "pd",
        "urllib",
        "request",
        "time",
        "localtime",
        "strftime",
        "pickle",
        "pkl",
        "requests",
        "ast",
        "math",
        "mygene",
        "MyGeneInfo",
        "CDpkl",
        "urllib",
        "request",
        "urlopen",
        "a",
        "i",
        "j",
        "decode",
        "j",
        "a",
        "readlines",
        "i",
        "header",
        "take",
        "first",
        "dflines",
        "append",
        "i",
        "i",
        "i",
        "split",
        "goodsplit",
        "dflines",
        "append",
        "goodsplit",
        "i",
        "i",
        "dflines",
        "i",
        "i",
        "dflines",
        "pkl",
        "dump",
        "CDdict",
        "open",
        "pkl",
        "load",
        "open",
        "i",
        "strip",
        "i",
        "open",
        "readlines",
        "i",
        "i",
        "inputmarks",
        "len",
        "i",
        "split",
        "i",
        "split",
        "convmarks",
        "append",
        "CDdict",
        "i",
        "KeyError",
        "convmarks",
        "append",
        "i",
        "i",
        "len",
        "inputmarks",
        "inputmarks",
        "i",
        "convmarks",
        "i",
        "mg",
        "querymany",
        "convmarks",
        "scopes",
        "fields",
        "species",
        "returnall",
        "genes",
        "genes",
        "i",
        "len",
        "genes",
        "genes",
        "i",
        "i",
        "genelist",
        "append",
        "genes",
        "i",
        "i",
        "genes",
        "i",
        "i",
        "unilist",
        "append",
        "genes",
        "i",
        "i",
        "genelist",
        "unilist",
        "v",
        "k",
        "k",
        "v",
        "marksdict",
        "items",
        "i",
        "dictout",
        "flatten",
        "i",
        "marksdict",
        "invmarksdict",
        "i",
        "keys",
        "marksdict",
        "invmarksdict",
        "i",
        "ensglist",
        "marksdict",
        "invmarksdict",
        "i",
        "ensglist",
        "marksdict",
        "invmarksdict",
        "i",
        "keys",
        "marksdict",
        "invmarksdict",
        "i",
        "unilist",
        "marksdict",
        "invmarksdict",
        "i",
        "unilist",
        "i",
        "marksdict",
        "keys",
        "j",
        "marksdict",
        "i",
        "k",
        "marksdict",
        "i",
        "dflist",
        "append",
        "i",
        "j",
        "k",
        "pd",
        "DataFrame",
        "dflist",
        "columns",
        "conversiondf",
        "values",
        "i",
        "tqdm",
        "ensgs",
        "i",
        "requests",
        "get",
        "server",
        "ext",
        "headers",
        "r",
        "ok",
        "r",
        "raise_for_status",
        "sys",
        "exit",
        "r",
        "json",
        "ast",
        "literal_eval",
        "repr",
        "decoded",
        "j",
        "jsondicts",
        "j",
        "transcripts",
        "i",
        "j",
        "tsl",
        "n",
        "split",
        "split",
        "i",
        "math",
        "ceil",
        "n",
        "split",
        "startnext",
        "stoplast",
        "stoplast",
        "stoplast",
        "split",
        "stoplast",
        "n",
        "n",
        "outputname",
        "strftime",
        "localtime",
        "outputname",
        "outputname",
        "gzip",
        "open",
        "pathtogencode",
        "fastas",
        "open",
        "outputname",
        "file",
        "islice",
        "fastas",
        "line",
        "lines",
        "line",
        "seq",
        "numbases",
        "numbases",
        "seq",
        "numbases",
        "numbases",
        "seq",
        "numbases",
        "ValueError",
        "i",
        "evensplit",
        "len",
        "seq",
        "file",
        "write",
        "seq",
        "i",
        "i",
        "line",
        "split",
        "splitline",
        "split",
        "splitline",
        "split",
        "ENSG",
        "transcripts",
        "keys",
        "ENST",
        "transcripts",
        "ENSG",
        "keys",
        "counttxnscripts",
        "conversiondf",
        "index",
        "conversiondf",
        "ENSG",
        "tolist",
        "join",
        "conversiondf",
        "iloc",
        "index",
        "ENST",
        "transcripts",
        "ENSG",
        "ENST",
        "file",
        "write",
        "newhead",
        "take",
        "seq",
        "line",
        "strip",
        "timeit",
        "default_timer",
        "toc",
        "tic"
    ],
    "literals": [
        "\"markerlist.txt\"",
        "\"gencode.v28.pc_transcripts.fa.gz\"",
        "'all'",
        "'p'",
        "'proteins'",
        "'path to .txt w/ protein names each on new line'",
        "'-o'",
        "'outputname'",
        "'output filename (default will use timestamp.fa)'",
        "'-g'",
        "'pathtogencode'",
        "'gencode.v28.pc_transcripts.fa.gz'",
        "'path to Gencode protein-coding transcripts .gz'",
        "'-n'",
        "'numbases'",
        "'number of bases (e.g. 200: first 200; -100: last 100'",
        "'--m'",
        "'store_true'",
        "'option to use stored ./CDdict.pkl'",
        "'--c'",
        "'store_true'",
        "'option to use stored ./CDdict.pkl'",
        "'all'",
        "'Beginning program.'",
        "'Querying UniProt for CD conversion table.'",
        "'CD      '",
        "'Swiss-Prot           '",
        "'MIM     '",
        "'Gene              '",
        "'Name(s) for the protein\\n'",
        "'https://www.uniprot.org/docs/cdlist.txt'",
        "\"utf-8\"",
        "'CD Number'",
        "'Swiss-Prot Entry Name'",
        "'UniProt ID'",
        "'\\n'",
        "'CD'",
        "'N.A.'",
        "'CDdict.pkl'",
        "'wb'",
        "'CDdict.pkl'",
        "'rb'",
        "'markerlist.txt'",
        "'r'",
        "'#'",
        "' '",
        "' '",
        "'Converted'",
        "'Querying MyGene.'",
        "'uniprot'",
        "'symbol'",
        "'alias'",
        "'ensembl.gene'",
        "'uniprot'",
        "'human'",
        "'ENSG'",
        "\"'Swiss-Prot': '\"",
        "'Converted'",
        "'out'",
        "'ENSGs'",
        "'query'",
        "'query'",
        "'ENSGs'",
        "'query'",
        "'ENSGs'",
        "'Uniprot'",
        "'query'",
        "'query'",
        "'Uniprot'",
        "'query'",
        "'Uniprot'",
        "'Uniprot'",
        "'ENSGs'",
        "'Input'",
        "'UniProt'",
        "'ENSG'",
        "'Querying Ensembl API.'",
        "'ENSG'",
        "\"http://rest.ensembl.org\"",
        "\"/overlap/id/%s?feature=transcript\"",
        "\"Content-Type\"",
        "\"application/json\"",
        "'transcript_support_level'",
        "'transcript_id'",
        "'Writing FASTA file.'",
        "''",
        "'%s_transcripts.fa'",
        "\"%Y%m%d%H%M\"",
        "'.fa'",
        "'.fa'",
        "'rt'",
        "'w'",
        "'>'",
        "''",
        "'all'",
        "'\\n'",
        "''",
        "'|'",
        "'.'",
        "'.'",
        "'ENSG'",
        "'>'",
        "'|'",
        "'|%s|'",
        "'TSL:%s'",
        "'\\n'",
        "'\\n'",
        "\"Done. Total program time was %d seconds.\""
    ],
    "variables": [
        "proteins",
        "pathtogencode",
        "numbases",
        "outputname",
        "CDpkl",
        "parser",
        "args",
        "proteins",
        "outputname",
        "pathtogencode",
        "numbases",
        "CDpkl",
        "numbases",
        "tic",
        "mg",
        "header",
        "dflines",
        "take",
        "take",
        "first",
        "first",
        "goodsplit",
        "CDdict",
        "CDdict",
        "inputmarks",
        "marksdict",
        "convmarks",
        "i",
        "marksdict",
        "dictout",
        "genes",
        "genelist",
        "unilist",
        "invmarksdict",
        "ensglist",
        "unilist",
        "dflist",
        "conversiondf",
        "take",
        "ensgs",
        "server",
        "transcripts",
        "transcripts",
        "i",
        "ext",
        "r",
        "decoded",
        "jsondicts",
        "tsl",
        "startnext",
        "stoplast",
        "startnext",
        "stoplast",
        "seq",
        "numbases",
        "outputname",
        "lines",
        "counttxnscripts",
        "seq",
        "seq",
        "seq",
        "take",
        "splitline",
        "ENSG",
        "ENST",
        "index",
        "newhead",
        "take",
        "toc"
    ],
    "comments": [
        "coding: utf-8",
        "# Protein to Transcripts",
        "Quick script for gettin human coding transcripts from protein names,",
        "some of which may be Cluster of Differentiation (CD) names. If CD",
        "names are present, uses Uniprot-published CD->Uniprot",
        "conversion table (found at https://www.uniprot.org/docs/cdlist.txt).",
        "",
        "If script has been run once already, can use generated --c flag",
        "to use stored pickled dictionary of conversions.",
        "",
        "After converting all (if any) from CD names:",
        "1. Inputs Uniprot IDs or gene symbol/alias to mygene package",
        "(http://mygene.info/) to get associated ENSG IDs from Ensemble.",
        "2. Sses Ensembl API (http://rest.ensembl.org) to get all transcripts",
        "as ENST IDs associated with that ENSG ID.",
        "3. Then cross-checks for published list of protein-coding human",
        "transcripts from Gencode",
        "(https://www.gencodegenes.org/releases/28lift37.html).",
        "",
        "Script can be run both in Jupyter Notebook and on command line. Use",
        "",
        "`jupyter nbconvert --to=python protoscripts.ipynb`",
        "",
        "to convert this to a CLI script, and **update the next cell.**",
        "In[2]:",
        "If running on jupyter, **do not** run this next cell.",
        "In[3]:",
        "Setup argument parser ###",
        "Parse arguments",
        "Import necessary packages.",
        "In[4]:",
        "this package gets transcipts IDs from UniProt IDs",
        "the function used to query",
        "### Convert from Cluster of Differentiation (CD) to UniProt",
        "Uniprot IDs are easier to work with and have corresponding Ensembl transcript IDs.",
        "In[5]:",
        "this header is where the table starts.",
        "make a list of lines for DataFrame conversion",
        "need to decode the website using utf-8",
        "start taking the lines",
        "the first line to take",
        "this will be the first line",
        "if the line starts with CD, take it",
        "only take the first three columns, all  other  columns",
        "contain spaces,  hard to parse",
        "only if the uniprot ID exists",
        "Make a dictionary with the conversions",
        "dump the dictionary for future use",
        "###  Input gene names",
        "Gene names are fed as a text file with a name on each line. Names in the text files can be a gene symbol/alias/CD string, with no spaces, or, if it goes by two names, with a single space between the two names. The text file can also have comments with lines starting with '#' that will be ignored.",
        "",
        "For example:",
        "",
        "`#These proteins are for my project`",
        "",
        "`#Gene protein names start here:`",
        "",
        "`CD137`",
        "",
        "`CD69`",
        "",
        "`ICOS (CD278)`",
        "",
        "`OX40 (CD134)`",
        "",
        "`HAVCR2`",
        "",
        "For now querying will use only the first name. Future plans to make it use the second if no results are returned, or ask for manual input of a UniProt ID.",
        "In[6]:",
        "get markers from somewhere",
        "add to a new list",
        "for  each  marker value",
        "separated by a space",
        "###  Query the MyGene package",
        "",
        "This next call queries the mygene package. If duplicate hits are found, all of them will be returned. If no hits are found, that transcript will not appear in the generated FASTA. Note that many duplicates might be returned for  gene symbols/aliases inputs, usually because the gene summary (from Ensembl) inlcudes the name (e.g. its an associated/related protein) or they share an alias. The resulting FASTA files should be manually curated by Uniprot ID to ensure only the correct transcript is present.",
        "In[7]:",
        "###  Flatten MyGene output",
        "The mygene output finds all possible transcript IDs matching the UniProt ID. This is a bit cumbersome because output is either a list, dict, or list of dicts, with some of those even containing lists. It's good though because it generalizes the single UniProt ID and corresponding gene to all possible transcripts generated from that locus. Crossed with the gencode human coding transcripts, only those that actually code proteins will be kept.",
        "",
        "Flatten the ouput, then put everything into a pandas dataframe.",
        "In[8]:",
        "function for flattening",
        "input(genes[i:i+15])",
        "the output",
        "get list of all the IDs",
        "### Query Ensembl API",
        "The ensembl API can be querried for transcript IDs and transcript support levels (TSL). TSLs may be important for a single gene coding for a single protein that has multiple documented coding transcripts. Those transcripts that have less support (i.e. closer to TSL=5 (TSL=1 is highly supported)) might want to be dropped.",
        "In[1]:",
        "catch those that don't have TSL",
        "### Write a new FASTA File",
        "Comb through the protein-coding human transcripts and catch all transcripts that match those from the provided proteins.",
        "In[2]:",
        "quick generator for splitting sequence across 80-char lines",
        "FASTA format recommends no more than 80 chars per line",
        "get ENSG",
        "get ENSG",
        "if counttxnscripts > 170:",
        "input(line)",
        "input(newhead)",
        "### Additional Code",
        "Code for future iterations of this program.",
        "In[11]:",
        "def manualinput(notfoundmarks):",
        "length = len(notfoundmarks)",
        "print(\"There are %d marker(s) not found. You can choose to ignore these or input UniProt IDs for some or\" + \\",
        "\" all of them. To skip all, type \"n\". To input UniProt IDs, type 'y'.\" % length)",
        "answer = input(\"Manually input UniProt IDs? (y/n) \")",
        "if answer == 'y':",
        "print(\"Either type in UniProt ID or '-' to skip.\")",
        "uniprotlist = list()",
        "for i in notfoundmarks:",
        "uniprotlist.append(input('Uniprot ID for %s' % i))",
        "return uniprotlist",
        "else:",
        "return ['-']*length",
        "In[12]:",
        "if len(dictout['missing']) != 0:",
        "print('Trying other names.')",
        "for i in dictout['missing']:",
        "for j in inputmarks:",
        "if i in j and len(i.split(' ')) == 2:",
        "str2 = splitted[1][1:len(splitted[1])-1]",
        "singledictout = mg.query(str2,scopes=['uniprot','symbol','alias'],",
        "fields=['ensembl.gene','uniprot'],",
        "species='human', returnall=True)",
        "if len(singledictout['missing']) == 1:",
        "stillnoluck.append(i)",
        "else:",
        "dictout['out'].append(singledictout)",
        "else:",
        "stillnoluck.append(i)",
        "manualuni = manualinput(stillnoluck)",
        "for k in manualuni:",
        "if i != '-':",
        "singledictout = mg.query(k,scopes=['uniprot','symbol','alias'],",
        "fields=['ensembl.gene','uniprot'],",
        "species='human', returnall=True)",
        "if len(singledictout['missing']) == 1:",
        "print('Provided Uniprot ID %s not found. Skipping.' % k)",
        "else:",
        "dictout['out'].append(singledictout)",
        "else:",
        "dictout['out'].append({'query': i'skipped': True})",
        "In[13]:",
        "while len(goodscripts) == 0:",
        "TSL += 1",
        "goodscripts = [i['transcript_id'] for i in jsondicts if int(i['transcript_support_level']) <= TSL]"
    ],
    "docstrings": [
        "\"\"\"\nQuick script for gettin human coding transcripts from protein names,\nsome of which may be Cluster of Differentiation (CD) names. If CD\nnames are present, uses Uniprot-published CD->Uniprot \nconversion table (found at https://www.uniprot.org/docs/cdlist.txt).\n\nIf script has been run once already, can use generated --c flag\nto use stored pickled dictionary of conversions.\n\nAfter converting all (if any) from CD names:\n1. Inputs Uniprot IDs or gene symbol/alias to mygene package \n(http://mygene.info/) to get associated ENSG IDs from Ensemble.\n2. Sses Ensembl API (http://rest.ensembl.org) to get all transcripts\nas ENST IDs associated with that ENSG ID. \n3. Then cross-checks for published list of protein-coding human \ntranscripts from Gencode \n(https://www.gencodegenes.org/releases/28lift37.html).\n\"\"\"",
        "'''\n    Uniprot has a website to convert CDs into Uniprot IDs.\n    I assume it is updated frequently; latest release April 2018.\n    The URL is a text file but has poor delimitters, so parsing is\n    a bit challenging.\n    '''"
    ],
    "functions": [
        "flatten",
        "evensplit"
    ],
    "classes": []
}