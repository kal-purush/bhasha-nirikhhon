{
    "identifiers": [
        "pandas",
        "pd",
        "math",
        "glob",
        "pickle",
        "MeCab",
        "os",
        "re",
        "urllib",
        "request",
        "unicodedata",
        "neologdn",
        "numpy",
        "np",
        "tweepy",
        "demoji",
        "sklearn",
        "model_selection",
        "GridSearchCV",
        "sklearn",
        "decomposition",
        "LatentDirichletAllocation",
        "LDA",
        "sklearn",
        "feature_extraction",
        "text",
        "CountVectorizer",
        "TfidfTransformer",
        "matplotlib",
        "pyplot",
        "plt",
        "wordcloud",
        "WordCloud",
        "MeCab",
        "Tagger",
        "tweepy",
        "OAuthHandler",
        "CONSUMER_KEY",
        "CONSUMER_SECRET",
        "auth",
        "set_access_token",
        "ACCESS_TOKEN",
        "ACCESS_SECRET",
        "tweepy",
        "API",
        "auth",
        "path",
        "os",
        "path",
        "exists",
        "path",
        "urllib",
        "request",
        "urlretrieve",
        "url",
        "path",
        "pd",
        "read_csv",
        "path",
        "header",
        "tolist",
        "series",
        "load_jp_stopwords",
        "text",
        "neologdn",
        "normalize",
        "text",
        "unicodedata",
        "normalize",
        "text_normalized",
        "re",
        "sub",
        "text_normalized",
        "re",
        "sub",
        "text_normalized",
        "re",
        "sub",
        "text_normalized",
        "demoji",
        "replace",
        "text_normalized",
        "repl",
        "avoid_pattern",
        "avoid_patterns",
        "re",
        "search",
        "avoid_pattern",
        "text_normalized",
        "re",
        "sub",
        "avoid_pattern",
        "text_normalized",
        "tagger",
        "parseToNode",
        "text_normalized",
        "node",
        "node",
        "feature",
        "split",
        "features",
        "surface",
        "len",
        "surface",
        "surface",
        "stop_words",
        "node",
        "next",
        "features",
        "features",
        "features",
        "features",
        "proper_noun_flag",
        "tokens",
        "append",
        "surface",
        "noun_flag",
        "pronoun_flag",
        "tokens",
        "append",
        "surface",
        "node",
        "next",
        "join",
        "tokens",
        "series",
        "tokenizer_func",
        "series",
        "x",
        "x",
        "lower",
        "series",
        "lda1",
        "lda2",
        "np",
        "dot",
        "lda1",
        "lda2",
        "np",
        "linalg",
        "norm",
        "lda1",
        "np",
        "linalg",
        "norm",
        "lda2",
        "model",
        "count_vectorizer",
        "n_top_words",
        "vectorizer",
        "get_feature_names_out",
        "topic_idx",
        "topic",
        "model",
        "components_",
        "join",
        "words",
        "i",
        "i",
        "topic",
        "argsort",
        "n_top_words",
        "WordCloud",
        "font_path",
        "font_path",
        "background_color",
        "max_words",
        "contour_width",
        "contour_color",
        "wordcloud",
        "generate",
        "long_string",
        "wordcloud",
        "to_file",
        "topic_idx",
        "ndarray",
        "accountname",
        "n",
        "n",
        "plt",
        "figure",
        "plt",
        "pie",
        "ndarray",
        "labels",
        "label",
        "counterclock",
        "startangle",
        "autopct",
        "fig",
        "savefig",
        "accountname",
        "accountname",
        "tweet",
        "tweepy",
        "Cursor",
        "api",
        "user_timeline",
        "screen_name",
        "accountname",
        "exclude_replies",
        "items",
        "tweet",
        "text",
        "tweet",
        "text",
        "tweet_texts",
        "tweet",
        "text",
        "open",
        "f",
        "f",
        "write",
        "tweet",
        "text",
        "preprocessed_jp",
        "tweet_texts",
        "i",
        "tweet_ss",
        "i",
        "tweets",
        "append",
        "stringdata",
        "vectorizer",
        "transform",
        "tweets",
        "loaded_model",
        "transform",
        "X",
        "i",
        "lda",
        "lda_model",
        "i",
        "i",
        "i",
        "x",
        "lda",
        "x",
        "max",
        "lda",
        "tweets",
        "i",
        "lda",
        "topicid",
        "np",
        "array",
        "lda",
        "roundgraph_save",
        "average_ndarray",
        "accountname",
        "accountname",
        "pickle",
        "dump",
        "average_ndarray",
        "open",
        "ldaname",
        "average_ndarray",
        "pickle",
        "load",
        "open",
        "ldaname",
        "open",
        "Tfidfname",
        "f",
        "pickle",
        "load",
        "f",
        "print_topics",
        "loaded_model",
        "vectorizer",
        "number_words",
        "analyze",
        "accountname",
        "analyze",
        "accountname",
        "accountname",
        "accountname",
        "format",
        "similality",
        "lda1",
        "lda2"
    ],
    "literals": [
        "\"/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\"",
        "\"eip6ryVGm4LTs6PEaY0mLpiXg\"",
        "\"d6TEZ0nWWyapBKtECyNAbo5NLGp4CS0vQJrrHuXV5J56EAMJp3\"",
        "\"1109729962276196354-ond0wSijFgiuMVtxCnZRcyW0prQsLo\"",
        "\"LMUobsWM23ifx25bweXVD5gN82Ylw8jyOGsMdt9FB8IoJ\"",
        "\"Japanese-revised.txt\"",
        "'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'",
        "'File already exists.'",
        "'Downloading...'",
        "\"Japanese-revised.txt\"",
        "'【.{1,10}】'",
        "'NFKC'",
        "r'(\\d)([,.])(\\d+)'",
        "r'\\1\\3'",
        "r'\\d+'",
        "'0'",
        "r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+'",
        "''",
        "''",
        "''",
        "','",
        "'*'",
        "'名詞'",
        "'名詞'",
        "'固有名詞'",
        "'代名詞'",
        "\" \"",
        "','",
        "'msgothic.ttc'",
        "\"white\"",
        "'steelblue'",
        "f\"pictures/wordcloud_{topic_idx}.png\"",
        "\"%.1f%%\"",
        "\"pictures/\"",
        "\"_lda_round.png\"",
        "''",
        "'RT'",
        "'@'",
        "'tweet_data_pre.txt'",
        "'a'",
        "''",
        "\"### \"",
        "\" >>> topic\"",
        "\"\"",
        "'models/'",
        "'_distribution.sav'",
        "'wb'",
        "\"models/lda.sav\"",
        "'rb'",
        "'models/Tfidf.sav'",
        "'rb'",
        "'fukkei_koho'",
        "'goroukun_spp'",
        "\"#\"",
        "'@'",
        "'さんと@'",
        "'さんの類似度は{}%です！！'",
        "\"#\"",
        "'\\n'"
    ],
    "variables": [
        "tagger",
        "CONSUMER_KEY",
        "CONSUMER_SECRET",
        "ACCESS_TOKEN",
        "ACCESS_SECRET",
        "auth",
        "api",
        "tweet_data",
        "stopword_url",
        "stop_words",
        "avoid_patterns",
        "tokens",
        "text_normalized",
        "text_normalized",
        "text_normalized",
        "text_normalized",
        "text_normalized",
        "text_normalized",
        "text_normalized",
        "node",
        "features",
        "surface",
        "node",
        "noun_flag",
        "proper_noun_flag",
        "pronoun_flag",
        "node",
        "series",
        "series",
        "words",
        "long_string",
        "font_path",
        "wordcloud",
        "label",
        "fig",
        "tweet_texts",
        "tweet_ss",
        "tweets",
        "stringdata",
        "stringdata",
        "X",
        "lda_model",
        "topicid",
        "average_ndarray",
        "ldaname",
        "ldaname",
        "loaded_model",
        "Tfidfname",
        "vectorizer",
        "vectorizer",
        "number_words",
        "accountname",
        "lda1",
        "lda2"
    ],
    "comments": [
        "モデルを保存",
        "形態素解析",
        "正規表現",
        "正規化用",
        "正規化用",
        "Twitter API",
        "絵文字",
        "LDA Modeling",
        "BoW / Tfidf",
        "Twitter API Key",
        "Tweepyを適用",
        "読み込んだツイートを格納",
        "---------------------------------------------------------------",
        "ストップワードのインストール",
        "形態素解析の処理部分",
        "ストップワードの読み込み",
        "正規化",
        "数字と桁区切り文字を全て0に変換",
        "URLを削除",
        "絵文字を削除",
        "不必要なパターンを削除",
        "location_flag= (features[2] == '地域')",
        "---------------Normalization-----------#",
        "2人のユーザーの興味のcos類似度を計算",
        "-----------------------------------------------------------------",
        "WordCloudを表示",
        "円グラフの表示",
        "特定のユーザーのジャンル確率を推定",
        "RTとリプライは除外",
        "前処理",
        "各トピックごとの分布割合を出力",
        "numpyの配列に変換",
        "グラフを表示",
        "確率分布の保存",
        "LDAのロード",
        "tfidfのロード",
        "WordCloudの表示",
        "ジャンル確率の推定と円グラフの保存",
        "類似度を出力"
    ],
    "docstrings": [],
    "functions": [
        "load_jp_stopwords",
        "preprocess_jp",
        "tokenizer_func",
        "similality",
        "print_topics",
        "roundgraph_save",
        "analyze"
    ],
    "classes": []
}