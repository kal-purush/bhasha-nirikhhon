{
    "identifiers": [
        "org",
        "firstinspires",
        "ftc",
        "teamcode",
        "opmode",
        "teleop",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "AngleUnit",
        "DEGREES",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "AxesOrder",
        "XYZ",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "AxesOrder",
        "XZY",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "AxesReference",
        "EXTRINSIC",
        "com",
        "qualcomm",
        "robotcore",
        "eventloop",
        "opmode",
        "Disabled",
        "com",
        "qualcomm",
        "robotcore",
        "eventloop",
        "opmode",
        "LinearOpMode",
        "com",
        "qualcomm",
        "robotcore",
        "eventloop",
        "opmode",
        "TeleOp",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "ClassFactory",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "hardware",
        "camera",
        "WebcamName",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "matrices",
        "OpenGLMatrix",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "matrices",
        "VectorF",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "Orientation",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "VuforiaLocalizer",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "VuforiaTrackable",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "VuforiaTrackableDefaultListener",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "navigation",
        "VuforiaTrackables",
        "org",
        "firstinspires",
        "ftc",
        "teamcode",
        "BuildConfig",
        "org",
        "firstinspires",
        "ftc",
        "teamcode",
        "api",
        "config",
        "Naming",
        "java",
        "util",
        "java",
        "util",
        "TeleOp",
        "name",
        "group",
        "Naming",
        "OPMODE_GROUP_DEMO",
        "VUFORIA_KEY",
        "BuildConfig",
        "VUFORIA_KEY",
        "mmPerInch",
        "mmTargetHeight",
        "mmPerInch",
        "halfField",
        "mmPerInch",
        "halfTile",
        "mmPerInch",
        "oneAndHalfTile",
        "mmPerInch",
        "lastLocation",
        "vuforia",
        "targets",
        "webcamName",
        "targetVisible",
        "Override",
        "webcamName",
        "hardwareMap",
        "get",
        "cameraMonitorViewId",
        "hardwareMap",
        "appContext",
        "getResources",
        "getIdentifier",
        "hardwareMap",
        "appContext",
        "getPackageName",
        "parameters",
        "cameraMonitorViewId",
        "parameters",
        "vuforiaLicenseKey",
        "VUFORIA_KEY",
        "parameters",
        "cameraName",
        "webcamName",
        "parameters",
        "useExtendedTracking",
        "vuforia",
        "ClassFactory",
        "getInstance",
        "createVuforia",
        "parameters",
        "targets",
        "vuforia",
        "loadTrackablesFromAsset",
        "allTrackables",
        "allTrackables",
        "addAll",
        "targets",
        "identifyTarget",
        "halfField",
        "oneAndHalfTile",
        "mmTargetHeight",
        "identifyTarget",
        "halfTile",
        "halfField",
        "mmTargetHeight",
        "identifyTarget",
        "halfField",
        "oneAndHalfTile",
        "mmTargetHeight",
        "identifyTarget",
        "halfTile",
        "halfField",
        "mmTargetHeight",
        "CAMERA_FORWARD_DISPLACEMENT",
        "mmPerInch",
        "CAMERA_VERTICAL_DISPLACEMENT",
        "mmPerInch",
        "CAMERA_LEFT_DISPLACEMENT",
        "mmPerInch",
        "cameraLocationOnRobot",
        "OpenGLMatrix",
        "translation",
        "CAMERA_FORWARD_DISPLACEMENT",
        "CAMERA_LEFT_DISPLACEMENT",
        "CAMERA_VERTICAL_DISPLACEMENT",
        "multiplied",
        "Orientation",
        "getRotationMatrix",
        "EXTRINSIC",
        "XZY",
        "DEGREES",
        "trackable",
        "allTrackables",
        "trackable",
        "getListener",
        "setCameraLocationOnRobot",
        "parameters",
        "cameraName",
        "cameraLocationOnRobot",
        "targets",
        "activate",
        "isStopRequested",
        "targetVisible",
        "trackable",
        "allTrackables",
        "trackable",
        "getListener",
        "isVisible",
        "telemetry",
        "addData",
        "trackable",
        "getName",
        "targetVisible",
        "robotLocationTransform",
        "trackable",
        "getListener",
        "getUpdatedRobotLocation",
        "robotLocationTransform",
        "lastLocation",
        "robotLocationTransform",
        "targetVisible",
        "translation",
        "lastLocation",
        "getTranslation",
        "telemetry",
        "addData",
        "translation",
        "get",
        "mmPerInch",
        "translation",
        "get",
        "mmPerInch",
        "translation",
        "get",
        "mmPerInch",
        "rotation",
        "Orientation",
        "getOrientation",
        "lastLocation",
        "EXTRINSIC",
        "XYZ",
        "DEGREES",
        "telemetry",
        "addData",
        "rotation",
        "firstAngle",
        "rotation",
        "secondAngle",
        "rotation",
        "thirdAngle",
        "telemetry",
        "addData",
        "telemetry",
        "update",
        "targets",
        "deactivate",
        "targetIndex",
        "targetName",
        "dx",
        "dy",
        "dz",
        "rx",
        "ry",
        "rz",
        "aTarget",
        "targets",
        "get",
        "targetIndex",
        "aTarget",
        "setName",
        "targetName",
        "aTarget",
        "setLocation",
        "OpenGLMatrix",
        "translation",
        "dx",
        "dy",
        "dz",
        "multiplied",
        "Orientation",
        "getRotationMatrix",
        "EXTRINSIC",
        "XYZ",
        "DEGREES",
        "rx",
        "ry",
        "rz"
    ],
    "literals": [
        "\"Vuforia Field Nav Webcam\"",
        "\"Webcam 1\"",
        "\"cameraMonitorViewId\"",
        "\"id\"",
        "\"FreightFrenzy\"",
        "\"Blue Storage\"",
        "\"Blue Alliance Wall\"",
        "\"Red Storage\"",
        "\"Red Alliance Wall\"",
        "\"Visible Target\"",
        "\"Pos (inches)\"",
        "\"{X, Y, Z} = %.1f, %.1f, %.1f\"",
        "\"Rot (deg)\"",
        "\"{Roll, Pitch, Heading} = %.0f, %.0f, %.0f\"",
        "\"Visible Target\"",
        "\"none\""
    ],
    "variables": [],
    "comments": [
        "Since ImageTarget trackables use mm to specifiy their dimensions, we must use mm for all the physical dimension.",
        "We will define some constants and conversions here",
        "the height of the center of the target image above the floor",
        "Class Members",
        "Connect to the camera we are to use.  This name must match what is set up in Robot Configuration",
        "VuforiaLocalizer.Parameters parameters = new VuforiaLocalizer.Parameters();",
        "We also indicate which camera we wish to use.",
        "Turn off Extended tracking.  Set this true if you want Vuforia to track beyond the target.",
        "Instantiate the Vuforia engine",
        "Load the data sets for the trackable objects. These particular data",
        "sets are stored in the 'assets' part of our application.",
        "For convenience, gather together all the trackable objects in one easily-iterable collection */",
        "Name and locate each trackable object",
        "eg: Enter the forward distance from the center of the robot to the camera lens",
        "eg: Camera is 6 Inches above ground",
        "eg: Enter the left distance from the center of the robot to the camera lens",
        "waitForStart();",
        "check all the trackable targets to see which one (if any) is visible.",
        "getUpdatedRobotLocation() will return null if no new information is available since",
        "the last time that call was made, or if the trackable is not currently visible.",
        "Provide feedback as to where the robot is located (if we know).",
        "express position (translation) of robot in inches.",
        "express the rotation of the robot in degrees.",
        "Disable Tracking when we are done;"
    ],
    "docstrings": [
        "Copyright (c) 2019 FIRST. All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without modification,\n * are permitted (subject to the limitations in the disclaimer below) provided that\n * the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice, this list\n * of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright notice, this\n * list of conditions and the following disclaimer in the documentation and/or\n * other materials provided with the distribution.\n *\n * Neither the name of FIRST nor the names of its contributors may be used to endorse or\n * promote products derived from this software without specific prior written permission.\n *\n * NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED BY THIS\n * LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\n * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "* This OpMode illustrates using the Vuforia localizer to determine positioning and orientation of\n * robot on the FTC field using a WEBCAM.  The code is structured as a LinearOpMode\n *\n * NOTE: If you are running on a Phone with a built-in camera, use the ConceptVuforiaFieldNavigation example instead of this one.\n * NOTE: It is possible to switch between multiple WebCams (eg: one for the left side and one for the right).\n *       For a related example of how to do this, see ConceptTensorFlowObjectDetectionSwitchableCameras\n *\n * When images are located, Vuforia is able to determine the position and orientation of the\n * image relative to the camera.  This sample code then combines that information with a\n * knowledge of where the target images are on the field, to determine the location of the camera.\n *\n * Finally, the location of the camera on the robot is used to determine the\n * robot's location and orientation on the field.\n *\n * To learn more about the FTC field coordinate model, see FTC_FieldCoordinateSystemDefinition.pdf in this folder\n *\n * Use Android Studio to Copy this Class, and Paste it into your team's code folder with a new name.\n * Remove or comment out the @Disabled line to add this opmode to the Driver Station OpMode list.\n *\n * IMPORTANT: In order to use this OpMode, you need to obtain your own Vuforia license key as\n * is explained below.",
        "* IMPORTANT: You need to obtain your own license key to use Vuforia. The string below with which\n     * 'parameters.vuforiaLicenseKey' is initialized is for illustration only, and will not function.\n     * A Vuforia 'Development' license key, can be obtained free of charge from the Vuforia developer\n     * web site at https://developer.vuforia.com/license-manager.\n     *\n     * Vuforia license keys are always 380 characters long, and look as if they contain mostly\n     * random data. As an example, here is a example of a fragment of a valid key:\n     *      ... yIgIzTqZ4mWjk9wd3cZO9T1axEqzuhxoGlfOOI2dRzKS4T0hQ8kT ...\n     * Once you've obtained a license key, copy the string from the Vuforia web site\n     * and paste it in to your code on the next line, between the double quotes.",
        "* Configure Vuforia by creating a Parameter object, and passing it to the Vuforia engine.\n         * We can pass Vuforia the handle to a camera preview resource (on the RC screen);\n         * If no camera-preview is desired, use the parameter-less constructor instead (commented out below).\n         * Note: A preview window is required if you want to view the camera stream on the Driver Station Phone.",
        "* In order for localization to work, we need to tell the system where each target is on the field, and\n         * where the phone resides on the robot.  These specifications are in the form of <em>transformation matrices.</em>\n         * Transformation matrices are a central, important concept in the math here involved in localization.\n         * See <a href=\"https://en.wikipedia.org/wiki/Transformation_matrix\">Transformation Matrix</a>\n         * for detailed information. Commonly, you'll encounter transformation matrices as instances\n         * of the {@link OpenGLMatrix} class.\n         *\n         * If you are standing in the Red Alliance Station looking towards the center of the field,\n         *     - The X axis runs from your left to the right. (positive from the center to the right)\n         *     - The Y axis runs from the Red Alliance Station towards the other side of the field\n         *       where the Blue Alliance Station is. (Positive is from the center, towards the BlueAlliance station)\n         *     - The Z axis runs from the floor, upwards towards the ceiling.  (Positive is above the floor)\n         *\n         * Before being transformed, each target image is conceptually located at the origin of the field's\n         *  coordinate system (the center of the field), facing up.",
        "* Create a transformation matrix describing where the camera is on the robot.\n         *\n         * Info:  The coordinate frame for the robot looks the same as the field.\n         * The robot's \"forward\" direction is facing out along X axis, with the LEFT side facing out along the Y axis.\n         * Z is UP on the robot.  This equates to a bearing angle of Zero degrees.\n         *\n         * For a WebCam, the default starting orientation of the camera is looking UP (pointing in the Z direction),\n         * with the wide (horizontal) axis of the camera aligned with the X axis, and\n         * the Narrow (vertical) axis of the camera aligned with the Y axis\n         *\n         * But, this example assumes that the camera is actually facing forward out the front of the robot.\n         * So, the \"default\" camera position requires two rotations to get it oriented correctly.\n         * 1) First it must be rotated +90 degrees around the X axis to get it horizontal (its now facing out the right side of the robot)\n         * 2) Next it must be be rotated +90 degrees (counter-clockwise) around the Z axis to face forward.\n         *\n         * Finally the camera can be translated to its actual mounting position on the robot.\n         *      In this example, it is centered on the robot (left-to-right and front-to-back), and 6 inches above ground level.",
        "Let all the trackable listeners know where the camera is.",
        "* WARNING:\n         * In this sample, we do not wait for PLAY to be pressed.  Target Tracking is started immediately when INIT is pressed.\n         * This sequence is used to enable the new remote DS Camera Preview feature to be used with this sample.\n         * CONSEQUENTLY do not put any driving commands in this loop.\n         * To restore the normal opmode structure, just un-comment the following line:",
        "Note: To use the remote camera preview:\n         * AFTER you hit Init on the Driver Station, use the \"options menu\" to select \"Camera Stream\"\n         * Tap the preview window to receive a fresh image.\n         * It is not permitted to transition to RUN while the camera preview window is active.\n         * Either press STOP to exit the OpMode, or use the \"options menu\" again, and select \"Camera Stream\" to close the preview window.",
        "*\n     * Identify a target by naming it, and setting its position and orientation on the field\n     * @param targetIndex\n     * @param targetName\n     * @param dx, dy, dz  Target offsets in x,y,z axes\n     * @param rx, ry, rz  Target rotations in x,y,z axes"
    ],
    "functions": [
        "runOpMode",
        "identifyTarget"
    ],
    "classes": [
        "ConceptVuforiaFieldNavigationWebcam"
    ]
}