{
    "identifiers": [
        "nltk",
        "nltk",
        "stem",
        "PorterStemmer",
        "PorterStemmer",
        "json",
        "pickle",
        "numpy",
        "np",
        "open",
        "read",
        "json",
        "loads",
        "train_data_file",
        "words",
        "ignore_words",
        "word",
        "words",
        "word",
        "ignore_words",
        "stemmer",
        "stem",
        "word",
        "lower",
        "stem_words",
        "append",
        "w",
        "stem_words",
        "words",
        "classes",
        "pattern_word_tags_list",
        "ignore_words",
        "intent",
        "intents",
        "pattern",
        "intent",
        "nltk",
        "word_tokenize",
        "pattern",
        "words",
        "extend",
        "pattern_word",
        "pattern_word_tags_list",
        "append",
        "pattern_word",
        "intent",
        "intent",
        "classes",
        "classes",
        "append",
        "intent",
        "get_stem_words",
        "words",
        "ignore_words",
        "sorted",
        "stem_words",
        "sorted",
        "classes",
        "stem_words",
        "classes",
        "pattern_word_tags_list",
        "stem_words",
        "pattern_word_tags_list",
        "word_tags",
        "pattern_word_tags_list",
        "word_tags",
        "get_stem_words",
        "pattern_words",
        "ignore_words",
        "word",
        "stem_words",
        "word",
        "stem_pattern_words",
        "bag_of_words",
        "append",
        "bag_of_words",
        "append",
        "bag",
        "append",
        "bag_of_words",
        "np",
        "array",
        "bag",
        "classes",
        "pattern_word_tags_list",
        "word_tags",
        "pattern_word_tags_list",
        "len",
        "classes",
        "word_tags",
        "classes",
        "index",
        "tag",
        "labels",
        "append",
        "labels_encoding",
        "np",
        "array",
        "labels",
        "create_bot_corpus",
        "words",
        "classes",
        "pattern_word_tags_list",
        "ignore_words",
        "pickle",
        "dump",
        "stem_words",
        "open",
        "pickle",
        "dump",
        "tag_classes",
        "open",
        "bag_of_words_encoding",
        "stem_words",
        "word_tags_list",
        "class_label_encoding",
        "tag_classes",
        "word_tags_list",
        "train_x",
        "train_y"
    ],
    "literals": [
        "'?'",
        "'!'",
        "','",
        "'.'",
        "\"'s\"",
        "\"'m\"",
        "'intents.json'",
        "'intents'",
        "'patterns'",
        "'tag'",
        "'tag'",
        "'tag'",
        "'words.pkl'",
        "'wb'",
        "'classes.pkl'",
        "'wb'"
    ],
    "variables": [
        "stemmer",
        "words",
        "classes",
        "pattern_word_tags_list",
        "ignore_words",
        "train_data_file",
        "intents",
        "stem_words",
        "w",
        "pattern_word",
        "stem_words",
        "stem_words",
        "classes",
        "bag",
        "pattern_words",
        "bag_of_words",
        "stem_pattern_words",
        "labels",
        "labels_encoding",
        "tag",
        "tag_index",
        "labels_encoding",
        "tag_index",
        "stem_words",
        "tag_classes",
        "word_tags_list",
        "train_x",
        "train_y"
    ],
    "comments": [
        "Text Data Preprocessing Lib",
        "list of unique roots words in the data",
        "list of unique tags in the data",
        "list of the pair of (['words', 'of', 'the', 'sentence'], 'tags')",
        "Add all patterns and tags to a list",
        "Add all tags to the classes list",
        "Training Dataset:",
        "Input Text----> as Bag of Words",
        "Tags-----------> as Label",
        "preprocess_train_data()"
    ],
    "docstrings": [],
    "functions": [
        "get_stem_words",
        "create_bot_corpus",
        "bag_of_words_encoding",
        "class_label_encoding",
        "preprocess_train_data"
    ],
    "classes": []
}