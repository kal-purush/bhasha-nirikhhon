{
    "identifiers": [
        "pandas",
        "pd",
        "sklearn",
        "naive_bayes",
        "MultinomialNB",
        "sklearn",
        "feature_extraction",
        "text",
        "TfidfVectorizer",
        "openpyxl",
        "load_workbook",
        "sklearn",
        "metrics",
        "pickle",
        "source",
        "pd",
        "read_excel",
        "source",
        "header",
        "names",
        "col_names",
        "source",
        "sentiment",
        "source",
        "open",
        "encoding",
        "stopwords",
        "word",
        "stopwords",
        "stopwordlist",
        "append",
        "word",
        "stopwordlist",
        "source",
        "pd",
        "read_excel",
        "source",
        "header",
        "datatest",
        "Tweet",
        "vect",
        "transform",
        "X_test",
        "nb",
        "predict",
        "X_test_dtm",
        "pd",
        "DataFrame",
        "test_predict",
        "index",
        "datatest",
        "index",
        "datatest",
        "sentiment_num",
        "datatest",
        "data_cluster",
        "datatest",
        "pd",
        "ExcelWriter",
        "source",
        "engine",
        "writer",
        "load_workbook",
        "source",
        "datatest",
        "to_excel",
        "writer",
        "writer",
        "save",
        "load_dataset",
        "data",
        "sentence",
        "data",
        "sentiment_num",
        "TfidfVectorizer",
        "strip_accents",
        "min_df",
        "max_df",
        "sublinear_tf",
        "use_idf",
        "stop_words",
        "turkish_stopwords",
        "ngram_range",
        "vect",
        "fit_transform",
        "X",
        "MultinomialNB",
        "nb",
        "fit",
        "X_dtm",
        "y",
        "pd",
        "Series",
        "ex",
        "vect",
        "transform",
        "a",
        "nb",
        "predict_proba",
        "a",
        "open",
        "pickle_out",
        "pickle",
        "dump",
        "nb",
        "pickle_out",
        "open",
        "pickle_out",
        "pickle",
        "dump",
        "vect",
        "pickle_out"
    ],
    "literals": [
        "\"sentence\"",
        "\"sentiment\"",
        "\"sentiment_num\"",
        "\"Positive\"",
        "\"Negative\"",
        "\"stopwords.txt\"",
        "\"utf-8\"",
        "\"sentiment_num\"",
        "\"sentiment\"",
        "\"Positive\"",
        "\"Negative\"",
        "\"sentiment_num\"",
        "\"Tweet\"",
        "\"openpyxl\"",
        "\"Sheet1\"",
        "\"__main__\"",
        "\"filmreviews.xlsx\"",
        "\"unicode\"",
        "\"LCW'yi Ã§ok seviyorum\"",
        "\"model.pickle\"",
        "\"wb\"",
        "\"vectorizer.pickle\"",
        "\"wb\""
    ],
    "variables": [
        "col_names",
        "source",
        "source",
        "stopwordlist",
        "datatest",
        "X_test",
        "X_test_dtm",
        "test_predict",
        "datatest",
        "datatest",
        "writer",
        "book",
        "data",
        "X",
        "y",
        "vect",
        "X_dtm",
        "nb",
        "ex",
        "a",
        "a"
    ],
    "comments": [
        "Getting Turkish Stop Words",
        "Vectorizing our data set",
        "Vectorizing our data set",
        "print(vect.get_feature_names())",
        "Building and evaluating a model. We will use multinominal Naive Bayes"
    ],
    "docstrings": [],
    "functions": [
        "load_dataset",
        "turkish_stopwords",
        "data_from_twitter"
    ],
    "classes": []
}