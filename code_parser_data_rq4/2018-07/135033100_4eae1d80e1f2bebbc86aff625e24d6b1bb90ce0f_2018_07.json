{
    "identifiers": [
        "boto3",
        "pathlib",
        "hiveContext",
        "bucket_name",
        "path_prefix",
        "dataset_dir",
        "hive_table_name",
        "boto3",
        "resource",
        "s3_client",
        "Bucket",
        "bucket_name",
        "s3_bucket",
        "objects",
        "Prefix",
        "path_prefix",
        "Delimiter",
        "s3_object",
        "s3_objects",
        "s3_object",
        "key",
        "endswith",
        "data_keys",
        "append",
        "s3_object",
        "key",
        "len",
        "data_keys",
        "pathlib",
        "Path",
        "dataset_dir",
        "mkdir",
        "exist_ok",
        "index",
        "data_key",
        "data_keys",
        "format",
        "dataset_dir",
        "index",
        "format",
        "index",
        "len",
        "data_keys",
        "data_key",
        "output_file_name",
        "pathlib",
        "Path",
        "output_file_name",
        "output_file_path",
        "is_file",
        "s3_bucket",
        "download_file",
        "data_key",
        "output_file_name",
        "hiveContext",
        "read",
        "json",
        "dataset_dir",
        "fetched_data",
        "createOrReplaceTempView",
        "format",
        "hive_table_name",
        "hiveContext",
        "sql",
        "hql_statement",
        "format",
        "hive_table_name",
        "fetched_data",
        "count"
    ],
    "literals": [
        "'s3'",
        "'/'",
        "'/'",
        "'.json'",
        "'Fetched the keys of %s data file(s).\\n'",
        "'{}/part_{}.json'",
        "'Downloading part ({}/{})\\nKey: {}\\nSaving to: {}\\n'",
        "'dataset_temp'",
        "'CREATE TABLE IF NOT EXISTS {} AS SELECT * FROM dataset_temp'",
        "'Fetched and loaded dataset to Hive.\\nTable name: {}\\nNumber of records: {}\\n'"
    ],
    "variables": [
        "s3_client",
        "s3_bucket",
        "s3_objects",
        "data_keys",
        "output_file_name",
        "output_file_path",
        "fetched_data",
        "hql_statement"
    ],
    "comments": [
        "",
        "Extract, transform and load script | Fetches data from Amazon S3 and loads it to Hive. ##",
        "",
        "Get all target directory keys",
        "Select data files keys only",
        "Report the number of data files",
        "Prepare output directory",
        "Fetch data",
        "Notify",
        "Check if data file already exists",
        "Download data file if missing",
        "Save fetched data to Hive"
    ],
    "docstrings": [],
    "functions": [
        "run_etl"
    ],
    "classes": []
}