{
    "identifiers": [
        "torch",
        "transformers",
        "AutoModelForCausalLM",
        "AutoTokenizer",
        "pandas",
        "pd",
        "numpy",
        "np",
        "random",
        "datasets",
        "Dataset",
        "transformers",
        "transformers",
        "AutoTokenizer",
        "AutoModelForSeq2SeqLM",
        "Seq2SeqTrainer",
        "Seq2SeqTrainingArguments",
        "DataCollatorForSeq2Seq",
        "datasets",
        "load_dataset",
        "Dataset",
        "pandas",
        "pd",
        "evaluate",
        "torch",
        "nltk",
        "transformers",
        "Seq2SeqTrainer",
        "Seq2SeqTrainingArguments",
        "AutoTokenizer",
        "AutoModelForSeq2SeqLM",
        "nltk",
        "argparse",
        "numpy",
        "np",
        "transformers",
        "AutoModelForSeq2SeqLM",
        "peft",
        "get_peft_config",
        "get_peft_model",
        "LoraConfig",
        "TaskType",
        "trl",
        "AutoModelForCausalLMWithValueHead",
        "transformers",
        "TrainingArguments",
        "Trainer",
        "trl",
        "SFTTrainer",
        "evaluate",
        "transformers",
        "AutoTokenizer",
        "AutoModelForCausalLM",
        "BitsAndBytesConfig",
        "re",
        "datasets",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "parse_args",
        "args",
        "parse_args",
        "args",
        "base_model_name",
        "args",
        "device_batch_size",
        "args",
        "gradient_accumulation_steps",
        "args",
        "eval_samples",
        "AutoTokenizer",
        "from_pretrained",
        "model_name_or_path",
        "token",
        "AutoModelForCausalLM",
        "from_pretrained",
        "model_name_or_path",
        "device_map",
        "cache_dir",
        "token",
        "LANGUAGE",
        "load_dataset",
        "LANGUAGE",
        "cache_dir",
        "LANGUAGE",
        "load_dataset",
        "ds",
        "ds",
        "example",
        "code",
        "re",
        "sub",
        "code",
        "flags",
        "re",
        "DOTALL",
        "code_without_comments",
        "strip",
        "join",
        "example",
        "example",
        "language",
        "code",
        "join",
        "example",
        "tokenizer",
        "chat_template",
        "tokenizer",
        "apply_chat_template",
        "chat",
        "tokenize",
        "add_generation_prompt",
        "example",
        "apply_chat_template",
        "train_dataset",
        "apply_chat_template",
        "train_dataset",
        "ex_0",
        "train_dataset",
        "features",
        "train_dataset",
        "apply_chat_template",
        "num_proc",
        "remove_columns",
        "column_names",
        "desc",
        "test_dataset",
        "apply_chat_template",
        "num_proc",
        "remove_columns",
        "column_names",
        "desc",
        "i",
        "processed_test_dataset",
        "all_lengths",
        "append",
        "tokenizer",
        "tokenize",
        "i",
        "__len__",
        "np",
        "percentile",
        "all_lengths",
        "evaluate",
        "evaluate",
        "load",
        "evaluate",
        "load",
        "evaluate",
        "load",
        "eval_pred",
        "eval_pred",
        "np",
        "argmax",
        "predictions",
        "axis",
        "np",
        "where",
        "predictions",
        "predictions",
        "tokenizer",
        "eos_token_id",
        "tokenizer",
        "batch_decode",
        "predictions",
        "np",
        "where",
        "labels",
        "labels",
        "tokenizer",
        "eos_token_id",
        "tokenizer",
        "batch_decode",
        "labels",
        "i",
        "split",
        "split",
        "strip",
        "i",
        "decoded_preds",
        "i",
        "split",
        "split",
        "strip",
        "i",
        "decoded_labels",
        "rouge",
        "compute",
        "predictions",
        "decoded_preds",
        "references",
        "decoded_labels",
        "use_stemmer",
        "meteor",
        "compute",
        "predictions",
        "decoded_preds",
        "references",
        "decoded_labels",
        "bleu",
        "compute",
        "predictions",
        "decoded_preds",
        "references",
        "decoded_labels",
        "meteor_result",
        "bleu_result",
        "np",
        "count_nonzero",
        "pred",
        "tokenizer",
        "eos_token_id",
        "pred",
        "predictions",
        "np",
        "mean",
        "prediction_lens",
        "k",
        "round",
        "v",
        "k",
        "v",
        "result",
        "items",
        "TrainingArguments",
        "per_device_train_batch_size",
        "device_batch",
        "gradient_accumulation_steps",
        "gradient_steps",
        "warmup_steps",
        "report_to",
        "learning_rate",
        "lr_scheduler_type",
        "num_train_epochs",
        "logging_steps",
        "optim",
        "bf16",
        "output_dir",
        "model_name_or_path",
        "split",
        "LANGUAGE",
        "logging_strategy",
        "dataloader_num_workers",
        "save_total_limit",
        "do_eval",
        "evaluation_strategy",
        "save_strategy",
        "save_steps",
        "eval_steps",
        "metric_for_best_model",
        "greater_is_better",
        "load_best_model_at_end",
        "SFTTrainer",
        "model",
        "packing",
        "max_seq_length",
        "args",
        "training_args",
        "train_dataset",
        "processed_train_dataset",
        "shuffle",
        "eval_dataset",
        "processed_test_dataset",
        "shuffle",
        "select",
        "eval_samples",
        "dataset_text_field",
        "compute_metrics",
        "compute_metrics",
        "callbacks",
        "transformers",
        "EarlyStoppingCallback",
        "early_stopping_patience",
        "trainer",
        "train",
        "trainer",
        "save_model"
    ],
    "literals": [
        "\"Run QLoRA model fine-tuning\"",
        "'--base_model_name'",
        "'codellama/CodeLlama-7b-Instruct-hf'",
        "\"Base model name\"",
        "'--device_batch_size'",
        "\"Per device train batch size\"",
        "'--gradient_accumulation_steps'",
        "\"Gradient accumulation steps\"",
        "'--eval_samples'",
        "\"Number of samples in the eval set\"",
        "'both'",
        "\"Running...\"",
        "'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'",
        "\"auto\"",
        "'./models'",
        "'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'",
        "'java'",
        "'python'",
        "\"google/code_x_glue_ct_code_to_text\"",
        "'datasets'",
        "'both'",
        "\"doejn771/code_x_glue_ct_code_to_text_java_python\"",
        "\"train\"",
        "\"validation\"",
        "r'\"\"\".*?\"\"\"'",
        "''",
        "' '",
        "'code_tokens'",
        "'language'",
        "\"role\"",
        "\"system\"",
        "\"content\"",
        "\"Provide summarization to given code segment\"",
        "\"role\"",
        "\"user\"",
        "\"content\"",
        "f\"Summarize {language} code:\\n{code}\"",
        "\"role\"",
        "\"assistant\"",
        "\"content\"",
        "f\"SUMMARY: {' '.join(example['docstring_tokens'])} DONE\"",
        "' '",
        "'docstring_tokens'",
        "\"{%- for message in messages -%}\\n{% if message['role'] == 'system' %}{% if loop.first %}{{ message['content'] }}{% endif %}{% elif message['role'] == 'user' %}{{ 'Human: ' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ 'Assistant: ' + message['content'] + '\\n\\n' }}{% endif %}\\n{%- endfor -%}\\n{% if add_generation_prompt %}Human: {{ '' }}{% endif %}\"",
        "\"text\"",
        "'text'",
        "'text'",
        "\"Applying chat template to train_sft\"",
        "\"Applying chat template to train_sft\"",
        "'text'",
        "'========== Sequence Length Per Percentiles =========='",
        "\"rouge\"",
        "\"meteor\"",
        "\"bleu\"",
        "\"SUMMARY: \"",
        "'DONE'",
        "\"SUMMARY: \"",
        "'DONE'",
        "'meteor'",
        "'meteor'",
        "'bleu'",
        "'bleu'",
        "\"gen_len\"",
        "\"cosine\"",
        "\"adamw_bnb_8bit\"",
        "f\"results/{model_name_or_path.split('/')[-1]}_{LANGUAGE}_indication_5k\"",
        "'/'",
        "\"steps\"",
        "\"steps\"",
        "\"steps\"",
        "'eval_meteor'",
        "'text'"
    ],
    "variables": [
        "parser",
        "args",
        "args",
        "LANGUAGE",
        "model_name_or_path",
        "device_batch",
        "gradient_steps",
        "eval_samples",
        "tokenizer",
        "model",
        "ds",
        "ds",
        "train_dataset",
        "test_dataset",
        "code_without_comments",
        "code",
        "language",
        "chat",
        "tokenizer",
        "chat_template",
        "example",
        "ex_0",
        "ex_1",
        "column_names",
        "processed_train_dataset",
        "all_lengths",
        "processed_test_dataset",
        "rouge",
        "meteor",
        "bleu",
        "predictions",
        "labels",
        "predictions",
        "predictions",
        "decoded_preds",
        "labels",
        "decoded_labels",
        "decoded_preds",
        "decoded_labels",
        "result",
        "meteor_result",
        "bleu_result",
        "result",
        "result",
        "prediction_lens",
        "result",
        "training_args",
        "trainer"
    ],
    "comments": [
        "Return the cleaned code",
        "code = remove_comments_from_code(example['code'])",
        "----------------------------- training -------------------------------",
        "pack samples together for efficient training",
        "maximum packed length"
    ],
    "docstrings": [],
    "functions": [
        "parse_args",
        "main",
        "apply_chat_template",
        "remove_comments_from_code",
        "compute_metrics"
    ],
    "classes": []
}