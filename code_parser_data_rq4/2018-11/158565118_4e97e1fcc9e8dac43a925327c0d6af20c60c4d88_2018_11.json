{
    "identifiers": [
        "tensorflow",
        "tf",
        "numpy",
        "np",
        "inputs",
        "true_w",
        "true_w",
        "inputs",
        "tf",
        "matmul",
        "vc",
        "tf",
        "transpose",
        "uo",
        "tf",
        "diag_part",
        "A",
        "tf",
        "log",
        "tf",
        "reduce_sum",
        "tf",
        "exp",
        "tf",
        "matmul",
        "vc",
        "tf",
        "transpose",
        "uo",
        "tf",
        "subtract",
        "B",
        "A",
        "inputs",
        "weights",
        "biases",
        "labels",
        "sample",
        "unigram_prob",
        "len",
        "sample",
        "inputs",
        "get_shape",
        "as_list",
        "input_size",
        "input_size",
        "sample_size",
        "tf",
        "convert_to_tensor",
        "sample",
        "inputs",
        "tf",
        "cast",
        "uc",
        "tf",
        "float64",
        "tf",
        "transpose",
        "uc",
        "tf",
        "gather",
        "weights",
        "labels",
        "tf",
        "cast",
        "uo",
        "tf",
        "float64",
        "tf",
        "reshape",
        "uo",
        "batch_size",
        "embedding_size",
        "tf",
        "gather",
        "weights",
        "sample",
        "tf",
        "reshape",
        "vk",
        "sample_size",
        "embedding_size",
        "tf",
        "cast",
        "vk",
        "tf",
        "float64",
        "tf",
        "convert_to_tensor",
        "unigram_prob",
        "dtype",
        "tf",
        "float64",
        "tf",
        "diag_part",
        "tf",
        "matmul",
        "uo",
        "uc_transpose",
        "tf",
        "reshape",
        "mult_uc_t_uo",
        "batch_size",
        "tf",
        "gather",
        "biases",
        "labels",
        "tf",
        "cast",
        "pos_bias",
        "tf",
        "float64",
        "tf",
        "add",
        "mult_uc_t_uo",
        "pos_bias",
        "tf",
        "gather",
        "unigram_prob_tensor",
        "labels",
        "tf",
        "reshape",
        "uo_p",
        "batch_size",
        "tf",
        "subtract",
        "s_uo_uc",
        "tf",
        "log",
        "tf",
        "scalar_mul",
        "k",
        "uo_p",
        "tf",
        "matmul",
        "vk",
        "uc_transpose",
        "tf",
        "gather",
        "biases",
        "sample",
        "tf",
        "reshape",
        "neg_bias",
        "sample_size",
        "tf",
        "cast",
        "neg_bias",
        "tf",
        "float64",
        "tf",
        "add",
        "mult_uc_t_vk",
        "neg_bias",
        "tf",
        "gather",
        "unigram_prob_tensor",
        "tf",
        "transpose",
        "sample",
        "tf",
        "reshape",
        "vk_p",
        "k",
        "tf",
        "subtract",
        "s_uc_vk",
        "tf",
        "log",
        "tf",
        "scalar_mul",
        "k",
        "vk_p",
        "tf",
        "sigmoid",
        "first_term",
        "tf",
        "constant",
        "shape",
        "k",
        "dtype",
        "tf",
        "float64",
        "tf",
        "log",
        "sigmoid_1",
        "tf",
        "reduce_sum",
        "tf",
        "scalar_mul",
        "tf",
        "log",
        "tf",
        "add",
        "I",
        "tf",
        "exp",
        "second_term",
        "tf",
        "scalar_mul",
        "tf",
        "add",
        "A",
        "B",
        "inputs",
        "weights",
        "biases",
        "labels",
        "sample",
        "unigram_prob",
        "tf",
        "reshape",
        "labels",
        "tf",
        "gather",
        "weights",
        "reshaped_labels",
        "axis",
        "tf",
        "gather",
        "biases",
        "reshaped_labels",
        "axis",
        "tf",
        "reshape",
        "tbias",
        "tf",
        "gather",
        "unigram_prob",
        "reshaped_labels",
        "axis",
        "tf",
        "gather",
        "weights",
        "sample",
        "axis",
        "tf",
        "gather",
        "unigram_prob",
        "np",
        "array",
        "sample",
        "T",
        "axis",
        "tf",
        "reshape",
        "tf",
        "reshape",
        "tf",
        "gather",
        "biases",
        "sample",
        "axis",
        "sample",
        "size",
        "tf",
        "cast",
        "inputs",
        "tf",
        "float64",
        "tf",
        "cast",
        "u_o",
        "tf",
        "float64",
        "tf",
        "cast",
        "u_o_biases",
        "tf",
        "float64",
        "tf",
        "cast",
        "u_o_probs",
        "tf",
        "float64",
        "tf",
        "add",
        "tf",
        "diag_part",
        "tf",
        "matmul",
        "u_o",
        "tf",
        "transpose",
        "u_c",
        "u_o_biases",
        "tf",
        "subtract",
        "swow1",
        "tf",
        "log",
        "sample",
        "size",
        "u_o_probs",
        "tf",
        "cast",
        "tf",
        "constant",
        "dtype",
        "tf",
        "float64",
        "tf",
        "log",
        "tf",
        "add",
        "one_mat",
        "tf",
        "exp",
        "insideSigmoid",
        "tf",
        "cast",
        "n_t_e",
        "tf",
        "float64",
        "tf",
        "cast",
        "n_t_e_biases",
        "tf",
        "float64",
        "tf",
        "cast",
        "n_t_e_probs",
        "tf",
        "float64",
        "tf",
        "add",
        "tf",
        "matmul",
        "n_t_e",
        "tf",
        "transpose",
        "u_c",
        "n_t_e_biases",
        "tf",
        "subtract",
        "swxwc",
        "tf",
        "log",
        "sample",
        "size",
        "n_t_e_probs",
        "tf",
        "exp",
        "Pr",
        "tf",
        "cast",
        "tf",
        "constant",
        "dtype",
        "tf",
        "float64",
        "tf",
        "log",
        "tf",
        "add",
        "one_mat",
        "deno",
        "tf",
        "reduce_sum",
        "logOfdeno",
        "axis",
        "tf",
        "subtract",
        "part1",
        "part2"
    ],
    "literals": [],
    "variables": [
        "uo",
        "vc",
        "A",
        "A",
        "B",
        "sample_size",
        "input_size",
        "batch_size",
        "embedding_size",
        "k",
        "sample",
        "uc",
        "uc",
        "uc_transpose",
        "uo",
        "uo",
        "uo",
        "vk",
        "vk",
        "vk",
        "unigram_prob_tensor",
        "mult_uc_t_uo",
        "mult_uc_t_uo",
        "pos_bias",
        "pos_bias",
        "s_uo_uc",
        "uo_p",
        "uo_p",
        "first_term",
        "mult_uc_t_vk",
        "neg_bias",
        "neg_bias",
        "neg_bias",
        "s_uc_vk",
        "vk_p",
        "vk_p",
        "second_term",
        "sigmoid_1",
        "I",
        "A",
        "B",
        "reshaped_labels",
        "u_o",
        "tbias",
        "u_o_biases",
        "u_o_probs",
        "n_t_e",
        "n_t_e_probs",
        "n_t_e_biases",
        "u_c",
        "u_o",
        "u_o_biases",
        "u_o_probs",
        "swow1",
        "insideSigmoid",
        "one_mat",
        "part1",
        "n_t_e",
        "n_t_e_biases",
        "n_t_e_probs",
        "swxwc",
        "Pr",
        "deno",
        "one_mat",
        "logOfdeno",
        "part2"
    ],
    "comments": [
        "print (vc.get_shape(), uo.get_shape())",
        "print (A.get_shape(), B.get_shape())",
        "labels: output words that are paired with each context words // word ids",
        "negative samples representation",
        "print(\"1\", k , uo, uc, vk)",
        "up = tf.nn.embedding_lookup(unigram_prob, labels)",
        "First Term",
        "uo = tf.Print(uo, [uo], message='DEBUG uo: ')",
        "print(mult_uc_t_uo)",
        "mult_uc_t_uo = tf.Print(mult_uc_t_uo, [mult_uc_t_uo], message='DEBUG mult_uc_t_uo: ')",
        "uo bias",
        "pos_bias = tf.Print(pos_bias, [pos_bias], message='DEBUG pos_bias: ')",
        "print(pos_bias)",
        "s_uo_uc = tf.Print(s_uo_uc, [s_uo_uc], message='DEBUG s_uo_uc: ')",
        "print(s_uo_uc)",
        "print(uo_p.get_shape())",
        "print(first_term.get_shape())",
        "vk_transpose=tf.transpose(vk)",
        "uo_p = tf.Print(uo_p, [uo_p], message='DEBUG uo_p: ')",
        "first_term = tf.Print(first_term, [first_term], message='DEBUG first_term: ')",
        "vk = tf.Print(vk, [vk], message='DEBUG vk: ')",
        "Second Term",
        "print(vk.get_shape(), uc_transpose.get_shape())",
        "print(mult_uc_t_vk.get_shape())",
        "vk bias",
        "print(neg_bias.get_shape(), s_uc_vk.get_shape(), vk_p.get_shape())",
        "vk_p = tf.gather(unigram_prob_tensor,tf.transpose(sample))",
        "print(second_term.get_shape())",
        "mult_uc_t_uo = tf.Print(mult_uc_t_uo, [mult_uc_t_uo], message='DEBUG mult_uc_t_uo: ')",
        "mult_uc_t_vk = tf.Print(mult_uc_t_vk, [mult_uc_t_vk], message='DEBUG mult_uc_t_vk: ')",
        "print(\"2\",mult_uc_t_uo, mult_uc_t_vk)",
        "neg_bias = tf.reshape(neg_bias, [-1, embedding_size])",
        "uo = tf.reshape(uo, [-1, embedding_size])",
        "pos_bias = tf.reshape(pos_bias, [-1])",
        "print(\"3\",pos_bias, neg_bias)",
        "print(\"4\", s_uo_uc, s_uo_vk)",
        "s_uc_vk = tf.Print(s_uc_vk, [s_uc_vk], message='DEBUG s_uc_vk: ')",
        "print(\"5\", uo_p, vk_p)",
        "uo_p = tf.Print(uo_p, [uo_p], message='DEBUG uo_p: ')",
        "vk_p = tf.Print(vk_p, [vk_p], message='DEBUG vk_p: ')",
        "first_term =tf.subtract(U_score, tf.log(tf.scalar_mul(k,P_o)+1e-10))",
        "second_term = tf.subtract(N_score,tf.log(tf.scalar_mul(k,P_n)+1e-10))",
        "print(\"6\",first_term, second_term)",
        "print(\"Value\", first_term[0].value, second_term[0][0].value)",
        "sigmoid_2 = tf.sigmoid(second_term)",
        "print(\"7\", sigmoid_1, sigmoid_2)",
        "sigmoid_1 = tf.Print(sigmoid_1, [sigmoid_1], message='DEBUG sigmoid_1: ')",
        "sigmoid_2 = tf.Print(sigmoid_2, [sigmoid_2], message='DEBUG sigmoid_2: ')",
        "print(\"value\" , sigmoid_1[0].value,sigmoid_2[0][0].value)",
        "print(\"8\", I)",
        "u_o = tf.gather(weights,reshaped_labels,axis=0)",
        "print (tf.gather(weights,labels,axis=0).get_shape())",
        "print (u_o.get_shape())",
        "print (u_o_probs.get_shape())",
        "u_o = tf.Print(u_o, [u_o], message='DEBUG u_o: ')",
        "tbias = tf.Print(tbias, [tbias], message='DEBUG tbias: ')",
        "u_o_biases = tf.Print(u_o_biases, [u_o_biases], message='DEBUG u_o_biases: ')",
        "u_o_probs = tf.Print(u_o_probs, [u_o_probs], message='DEBUG u_o_probs: ')",
        "print (n_t_e.get_shape())",
        "print (n_t_e_probs.get_shape())",
        "print (n_t_e_biases.get_shape())",
        "start equation calculation",
        "swow1 = tf.Print(swow1, [swow1], message='DEBUG biase + mul: ')",
        "insideSigmoid = tf.Print(insideSigmoid, [insideSigmoid], message='DEBUG first term: ')",
        "part1 = -(tf.nn.softplus(-insideSigmoid))",
        "part1 = tf.Print(part1,[part1],message = 'check value')",
        "print (part1)",
        "print (swxwc.get_shape())",
        "print (tf.matmul(n_t_e, tf.transpose(u_c)).get_shape(),n_t_e_biases.get_shape(),'check dimension')",
        "print('reached here')",
        "print('reached here')",
        "log(1-1/(1+e^(-x))) = log(1/(1+e^(x)) = -log(1+e^(x)) = -log(Pr))",
        "print('reached here')",
        "print (part2.get_shape())",
        "print ((tf.subtract(part1,part2)).get_shape())"
    ],
    "docstrings": [
        "\"\"\"\n    ==========================================================================\n\n    inputs: The embeddings for context words. Dimension is [batch_size, embedding_size].\n    true_w: The embeddings for predicting words. Dimension of true_w is [batch_size, embedding_size].\n\n    Write the code that calculate A = log(exp({u_o}^T v_c))\n\n    A =\n\n\n    And write the code that calculate B = log(\\sum{exp({u_w}^T v_c)})\n\n\n    B =\n\n    ==========================================================================\n    \"\"\"",
        "\"\"\"\n    ==========================================================================\n\n    inputs: Embeddings for context words. Dimension is [batch_size, embedding_size].\n    weigths: Weights for nce loss. Dimension is [Vocabulary, embedding_size].\n    biases: Biases for nce loss. Dimension is [Vocabulary, 1].\n    labels: Word_ids for predicting words. Dimesion is [batch_size, 1].\n    sample: Word_ids for negative samples. Dimension is [num_sampled].\n    unigram_prob: Unigram probability. Dimesion is [Vocabulary].\n\n    Implement Noise Contrastive Estimation Loss Here\n\n    ==========================================================================\n    \"\"\"",
        "\"\"\"\n    ==========================================================================\n    inputs: Embeddings for context words. Dimension is [batch_size, embedding_size].\n    weigths: Weights for nce loss. Dimension is [Vocabulary, embeeding_size].\n    biases: Biases for nce loss. Dimension is [Vocabulary, 1].\n    labels: Word_ids for predicting words. Dimesion is [batch_size, 1].\n    samples: Word_ids for negative samples. Dimension is [num_sampled].\n    unigram_prob: Unigram probability. Dimesion is [Vocabulary].\n    Implement Noise Contrastive Estimation Loss Here\n    ==========================================================================\n    \"\"\""
    ],
    "functions": [
        "cross_entropy_loss",
        "nce_loss",
        "nce_loss1"
    ],
    "classes": []
}