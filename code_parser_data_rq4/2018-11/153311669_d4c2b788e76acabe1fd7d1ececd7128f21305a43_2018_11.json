{
    "identifiers": [
        "matplotlib",
        "matplotlib",
        "use",
        "matplotlib",
        "pyplot",
        "plt",
        "numpy",
        "scipy",
        "spatial",
        "distance",
        "cosine",
        "keras",
        "engine",
        "Model",
        "merge",
        "keras",
        "layers",
        "embeddings",
        "Embedding",
        "keras",
        "layers",
        "recurrent",
        "LSTM",
        "keras",
        "layers",
        "core",
        "Flatten",
        "Dense",
        "Activation",
        "Lambda",
        "keras",
        "layers",
        "Input",
        "keras",
        "layers",
        "wrappers",
        "TimeDistributed",
        "keras",
        "backend",
        "K",
        "data_iterator",
        "Word2VecIterator",
        "MENEvaluator",
        "infinite_cycle",
        "LossHistory",
        "word_to_indices",
        "word2vec_model",
        "word2vec_model",
        "corpus",
        "n_neg",
        "batch_size",
        "min_count",
        "Word2VecIterator",
        "corpus",
        "n_neg",
        "batch_size",
        "min_count",
        "word2vec_model",
        "learn_context_weights",
        "Input",
        "shape",
        "dtype",
        "name",
        "Input",
        "shape",
        "dtype",
        "name",
        "Input",
        "shape",
        "dtype",
        "name",
        "learn_context_weights",
        "word2vec_model",
        "syn1neg",
        "Embedding",
        "input_dim",
        "len",
        "iterator",
        "word_index",
        "output_dim",
        "input_length",
        "weights",
        "context_weights",
        "learn_context_weights",
        "Flatten",
        "context_embedding",
        "context",
        "Embedding",
        "input_dim",
        "output_dim",
        "mask_zero",
        "input_length",
        "char_embedding",
        "content_forward",
        "char_embedding",
        "content_backward",
        "LSTM",
        "output_dim",
        "return_sequences",
        "activation",
        "embed_forward",
        "LSTM",
        "output_dim",
        "return_sequences",
        "activation",
        "go_backwards",
        "inputs",
        "mask",
        "inputs",
        "input_shapes",
        "input_shapes",
        "Lambda",
        "reverse_tensor",
        "output_shape",
        "reverse_tensor_shape",
        "reverse",
        "backwards_lstm",
        "embed_backward",
        "TimeDistributed",
        "Dense",
        "output_dim",
        "merge",
        "rnn_forward",
        "rnn_backward",
        "mode",
        "TimeDistributed",
        "Dense",
        "output_dim",
        "activation",
        "bias",
        "rnn_bidi",
        "TimeDistributed",
        "Dense",
        "output_dim",
        "activity_regularizer",
        "bias",
        "attention_1",
        "inputs",
        "mask",
        "inputs",
        "inputs",
        "K",
        "squeeze",
        "logits",
        "axis",
        "K",
        "mask",
        "logits",
        "numpy",
        "inf",
        "K",
        "expand_dims",
        "K",
        "softmax",
        "pre_softmax",
        "K",
        "sum",
        "vectors",
        "weights",
        "axis",
        "input_shapes",
        "input_shapes",
        "input_shapes",
        "Lambda",
        "attn_merge",
        "output_shape",
        "attn_merge_shape",
        "inputs",
        "mask",
        "attn",
        "rnn_bidi",
        "attention_2",
        "Activation",
        "name",
        "merge",
        "content_flat",
        "context_flat",
        "mode",
        "dot_axes",
        "Model",
        "input",
        "content_forward",
        "content_backward",
        "context",
        "output",
        "output",
        "model",
        "compile",
        "loss",
        "optimizer",
        "metrics",
        "content_forward",
        "content_backward",
        "K",
        "inputs",
        "content_flat",
        "K",
        "inputs",
        "K",
        "squeeze",
        "attention_2",
        "axis",
        "model",
        "epochs",
        "model_name",
        "LossHistory",
        "MENEvaluator",
        "model",
        "fit_generator",
        "iter",
        "infinite_cycle",
        "iterator",
        "len",
        "iterator",
        "epochs",
        "callbacks",
        "history",
        "evaluation",
        "plt",
        "figure",
        "plt",
        "plot",
        "history",
        "total_seen",
        "history",
        "losses",
        "plt",
        "ylim",
        "plt",
        "savefig",
        "model_name",
        "word",
        "word_to_indices",
        "word",
        "numpy",
        "array",
        "indices",
        "numpy",
        "array",
        "indices",
        "_predict",
        "forward",
        "backward",
        "_attention",
        "forward",
        "backward",
        "embedding",
        "attention",
        "word",
        "n",
        "context",
        "cutoff",
        "word_vectors",
        "predict",
        "x",
        "x",
        "iterator",
        "word_index",
        "numpy",
        "array",
        "cosine",
        "y",
        "word_vectors",
        "iterator",
        "word2index",
        "word",
        "y",
        "word_vectors",
        "numpy",
        "argsort",
        "distances",
        "cutoff",
        "arg",
        "arg",
        "sorted_args",
        "iterator",
        "word_count",
        "iterator",
        "word_index",
        "y",
        "cutoff",
        "iterator",
        "word_index",
        "y",
        "y",
        "sorted_args",
        "distances",
        "sorted_args",
        "n",
        "words",
        "n"
    ],
    "literals": [
        "'Agg'",
        "'int32'",
        "'content_forward'",
        "'int32'",
        "'content_backward'",
        "'int32'",
        "'context'",
        "'tanh'",
        "'tanh'",
        "'concat'",
        "'tanh'",
        "'activity_l2'",
        "'sigmoid'",
        "'output'",
        "'dot'",
        "'binary_crossentropy'",
        "'adam'",
        "'accuracy'",
        "'.png'"
    ],
    "variables": [
        "word_vectors",
        "word2vec_model",
        "iterator",
        "content_forward",
        "content_backward",
        "context",
        "context_weights",
        "context_weights",
        "context_embedding",
        "context_embedding",
        "trainable",
        "context_flat",
        "char_embedding",
        "embed_forward",
        "embed_backward",
        "numSteps",
        "rnn_forward",
        "backwards_lstm",
        "reverse",
        "reverse",
        "supports_masking",
        "rnn_backward",
        "rnn_bidi",
        "attention_1",
        "attention_2",
        "vectors",
        "logits",
        "logits",
        "pre_softmax",
        "weights",
        "attn",
        "attn",
        "supports_masking",
        "attn",
        "compute_mask",
        "content_flat",
        "output",
        "model",
        "inputs",
        "_predict",
        "_attention",
        "model",
        "history",
        "evaluation",
        "indices",
        "forward",
        "backward",
        "embedding",
        "attention",
        "word_vectors",
        "distances",
        "sorted_args",
        "sorted_args",
        "words"
    ],
    "comments": [
        "Flatten the logits and take a softmax"
    ],
    "docstrings": [],
    "functions": [
        "build_iterator",
        "build",
        "reverse_tensor",
        "reverse_tensor_shape",
        "attn_merge",
        "attn_merge_shape",
        "train",
        "predict",
        "most_similar"
    ],
    "classes": [
        "WordSegmenter"
    ]
}