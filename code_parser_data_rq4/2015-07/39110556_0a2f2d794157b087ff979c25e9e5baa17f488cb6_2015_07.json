{
    "identifiers": [
        "natural",
        "types",
        "args",
        "types",
        "natural",
        "lineIndex",
        "args",
        "args",
        "lineIndex",
        "splitTokens",
        "args",
        "line",
        "tokenizer",
        "content",
        "types",
        "line",
        "types",
        "tokenizer",
        "line",
        "line",
        "tokenizer",
        "line",
        "textIndex",
        "texts",
        "texts",
        "textIndex",
        "lineText",
        "text",
        "index",
        "lineIndex",
        "RangeError",
        "text",
        "lineText",
        "index",
        "lineIndex",
        "text",
        "types",
        "lineLocation",
        "lineLocation",
        "lineIndex",
        "lineLocation",
        "lineIndex",
        "text",
        "types",
        "location",
        "text",
        "token",
        "content",
        "line",
        "token",
        "content",
        "token"
    ],
    "literals": [
        "\"natural\"",
        "\"node-author-intrusion\"",
        "\"Cannot find text of \"",
        "\" in \""
    ],
    "variables": [
        "tokenizer",
        "line",
        "lineText",
        "lineLocation",
        "texts",
        "index",
        "text",
        "lineIndex",
        "location",
        "token"
    ],
    "comments": [
        "<reference path=\"./refs\"/>",
        "Splitting is a pretty simple iterative process. We always have to break",
        "apart using the chosen word tokenizer. At the moment, we only support a",
        "single tokenizer for the text.",
        "When we tokenize the line, we need to also build up a location for the",
        "token (including length). This is place inside the line's tokens.",
        "Split out the tokens using the tokenizer.",
        "Create the tokens with the text and location.",
        "Pull out the token and figure where it is in the source file.",
        "Create a token object for this token with its location.",
        "Add the token to both the line and the content file. The content list is",
        "used when we want to do operations across all paragraphs."
    ],
    "docstrings": [],
    "functions": [
        "process",
        "splitTokens"
    ],
    "classes": []
}