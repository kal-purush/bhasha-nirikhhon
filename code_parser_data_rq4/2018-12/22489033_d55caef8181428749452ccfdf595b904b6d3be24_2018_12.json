{
    "identifiers": [
        "gym",
        "sys",
        "os",
        "numpy",
        "np",
        "tensorflow",
        "tf",
        "matplotlib",
        "pyplot",
        "plt",
        "itertools",
        "shutil",
        "threading",
        "multiprocessing",
        "nets",
        "create_networks",
        "worker",
        "Worker",
        "gym",
        "envs",
        "make",
        "ENV_NAME",
        "ENV_NAME",
        "ENV_NAME",
        "Env",
        "env",
        "action_space",
        "n",
        "env",
        "close",
        "x",
        "len",
        "x",
        "np",
        "zeros",
        "n",
        "i",
        "n",
        "max",
        "i",
        "x",
        "start",
        "i",
        "sum",
        "i",
        "start",
        "y",
        "multiprocessing",
        "cpu_count",
        "tf",
        "device",
        "tf",
        "Variable",
        "name",
        "trainable",
        "tf",
        "variable_scope",
        "vs",
        "create_networks",
        "NUM_ACTIONS",
        "itertools",
        "count",
        "worker_id",
        "NUM_WORKERS",
        "Worker",
        "name",
        "format",
        "worker_id",
        "env",
        "Env",
        "policy_net",
        "policy_net",
        "value_net",
        "value_net",
        "global_counter",
        "global_counter",
        "returns_list",
        "returns_list",
        "discount_factor",
        "max_global_steps",
        "MAX_GLOBAL_STEPS",
        "workers",
        "append",
        "worker",
        "tf",
        "Session",
        "sess",
        "sess",
        "run",
        "tf",
        "global_variables_initializer",
        "tf",
        "train",
        "Coordinator",
        "worker",
        "workers",
        "worker",
        "run",
        "sess",
        "coord",
        "STEPS_PER_UPDATE",
        "threading",
        "target",
        "worker_fn",
        "t",
        "start",
        "worker_threads",
        "append",
        "t",
        "coord",
        "join",
        "worker_threads",
        "stop_grace_period_secs",
        "np",
        "array",
        "returns_list",
        "smooth",
        "x",
        "plt",
        "plot",
        "x",
        "label",
        "plt",
        "plot",
        "y",
        "label",
        "plt",
        "legend",
        "plt",
        "show"
    ],
    "literals": [
        "\"Breakout-v0\"",
        "\"Pong-v0\"",
        "\"Breakout-v0\"",
        "\"/cpu:0\"",
        "\"global_step\"",
        "\"global\"",
        "\"worker_{}\"",
        "'orig'",
        "'smoothed'"
    ],
    "variables": [
        "ENV_NAME",
        "MAX_GLOBAL_STEPS",
        "STEPS_PER_UPDATE",
        "NUM_ACTIONS",
        "env",
        "NUM_ACTIONS",
        "n",
        "y",
        "start",
        "y",
        "i",
        "NUM_WORKERS",
        "global_step",
        "policy_net",
        "value_net",
        "global_counter",
        "returns_list",
        "workers",
        "worker",
        "coord",
        "worker_threads",
        "worker_fn",
        "t",
        "x",
        "y"
    ],
    "comments": [
        "Depending on the game we may have a limited action space",
        "env.action_space.n returns a bigger number",
        "last 100",
        "Set the number of workers",
        "Keeps track of the number of updates we've performed",
        "https://www.tensorflow.org/api_docs/python/tf/train/global_step",
        "Global policy and value nets",
        "Global step iterator",
        "Save returns",
        "Create workers",
        "Start worker threads",
        "Wait for all workers to finish",
        "Plot the smoothed returns"
    ],
    "docstrings": [],
    "functions": [
        "Env",
        "smooth"
    ],
    "classes": []
}