{
    "identifiers": [
        "chainer",
        "chainer",
        "functions",
        "F",
        "chainer",
        "links",
        "L",
        "chainer",
        "Chain",
        "n_units",
        "n_out",
        "MLP",
        "l1",
        "L",
        "Linear",
        "n_units",
        "l2",
        "L",
        "Linear",
        "n_units",
        "l3",
        "L",
        "Linear",
        "n_out",
        "x",
        "F",
        "relu",
        "l1",
        "x",
        "F",
        "relu",
        "l2",
        "h1",
        "l3",
        "h2",
        "L",
        "Classifier",
        "MLP",
        "L",
        "Classifier",
        "MLP",
        "gpu",
        "chainer",
        "cuda",
        "get_device",
        "args",
        "gpu",
        "use",
        "model",
        "to_gpu"
    ],
    "literals": [],
    "variables": [
        "h1",
        "h2",
        "model",
        "model",
        "gpu"
    ],
    "comments": [
        "the size of the inputs to each layer will be inferred",
        "n_in -> n_units",
        "n_units -> n_units",
        "n_units -> n_out",
        "-1 if use CPU",
        "Make a specified GPU current",
        "Copy the model to the GPU"
    ],
    "docstrings": [],
    "functions": [
        "__call__"
    ],
    "classes": [
        "MLP"
    ]
}