{
    "identifiers": [
        "logging",
        "argparse",
        "os",
        "time",
        "argparse",
        "torch",
        "torch",
        "nn",
        "nn",
        "torch",
        "nn",
        "functional",
        "F",
        "torch",
        "optim",
        "optim",
        "torch",
        "optim",
        "lr_scheduler",
        "StepLR",
        "MultiStepLR",
        "torchvision",
        "datasets",
        "transforms",
        "models",
        "mnist",
        "lenet",
        "LeNet",
        "models",
        "cifar10",
        "vgg",
        "VGG",
        "nni",
        "compression",
        "pytorch",
        "utils",
        "counter",
        "count_flops_params",
        "nni",
        "nni",
        "compression",
        "pytorch",
        "apply_compression_results",
        "ModelSpeedup",
        "nni",
        "algorithms",
        "compression",
        "pytorch",
        "pruning",
        "LevelPruner",
        "SlimPruner",
        "FPGMPruner",
        "L1FilterPruner",
        "L2FilterPruner",
        "AGPPruner",
        "ActivationAPoZRankFilterPruner",
        "logging",
        "getLogger",
        "_logger",
        "setLevel",
        "logging",
        "INFO",
        "LevelPruner",
        "L1FilterPruner",
        "L2FilterPruner",
        "SlimPruner",
        "AGPPruner",
        "FPGMPruner",
        "ActivationAPoZRankFilterPruner",
        "args",
        "device",
        "args",
        "dataset",
        "torch",
        "randn",
        "args",
        "test_batch_size",
        "to",
        "device",
        "args",
        "dataset",
        "torch",
        "randn",
        "args",
        "test_batch_size",
        "to",
        "device",
        "dummy_input",
        "model",
        "pruner_name",
        "device",
        "optimizer",
        "dependency_aware",
        "str2pruner",
        "pruner_name",
        "pruner_name",
        "args",
        "sparsity",
        "pruner_name",
        "args",
        "sparsity",
        "pruner_name",
        "args",
        "sparsity",
        "args",
        "sparsity",
        "dependency_aware",
        "get_dummy_input",
        "args",
        "device",
        "dummy_input",
        "pruner_cls",
        "model",
        "config_list",
        "optimizer",
        "kw_args",
        "pruner",
        "dataset",
        "data_dir",
        "batch_size",
        "test_batch_size",
        "torch",
        "cuda",
        "is_available",
        "dataset",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "datasets",
        "MNIST",
        "data_dir",
        "train",
        "download",
        "transform",
        "transforms",
        "Compose",
        "transforms",
        "ToTensor",
        "transforms",
        "Normalize",
        "batch_size",
        "batch_size",
        "shuffle",
        "kwargs",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "datasets",
        "MNIST",
        "data_dir",
        "train",
        "transform",
        "transforms",
        "Compose",
        "transforms",
        "ToTensor",
        "transforms",
        "Normalize",
        "batch_size",
        "test_batch_size",
        "shuffle",
        "kwargs",
        "torch",
        "nn",
        "NLLLoss",
        "dataset",
        "transforms",
        "Normalize",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "datasets",
        "CIFAR10",
        "data_dir",
        "train",
        "transform",
        "transforms",
        "Compose",
        "transforms",
        "RandomHorizontalFlip",
        "transforms",
        "RandomCrop",
        "transforms",
        "ToTensor",
        "normalize",
        "download",
        "batch_size",
        "batch_size",
        "shuffle",
        "kwargs",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "datasets",
        "CIFAR10",
        "data_dir",
        "train",
        "transform",
        "transforms",
        "Compose",
        "transforms",
        "ToTensor",
        "normalize",
        "batch_size",
        "batch_size",
        "shuffle",
        "kwargs",
        "torch",
        "nn",
        "CrossEntropyLoss",
        "train_loader",
        "test_loader",
        "criterion",
        "args",
        "device",
        "train_loader",
        "test_loader",
        "criterion",
        "args",
        "model",
        "LeNet",
        "to",
        "device",
        "args",
        "pretrained_model_dir",
        "torch",
        "optim",
        "Adadelta",
        "model",
        "parameters",
        "lr",
        "StepLR",
        "optimizer",
        "step_size",
        "gamma",
        "args",
        "model",
        "VGG",
        "depth",
        "to",
        "device",
        "args",
        "pretrained_model_dir",
        "torch",
        "optim",
        "SGD",
        "model",
        "parameters",
        "lr",
        "momentum",
        "weight_decay",
        "MultiStepLR",
        "optimizer",
        "milestones",
        "args",
        "pretrain_epochs",
        "args",
        "pretrain_epochs",
        "gamma",
        "args",
        "model",
        "VGG",
        "depth",
        "to",
        "device",
        "args",
        "pretrained_model_dir",
        "torch",
        "optim",
        "SGD",
        "model",
        "parameters",
        "lr",
        "momentum",
        "weight_decay",
        "MultiStepLR",
        "optimizer",
        "milestones",
        "args",
        "pretrain_epochs",
        "args",
        "pretrain_epochs",
        "gamma",
        "ValueError",
        "args",
        "pretrained_model_dir",
        "epoch",
        "args",
        "pretrain_epochs",
        "train",
        "args",
        "model",
        "device",
        "train_loader",
        "criterion",
        "optimizer",
        "epoch",
        "sparse_bn",
        "args",
        "pruner",
        "scheduler",
        "step",
        "test",
        "args",
        "model",
        "device",
        "criterion",
        "test_loader",
        "acc",
        "best_acc",
        "acc",
        "model",
        "state_dict",
        "model",
        "load_state_dict",
        "state_dict",
        "best_acc",
        "torch",
        "save",
        "state_dict",
        "os",
        "path",
        "join",
        "args",
        "experiment_data_dir",
        "args",
        "dataset",
        "args",
        "model",
        "args",
        "experiment_data_dir",
        "model",
        "load_state_dict",
        "torch",
        "load",
        "args",
        "pretrained_model_dir",
        "test",
        "args",
        "model",
        "device",
        "criterion",
        "test_loader",
        "torch",
        "optim",
        "SGD",
        "model",
        "parameters",
        "lr",
        "momentum",
        "weight_decay",
        "MultiStepLR",
        "optimizer",
        "milestones",
        "args",
        "pretrain_epochs",
        "args",
        "pretrain_epochs",
        "gamma",
        "best_acc",
        "model",
        "optimizer",
        "scheduler",
        "model",
        "m",
        "model",
        "modules",
        "isinstance",
        "m",
        "nn",
        "BatchNorm2d",
        "m",
        "weight",
        "grad",
        "data",
        "add_",
        "torch",
        "sign",
        "m",
        "weight",
        "data",
        "args",
        "model",
        "device",
        "train_loader",
        "criterion",
        "optimizer",
        "epoch",
        "sparse_bn",
        "model",
        "train",
        "batch_idx",
        "data",
        "target",
        "train_loader",
        "data",
        "to",
        "device",
        "target",
        "to",
        "device",
        "optimizer",
        "zero_grad",
        "model",
        "data",
        "criterion",
        "output",
        "target",
        "loss",
        "backward",
        "sparse_bn",
        "updateBN",
        "model",
        "optimizer",
        "step",
        "batch_idx",
        "args",
        "log_interval",
        "format",
        "epoch",
        "batch_idx",
        "len",
        "data",
        "len",
        "train_loader",
        "dataset",
        "batch_idx",
        "len",
        "train_loader",
        "loss",
        "item",
        "args",
        "dry_run",
        "args",
        "model",
        "device",
        "criterion",
        "test_loader",
        "model",
        "eval",
        "torch",
        "no_grad",
        "data",
        "target",
        "test_loader",
        "data",
        "to",
        "device",
        "target",
        "to",
        "device",
        "model",
        "data",
        "test_loss",
        "criterion",
        "output",
        "target",
        "item",
        "output",
        "argmax",
        "dim",
        "keepdim",
        "correct",
        "pred",
        "eq",
        "target",
        "view_as",
        "pred",
        "sum",
        "item",
        "test_loss",
        "len",
        "test_loader",
        "dataset",
        "correct",
        "len",
        "test_loader",
        "dataset",
        "format",
        "test_loss",
        "acc",
        "acc",
        "args",
        "torch",
        "device",
        "torch",
        "cuda",
        "is_available",
        "os",
        "makedirs",
        "args",
        "experiment_data_dir",
        "exist_ok",
        "get_data",
        "args",
        "dataset",
        "args",
        "data_dir",
        "args",
        "batch_size",
        "args",
        "test_batch_size",
        "get_model_optimizer_scheduler",
        "args",
        "device",
        "train_loader",
        "test_loader",
        "criterion",
        "get_dummy_input",
        "args",
        "device",
        "count_flops_params",
        "model",
        "dummy_input",
        "flops",
        "os",
        "path",
        "join",
        "args",
        "experiment_data_dir",
        "format",
        "args",
        "model",
        "args",
        "dataset",
        "args",
        "pruner",
        "os",
        "path",
        "join",
        "args",
        "experiment_data_dir",
        "format",
        "args",
        "model",
        "args",
        "dataset",
        "args",
        "pruner",
        "get_pruner",
        "model",
        "args",
        "pruner",
        "device",
        "optimizer",
        "args",
        "dependency_aware",
        "pruner",
        "compress",
        "args",
        "multi_gpu",
        "torch",
        "cuda",
        "device_count",
        "nn",
        "DataParallel",
        "model",
        "args",
        "test_only",
        "test",
        "args",
        "model",
        "device",
        "criterion",
        "test_loader",
        "epoch",
        "args",
        "fine_tune_epochs",
        "pruner",
        "update_epoch",
        "epoch",
        "format",
        "epoch",
        "train",
        "args",
        "model",
        "device",
        "train_loader",
        "criterion",
        "optimizer",
        "epoch",
        "scheduler",
        "step",
        "test",
        "args",
        "model",
        "device",
        "criterion",
        "test_loader",
        "top1",
        "best_top1",
        "top1",
        "pruner",
        "export_model",
        "model_path",
        "model_path",
        "mask_path",
        "mask_path",
        "args",
        "nni",
        "nni",
        "report_final_result",
        "best_top1",
        "args",
        "speed_up",
        "model_path",
        "get_model_optimizer_scheduler",
        "args",
        "device",
        "train_loader",
        "test_loader",
        "criterion",
        "model",
        "eval",
        "apply_compression_results",
        "model",
        "mask_path",
        "device",
        "time",
        "time",
        "_",
        "model",
        "dummy_input",
        "time",
        "time",
        "start",
        "ModelSpeedup",
        "model",
        "dummy_input",
        "mask_path",
        "device",
        "m_speedup",
        "speedup_model",
        "count_flops_params",
        "model",
        "dummy_input",
        "flops",
        "time",
        "time",
        "_",
        "model",
        "dummy_input",
        "time",
        "time",
        "start",
        "test",
        "args",
        "model",
        "device",
        "criterion",
        "test_loader",
        "argparse",
        "ArgumentParser",
        "description",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "choices",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "metavar",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "choices",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "parse_args",
        "args",
        "nni",
        "nni",
        "get_next_parameter",
        "main",
        "args"
    ],
    "literals": [
        "'mnist_example'",
        "'level'",
        "'l1filter'",
        "'l2filter'",
        "'slim'",
        "'agp'",
        "'fpgm'",
        "'apoz'",
        "'mnist'",
        "'cifar10'",
        "'imagenet'",
        "'level'",
        "'sparsity'",
        "'op_types'",
        "'default'",
        "'l1filter'",
        "'sparsity'",
        "'op_types'",
        "'Conv2d'",
        "'op_names'",
        "'feature.0'",
        "'feature.24'",
        "'feature.27'",
        "'feature.30'",
        "'feature.34'",
        "'feature.37'",
        "'slim'",
        "'sparsity'",
        "'op_types'",
        "'BatchNorm2d'",
        "'sparsity'",
        "'op_types'",
        "'Conv2d'",
        "'Enable the dependency_aware mode'",
        "'dependency_aware'",
        "'dummy_input'",
        "'num_workers'",
        "'pin_memory'",
        "'mnist'",
        "'cifar10'",
        "'lenet'",
        "'vgg16'",
        "'vgg19'",
        "\"model not recognized\"",
        "'start pre-training...'",
        "'slim'",
        "f'pretrain_{args.dataset}_{args.model}.pth'",
        "'Model trained saved to %s'",
        "'Pretrained model acc:'",
        "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'",
        "'Test Loss: {}  Accuracy: {}%\\n'",
        "\"cuda\"",
        "\"cpu\"",
        "f\"FLOPs: {flops}, params: {params}\"",
        "'start pruning...'",
        "'pruned_{}_{}_{}.pth'",
        "'mask_{}_{}_{}.pth'",
        "'# Epoch {} #'",
        "'elapsed time when use mask: '",
        "f\"FLOPs: {flops}, params: {params}\"",
        "'elapsed time when use speedup: '",
        "'__main__'",
        "'PyTorch Example for model comporession'",
        "'--dataset'",
        "'cifar10'",
        "'dataset to use, mnist, cifar10 or imagenet'",
        "'--data-dir'",
        "'./data/'",
        "'dataset directory'",
        "'--model'",
        "'vgg16'",
        "'LeNet'",
        "'vgg16'",
        "'vgg19'",
        "'resnet18'",
        "'model to use'",
        "'--pretrained-model-dir'",
        "'path to pretrained model'",
        "'--pretrain-epochs'",
        "'number of epochs to pretrain the model'",
        "'--batch-size'",
        "'input batch size for training'",
        "'--test-batch-size'",
        "'input batch size for testing'",
        "'--experiment-data-dir'",
        "'./experiment_data'",
        "'For saving output checkpoints'",
        "'--log-interval'",
        "'N'",
        "'how many batches to wait before logging training status'",
        "'--dry-run'",
        "'store_true'",
        "'quickly check a single pass'",
        "'--multi-gpu'",
        "'store_true'",
        "'run on mulitple gpus'",
        "'--test-only'",
        "'store_true'",
        "'run test only'",
        "'--sparsity'",
        "'target overall target sparsity'",
        "'--dependency-aware'",
        "'store_true'",
        "'toggle dependency aware mode'",
        "'--pruner'",
        "'l1filter'",
        "'level'",
        "'l1filter'",
        "'l2filter'",
        "'slim'",
        "'agp'",
        "'fpgm'",
        "'apoz'",
        "'pruner to use'",
        "'--fine-tune-epochs'",
        "'epochs to fine tune'",
        "'--speed-up'",
        "'store_true'",
        "'whether to speed-up the pruned model'",
        "'--nni'",
        "'store_true'",
        "\"whether to tune the pruners using NNi tuners\"",
        "'sparsity'",
        "'pruner'",
        "'pruner'"
    ],
    "variables": [
        "_logger",
        "str2pruner",
        "dummy_input",
        "dummy_input",
        "pruner_cls",
        "config_list",
        "config_list",
        "config_list",
        "config_list",
        "kw_args",
        "dummy_input",
        "kw_args",
        "kw_args",
        "pruner",
        "kwargs",
        "train_loader",
        "test_loader",
        "criterion",
        "normalize",
        "train_loader",
        "test_loader",
        "criterion",
        "model",
        "optimizer",
        "scheduler",
        "model",
        "optimizer",
        "scheduler",
        "model",
        "optimizer",
        "scheduler",
        "best_acc",
        "acc",
        "best_acc",
        "state_dict",
        "acc",
        "best_acc",
        "optimizer",
        "scheduler",
        "data",
        "target",
        "output",
        "loss",
        "test_loss",
        "correct",
        "data",
        "target",
        "output",
        "pred",
        "acc",
        "device",
        "train_loader",
        "test_loader",
        "criterion",
        "model",
        "optimizer",
        "scheduler",
        "dummy_input",
        "flops",
        "results",
        "model_path",
        "mask_path",
        "pruner",
        "model",
        "model",
        "best_top1",
        "top1",
        "best_top1",
        "args",
        "pretrained_model_dir",
        "model",
        "_",
        "_",
        "start",
        "use_mask_out",
        "m_speedup",
        "flops",
        "results",
        "start",
        "use_speedup_out",
        "top1",
        "parser",
        "args",
        "args",
        "sparsity",
        "args",
        "pruner",
        "args",
        "model"
    ],
    "comments": [
        "Copyright (c) Microsoft Corporation.",
        "Licensed under the MIT license.",
        "Reproduced result in paper 'PRUNING FILTERS FOR EFFICIENT CONVNETS',",
        "Conv_1, Conv_8, Conv_9, Conv_10, Conv_11, Conv_12 are pruned with 50% sparsity, as 'VGG-16-pruned-A'",
        "note that, not all pruners support the dependency_aware mode",
        "setup new opotimizer for fine-tuning",
        "L1 regularization on BN layer",
        "prepare model and data",
        "Export the best model, 'model_path' stores state_dict of the pruned model,",
        "mask_path stores mask_dict of the pruned model",
        "reload the best checkpoint for speed-up",
        "test model speed",
        "dataset and model",
        "pruner",
        "fine-tuning",
        "speed-up"
    ],
    "docstrings": [
        "'''\nNNI example for supported basic pruning algorithms.\nIn this example, we show the end-to-end pruning process: pre-training -> pruning -> fine-tuning.\nNote that pruners use masks to simulate the real pruning. In order to obtain a real compressed model, model speed up is required.\nYou can also try auto_pruners_torch.py to see the usage of some automatic pruning algorithms.\n\n'''"
    ],
    "functions": [
        "get_dummy_input",
        "get_pruner",
        "get_data",
        "get_model_optimizer_scheduler",
        "updateBN",
        "train",
        "test",
        "main"
    ],
    "classes": []
}