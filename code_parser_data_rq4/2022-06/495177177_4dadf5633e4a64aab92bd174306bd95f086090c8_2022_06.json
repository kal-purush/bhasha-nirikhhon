{
    "identifiers": [
        "cv2",
        "numpy",
        "np",
        "matplotlib",
        "pyplot",
        "plt",
        "tensorflow",
        "keras",
        "models",
        "Model",
        "tensorflow",
        "keras",
        "layers",
        "GlobalMaxPooling2D",
        "Dense",
        "tensorflow",
        "keras",
        "optimizers",
        "Adam",
        "PIL",
        "Image",
        "data",
        "plt",
        "figure",
        "figsize",
        "data",
        "class_names",
        "images",
        "labels",
        "data",
        "take",
        "i",
        "plt",
        "subplot",
        "i",
        "plt",
        "imshow",
        "images",
        "i",
        "numpy",
        "astype",
        "plt",
        "title",
        "class_names",
        "np",
        "argmax",
        "labels",
        "i",
        "plt",
        "axis",
        "model",
        "cv2",
        "ocl",
        "setUseOpenCL",
        "cv2",
        "VideoCapture",
        "cap",
        "read",
        "ret",
        "cv2",
        "CascadeClassifier",
        "facecasc",
        "detectMultiScale",
        "frame",
        "scaleFactor",
        "minNeighbors",
        "x",
        "y",
        "w",
        "h",
        "faces",
        "cv2",
        "rectangle",
        "frame",
        "x",
        "y",
        "x",
        "w",
        "y",
        "h",
        "frame",
        "y",
        "y",
        "h",
        "x",
        "x",
        "w",
        "np",
        "expand_dims",
        "cv2",
        "resize",
        "roi_gray",
        "model",
        "predict",
        "cropped_img",
        "np",
        "argmax",
        "prediction",
        "np",
        "round",
        "np",
        "prediction",
        "maxindex",
        "emotion_dict",
        "maxindex",
        "t1",
        "cv2",
        "putText",
        "frame",
        "text",
        "x",
        "y",
        "cv2",
        "FONT_HERSHEY_SIMPLEX",
        "cv2",
        "LINE_AA",
        "cv2",
        "imshow",
        "cv2",
        "resize",
        "frame",
        "interpolation",
        "cv2",
        "INTER_CUBIC",
        "cv2",
        "waitKey",
        "ord",
        "cap",
        "release",
        "cv2",
        "destroyAllWindows",
        "model",
        "frame",
        "cv2",
        "CascadeClassifier",
        "facecasc",
        "detectMultiScale",
        "frame",
        "scaleFactor",
        "minNeighbors",
        "x",
        "y",
        "w",
        "h",
        "faces",
        "cv2",
        "rectangle",
        "frame",
        "x",
        "y",
        "x",
        "w",
        "y",
        "h",
        "frame",
        "y",
        "y",
        "h",
        "x",
        "x",
        "w",
        "np",
        "expand_dims",
        "cv2",
        "resize",
        "roi_gray",
        "model",
        "predict",
        "cropped_img",
        "np",
        "argmax",
        "prediction",
        "np",
        "round",
        "np",
        "prediction",
        "maxindex",
        "emotion_dict",
        "maxindex",
        "t1",
        "cv2",
        "putText",
        "frame",
        "text",
        "x",
        "y",
        "cv2",
        "FONT_HERSHEY_SIMPLEX",
        "cv2",
        "LINE_AA",
        "cv2",
        "resize",
        "frame",
        "model_arch",
        "model_arch",
        "include_top",
        "pooling",
        "input_shape",
        "weights",
        "GlobalMaxPooling2D",
        "pretrained_model",
        "output",
        "Dense",
        "activation",
        "x",
        "Dense",
        "activation",
        "x",
        "Dense",
        "activation",
        "x",
        "Model",
        "pretrained_model",
        "input",
        "output",
        "ind",
        "cv2",
        "ocl",
        "setUseOpenCL",
        "emotion_dict",
        "ind",
        "cv2",
        "VideoCapture",
        "cap",
        "read",
        "ret",
        "cv2",
        "CascadeClassifier",
        "facecasc",
        "detectMultiScale",
        "frame",
        "scaleFactor",
        "minNeighbors",
        "x",
        "y",
        "w",
        "h",
        "faces",
        "cv2",
        "rectangle",
        "frame",
        "x",
        "y",
        "x",
        "w",
        "y",
        "h",
        "frame",
        "y",
        "y",
        "h",
        "x",
        "x",
        "w",
        "np",
        "expand_dims",
        "np",
        "expand_dims",
        "cv2",
        "resize",
        "roi_gray",
        "count",
        "c",
        "cv2",
        "imwrite",
        "path",
        "s",
        "roi_gray",
        "c",
        "cv2",
        "putText",
        "frame",
        "emotion_dict",
        "maxindex",
        "x",
        "y",
        "cv2",
        "FONT_HERSHEY_SIMPLEX",
        "cv2",
        "LINE_AA",
        "count",
        "cv2",
        "imshow",
        "cv2",
        "resize",
        "frame",
        "interpolation",
        "cv2",
        "INTER_CUBIC",
        "cv2",
        "waitKey",
        "ord",
        "cap",
        "release",
        "cv2",
        "destroyAllWindows"
    ],
    "literals": [
        "\"uint8\"",
        "\"off\"",
        "\"Angry\"",
        "\"Disgusted\"",
        "\"Fearful\"",
        "\"Happy\"",
        "\"Neutral\"",
        "\"Sad\"",
        "\"Surprised\"",
        "'haarcascade_frontalface_default.xml'",
        "\" \"",
        "'%'",
        "'Video'",
        "'q'",
        "\"Angry\"",
        "\"Disgusted\"",
        "\"Fearful\"",
        "\"Happy\"",
        "\"Neutral\"",
        "\"Sad\"",
        "\"Surprised\"",
        "'haarcascade_frontalface_default.xml'",
        "\" \"",
        "'%'",
        "'none'",
        "'imagenet'",
        "'relu'",
        "'relu'",
        "'softmax'",
        "\"Angry\"",
        "\"Disgusted\"",
        "\"Fearful\"",
        "\"Happy\"",
        "\"Neutral\"",
        "\"Sad\"",
        "\"Surprised\"",
        "'data/'",
        "'haarcascade_frontalface_default.xml'",
        "\"XframeN%dF%d.jpg\"",
        "'Video'",
        "'q'"
    ],
    "variables": [
        "class_names",
        "ax",
        "emotion_dict",
        "cap",
        "ret",
        "frame",
        "facecasc",
        "faces",
        "roi_gray",
        "cropped_img",
        "prediction",
        "maxindex",
        "t1",
        "text",
        "emotion_dict",
        "facecasc",
        "faces",
        "roi_gray",
        "cropped_img",
        "prediction",
        "maxindex",
        "t1",
        "text",
        "pretrained_model",
        "pretrained_model",
        "trainable",
        "x",
        "x",
        "x",
        "output",
        "emotion_dict",
        "path",
        "count",
        "cap",
        "ret",
        "frame",
        "facecasc",
        "faces",
        "c",
        "roi_gray",
        "cropped_img",
        "s",
        "maxindex"
    ],
    "comments": [
        "prevents openCL usage and unnecessary logging messages",
        "dictionary which assigns each label an emotion (alphabetical order)",
        "start the webcam feed",
        "Find haar cascade to draw bounding box around face",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)",
        "faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)",
        "cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)",
        "print(prediction)",
        "prevents openCL usage and unnecessary logging messages",
        "dictionary which assigns each label an emotion (alphabetical order)",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
        "cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)",
        "print(prediction)",
        "prevents openCL usage and unnecessary logging messages",
        "dictionary which assigns each label an emotion (alphabetical order)",
        "start the webcam feed",
        "Find haar cascade to draw bounding box around face",
        "cv2.imwrite(\"tmp.jpg\", frame)",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)",
        "faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)",
        "prediction = model.predict(cropped_img)",
        "maxindex = int(np.argmax(prediction))"
    ],
    "docstrings": [],
    "functions": [
        "plot_images",
        "emotion_detection",
        "detectImage",
        "get_model",
        "emotion"
    ],
    "classes": []
}