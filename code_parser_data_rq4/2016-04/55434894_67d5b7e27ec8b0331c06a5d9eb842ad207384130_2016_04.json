{
    "identifiers": [
        "numpy",
        "np",
        "util",
        "bagger",
        "util",
        "splitter",
        "split",
        "split",
        "np",
        "array",
        "len",
        "train",
        "np",
        "array",
        "len",
        "test",
        "train",
        "train_beta",
        "bagger",
        "bag",
        "train_idx",
        "size",
        "bag_size",
        "bagger",
        "bag",
        "test_idx",
        "size",
        "bag_size",
        "bagger",
        "random_combination",
        "tr_bag",
        "te_bag",
        "bag",
        "bag_pairs",
        "len",
        "bag",
        "len",
        "bag",
        "main"
    ],
    "literals": [
        "'../dataset/powersupply.arff'",
        "'beta'",
        "'__main__'"
    ],
    "variables": [
        "train",
        "train_beta",
        "test",
        "train_idx",
        "test_idx",
        "sigma",
        "bag_size",
        "tr_bag",
        "te_bag",
        "bag_pairs"
    ],
    "comments": [
        "from util import kmm",
        "from pyspark import SparkContext",
        "tr_data = sc.broadcast(train)",
        "te_data = sc.broadcast(test)",
        "bag_pairs = bagger.cartesian(tr_bag, te_bag)",
        "bag_index_rdd = sc.parallelize(bag_pairs)",
        "bag_index_rdd.map(lambda (tr, te): kmm(tr_data.value[tr], te_data.value[te], sigma))",
        "bag_index_rdd.collect()",
        "sc = SparkContext(appName=\"PythonPartitioning\", pyFiles=['lib.zip'])"
    ],
    "docstrings": [],
    "functions": [
        "main"
    ],
    "classes": []
}