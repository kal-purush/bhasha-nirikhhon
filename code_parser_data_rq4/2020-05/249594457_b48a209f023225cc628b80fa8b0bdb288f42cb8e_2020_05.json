{
    "identifiers": [
        "keras",
        "models",
        "load_model",
        "numpy",
        "np",
        "face_recognition",
        "cv2",
        "img",
        "resize_dims",
        "cv2",
        "resize",
        "img",
        "resize_dims",
        "face_recognition",
        "face_locations",
        "image",
        "model",
        "face_locations",
        "face_locations",
        "image",
        "top",
        "bottom",
        "left",
        "right",
        "face_image",
        "shape",
        "img",
        "img",
        "resize_dims",
        "cv2",
        "resize",
        "img",
        "resize_dims",
        "cv2",
        "cvtColor",
        "face_image",
        "cv2",
        "COLOR_BGR2GRAY",
        "np",
        "reshape",
        "face_image",
        "face_image",
        "shape",
        "face_image",
        "shape",
        "face_image",
        "frame",
        "model",
        "model_path",
        "initial_resize_dims",
        "get_face_image",
        "frame",
        "resize_dims",
        "postprocess",
        "face_image",
        "np",
        "argmax",
        "model",
        "predict",
        "face_image",
        "v",
        "k",
        "k",
        "v",
        "emotion_dict",
        "items",
        "label_map",
        "predicted_class",
        "predicted_label",
        "predicted_class",
        "predicted_class",
        "predicted_class"
    ],
    "literals": [
        "'Angry'",
        "'Sad'",
        "'Neutral'",
        "'Disgust'",
        "'Surprise'",
        "'Fear'",
        "'Happy'",
        "\"cnn\""
    ],
    "variables": [
        "emotion_dict",
        "image",
        "face_locations",
        "top",
        "right",
        "bottom",
        "left",
        "face_image",
        "face_image",
        "face_image",
        "face_image",
        "face_image",
        "face_image",
        "predicted_class",
        "label_map",
        "predicted_label"
    ],
    "comments": [
        "model = load_model('weights/model_v6_23.hdf5')",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)",
        "face_locations = faceCascade.detectMultiScale(",
        "gray,",
        "scaleFactor=1.5,",
        "minNeighbors=5,",
        "minSize=(30, 30),",
        "flags=cv2.CASCADE_SCALE_IMAGE",
        ")",
        "x, y, w, h = face_locations[0]",
        "face_image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)",
        "read the image and preprocess it",
        "",
        "img_path = '/Users/saumya/Desktop/trial_runs/266f6f25-7597-44f6-85d9-e31d17fd7066/1.png'",
        "image = cv2.imread(img_path)",
        "",
        "prediction_on_frame(image, model)"
    ],
    "docstrings": [
        "\"\"\"\n## Using pre-trained model from https://github.com/priya-dwivedi/face_and_emotion_detection\n\"\"\""
    ],
    "functions": [
        "get_face_image",
        "postprocess",
        "emotion_prediction_on_frame"
    ],
    "classes": []
}