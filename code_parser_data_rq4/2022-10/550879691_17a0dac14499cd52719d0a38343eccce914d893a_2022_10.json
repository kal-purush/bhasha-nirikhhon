{
    "identifiers": [
        "matplotlib",
        "matplotlib",
        "use",
        "os",
        "os",
        "environ",
        "argparse",
        "numpy",
        "np",
        "tqdm",
        "tqdm",
        "matplotlib",
        "pyplot",
        "plt",
        "datetime",
        "keras",
        "layers",
        "Input",
        "keras",
        "models",
        "Model",
        "Sequential",
        "keras",
        "layers",
        "core",
        "Reshape",
        "Dense",
        "Dropout",
        "Flatten",
        "keras",
        "layers",
        "advanced_activations",
        "LeakyReLU",
        "keras",
        "layers",
        "convolutional",
        "Convolution2D",
        "UpSampling2D",
        "keras",
        "layers",
        "BatchNormalization",
        "keras",
        "datasets",
        "mnist",
        "keras",
        "optimizers",
        "Adam",
        "keras",
        "backend",
        "K",
        "keras",
        "initializers",
        "random",
        "sklearn",
        "model_selection",
        "train_test_split",
        "sklearn",
        "metrics",
        "mean_squared_error",
        "sklearn",
        "preprocessing",
        "MinMaxScaler",
        "pickle",
        "model",
        "dirtopology",
        "model_name",
        "open",
        "dirtopology",
        "model_name",
        "fh",
        "model",
        "summary",
        "print_fn",
        "x",
        "fh",
        "write",
        "x",
        "X",
        "input_minmax_scaler",
        "input_minmax_scaler",
        "MinMaxScaler",
        "feature_range",
        "copy",
        "input_minmax_scaler",
        "fit_transform",
        "X",
        "input_minmax_scaler",
        "filename",
        "filename",
        "np",
        "loadtxt",
        "filename",
        "delimiter",
        "sci_minmax",
        "input_data",
        "input_data",
        "shape",
        "input_data",
        "shape",
        "rows",
        "input_data",
        "reshape",
        "input_data",
        "shape",
        "rows",
        "cols",
        "rows",
        "X_train",
        "shape",
        "input_data",
        "input_data",
        "shape",
        "rows",
        "input_data",
        "reshape",
        "input_data",
        "shape",
        "rows",
        "cols",
        "rows",
        "X_train",
        "shape",
        "X_train",
        "input_minmax_scaler",
        "epoch",
        "dirr",
        "batch",
        "plt",
        "figure",
        "figsize",
        "plt",
        "plot",
        "dLosses",
        "label",
        "plt",
        "plot",
        "gLosses",
        "label",
        "plt",
        "xlabel",
        "plt",
        "ylabel",
        "plt",
        "legend",
        "plt",
        "savefig",
        "dirr",
        "batch",
        "epoch",
        "np",
        "savetxt",
        "dirr",
        "batch",
        "np",
        "array",
        "dLosses",
        "fmt",
        "delimiter",
        "np",
        "savetxt",
        "dirr",
        "batch",
        "np",
        "array",
        "gLosses",
        "fmt",
        "delimiter",
        "epoch",
        "dirr",
        "batch",
        "examples",
        "np",
        "random",
        "uniform",
        "size",
        "examples",
        "randomDim",
        "generator",
        "predict",
        "noise",
        "generated_movements",
        "reshape",
        "examples",
        "rows",
        "cols",
        "i",
        "movement",
        "generated_movements",
        "start",
        "np",
        "savetxt",
        "dirr",
        "batch",
        "epoch",
        "i",
        "input_minmax_scaler",
        "inverse_transform",
        "movement",
        "fmt",
        "delimiter",
        "epoch",
        "dirmodels",
        "gen",
        "discr",
        "gen",
        "save",
        "dirmodels",
        "epoch",
        "discr",
        "save",
        "dirmodels",
        "epoch",
        "epoch",
        "dirmodels",
        "load_model",
        "dirmodels",
        "epoch",
        "load_model",
        "dirmodels",
        "epoch",
        "generatorLoad",
        "discriminatorLoad",
        "epochs",
        "batchSize",
        "unit_of_movement",
        "n_example",
        "train_file",
        "mocap",
        "Adam",
        "lr",
        "beta_1",
        "generator",
        "Sequential",
        "generator",
        "add",
        "Dense",
        "input_dim",
        "randomDim",
        "kernel_initializer",
        "initializers",
        "RandomNormal",
        "stddev",
        "generator",
        "add",
        "LeakyReLU",
        "generator",
        "add",
        "Dense",
        "generator",
        "add",
        "LeakyReLU",
        "generator",
        "add",
        "Dense",
        "generator",
        "add",
        "LeakyReLU",
        "generator",
        "add",
        "Dense",
        "input_dim",
        "activation",
        "generator",
        "compile",
        "loss",
        "optimizer",
        "adam",
        "Sequential",
        "discriminator",
        "add",
        "Dense",
        "input_dim",
        "input_dim",
        "kernel_initializer",
        "initializers",
        "RandomNormal",
        "stddev",
        "discriminator",
        "add",
        "LeakyReLU",
        "discriminator",
        "add",
        "Dropout",
        "discriminator",
        "add",
        "Dense",
        "discriminator",
        "add",
        "LeakyReLU",
        "discriminator",
        "add",
        "Dropout",
        "discriminator",
        "add",
        "Dense",
        "discriminator",
        "add",
        "LeakyReLU",
        "discriminator",
        "add",
        "Dropout",
        "discriminator",
        "add",
        "Dense",
        "activation",
        "discriminator",
        "compile",
        "loss",
        "optimizer",
        "Input",
        "shape",
        "randomDim",
        "generator",
        "ganInput",
        "discriminator",
        "x",
        "Model",
        "inputs",
        "ganInput",
        "outputs",
        "ganOutput",
        "gan",
        "compile",
        "loss",
        "optimizer",
        "adam",
        "dLosses",
        "gLosses",
        "input_minmax_scaler",
        "import_data",
        "train_file",
        "X_train",
        "shape",
        "batchSize",
        "epochs",
        "batchSize",
        "batchCount",
        "e",
        "epochs",
        "e",
        "_",
        "tqdm",
        "batchCount",
        "np",
        "random",
        "uniform",
        "size",
        "batchSize",
        "randomDim",
        "X_train",
        "np",
        "random",
        "randint",
        "X_train",
        "shape",
        "size",
        "batchSize",
        "generator",
        "predict",
        "noise",
        "np",
        "concatenate",
        "imageBatch",
        "generatedImages",
        "np",
        "zeros",
        "batchSize",
        "batchSize",
        "discriminator",
        "train_on_batch",
        "X",
        "yDis",
        "np",
        "random",
        "uniform",
        "size",
        "batchSize",
        "randomDim",
        "np",
        "ones",
        "batchSize",
        "gan",
        "train_on_batch",
        "noise",
        "yGen",
        "format",
        "dloss",
        "gloss",
        "dLosses",
        "append",
        "dloss",
        "gLosses",
        "append",
        "gloss",
        "e",
        "e",
        "datetime",
        "datetime",
        "now",
        "now",
        "strftime",
        "mocap",
        "timestamp",
        "mocap",
        "epochs",
        "batchSize",
        "unit_of_movement",
        "mocap",
        "timestamp",
        "mocap",
        "epochs",
        "batchSize",
        "unit_of_movement",
        "dirmodels",
        "dirmodels",
        "e",
        "epochs",
        "os",
        "path",
        "exists",
        "dirr",
        "os",
        "makedirs",
        "dirr",
        "os",
        "path",
        "exists",
        "dirrloss",
        "os",
        "makedirs",
        "dirrloss",
        "os",
        "path",
        "exists",
        "dirmodels",
        "os",
        "makedirs",
        "dirmodels",
        "os",
        "path",
        "exists",
        "dirtopology",
        "os",
        "makedirs",
        "dirtopology",
        "saveGeneratedMovements",
        "e",
        "dirr",
        "batchSize",
        "n_example",
        "myprint",
        "discriminator",
        "dirtopology",
        "myprint",
        "generator",
        "dirtopology",
        "myprint",
        "gan",
        "dirtopology",
        "plotLoss",
        "e",
        "dirrloss",
        "batchSize",
        "saveModels",
        "e",
        "dirmodels",
        "generator",
        "discriminator",
        "open",
        "dirmodels",
        "pickle",
        "dump",
        "input_minmax_scaler",
        "filehandler",
        "protocol",
        "rows",
        "cols",
        "input_dim",
        "argparse",
        "ArgumentParser",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "parse_args",
        "args",
        "um",
        "cols",
        "rows",
        "train",
        "args",
        "e",
        "args",
        "bs",
        "args",
        "um",
        "args",
        "ne",
        "args",
        "db",
        "args",
        "mocap"
    ],
    "literals": [
        "'Agg'",
        "\"KERAS_BACKEND\"",
        "\"tensorflow\"",
        "'/'",
        "'_report.txt'",
        "'w'",
        "'\\n'",
        "\"../data/newmergeofData_025.txt\"",
        "\"../data/newmergeofData_01.txt\"",
        "\"Filename: \"",
        "';'",
        "\"input dim \"",
        "\"X_train dimension \"",
        "\"X_train dimension \"",
        "'Discriminitive loss'",
        "'Generative loss'",
        "'Epoch'",
        "'Loss'",
        "'/gan_loss_bs_'",
        "'_epoch %d.png'",
        "'/bs_'",
        "'_dLoss.csv'",
        "\"%f\"",
        "','",
        "'/bs_'",
        "'_gLoss.csv'",
        "\"%f\"",
        "','",
        "\"/n_batch_\"",
        "\"_generatedMovements_epoch_\"",
        "\"_movement_\"",
        "\".csv\"",
        "\"%f\"",
        "','",
        "'/gan_generator_epoch_%d.h5'",
        "'/gan_discriminator_epoch_%d.h5'",
        "'/gan_generator_epoch_%d.h5'",
        "'/gan_discriminator_epoch_%d.h5'",
        "'/home/bee/robotak/rsait-crss/python/gan/generation/data/input_training.txt'",
        "'openpose'",
        "'tanh'",
        "'binary_crossentropy'",
        "'sigmoid'",
        "'binary_crossentropy'",
        "'adam'",
        "'binary_crossentropy'",
        "'Epochs:'",
        "'Batch size:'",
        "'Batches per epoch:'",
        "'-'",
        "'Epoch %d'",
        "'-'",
        "'Discriminator Loss ={}, GAN loss ={}'",
        "\"%Y-%m-%d\"",
        "'../samples/'",
        "'/'",
        "'/'",
        "'_n_epochs_'",
        "\"_batchSize_\"",
        "\"_um_\"",
        "'../models/'",
        "'/'",
        "'/'",
        "'_n_epochs_'",
        "\"_batchSize_\"",
        "\"_um_\"",
        "'/loss_file/'",
        "'/topology_net/'",
        "'discriminator'",
        "'generator'",
        "'gan'",
        "'/pickle_min_maxScaler'",
        "'wb'",
        "'__main__'",
        "\"--e\"",
        "\"Number of epochs for training.\"",
        "\"--bs\"",
        "\"Batch Size \"",
        "\"--um\"",
        "\"Number of poses that composes a Unit of Movement\"",
        "\"--ne\"",
        "\"Number of example generated for each epochs\"",
        "\"--db\"",
        "'/home/bee/robotak/rsait-crss/python/gan/generation/data/input_training.txt'",
        "\"Path of the training database\"",
        "\"--mocap\"",
        "'openpose'",
        "\"Used motion capturing system\""
    ],
    "variables": [
        "randomDim",
        "input_minmax_scaler",
        "input_minmax_scaler",
        "input_data",
        "input_data",
        "input_minmax_scaler",
        "X_train",
        "input_data",
        "X_train",
        "noise",
        "generated_movements",
        "generated_movements",
        "generatorLoad",
        "discriminatorLoad",
        "adam",
        "generator",
        "discriminator",
        "discriminator",
        "trainable",
        "ganInput",
        "x",
        "ganOutput",
        "gan",
        "dLosses",
        "gLosses",
        "X_train",
        "input_minmax_scaler",
        "batchCount",
        "noise",
        "imageBatch",
        "generatedImages",
        "X",
        "yDis",
        "yDis",
        "discriminator",
        "trainable",
        "dloss",
        "noise",
        "yGen",
        "discriminator",
        "trainable",
        "gloss",
        "now",
        "timestamp",
        "dirr",
        "dirmodels",
        "dirrloss",
        "dirtopology",
        "filehandler",
        "parser",
        "args",
        "rows",
        "cols",
        "input_dim"
    ],
    "comments": [
        "!/usr/bin/env python",
        "",
        "K.set_image_dim_ordering('th')",
        "Deterministic output.",
        "Tired of seeing the same results every time? Remove the line below.",
        "np.random.seed(1000)",
        "The results are a little better when the dimensionality of the random vector is only 10.",
        "The dimensionality has been left at 100 for consistency with other GAN implementations.",
        "rows, cols = 4, 14",
        "input_shape = (4,14)",
        "input_dim = cols * rows",
        "Pass the file handle in as a lambda function to make it callable",
        "folder,namefile):",
        "mergeofData  input_training newmergeofData_025.txt newmergeofData_01.txt",
        "input_data = np.loadtxt(\"../data/newmergeofData_025.txt\",delimiter=';')",
        "",
        "for i, f in enumerate(filename, start=1):",
        "input_data_temp = np.loadtxt(f, delimiter=';')",
        "#input_data2 = np.loadtxt(\"../data/newmergeofData_01.txt\",delimiter=';')",
        "input_data=np.concatenate((input_data,input_data_temp),axis=0)",
        "Plot the loss from each batch",
        "Save The generated Movements",
        "Save the generator and discriminator networks (and weights) for later use",
        "Creation of the model",
        "Optimizer",
        "generator.add(Dense(1024))",
        "generator.add(LeakyReLU(0.2))",
        "discriminator.add(Dense(1024, input_dim=input_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))",
        "discriminator.add(LeakyReLU(0.2))",
        "discriminator.add(Dropout(0.3))",
        "discriminator.add(Dense(512))",
        "=adam)",
        "Combined network",
        "Generate fake MNIST images",
        "print np.shape(imageBatch), np.shape(generatedImages)",
        "Labels for generated and real data",
        "One-sided label smoothing",
        "Train discriminator",
        "Train generator",
        "Store loss of most recent batch from this epoch",
        "timestamp=now.strftime(\"%Y-%m-%d-%H:%M\")",
        "+ '_' + str(timestamp)",
        "+ '_' + str(timestamp)",
        "save in a file the models",
        "Plot losses from every epoch",
        "save a model",
        "save a pickle for min_max_scaler"
    ],
    "docstrings": [],
    "functions": [
        "myprint",
        "sci_minmax",
        "import_data",
        "plotLoss",
        "saveGeneratedMovements",
        "saveModels",
        "loadModels",
        "train"
    ],
    "classes": []
}