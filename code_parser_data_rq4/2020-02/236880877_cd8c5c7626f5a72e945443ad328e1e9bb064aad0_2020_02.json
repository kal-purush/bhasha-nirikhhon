{
    "identifiers": [
        "pandas",
        "pd",
        "numpy",
        "np",
        "matplotlib",
        "pyplot",
        "plt",
        "seaborn",
        "sns",
        "xgboost",
        "xgb",
        "sklearn",
        "linear_model",
        "LogisticRegression",
        "sklearn",
        "svm",
        "SVC",
        "NuSVC",
        "sklearn",
        "ensemble",
        "AdaBoostClassifier",
        "RandomForestClassifier",
        "GradientBoostingClassifier",
        "VotingClassifier",
        "sklearn",
        "tree",
        "DecisionTreeClassifier",
        "sklearn",
        "discriminant_analysis",
        "LinearDiscriminantAnalysis",
        "QuadraticDiscriminantAnalysis",
        "sklearn",
        "naive_bayes",
        "GaussianNB",
        "BernoulliNB",
        "MultinomialNB",
        "sklearn",
        "neighbors",
        "KNeighborsClassifier",
        "RadiusNeighborsClassifier",
        "sklearn",
        "decomposition",
        "PCA",
        "sklearn",
        "decomposition",
        "FastICA",
        "keras",
        "models",
        "Sequential",
        "keras",
        "layers",
        "Dense",
        "sklearn",
        "preprocessing",
        "MinMaxScaler",
        "sklearn",
        "preprocessing",
        "LabelEncoder",
        "sklearn",
        "model_selection",
        "train_test_split",
        "sklearn",
        "model_selection",
        "StratifiedKFold",
        "StratifiedShuffleSplit",
        "sklearn",
        "model_selection",
        "GridSearchCV",
        "sklearn",
        "metrics",
        "met",
        "sklearn",
        "metrics",
        "classification_report",
        "warnings",
        "warnings",
        "filterwarnings",
        "matplotlib",
        "inline",
        "pd",
        "read_csv",
        "pd",
        "read_csv",
        "testing_set",
        "training_set",
        "shape",
        "testing_set",
        "shape",
        "training_set",
        "columns",
        "testing_set",
        "columns",
        "training_set",
        "head",
        "training_set",
        "describe",
        "sns",
        "heatmap",
        "training_set",
        "isnull",
        "yticklabels",
        "cbar",
        "cmap",
        "sns",
        "heatmap",
        "testing_set",
        "isnull",
        "yticklabels",
        "cbar",
        "cmap",
        "sns",
        "set_style",
        "sns",
        "countplot",
        "x",
        "data",
        "training_set",
        "palette",
        "sns",
        "set_style",
        "sns",
        "countplot",
        "x",
        "hue",
        "data",
        "training_set",
        "palette",
        "plt",
        "title",
        "plt",
        "legend",
        "loc",
        "sns",
        "set_style",
        "sns",
        "countplot",
        "x",
        "hue",
        "data",
        "training_set",
        "palette",
        "sns",
        "set_style",
        "sns",
        "countplot",
        "x",
        "hue",
        "data",
        "training_set",
        "palette",
        "plt",
        "legend",
        "loc",
        "bbox_to_anchor",
        "sns",
        "distplot",
        "training_set",
        "dropna",
        "kde",
        "color",
        "bins",
        "sns",
        "countplot",
        "x",
        "data",
        "training_set",
        "training_set",
        "hist",
        "color",
        "bins",
        "figsize",
        "training_set",
        "isnull",
        "sum",
        "testing_set",
        "isnull",
        "sum",
        "dataset",
        "training_set",
        "testing_set",
        "dataset",
        "fillna",
        "dataset",
        "median",
        "inplace",
        "dataset",
        "fillna",
        "dataset",
        "mode",
        "inplace",
        "dataset",
        "fillna",
        "dataset",
        "median",
        "inplace",
        "training_set",
        "drop",
        "drop_column",
        "axis",
        "inplace",
        "testing_set",
        "drop",
        "drop_column",
        "axis",
        "inplace",
        "training_set",
        "isnull",
        "sum",
        "testing_set",
        "isnull",
        "sum",
        "dataset",
        "training_set",
        "testing_set",
        "dataset",
        "dataset",
        "dataset",
        "loc",
        "dataset",
        "pd",
        "qcut",
        "dataset",
        "pd",
        "cut",
        "dataset",
        "astype",
        "training_set",
        "info",
        "testing_set",
        "info",
        "training_set",
        "sample",
        "training_set",
        "training_set",
        "contains",
        "LabelEncoder",
        "dataset",
        "training_set",
        "testing_set",
        "label",
        "fit_transform",
        "dataset",
        "label",
        "fit_transform",
        "dataset",
        "label",
        "fit_transform",
        "dataset",
        "label",
        "fit_transform",
        "dataset",
        "Target",
        "training_set_x",
        "training_set_xy",
        "Target",
        "training_set_x_bin",
        "training_set_xy_bin",
        "pd",
        "get_dummies",
        "training_set",
        "training_set_x",
        "drop_first",
        "training_set_dummy",
        "columns",
        "tolist",
        "Target",
        "training_set_x_dummy",
        "training_set_xy_dummy",
        "training_set_dummy",
        "head",
        "training_set",
        "training_set_dummy",
        "pd",
        "get_dummies",
        "testing_set",
        "training_set_x",
        "drop_first",
        "MinMaxScaler",
        "ss",
        "fit_transform",
        "training_set_dummy",
        "ss",
        "fit_transform",
        "testing_set_dummy",
        "GradientBoostingClassifier",
        "AdaBoostClassifier",
        "RadiusNeighborsClassifier",
        "radius",
        "LinearDiscriminantAnalysis",
        "GaussianNB",
        "BernoulliNB",
        "KNeighborsClassifier",
        "RandomForestClassifier",
        "min_samples_leaf",
        "min_samples_split",
        "max_depth",
        "DecisionTreeClassifier",
        "LogisticRegression",
        "xgb",
        "XGBClassifier",
        "train_test_split",
        "training_set_dummy",
        "y",
        "test_size",
        "random_state",
        "Name",
        "classify",
        "classifiers",
        "items",
        "classify",
        "fit",
        "X_training",
        "y_training",
        "classify",
        "predict",
        "X_validating",
        "Name",
        "met",
        "accuracy_score",
        "y_validating",
        "y_predictng",
        "met",
        "accuracy_score",
        "y_validating",
        "y_predictng",
        "base_accuracy",
        "classify",
        "predict",
        "testing_set_dummy",
        "met",
        "accuracy_score",
        "y_validating",
        "y_predictng",
        "pd",
        "DataFrame",
        "pID",
        "predictions_test",
        "predicted_test_value",
        "to_csv",
        "index",
        "GradientBoostingClassifier",
        "RandomForestClassifier",
        "LinearDiscriminantAnalysis",
        "LogisticRegression",
        "xgb",
        "XGBClassifier",
        "VotingClassifier",
        "estimators",
        "clf1",
        "clf2",
        "clf3",
        "clf4",
        "clf5",
        "voting",
        "exTreeClf",
        "fit",
        "X_training",
        "y_training",
        "exTreeClf",
        "predict",
        "X_validating",
        "met",
        "accuracy_score",
        "y_validating",
        "y_pred",
        "exTreeClf",
        "predict",
        "testing_set_dummy",
        "pd",
        "DataFrame",
        "pID",
        "predictions_test",
        "predicted_test_value",
        "to_csv",
        "index",
        "LinearDiscriminantAnalysis",
        "xgboost",
        "fit",
        "training_set_dummy",
        "y",
        "np",
        "argwhere",
        "xgboost",
        "predict_proba",
        "testing_set_dummy",
        "pd",
        "Series",
        "np",
        "argwhere",
        "xgboost",
        "predict_proba",
        "testing_set_dummy",
        "idx",
        "test_index_with_80p",
        "training_set_dummy",
        "append",
        "testing_set_dummy",
        "iloc",
        "idx",
        "ignore_index",
        "y",
        "append",
        "y_pred_with_80p",
        "ignore_index",
        "y",
        "shape",
        "LinearDiscriminantAnalysis",
        "xgboost",
        "fit",
        "training_set_dummy",
        "y",
        "x",
        "xgboost",
        "predict",
        "testing_set_dummy",
        "predicted_test",
        "append",
        "x",
        "pd",
        "DataFrame",
        "pID",
        "predicted_test",
        "predicted_test_value",
        "to_csv",
        "index"
    ],
    "literals": [
        "'ignore'",
        "'../input/train.csv'",
        "'../input/test.csv'",
        "'PassengerId'",
        "'Dark2'",
        "'Dark2'",
        "'whitegrid'",
        "'Survived'",
        "'RdBu_r'",
        "'whitegrid'",
        "'Survived'",
        "'Sex'",
        "'RdBu_r'",
        "\"Gender vs Survived\"",
        "'top left'",
        "'whitegrid'",
        "'Survived'",
        "'Pclass'",
        "'rainbow'",
        "'whitegrid'",
        "'Survived'",
        "'Embarked'",
        "'Dark2'",
        "'top left'",
        "'Age'",
        "'darkred'",
        "'SibSp'",
        "'Fare'",
        "'green'",
        "\"\\n\"",
        "'Age'",
        "'Age'",
        "'Embarked'",
        "'Embarked'",
        "'Fare'",
        "'Fare'",
        "'PassengerId'",
        "'Cabin'",
        "'Ticket'",
        "\"-\"",
        "'FamilySize'",
        "'SibSp'",
        "'Parch'",
        "'IsAlone'",
        "'IsAlone'",
        "'FamilySize'",
        "'FareBin'",
        "'Fare'",
        "'AgeBin'",
        "'Age'",
        "\"Name\"",
        "\"Master\"",
        "'Sex_Code'",
        "'Sex'",
        "'Embarked_Code'",
        "'Embarked'",
        "'AgeBin_Code'",
        "'AgeBin'",
        "'FareBin_Code'",
        "'FareBin'",
        "'Survived'",
        "'Sex'",
        "'Pclass'",
        "'Embarked'",
        "'SibSp'",
        "'Parch'",
        "'Age'",
        "'Fare'",
        "'FamilySize'",
        "'IsAlone'",
        "'Sex_Code'",
        "'Pclass'",
        "'Embarked_Code'",
        "'SibSp'",
        "'Parch'",
        "'Age'",
        "'Fare'",
        "'Original X Y: '",
        "'\\n'",
        "'Sex_Code'",
        "'Pclass'",
        "'Embarked_Code'",
        "'FamilySize'",
        "'AgeBin_Code'",
        "'FareBin_Code'",
        "'Bin X Y: '",
        "'\\n'",
        "'Dummy X Y: '",
        "'\\n'",
        "'Survived'",
        "'Gradient Boosting Classifier'",
        "'Adaptive Boosting Classifier'",
        "'RadiusNN'",
        "'Linear Discriminant Analysis'",
        "'GaussianNB'",
        "'BerNB'",
        "'KNN'",
        "'Random Forest Classifier'",
        "'Decision Tree Classifier'",
        "'Logistic Regression'",
        "\"XGBoost\"",
        "'Accuracy Score of '",
        "\" : \"",
        "'PassengerId'",
        "'Survived'",
        "\"PredictedTestScore.csv\"",
        "'svc'",
        "'rfc'",
        "'gbc'",
        "'lr'",
        "'lda'",
        "'hard'",
        "'PassengerId'",
        "'Survived'",
        "\"PredictedTestScore.csv\"",
        "'PassengerId'",
        "'Survived'",
        "\"PredictedTestScore.csv\""
    ],
    "variables": [
        "training_set",
        "testing_set",
        "pID",
        "drop_column",
        "dataset",
        "dataset",
        "dataset",
        "dataset",
        "label",
        "dataset",
        "dataset",
        "dataset",
        "dataset",
        "Target",
        "training_set_x",
        "training_set_x_calc",
        "training_set_xy",
        "training_set_x_bin",
        "training_set_xy_bin",
        "training_set_dummy",
        "training_set_x_dummy",
        "training_set_xy_dummy",
        "y",
        "X",
        "testing_set_dummy",
        "ss",
        "training_set_dummy_ss",
        "testing_set_dummy_ss",
        "classifiers",
        "X_training",
        "X_validating",
        "y_training",
        "y_validating",
        "base_accuracy",
        "y_predictng",
        "predictions_test",
        "base_accuracy",
        "predicted_test_value",
        "clf1",
        "clf2",
        "clf3",
        "clf4",
        "clf5",
        "exTreeClf",
        "y_pred",
        "predictions_test",
        "predicted_test_value",
        "xgboost",
        "test_index_with_80p",
        "y_pred_with_80p",
        "training_set_dummy",
        "y",
        "xgboost",
        "predicted_test",
        "predicted_test_value"
    ],
    "comments": [
        "%% [markdown]",
        "# Titanic Survival with Python",
        "",
        "",
        "## Importing Libraries",
        "",
        "Let's import libraries to get started!",
        "%% [code]",
        "%% [markdown]",
        "## Dataset - Train and Test Dataset. Find columns in testing and training set and Number of records available in each set.",
        "",
        "Import the train and test dataset and verify the columns available.",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [markdown]",
        "# Data Exploration :",
        "",
        "### 'Survived' column is the target variable which needs to be predicted and is not present in testing set.",
        "",
        "%% [code]",
        "%% [code]",
        "%% [markdown]",
        "",
        "%% [markdown]",
        "## Plot the Data",
        "%% [markdown]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [markdown]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [markdown]",
        "## Data Cleaning",
        "",
        "Fill in missing age data instead of just dropping the missing age data rows. One way to do this is by filling in the mean age of all the passengers (imputation). However, we can be smarter about this and check the average age by passenger class.",
        "%% [code]",
        "%% [markdown]",
        "%% [code]",
        "complete missing age with median",
        "complete embarked with mode",
        "complete missing fare with median",
        "delete the cabin feature/column and others previously stated to exclude in train dataset",
        "%% [code]",
        "CREATE: Feature Engineering for train and test/validation dataset",
        "Discrete variables",
        "initialize to yes/1 is alone",
        "now update to no/0 if family size is greater than 1",
        "quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split",
        "dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]",
        "Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut",
        "Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html",
        "Age Bins/Buckets using cut or value bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html",
        "cleanup rare title names",
        "#print(data1['Title'].value_counts())",
        "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/",
        "title_names = (training_set['Title'].value_counts() < stat_min) #this will create a true false series with title name as index",
        "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/",
        "training_set['Title'] = training_set['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)",
        "print(training_set['Title'].value_counts())",
        "print(\"-\"*10)",
        "preview data again",
        "%% [code]",
        "%% [code]",
        "CONVERT: convert objects to category using Label Encoder for train and test/validation dataset",
        "code categorical data",
        "dataset['Title_Code'] = label.fit_transform(dataset['Title'])",
        "define y variable aka target/outcome",
        "define x variables for original features aka feature selection",
        "pretty name/values for charts",
        "coded for algorithm calculation",
        "define x variables for original w/bin features to remove continuous variables",
        "define x and y variables for dummy features original",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "ss = StandardScaler()",
        "%% [code]",
        "pca = PCA(n_components=6)",
        "X_train_pca = pca.fit_transform(training_set_dummy)",
        "X_test_pca = pca.transform(testing_set_dummy)",
        "%% [code]",
        "transformer = FastICA()",
        "X_train_ica = transformer.fit_transform(training_set_dummy)",
        "%% [code]",
        "X_test_ica = transformer.transform(testing_set_dummy)",
        "%% [markdown]",
        "# Building Machine learning Models :",
        "%% [code]",
        "Models",
        "%% [markdown]",
        "## Sampling Data",
        "%% [markdown]",
        "### Train test split",
        "%% [code]",
        "%% [code]",
        "Generate Submission File",
        "%% [markdown]",
        "### Stratified KFold Sampling",
        "%% [code]",
        "skfold = StratifiedKFold(n_splits=2,random_state=42,shuffle=True)",
        "for Name,classify in classifiers.items():",
        "for train_KF, test_KF in skfold.split(X,y):",
        "X_train,X_test = X.iloc[train_KF], X.iloc[test_KF]",
        "y_train,y_test = y.iloc[train_KF], y.iloc[test_KF]",
        "classify.fit(X_train,y_train)",
        "y_pred = classify.predict(X_test)",
        "print('Accuracy Score of '+str(Name) + \" : \" +str(met.accuracy_score(y_test,y_pred)))",
        "print(classification_report(y_test,y_pred))",
        "%% [markdown]",
        "### Stratified Shuffle Split",
        "%% [code]",
        "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=1)",
        "for Name,classify in classifiers.items():",
        "for train_KF, test_KF in sss.split(X,y):",
        "X_train,X_test = X.iloc[train_KF], X.iloc[test_KF]",
        "y_train,y_test = y.iloc[train_KF], y.iloc[test_KF]",
        "classify.fit(X_train,y_train)",
        "y_pred = classify.predict(X_test)",
        "print('Accuracy Score of '+str(Name) + \" : \" +str(met.accuracy_score(y_test,y_pred)))",
        "print(classification_report(y_test,y_pred))",
        "%% [markdown]",
        "### GridSearchCV",
        "%% [markdown]",
        "%% [code]",
        "param_grid = {'C':[5000],'gamma':[0.0001]}",
        "gscv = GridSearchCV(SVC(),param_grid)",
        "gscv.fit(X_training,y_training)",
        "predictions = gscv.predict(X_validating)",
        "print(met.accuracy_score(y_validating,predictions))",
        "print(gscv.best_params_)",
        "print(gscv.best_score_)",
        "%% [markdown]",
        "%% [code]",
        "param_grid = {'learning_rate':[0.1],\"n_estimators\":[40],'min_samples_leaf':[15],'min_samples_split':[45],\"max_depth\":[3],'loss': ['deviance'],\"max_features\":[\"auto\"]}",
        "gbccv = GridSearchCV(GradientBoostingClassifier(),param_grid)",
        "gbccv.fit(X_training,y_training)",
        "predictions_train = gbccv.predict(X_validating)",
        "print(met.accuracy_score(y_validating,predictions_train))",
        "print(gbccv.best_params_)",
        "print(gbccv.best_score_)",
        "%% [markdown]",
        "%% [code]",
        "param_grid = {'learning_rate':[0.1],'gamma':[0.4],\"n_estimator\":[10],\"max_depth\":[3]}",
        "xgbcv = GridSearchCV(xgb.XGBClassifier(),param_grid)",
        "xgbcv.fit(X_training,y_training)",
        "predictions_train = xgbcv.predict(X_validating)",
        "print(met.accuracy_score(y_validating,predictions_train))",
        "print(xgbcv.best_params_)",
        "print(xgbcv.best_score_)",
        "%% [markdown]",
        "%% [code]",
        "param_grid = {'min_samples_leaf':[10],'min_samples_split':[20],\"max_depth\":[5]}",
        "xgbcv = GridSearchCV(RandomForestClassifier(),param_grid)",
        "xgbcv.fit(X_training,y_training)",
        "predictions_train = xgbcv.predict(X_validating)",
        "print(met.accuracy_score(y_validating,predictions_train))",
        "print(xgbcv.best_params_)",
        "print(xgbcv.best_score_)",
        "%% [code]",
        "QDA = QuadraticDiscriminantAnalysis()",
        "QDA.fit(X_training,y_training)",
        "%% [code]",
        "%% [code]",
        "%% [markdown]",
        "%% [code]",
        "model = Sequential()",
        "model.add(Dense(32, input_dim=10, activation='relu'))",
        "model.add(Dense(32, activation='relu'))",
        "model.add(Dense(16, activation='relu'))",
        "model.add(Dense(8, activation='relu'))",
        "model.add(Dense(1, activation='sigmoid'))",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])",
        "%% [code]",
        "fit the keras model on the dataset",
        "model.fit(X_training, y_training, epochs=1000, batch_size=50,validation_data=(X_validating,y_validating),verbose=0)",
        "%% [code]",
        "predicted_test = []",
        "for x in model.predict_classes(X_test_ica):",
        "predicted_test.append(x[:][0])",
        "%% [code]",
        "predicted_test_value = pd.DataFrame({ 'PassengerId': pID,",
        "'Survived': predicted_test })",
        "predicted_test_value.to_csv(\"PredictedTestScore.csv\", index=False)",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]",
        "%% [code]"
    ],
    "docstrings": [
        "**Objective is to develop a classification model to predict, if a passenger survives or perishes. Let's begin our understanding of the dataset followed by widely used classification algorithm.**",
        "**By Using .info() command, we can notice that \"Age\" and \"Cabin\" column have missing values.**",
        "**Roughly 20 percent values in Age column is missing. We can make a reasonable impution on Age column. But Cabin column, we are missing approx 80% values. We'll drop the cabin column.**",
        "**Performing basic visulization with the help of Seaborn.**",
        "**The plot between Gender and Target variable, clearly suggest that more men have suffered the fate of Jack from Titanic.**",
        "**Feature Engineering - https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy**",
        "**GridSearchCV for SVC**",
        "**GridSearchCV for Gradient Boosting Classifier**",
        "**GridSearchCV for XGBoost**",
        "**GridSearchCV for Random Forest Classifier**",
        "**Deep Learning Model**"
    ],
    "functions": [],
    "classes": []
}