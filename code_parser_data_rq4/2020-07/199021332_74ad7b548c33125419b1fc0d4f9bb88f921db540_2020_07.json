{
    "identifiers": [
        "google",
        "cloud",
        "bigquery",
        "os",
        "pandas",
        "pd",
        "os",
        "environ",
        "bigquery",
        "Client",
        "project",
        "pd",
        "read_csv",
        "localfilename",
        "thousands",
        "df1",
        "astype",
        "df1",
        "apply",
        "x",
        "x",
        "zfill",
        "df1",
        "pd",
        "read_csv",
        "localfilename2",
        "thousands",
        "df2",
        "drop",
        "df2",
        "df2",
        "State",
        "index",
        "df2",
        "astype",
        "df2",
        "dtypes",
        "df2",
        "head",
        "df2",
        "apply",
        "x",
        "x",
        "zfill",
        "df2",
        "df1",
        "drop",
        "df1",
        "df1",
        "Year",
        "df1",
        "Month",
        "index",
        "new_df1",
        "head",
        "new_df1",
        "append",
        "df2",
        "ignore_index",
        "new_df1",
        "head",
        "df2"
    ],
    "literals": [
        "\"GOOGLE_APPLICATION_CREDENTIALS\"",
        "\"C:/Users/andyolson/Documents/python/jacobsmarketing-0d9cb1eb005c.json\"",
        "'jacobsmarketing'",
        "r'N:\\Data\\GeneralInfo\\labor\\reBoot\\upload\\ssamatab1_upload_test.csv'",
        "r'N:\\Data\\GeneralInfo\\labor\\reBoot\\upload\\ssamatab1_Mth_update.csv'",
        "','",
        "\"ZipCode\"",
        "\"State FIPS Code\"",
        "\"Area FIPS Code - CBSA\"",
        "\"CrossFIBS\"",
        "\"Unemployment Rate\"",
        "'CrossFIBS'",
        "'CrossFIBS'",
        "'CrossFIBS'",
        "'ZipCode'",
        "','",
        "\" PR\"",
        "\"ZipCode\"",
        "\"State FIPS Code\"",
        "\"Area FIPS Code - CBSA\"",
        "\"CrossFIBS\"",
        "\"Unemployment Rate\"",
        "\"Employment\"",
        "\"Unemployment\"",
        "'CrossFIBS'",
        "'CrossFIBS'",
        "'CrossFIBS'",
        "'ZipCode'",
        "\"---we good?---\"",
        "r'N:\\Data\\GeneralInfo\\labor\\reBoot'",
        "\"complete\""
    ],
    "variables": [
        "client",
        "localfilename",
        "localfilename2",
        "df1",
        "df1",
        "df1",
        "df2",
        "df2",
        "df2",
        "df2",
        "new_df1",
        "new_df1",
        "path_out"
    ],
    "comments": [
        "-*- coding: utf-8 -*-",
        "Google Bigquery authentication and client initiation",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/mvonoven/Projects/GCP/jacobsmarketing-a0a20419ac82.json\"",
        "was ssamatab1_upload.csv",
        "dataset_id = 'locations'  # 'locations'",
        "convert comma objects to INT",
        "zero fill on front",
        "removing NAN & (n) values ~ not working yet",
        "zero fill on front",
        "check",
        "print (df2.dtypes)",
        "print (df1.dtypes)",
        "df2.drop(df1[(df1.State == \"PR\"",
        "remove restated month -- testing",
        "https://stackoverflow.com/questions/29017525/deleting-rows-based-on-multiple-conditions-python-pandas",
        "https://stackoverflow.com/questions/52456874/drop-rows-on-multiple-conditions-in-pandas-dataframe",
        "big deal below",
        "new_df1 = new_df1.astype({\"State FIPS Code\": int, \"Unemployment Rate\": float})  # not working yet",
        "for col in [\"State FIPS Code\",\"Employment\",\"Unemployment\"]:",
        "new_df1 = new_df1.astype({col: int, \"Unemployment Rate\": float})",
        "new_df1 = new_df1.astype({\"ZipCode\": str,\"CrossFIBS\": str})",
        "add output",
        "new_df1.to_csv(path_out + '\\ssama_master.csv', index=False)"
    ],
    "docstrings": [
        "\"\"\"\nCreated on Tue Jun  9 10:47:18 2020\nsimple two file append\n  part 1 of 2 monthly updates >>> csv version\n  *** make sure update file has MSA removed and no extra fields at the end of the data (NaN)\n  - \n  \n@author: AndyOlson\n\"\"\""
    ],
    "functions": [],
    "classes": []
}