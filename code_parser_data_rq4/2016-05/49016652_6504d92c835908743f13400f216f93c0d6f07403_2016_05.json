{
    "identifiers": [
        "re",
        "matplotlib",
        "patches",
        "mpatches",
        "matplotlib",
        "pyplot",
        "plt",
        "open",
        "line",
        "reader_1",
        "r",
        "r",
        "re",
        "split",
        "line",
        "r",
        "polluters",
        "append",
        "tokens",
        "reader_1",
        "close",
        "open",
        "line",
        "reader_2",
        "r",
        "r",
        "re",
        "split",
        "line",
        "r",
        "legitimate_users",
        "append",
        "tokens",
        "reader_2",
        "close",
        "r",
        "r",
        "polluters",
        "legitimate_users",
        "len",
        "polluters",
        "len",
        "legitimate_users",
        "mpatches",
        "Patch",
        "color",
        "label",
        "mpatches",
        "Patch",
        "color",
        "label",
        "plt",
        "figure",
        "figsize",
        "plt",
        "plot",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "plt",
        "plot",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "plt",
        "legend",
        "handles",
        "bots_patch",
        "humans_patch",
        "plt",
        "axis",
        "plt",
        "ylabel",
        "plt",
        "xlabel",
        "plt",
        "title",
        "plt",
        "show",
        "plt",
        "figure",
        "figsize",
        "plt",
        "plot",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "plt",
        "plot",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "x",
        "x",
        "dataset_X",
        "len",
        "polluters",
        "plt",
        "legend",
        "handles",
        "bots_patch",
        "humans_patch",
        "plt",
        "axis",
        "plt",
        "ylabel",
        "plt",
        "xlabel",
        "plt",
        "title",
        "plt",
        "show"
    ],
    "literals": [
        "\"bots.txt\"",
        "'r'",
        "\"[\\t\\n]\"",
        "\"\"",
        "\"data read from polluters.txt\"",
        "\"humans.txt\"",
        "'r'",
        "\"[\\t\\n]\"",
        "\"\"",
        "\"data read from legitimate_users.txt\"",
        "'green'",
        "'Humans'",
        "'blue'",
        "'Bots'",
        "\"go\"",
        "\"bo\"",
        "\"Number of followers\"",
        "\"Number of followings\"",
        "\"# followers vs. # followings graph (Bots overlapping)\"",
        "\"bo\"",
        "\"go\"",
        "\"Number of followers\"",
        "\"Number of followings\"",
        "\"# followers vs. # followings graph (Humans overlapping)\""
    ],
    "variables": [
        "polluters",
        "reader_1",
        "tokens",
        "legitimate_users",
        "reader_2",
        "tokens",
        "dataset_X",
        "dataset_Y",
        "humans_patch",
        "bots_patch"
    ],
    "comments": [
        "This file reads data from polluters.txt and legitimate_users.txt and do analysis on the data",
        "Read data from polluters.txt and legitimate_users.txt",
        "Combine 2 datasets for classification, dataset_Y is the target list",
        "Plot graph of #followers / #followings to see the data distribution patterns"
    ],
    "docstrings": [
        "\"\"\"\n#Plot distribution graphs for each feature\nlabels = [\"Number of followings\", \"Number of follwers\", \"Number of tweets\", \"Length of screen name\", \"Length of self description\", \"Standard deviation difference\", \"Lag1 autocorrelation\", \"Ratio of urls over tweets\"]\ndata = [dataset_X_numberOfFollowings, dataset_X_numberOfFollowers, dataset_X_numberOfTweets, dataset_X_lengthOfScreenName, dataset_X_lengthOfDescriptionInUserProfile, dataset_X_standard_deviation_diff, dataset_X_lag1_autocorrelation, dataset_X_ratio_urls_tweets]\nweekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n\ni = 0\nfor d in data:\n    plt.plot(d, dataset_Y, 'bo')\n    xmin, xmax, ymin, ymax = plt.axis()\n    plt.axis([xmin-xmax*0.05, xmax+xmax*0.05, -0.05, 1.05])\n    plt.xlabel(labels[i])\n    plt.show()\n    i += 1\n\n\nfor d in list(range(7)):\n    dataset_X_number_tweets_d = [r[d] for r in dataset_X_number_tweets_weekdays]\n    plt.plot(dataset_X_number_tweets_d, dataset_Y, 'bo')\n    xmin, xmax, ymin, ymax = plt.axis()\n    plt.axis([xmin-xmax*0.05, xmax+xmax*0.05, -0.05, 1.05])\n    plt.xlabel(\"Number of tweets posted on \" + weekdays[d] + \"s\")\n    plt.show()\n    dataset_X_ratio_tweets_d = [r[d] for r in dataset_X_ratio_tweets_weekdays]\n    plt.plot(dataset_X_number_tweets_d, dataset_Y, 'bo')\n    xmin, xmax, ymin, ymax = plt.axis()\n    plt.axis([xmin-xmax*0.05, xmax+xmax*0.05, -0.05, 1.05])\n    plt.xlabel(\"Ratio of tweets posted on \" + weekdays[d] + \"s\")\n    plt.show()\n\n\n#Plot CDF functions for each feature\ni = 0\nfor d in data:\n    sorted_dataset_X = list(np.sort(d[:len(polluters)]))\n    yvals_1 = list(np.arange(len(sorted_dataset_X))/float(len(sorted_dataset_X)))\n    sorted_data_2 = list(np.sort(d[len(polluters):]))\n    yvals_2 = list(np.arange(len(sorted_data_2))/float(len(sorted_data_2)))\n    plt.plot(sorted_dataset_X, yvals_1, 'b')\n    plt.plot(sorted_data_2, yvals_2, 'g')\n    xmin, xmax, ymin, ymax = plt.axis()\n    plt.axis([xmin-xmax*0.05, xmax+xmax*0.05, -0.05, 1.05])\n    plt.xlabel(\"CDF - \" + labels[i])\n    plt.show()\n    i += 1\n\nfor d in list(range(7)):\n    dataset_X_number_tweets_d = [r[d] for r in dataset_X_number_tweets_weekdays]\n    sorted_dataset_X = list(np.sort(dataset_X_number_tweets_d[:len(polluters)]))\n    yvals_1 = list(np.arange(len(sorted_dataset_X))/float(len(sorted_dataset_X)))\n    sorted_data_2 = list(np.sort(dataset_X_number_tweets_d[len(polluters):]))\n    yvals_2 = list(np.arange(len(sorted_data_2))/float(len(sorted_data_2)))\n    plt.plot(sorted_dataset_X, yvals_1, 'b')\n    plt.plot(sorted_data_2, yvals_2, 'g')\n    xmin, xmax, ymin, ymax = plt.axis()\n    plt.axis([xmin-xmax*0.05, xmax+xmax*0.05, -0.05, 1.05])\n    plt.xlabel(\"CDF - Number of tweets posted on \" + weekdays[d] + \"s\")\n    plt.show()\n    \n    dataset_X_ratio_tweets_d = [r[d] for r in dataset_X_ratio_tweets_weekdays]\n    sorted_dataset_X = list(np.sort(dataset_X_ratio_tweets_d[:len(polluters)]))\n    yvals_1 = list(np.arange(len(sorted_dataset_X))/float(len(sorted_dataset_X)))\n    sorted_data_2 = list(np.sort(dataset_X_ratio_tweets_d[len(polluters):]))\n    yvals_2 = list(np.arange(len(sorted_data_2))/float(len(sorted_data_2)))\n    plt.plot(sorted_dataset_X, yvals_1, 'b')\n    plt.plot(sorted_data_2, yvals_2, 'g')\n    xmin, xmax, ymin, ymax = plt.axis()\n    plt.axis([xmin-xmax*0.05, xmax+xmax*0.05, -0.05, 1.05])\n    plt.xlabel(\"CDF - Ratio of tweets posted on \" + weekdays[d] + \"s\")\n    plt.show()  \n\n\n#Try Support Vector Classification with different kernels\n#This only works when kernel='rbf', can't figure out why\nX_train, X_test, y_train, y_test = train_test_split(dataset_X, dataset_Y, test_size = 0.8, random_state = 0)\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)\nprediction = clf.predict(X_test)\ni = 0\ne = 0\nwhile i < len(prediction):\n    if prediction[i] != y_test[i]:\n        e += 1\n    i += 1\nprint(\"# errors (total: %d): \" % len(X_test))\nprint(\"rbf: \", e)\n\"\"\""
    ],
    "functions": [],
    "classes": []
}