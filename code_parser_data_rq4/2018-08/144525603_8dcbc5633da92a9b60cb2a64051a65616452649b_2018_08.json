{
    "identifiers": [
        "absolute_import",
        "division",
        "print_function",
        "math",
        "tensorflow",
        "tf",
        "datasets",
        "dataset_factory",
        "nets",
        "nets_factory",
        "preprocessing",
        "preprocessing_factory",
        "tf",
        "contrib",
        "slim",
        "tf",
        "app",
        "flags",
        "DEFINE_integer",
        "tf",
        "app",
        "flags",
        "DEFINE_integer",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_integer",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_integer",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_string",
        "tf",
        "app",
        "flags",
        "DEFINE_float",
        "tf",
        "app",
        "flags",
        "DEFINE_integer",
        "tf",
        "app",
        "flags",
        "FLAGS",
        "_",
        "FLAGS",
        "dataset_dir",
        "ValueError",
        "tf",
        "logging",
        "set_verbosity",
        "tf",
        "logging",
        "INFO",
        "tf",
        "Graph",
        "as_default",
        "slim",
        "get_or_create_global_step",
        "dataset_factory",
        "get_dataset",
        "FLAGS",
        "dataset_name",
        "FLAGS",
        "dataset_split_name",
        "FLAGS",
        "dataset_dir",
        "nets_factory",
        "get_network_fn",
        "FLAGS",
        "model_name",
        "num_classes",
        "dataset",
        "num_classes",
        "FLAGS",
        "labels_offset",
        "is_training",
        "slim",
        "dataset_data_provider",
        "DatasetDataProvider",
        "dataset",
        "shuffle",
        "common_queue_capacity",
        "FLAGS",
        "batch_size",
        "common_queue_min",
        "FLAGS",
        "batch_size",
        "provider",
        "get",
        "label",
        "FLAGS",
        "labels_offset",
        "FLAGS",
        "preprocessing_name",
        "FLAGS",
        "model_name",
        "preprocessing_factory",
        "get_preprocessing",
        "preprocessing_name",
        "is_training",
        "FLAGS",
        "eval_image_size",
        "network_fn",
        "default_image_size",
        "image_preprocessing_fn",
        "image",
        "eval_image_size",
        "eval_image_size",
        "tf",
        "train",
        "batch",
        "image",
        "label",
        "batch_size",
        "FLAGS",
        "batch_size",
        "num_threads",
        "FLAGS",
        "num_preprocessing_threads",
        "capacity",
        "FLAGS",
        "batch_size",
        "network_fn",
        "images",
        "FLAGS",
        "moving_average_decay",
        "tf",
        "train",
        "ExponentialMovingAverage",
        "FLAGS",
        "moving_average_decay",
        "tf_global_step",
        "variable_averages",
        "variables_to_restore",
        "slim",
        "get_model_variables",
        "tf_global_step",
        "op",
        "name",
        "tf_global_step",
        "slim",
        "get_variables_to_restore",
        "logits",
        "tf",
        "argmax",
        "logits",
        "tf",
        "squeeze",
        "labels",
        "slim",
        "metrics",
        "aggregate_metric_map",
        "slim",
        "metrics",
        "streaming_accuracy",
        "predictions",
        "labels",
        "slim",
        "metrics",
        "streaming_recall_at_k",
        "logits",
        "labels",
        "name",
        "value",
        "names_to_values",
        "items",
        "name",
        "tf",
        "summary",
        "scalar",
        "summary_name",
        "value",
        "collections",
        "tf",
        "Print",
        "op",
        "value",
        "summary_name",
        "tf",
        "add_to_collection",
        "tf",
        "GraphKeys",
        "SUMMARIES",
        "op",
        "FLAGS",
        "max_num_batches",
        "FLAGS",
        "max_num_batches",
        "math",
        "ceil",
        "dataset",
        "num_samples",
        "FLAGS",
        "batch_size",
        "tf",
        "gfile",
        "IsDirectory",
        "FLAGS",
        "checkpoint_path",
        "tf",
        "train",
        "latest_checkpoint",
        "FLAGS",
        "checkpoint_path",
        "FLAGS",
        "checkpoint_path",
        "checkpoint_path",
        "tf",
        "logging",
        "info",
        "checkpoint_path",
        "slim",
        "evaluation",
        "evaluate_once",
        "master",
        "FLAGS",
        "master",
        "checkpoint_path",
        "checkpoint_path",
        "logdir",
        "FLAGS",
        "eval_dir",
        "num_evals",
        "num_batches",
        "eval_op",
        "names_to_updates",
        "values",
        "variables_to_restore",
        "variables_to_restore",
        "tf",
        "app",
        "run"
    ],
    "literals": [
        "'batch_size'",
        "'The number of samples in each batch.'",
        "'max_num_batches'",
        "'Max number of batches to evaluate by default use all.'",
        "'master'",
        "''",
        "'The address of the TensorFlow master to use.'",
        "'checkpoint_path'",
        "'/tmp/tfmodel/'",
        "'The directory where the model was written to or an absolute path to a '",
        "'checkpoint file.'",
        "'eval_dir'",
        "'/tmp/tfmodel/'",
        "'Directory where the results are saved to.'",
        "'num_preprocessing_threads'",
        "'The number of threads used to create the batches.'",
        "'dataset_name'",
        "'imagenet'",
        "'The name of the dataset to load.'",
        "'dataset_split_name'",
        "'test'",
        "'The name of the train/test split.'",
        "'dataset_dir'",
        "'The directory where the dataset files are stored.'",
        "'labels_offset'",
        "'An offset for the labels in the dataset. This flag is primarily used to '",
        "'evaluate the VGG and ResNet architectures which do not use a background '",
        "'class for the ImageNet dataset.'",
        "'model_name'",
        "'inception_v3'",
        "'The name of the architecture to evaluate.'",
        "'preprocessing_name'",
        "'The name of the preprocessing to use. If left '",
        "'as `None`, then the model_name flag is used.'",
        "'moving_average_decay'",
        "'The decay to use for the moving average.'",
        "'If left as None, then moving averages are not used.'",
        "'eval_image_size'",
        "'Eval image size'",
        "'You must supply the dataset directory with --dataset_dir'",
        "'image'",
        "'label'",
        "'-------'",
        "'Accuracy'",
        "'Recall_5'",
        "'eval/%s'",
        "'<><><>'",
        "'Evaluating %s'",
        "'__main__'"
    ],
    "variables": [
        "slim",
        "FLAGS",
        "tf_global_step",
        "dataset",
        "network_fn",
        "provider",
        "image",
        "label",
        "preprocessing_name",
        "image_preprocessing_fn",
        "eval_image_size",
        "image",
        "images",
        "labels",
        "logits",
        "_",
        "variable_averages",
        "variables_to_restore",
        "variables_to_restore",
        "variables_to_restore",
        "predictions",
        "labels",
        "names_to_values",
        "names_to_updates",
        "summary_name",
        "op",
        "op",
        "num_batches",
        "num_batches",
        "checkpoint_path",
        "checkpoint_path"
    ],
    "comments": [
        "Copyright 2016 The TensorFlow Authors. All Rights Reserved.",
        "",
        "Licensed under the Apache License, Version 2.0 (the \"License\");",
        "you may not use this file except in compliance with the License.",
        "You may obtain a copy of the License at",
        "",
        "http://www.apache.org/licenses/LICENSE-2.0",
        "",
        "Unless required by applicable law or agreed to in writing, software",
        "distributed under the License is distributed on an \"AS IS\" BASIS,",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
        "See the License for the specific language governing permissions and",
        "limitations under the License.",
        "==============================================================================",
        "",
        "Select the dataset #",
        "",
        "",
        "Select the model #",
        "",
        "",
        "Create a dataset provider that loads data from the dataset #",
        "",
        "",
        "Select the preprocessing function #",
        "",
        "",
        "Define the model #",
        "",
        "Define the metrics:",
        "Print the summaries to screen.",
        "TODO(sguada) use num_epochs=1",
        "This ensures that we make a single pass over all of the data."
    ],
    "docstrings": [
        "\"\"\"Generic evaluation script that evaluates a model using a given dataset.\"\"\""
    ],
    "functions": [
        "main"
    ],
    "classes": []
}