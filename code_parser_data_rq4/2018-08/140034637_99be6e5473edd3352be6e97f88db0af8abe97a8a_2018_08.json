{
    "identifiers": [
        "print_function",
        "keras",
        "callbacks",
        "LambdaCallback",
        "keras",
        "models",
        "Sequential",
        "keras",
        "layers",
        "Dense",
        "Activation",
        "keras",
        "layers",
        "LSTM",
        "keras",
        "optimizers",
        "RMSprop",
        "keras",
        "utils",
        "data_utils",
        "get_file",
        "numpy",
        "np",
        "random",
        "sys",
        "io",
        "io",
        "open",
        "path",
        "encoding",
        "f",
        "f",
        "read",
        "lower",
        "len",
        "text",
        "sorted",
        "text",
        "len",
        "chars",
        "c",
        "i",
        "i",
        "c",
        "chars",
        "i",
        "c",
        "i",
        "c",
        "chars",
        "i",
        "len",
        "text",
        "maxlen",
        "step",
        "sentences",
        "append",
        "text",
        "i",
        "i",
        "maxlen",
        "next_chars",
        "append",
        "text",
        "i",
        "maxlen",
        "len",
        "sentences",
        "np",
        "zeros",
        "len",
        "sentences",
        "maxlen",
        "len",
        "chars",
        "dtype",
        "np",
        "np",
        "zeros",
        "len",
        "sentences",
        "len",
        "chars",
        "dtype",
        "np",
        "i",
        "sentence",
        "sentences",
        "t",
        "sentence",
        "char_indices",
        "char_indices",
        "next_chars",
        "i",
        "Sequential",
        "model",
        "add",
        "LSTM",
        "input_shape",
        "maxlen",
        "len",
        "chars",
        "model",
        "add",
        "Dense",
        "len",
        "chars",
        "model",
        "add",
        "Activation",
        "RMSprop",
        "lr",
        "model",
        "compile",
        "loss",
        "optimizer",
        "optimizer",
        "preds",
        "temperature",
        "np",
        "asarray",
        "preds",
        "astype",
        "np",
        "log",
        "preds",
        "temperature",
        "np",
        "exp",
        "preds",
        "exp_preds",
        "np",
        "sum",
        "exp_preds",
        "np",
        "random",
        "multinomial",
        "preds",
        "np",
        "argmax",
        "probas",
        "epoch",
        "logs",
        "epoch",
        "random",
        "randint",
        "len",
        "text",
        "maxlen",
        "diversity",
        "diversity",
        "text",
        "start_index",
        "start_index",
        "maxlen",
        "generated",
        "sentence",
        "sentence",
        "sys",
        "stdout",
        "write",
        "generated",
        "i",
        "np",
        "zeros",
        "maxlen",
        "len",
        "chars",
        "t",
        "sentence",
        "char_indices",
        "model",
        "predict",
        "x_pred",
        "verbose",
        "sample",
        "preds",
        "diversity",
        "indices_char",
        "next_index",
        "generated",
        "next_char",
        "sentence",
        "next_char",
        "sys",
        "stdout",
        "write",
        "next_char",
        "sys",
        "stdout",
        "flush",
        "LambdaCallback",
        "on_epoch_end",
        "on_epoch_end",
        "model",
        "fit",
        "x",
        "y",
        "batch_size",
        "epochs",
        "callbacks",
        "print_callback",
        "model",
        "save"
    ],
    "literals": [
        "'data/suicide_notes.txt'",
        "'utf-8'",
        "'corpus length:'",
        "'total chars:'",
        "'nb sequences:'",
        "'Vectorization...'",
        "'Build model...'",
        "'softmax'",
        "'categorical_crossentropy'",
        "'float64'",
        "'----- Generating text after Epoch: %d'",
        "'----- diversity:'",
        "''",
        "'----- Generating with seed: \"'",
        "'\"'",
        "'output/suicide_generator_model.h5'"
    ],
    "variables": [
        "path",
        "text",
        "chars",
        "char_indices",
        "indices_char",
        "maxlen",
        "step",
        "sentences",
        "next_chars",
        "x",
        "y",
        "x",
        "i",
        "t",
        "y",
        "i",
        "model",
        "optimizer",
        "preds",
        "preds",
        "exp_preds",
        "preds",
        "probas",
        "start_index",
        "generated",
        "sentence",
        "x_pred",
        "x_pred",
        "t",
        "preds",
        "next_index",
        "next_char",
        "sentence",
        "print_callback"
    ],
    "comments": [
        "cut the text in semi-redundant sequences of maxlen characters",
        "build the model: a single LSTM",
        "helper function to sample an index from a probability array",
        "Function invoked at end of each epoch. Prints generated text."
    ],
    "docstrings": [
        "'''Example script to generate text from Nietzsche's writings.\n\nAt least 20 epochs are required before the generated text\nstarts sounding coherent.\n\nIt is recommended to run this script on GPU, as recurrent\nnetworks are quite computationally intensive.\n\nIf you try this script on new data, make sure your corpus\nhas at least ~100k characters. ~1M is better.\n'''"
    ],
    "functions": [
        "sample",
        "on_epoch_end"
    ],
    "classes": []
}