{
    "identifiers": [
        "os",
        "path",
        "math",
        "sys",
        "re",
        "random",
        "wordlist",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "stopwords",
        "w",
        "w",
        "wordlist",
        "w",
        "stopwords",
        "filename",
        "open",
        "filename",
        "encoding",
        "f",
        "f",
        "read",
        "encode",
        "c",
        "c",
        "fileName",
        "open",
        "fileName",
        "encoding",
        "file",
        "read",
        "file",
        "close",
        "text",
        "s",
        "s",
        "lower",
        "strip",
        "punctuation",
        "result",
        "text",
        "read_file",
        "path",
        "read_file",
        "path",
        "read_file",
        "word",
        "text",
        "split",
        "clean_up",
        "word",
        "re",
        "search",
        "regex",
        "nouns",
        "noun_count",
        "re",
        "search",
        "regex",
        "verbs",
        "verb_count",
        "re",
        "search",
        "regex",
        "adverbs",
        "adverb_count",
        "re",
        "search",
        "regex",
        "adjectives",
        "adjective_count",
        "noun_count",
        "verb_count",
        "adverb_count",
        "adjective_count",
        "word_types",
        "text",
        "text",
        "split",
        "period",
        "periodSplit",
        "period",
        "split",
        "exclaim",
        "exclaimSplit",
        "exclaim",
        "split",
        "question",
        "questionSplit",
        "len",
        "question",
        "finalSplit",
        "append",
        "question",
        "finalSplit",
        "text",
        "text",
        "split",
        "comma",
        "commaSplit",
        "comma",
        "split",
        "semi",
        "semiSplit",
        "semi",
        "split",
        "hyphen",
        "hyphenSplit",
        "len",
        "hyphen",
        "finalSplit",
        "append",
        "hyphen",
        "finalSplit",
        "text",
        "remove_action",
        "text",
        "splitlines",
        "text",
        "line",
        "lines",
        "len",
        "line",
        "line",
        "strip",
        "line",
        "split",
        "line",
        "len",
        "line",
        "line",
        "speaker",
        "dialogue",
        "dialogue",
        "speaker",
        "speech",
        "dialogue",
        "text",
        "re",
        "sub",
        "text",
        "text",
        "text",
        "split",
        "word",
        "words",
        "clean_up",
        "word",
        "length",
        "len",
        "word",
        "totalWords",
        "totalWords",
        "length",
        "totalWords",
        "text",
        "text",
        "split",
        "word",
        "words",
        "clean_up",
        "word",
        "word",
        "distinctWords",
        "distinctWords",
        "append",
        "word",
        "len",
        "words",
        "len",
        "distinctWords",
        "len",
        "words",
        "text",
        "text",
        "split",
        "word",
        "words",
        "clean_up",
        "word",
        "word",
        "allWords",
        "uniqueWords",
        "append",
        "word",
        "word",
        "uniqueWords",
        "uniqueWords",
        "remove",
        "word",
        "allWords",
        "append",
        "word",
        "len",
        "words",
        "len",
        "uniqueWords",
        "len",
        "words",
        "text",
        "len",
        "split_sentence",
        "text",
        "sentences",
        "len",
        "text",
        "split",
        "sentences",
        "text",
        "len",
        "split_sentence",
        "text",
        "sentences",
        "len",
        "split_phrase",
        "text",
        "len",
        "split_sentence",
        "text",
        "text",
        "text",
        "lower",
        "re",
        "findall",
        "text",
        "len",
        "text",
        "split",
        "words",
        "len",
        "filler",
        "len",
        "text",
        "split",
        "text",
        "re",
        "findall",
        "text",
        "len",
        "obscenities",
        "text",
        "len",
        "re",
        "findall",
        "text",
        "text",
        "fullPhrase",
        "full",
        "fullPhrase",
        "fullPhrases",
        "len",
        "re",
        "findall",
        "regex",
        "text",
        "contraction",
        "contraction",
        "contractions",
        "len",
        "re",
        "findall",
        "regex",
        "text",
        "fullPhrases",
        "contractions",
        "fullPhrases",
        "text",
        "text",
        "split",
        "re",
        "findall",
        "text",
        "len",
        "words",
        "numWords",
        "len",
        "religiousWords",
        "numWords",
        "text",
        "text",
        "split",
        "re",
        "findall",
        "text",
        "len",
        "words",
        "numWords",
        "len",
        "religiousWords",
        "numWords",
        "sig1",
        "sig2",
        "weight",
        "x",
        "difference",
        "abs",
        "sig1",
        "x",
        "sig2",
        "x",
        "weight",
        "x",
        "difference",
        "attributes",
        "resultSet",
        "compare_signatures",
        "attributes",
        "resultSet",
        "weight",
        "resultSet",
        "resultSet",
        "compare_signatures",
        "attributes",
        "resultSet",
        "weight",
        "diff",
        "min",
        "diff",
        "match",
        "x",
        "random",
        "random",
        "weights",
        "append",
        "w",
        "weights",
        "resultSet",
        "i",
        "len",
        "resultSet",
        "i",
        "resultSet",
        "i",
        "resultSet",
        "i",
        "charSpeak",
        "avg_word_length",
        "charSpeak",
        "attributes",
        "insert",
        "wordLength",
        "type_token_ratio",
        "charSpeak",
        "attributes",
        "insert",
        "ttr",
        "hapax_legomena_ratio",
        "charSpeak",
        "attributes",
        "insert",
        "hlr",
        "avg_sentence_length",
        "charSpeak",
        "attributes",
        "insert",
        "sentenceLength",
        "avg_sentence_complexity",
        "charSpeak",
        "attributes",
        "insert",
        "complexity",
        "contraction_ratio",
        "charSpeak",
        "attributes",
        "insert",
        "contractions",
        "filler_ratio",
        "charSpeak",
        "attributes",
        "insert",
        "filler",
        "obscenity_usage",
        "charSpeak",
        "attributes",
        "insert",
        "obscenity",
        "religion_ratio",
        "charSpeak",
        "attributes",
        "insert",
        "religiousness",
        "elf_ratio",
        "charSpeak",
        "attributes",
        "insert",
        "elfiness",
        "attributes",
        "resultSet",
        "resultSet",
        "keys",
        "resultSet",
        "print_result",
        "resultSet",
        "control",
        "test",
        "get_attributes",
        "remove_action",
        "test",
        "get_result_set",
        "control",
        "find_match",
        "test",
        "resultSet",
        "control",
        "attribute_text",
        "remove_action",
        "control",
        "character",
        "dialogue",
        "keys",
        "get_attributes",
        "dialogue",
        "character",
        "attributes",
        "resultSet",
        "character",
        "read_file",
        "sys",
        "argv",
        "attribute_text",
        "remove_action",
        "file",
        "dialogue",
        "character",
        "read_file",
        "path",
        "filename",
        "read_file",
        "path",
        "word_type_count",
        "test",
        "print_all",
        "get_result_set",
        "control",
        "find_author",
        "control",
        "test",
        "main"
    ],
    "literals": [
        "'a'",
        "'about'",
        "'above'",
        "'across'",
        "'after'",
        "'afterwards'",
        "'again'",
        "'against'",
        "'all'",
        "'almost'",
        "'alone'",
        "'along'",
        "'already'",
        "'also'",
        "'although'",
        "'always'",
        "'am'",
        "'among'",
        "'amongst'",
        "'amoungst'",
        "'amount'",
        "'an'",
        "'and'",
        "'another'",
        "'any'",
        "'anyhow'",
        "'anyone'",
        "'anything'",
        "'anyway'",
        "'anywhere'",
        "'are'",
        "'around'",
        "'as'",
        "'at'",
        "'back'",
        "'be'",
        "'became'",
        "'because'",
        "'become'",
        "'becomes'",
        "'becoming'",
        "'been'",
        "'before'",
        "'beforehand'",
        "'behind'",
        "'being'",
        "'below'",
        "'beside'",
        "'besides'",
        "'between'",
        "'beyond'",
        "'bill'",
        "'both'",
        "'bottom'",
        "'but'",
        "'by'",
        "'call'",
        "'can'",
        "'cannot'",
        "'cant'",
        "'co'",
        "'computer'",
        "'con'",
        "'could'",
        "'couldnt'",
        "'cry'",
        "'de'",
        "'describe'",
        "'detail'",
        "'did'",
        "'do'",
        "'done'",
        "'down'",
        "'due'",
        "'during'",
        "'each'",
        "'eg'",
        "'eight'",
        "'either'",
        "'eleven'",
        "'else'",
        "'elsewhere'",
        "'empty'",
        "'enough'",
        "'etc'",
        "'even'",
        "'ever'",
        "'every'",
        "'everyone'",
        "'everything'",
        "'everywhere'",
        "'except'",
        "'few'",
        "'fifteen'",
        "'fifty'",
        "'fill'",
        "'find'",
        "'fire'",
        "'first'",
        "'five'",
        "'for'",
        "'former'",
        "'formerly'",
        "'forty'",
        "'found'",
        "'four'",
        "'from'",
        "'front'",
        "'full'",
        "'further'",
        "'get'",
        "'give'",
        "'go'",
        "'had'",
        "'has'",
        "'hasnt'",
        "'have'",
        "'he'",
        "'hence'",
        "'her'",
        "'here'",
        "'hereafter'",
        "'hereby'",
        "'herein'",
        "'hereupon'",
        "'hers'",
        "'herself'",
        "'him'",
        "'himself'",
        "'his'",
        "'how'",
        "'however'",
        "'hundred'",
        "'i'",
        "'ie'",
        "'if'",
        "'in'",
        "'inc'",
        "'indeed'",
        "'interest'",
        "'into'",
        "'is'",
        "'it'",
        "'its'",
        "'itself'",
        "'keep'",
        "'last'",
        "'latter'",
        "'latterly'",
        "'least'",
        "'less'",
        "'ltd'",
        "'made'",
        "'many'",
        "'may'",
        "'me'",
        "'meanwhile'",
        "'might'",
        "'mill'",
        "'mine'",
        "'more'",
        "'moreover'",
        "'most'",
        "'mostly'",
        "'move'",
        "'much'",
        "'must'",
        "'my'",
        "'myself'",
        "'name'",
        "'namely'",
        "'neither'",
        "'never'",
        "'nevertheless'",
        "'next'",
        "'nine'",
        "'no'",
        "'nobody'",
        "'none'",
        "'noone'",
        "'nor'",
        "'not'",
        "'nothing'",
        "'now'",
        "'nowhere'",
        "'of'",
        "'off'",
        "'often'",
        "'on'",
        "'once'",
        "'one'",
        "'only'",
        "'onto'",
        "'or'",
        "'other'",
        "'others'",
        "'otherwise'",
        "'our'",
        "'ours'",
        "'ourselves'",
        "'out'",
        "'over'",
        "'own'",
        "'part'",
        "'per'",
        "'perhaps'",
        "'please'",
        "'put'",
        "'rather'",
        "'re'",
        "'s'",
        "'same'",
        "'see'",
        "'seem'",
        "'seemed'",
        "'seeming'",
        "'seems'",
        "'serious'",
        "'several'",
        "'she'",
        "'should'",
        "'show'",
        "'side'",
        "'since'",
        "'sincere'",
        "'six'",
        "'sixty'",
        "'so'",
        "'some'",
        "'somehow'",
        "'someone'",
        "'something'",
        "'sometime'",
        "'sometimes'",
        "'somewhere'",
        "'still'",
        "'such'",
        "'system'",
        "'take'",
        "'ten'",
        "'than'",
        "'that'",
        "'the'",
        "'their'",
        "'them'",
        "'themselves'",
        "'then'",
        "'thence'",
        "'there'",
        "'thereafter'",
        "'thereby'",
        "'therefore'",
        "'therein'",
        "'thereupon'",
        "'these'",
        "'they'",
        "'thick'",
        "'thin'",
        "'third'",
        "'this'",
        "'those'",
        "'though'",
        "'three'",
        "'three'",
        "'through'",
        "'throughout'",
        "'thru'",
        "'thus'",
        "'to'",
        "'together'",
        "'too'",
        "'top'",
        "'toward'",
        "'towards'",
        "'twelve'",
        "'twenty'",
        "'two'",
        "'un'",
        "'under'",
        "'until'",
        "'up'",
        "'upon'",
        "'us'",
        "'very'",
        "'via'",
        "'was'",
        "'we'",
        "'well'",
        "'were'",
        "'what'",
        "'whatever'",
        "'when'",
        "'whence'",
        "'whenever'",
        "'where'",
        "'whereafter'",
        "'whereas'",
        "'whereby'",
        "'wherein'",
        "'whereupon'",
        "'wherever'",
        "'whether'",
        "'which'",
        "'while'",
        "'whither'",
        "'who'",
        "'whoever'",
        "'whole'",
        "'whom'",
        "'whose'",
        "'why'",
        "'will'",
        "'with'",
        "'within'",
        "'without'",
        "'would'",
        "'yet'",
        "'you'",
        "'your'",
        "'yours'",
        "'yourself'",
        "'yourselves'",
        "\"utf8\"",
        "\"utf-8\"",
        "\"End of file\"",
        "'utf-8'",
        "'D:\\CSE\\Python\\Words'",
        "r'\\Verbs\\31K_verbs.txt'",
        "r'\\Adverbs\\6K_adverbs.txt'",
        "r'D:\\CSE\\Python\\Words\\Adjectives\\28K_adjectives.txt'",
        "' '",
        "'r\\'\\b('",
        "')\\b'",
        "'.'",
        "'!'",
        "'?'",
        "','",
        "';'",
        "'-'",
        "'Alistair'",
        "''",
        "'Anders'",
        "''",
        "'Aveline'",
        "''",
        "'Bethany'",
        "''",
        "'Blackwall'",
        "''",
        "'Carver'",
        "''",
        "'Cassandra'",
        "''",
        "'Cole'",
        "''",
        "'Dorian'",
        "''",
        "'Fenris'",
        "''",
        "'Iron Bull'",
        "''",
        "'Isabela'",
        "''",
        "'Leliana'",
        "''",
        "'Loghain'",
        "''",
        "'Merrill'",
        "''",
        "'Morrigan'",
        "''",
        "'Oghren'",
        "''",
        "'Sebastian'",
        "''",
        "'Sera'",
        "''",
        "'Shale'",
        "''",
        "'Solas'",
        "''",
        "'Sten'",
        "''",
        "'Varric'",
        "''",
        "'Vivienne'",
        "''",
        "'Wynne'",
        "''",
        "''",
        "'â”€'",
        "':'",
        "'%s %s'",
        "'\\((.*?)\\)'",
        "''",
        "' '",
        "' '",
        "' '",
        "' '",
        "'( um | um,| um\\.\\.\\.| er | er,| er\\.\\.\\.| ah | ah,| ah\\.\\.\\.| uh | uh,| uh\\.\\.\\.)'",
        "' '",
        "' '",
        "'( ass | ass\\.|asshole|arse|bastard|bitch|cunt|damn|dick|douche|fuck|hell|piss|pussy|shit|slut|whore)'",
        "'fuck'",
        "'do not'",
        "'what is'",
        "'where is'",
        "'where did'",
        "'would not'",
        "'could not'",
        "'cannot'",
        "'can not'",
        "'will not'",
        "'are not'",
        "'is not'",
        "'have not'",
        "'had not'",
        "'has not'",
        "'he is'",
        "'he will'",
        "'she is'",
        "'she will'",
        "'they are'",
        "'they will'",
        "'I am'",
        "'should have'",
        "'don\\'t'",
        "'what\\'s'",
        "'where\\'s'",
        "'where\\'d'",
        "'wouldn\\'t'",
        "'couldn\\'t'",
        "'can\\'t'",
        "'won\\'t'",
        "'aren\\'t'",
        "'isn\\'t'",
        "'haven\\'t'",
        "'hasn\\'t'",
        "'hadn\\'t'",
        "'he\\'s'",
        "'he\\'ll'",
        "'she\\'s'",
        "'she\\'ll'",
        "'they\\'re'",
        "'they\\'ll'",
        "'I\\'m'",
        "'should\\'ve'",
        "' '",
        "'(Andraste|Maker|Chant|Divine|Holy)'",
        "' '",
        "r'\\b(Fen\\'Harel | Elgar\\'nan | Mythal | Falon\\'Din | Dirthamen | Sylaise | Andruil | June | Ghilan\\'nain | Arlathan)\\b'",
        "'Blackwall'",
        "'Blackwall'",
        "'%.0f'",
        "'%.4f'",
        "'\\n'",
        "''",
        "'D:\\CSE\\Python\\Test_Files'",
        "\"\\\\varric_test_2.txt\"",
        "\"\\dai_readable.txt\"",
        "'__main__'"
    ],
    "variables": [
        "stopwords",
        "c",
        "file",
        "text",
        "punctuation",
        "result",
        "path",
        "verbs",
        "adverbs",
        "adjectives",
        "noun_count",
        "verb_count",
        "adverb_count",
        "adjective_count",
        "regex",
        "word_types",
        "periodSplit",
        "finalSplit",
        "exclaimSplit",
        "questionSplit",
        "commaSplit",
        "finalSplit",
        "semiSplit",
        "hyphenSplit",
        "text",
        "lines",
        "dialogue",
        "speech",
        "line",
        "speaker",
        "speech",
        "dialogue",
        "speaker",
        "words",
        "totalWords",
        "length",
        "word",
        "words",
        "distinctWords",
        "word",
        "words",
        "allWords",
        "uniqueWords",
        "word",
        "sentences",
        "sentences",
        "text",
        "filler",
        "words",
        "obscenities",
        "full",
        "fullPhrases",
        "contractions",
        "regex",
        "regex",
        "words",
        "religiousWords",
        "numWords",
        "words",
        "religiousWords",
        "numWords",
        "difference",
        "weight",
        "min",
        "match",
        "diff",
        "min",
        "match",
        "weights",
        "w",
        "attributes",
        "wordLength",
        "ttr",
        "hlr",
        "sentenceLength",
        "complexity",
        "contractions",
        "filler",
        "obscenity",
        "religiousness",
        "elfiness",
        "test",
        "resultSet",
        "dialogue",
        "resultSet",
        "attributes",
        "resultSet",
        "character",
        "file",
        "dialogue",
        "path",
        "filename",
        "test",
        "control"
    ],
    "comments": [
        "nouns = read_file(path + \"\\Nouns\\91K_nouns.txt\")",
        "This is as close as I'm gonna get to type safety here",
        "If you get -1 something's fucked"
    ],
    "docstrings": [
        "''' Return a version of string str in which all letters have been\n    converted to lowercase and punctuation characters have been stripped\n    from both ends. Inner punctuation is left untouched. '''",
        "'''!\"',;:.-?)([]<>*#\\n\\t\\r'''"
    ],
    "functions": [
        "removeStopwords",
        "test_read",
        "read_file",
        "clean_up",
        "word_type_count",
        "split_sentence",
        "split_phrase",
        "attribute_text",
        "remove_action",
        "avg_word_length",
        "type_token_ratio",
        "hapax_legomena_ratio",
        "avg_sentence_length",
        "avg_sentence_complexity",
        "filler_ratio",
        "obscenity_usage",
        "fuck_count",
        "contraction_ratio",
        "religion_ratio",
        "elf_ratio",
        "compare_signatures",
        "find_match",
        "randomize_weights",
        "print_result",
        "get_attributes",
        "print_all",
        "find_author",
        "get_result_set",
        "print_character",
        "main"
    ],
    "classes": []
}