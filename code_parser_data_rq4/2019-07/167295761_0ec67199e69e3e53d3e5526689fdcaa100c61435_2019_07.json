{
    "identifiers": [
        "random",
        "torch",
        "torch",
        "multiprocessing",
        "multiprocessing",
        "torch",
        "utils",
        "data",
        "sampler",
        "SequentialSampler",
        "RandomSampler",
        "BatchSampler",
        "signal",
        "functools",
        "torch",
        "_six",
        "container_abcs",
        "re",
        "sys",
        "threading",
        "traceback",
        "os",
        "time",
        "atexit",
        "logging",
        "torch",
        "_six",
        "string_classes",
        "int_classes",
        "FileNotFoundError",
        "torch",
        "utils",
        "data",
        "_utils",
        "ExceptionWrapper",
        "MP_STATUS_CHECK_INTERVAL",
        "torch",
        "utils",
        "data",
        "_utils",
        "worker",
        "ManagerWatchdog",
        "sys",
        "version_info",
        "queue",
        "queue",
        "dataset",
        "index_queue",
        "data_queue",
        "done_event",
        "collate_fn",
        "seed",
        "init_fn",
        "worker_id",
        "_use_shared_memory",
        "torch",
        "set_num_threads",
        "random",
        "seed",
        "seed",
        "torch",
        "manual_seed",
        "seed",
        "data_queue",
        "cancel_join_thread",
        "init_fn",
        "init_fn",
        "worker_id",
        "ManagerWatchdog",
        "watchdog",
        "is_alive",
        "index_queue",
        "get",
        "timeout",
        "MP_STATUS_CHECK_INTERVAL",
        "queue",
        "Empty",
        "OSError",
        "logging",
        "info",
        "r",
        "logging",
        "info",
        "done_event",
        "is_set",
        "done_event",
        "is_set",
        "r",
        "collate_fn",
        "dataset",
        "i",
        "i",
        "batch_indices",
        "data_queue",
        "put",
        "idx",
        "ExceptionWrapper",
        "sys",
        "exc_info",
        "data_queue",
        "put",
        "idx",
        "samples",
        "samples",
        "KeyboardInterrupt",
        "logging",
        "info",
        "in_queue",
        "out_queue",
        "device_id",
        "done_event",
        "torch",
        "cuda",
        "set_device",
        "device_id",
        "in_queue",
        "get",
        "timeout",
        "MP_STATUS_CHECK_INTERVAL",
        "queue",
        "Empty",
        "done_event",
        "is_set",
        "r",
        "done_event",
        "is_set",
        "done_event",
        "is_set",
        "isinstance",
        "r",
        "ExceptionWrapper",
        "out_queue",
        "put",
        "r",
        "r",
        "pin_memory_batch",
        "batch",
        "out_queue",
        "put",
        "idx",
        "ExceptionWrapper",
        "sys",
        "exc_info",
        "out_queue",
        "put",
        "idx",
        "batch",
        "torch",
        "DoubleTensor",
        "torch",
        "FloatTensor",
        "torch",
        "HalfTensor",
        "torch",
        "LongTensor",
        "torch",
        "IntTensor",
        "torch",
        "ShortTensor",
        "torch",
        "CharTensor",
        "torch",
        "ByteTensor",
        "batch",
        "batch",
        "isinstance",
        "batch",
        "torch",
        "Tensor",
        "_use_shared_memory",
        "sum",
        "x",
        "numel",
        "x",
        "batch",
        "batch",
        "storage",
        "_new_shared",
        "numel",
        "batch",
        "storage",
        "torch",
        "stack",
        "batch",
        "elem_type",
        "__module__",
        "elem_type",
        "elem_type",
        "batch",
        "elem_type",
        "re",
        "search",
        "elem",
        "dtype",
        "error_msg",
        "format",
        "elem",
        "dtype",
        "torch",
        "stack",
        "torch",
        "from_numpy",
        "b",
        "b",
        "batch",
        "elem",
        "shape",
        "elem",
        "dtype",
        "name",
        "startswith",
        "numpy_type_map",
        "elem",
        "dtype",
        "name",
        "py_type",
        "batch",
        "isinstance",
        "batch",
        "int_classes",
        "torch",
        "LongTensor",
        "batch",
        "isinstance",
        "batch",
        "torch",
        "DoubleTensor",
        "batch",
        "isinstance",
        "batch",
        "string_classes",
        "batch",
        "isinstance",
        "batch",
        "container_abcs",
        "Mapping",
        "key",
        "default_collate",
        "d",
        "key",
        "d",
        "batch",
        "key",
        "batch",
        "isinstance",
        "batch",
        "container_abcs",
        "Sequence",
        "batch",
        "default_collate",
        "samples",
        "samples",
        "transposed",
        "error_msg",
        "format",
        "batch",
        "batch",
        "isinstance",
        "batch",
        "torch",
        "Tensor",
        "batch",
        "pin_memory",
        "isinstance",
        "batch",
        "string_classes",
        "batch",
        "isinstance",
        "batch",
        "container_abcs",
        "Mapping",
        "k",
        "pin_memory_batch",
        "sample",
        "k",
        "sample",
        "batch",
        "items",
        "isinstance",
        "batch",
        "container_abcs",
        "Sequence",
        "pin_memory_batch",
        "sample",
        "sample",
        "batch",
        "batch",
        "loader",
        "workers",
        "index_queues",
        "worker_result_queue",
        "done_event",
        "loader",
        "dataset",
        "loader",
        "collate_fn",
        "loader",
        "batch_sampler",
        "loader",
        "num_workers",
        "loader",
        "pin_memory",
        "torch",
        "cuda",
        "is_available",
        "loader",
        "timeout",
        "iter",
        "batch_sampler",
        "num_workers",
        "loader",
        "worker_init_fn",
        "workers",
        "index_queues",
        "worker_result_queue",
        "done_event",
        "pin_memory",
        "queue",
        "threading",
        "target",
        "_pin_memory_loop",
        "args",
        "worker_result_queue",
        "data_queue",
        "torch",
        "cuda",
        "current_device",
        "done_event",
        "pin_memory_thread",
        "start",
        "pin_memory_thread",
        "worker_result_queue",
        "_",
        "num_workers",
        "_put_indices",
        "len",
        "batch_sampler",
        "timeout",
        "data_queue",
        "get",
        "timeout",
        "timeout",
        "queue",
        "Empty",
        "RuntimeError",
        "format",
        "timeout",
        "pin_memory",
        "pin_memory_thread",
        "is_alive",
        "data_queue",
        "get",
        "timeout",
        "MP_STATUS_CHECK_INTERVAL",
        "queue",
        "Empty",
        "RuntimeError",
        "data_queue",
        "get",
        "num_workers",
        "next",
        "sample_iter",
        "collate_fn",
        "dataset",
        "i",
        "i",
        "indices",
        "pin_memory",
        "pin_memory_batch",
        "batch",
        "batch",
        "rcvd_idx",
        "reorder_dict",
        "reorder_dict",
        "pop",
        "rcvd_idx",
        "_process_next_batch",
        "batch",
        "batches_outstanding",
        "StopIteration",
        "batches_outstanding",
        "_get_batch",
        "batches_outstanding",
        "idx",
        "rcvd_idx",
        "reorder_dict",
        "batch",
        "_process_next_batch",
        "batch",
        "__next__",
        "batches_outstanding",
        "num_workers",
        "next",
        "sample_iter",
        "indices",
        "index_queues",
        "worker_queue_idx",
        "put",
        "send_idx",
        "indices",
        "worker_queue_idx",
        "num_workers",
        "batches_outstanding",
        "send_idx",
        "batch",
        "rcvd_idx",
        "_put_indices",
        "isinstance",
        "batch",
        "ExceptionWrapper",
        "batch",
        "exc_type",
        "batch",
        "exc_msg",
        "batch",
        "NotImplementedError",
        "dataset",
        "batch_size",
        "shuffle",
        "sampler",
        "batch_sampler",
        "num_workers",
        "collate_fn",
        "default_collate",
        "pin_memory",
        "drop_last",
        "timeout",
        "worker_init_fn",
        "dataset",
        "batch_size",
        "num_workers",
        "collate_fn",
        "pin_memory",
        "drop_last",
        "timeout",
        "worker_init_fn",
        "batch_sampler",
        "batch_size",
        "shuffle",
        "sampler",
        "drop_last",
        "ValueError",
        "sampler",
        "shuffle",
        "ValueError",
        "num_workers",
        "ValueError",
        "batch_sampler",
        "sampler",
        "shuffle",
        "RandomSampler",
        "dataset",
        "SequentialSampler",
        "dataset",
        "BatchSampler",
        "sampler",
        "batch_size",
        "drop_last",
        "sampler",
        "batch_sampler",
        "num_workers",
        "multiprocessing",
        "multiprocessing",
        "Event",
        "torch",
        "LongTensor",
        "random_",
        "item",
        "i",
        "num_workers",
        "multiprocessing",
        "index_queue",
        "cancel_join_thread",
        "multiprocessing",
        "Process",
        "target",
        "_worker_loop",
        "args",
        "dataset",
        "index_queue",
        "worker_result_queue",
        "done_event",
        "collate_fn",
        "base_seed",
        "i",
        "worker_init_fn",
        "i",
        "w",
        "start",
        "index_queues",
        "append",
        "index_queue",
        "workers",
        "append",
        "w",
        "attr",
        "val",
        "__initialized",
        "attr",
        "ValueError",
        "format",
        "attr",
        "__class__",
        "ForkOnceDataLoader",
        "__setattr__",
        "attr",
        "val",
        "_ForkOnceDataLoaderIter",
        "workers",
        "index_queues",
        "worker_result_queue",
        "done_event",
        "len",
        "batch_sampler",
        "shutdown",
        "worker_pids_set",
        "done_event",
        "hasattr",
        "worker_result_queue",
        "cancel_join_thread",
        "worker_result_queue",
        "put",
        "pin_memory_thread",
        "join",
        "worker_result_queue",
        "close",
        "q",
        "index_queues",
        "q",
        "put",
        "q",
        "close",
        "w",
        "workers",
        "w",
        "join",
        "num_workers",
        "_shutdown_workers"
    ],
    "literals": [
        "r\"\"\"Whether to use shared memory in default_collate\"\"\"",
        "'WORKER EXIT 3'",
        "'WORKER EXIT 1'",
        "'WORKER EXIT 2'",
        "'float64'",
        "'float32'",
        "'float16'",
        "'int64'",
        "'int32'",
        "'int16'",
        "'int8'",
        "'uint8'",
        "r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"",
        "\"batch must contain tensors, numbers, dicts or lists; found {}\"",
        "'numpy'",
        "'str_'",
        "'string_'",
        "'ndarray'",
        "'[SaUO]'",
        "'float'",
        "r\"\"\"Iterates once over the ForkOnceDataLoader's dataset, as specified by the sampler\"\"\"",
        "'DataLoader timed out after {} seconds'",
        "'Pin memory thread exited unexpectedly'",
        "\"_ForkOnceDataLoaderIter cannot be pickled\"",
        "r\"\"\"\n    ForkOnce Data loader. Combines a dataset and a sampler, and provides\n    single- or multi-threaded iterators over the dataset.\n    Assumes decoding is mostly situated in C libraries, which disable the\n    Python Global Interpreter Lock (GIL).\n    Arguments:\n        dataset (Dataset): dataset from which to load the data.\n        batch_size (int, optional): how many samples per batch to load\n            (default: ``1``).\n        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n            at every epoch (default: ``False``).\n        sampler (Sampler, optional): defines the strategy to draw samples from\n            the dataset. If specified, ``shuffle`` must be False.\n        batch_sampler (Sampler, optional): like sampler, but returns a batch of\n            indices at a time. Mutually exclusive with :attr:`batch_size`,\n            :attr:`shuffle`, :attr:`sampler`, and :attr:`drop_last`.\n        num_workers (int, optional): how many additional threads to use for data\n            loading. 0 means that the data will be loaded in the main thread.\n            (default: ``0``)\n        collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n        pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n            into CUDA pinned memory before returning them.\n        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n            if the dataset size is not divisible by the batch size. If ``False`` and\n            the size of dataset is not divisible by the batch size, then the last batch\n            will be smaller. (default: ``False``)\n        worker_init_fn (callable, optional): If not ``None``, this will be called on each\n            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n            input, after seeding and before data loading. (default: ``None``)\n    .. note:: By default, each worker will have its PyTorch seed set to\n              ``base_seed + worker_id``, where ``base_seed`` is a long generated\n              by main process using its RNG. However, seeds for other libraies\n              may be duplicated upon initializing workers (w.g., NumPy), causing\n              each worker to return identical random numbers. (See\n              :ref:`dataloader-workers-random-seed` section in FAQ.) You may\n              use :func:`torch.initial_seed()` to access the PyTorch seed for\n              each worker in :attr:`worker_init_fn`, and use it to set other\n              seeds before data loading.\n    .. warning:: If ``spawn`` start method is used, :attr:`worker_init_fn` cannot be an\n                 unpicklable object, e.g., a lambda function.\n    \"\"\"",
        "'batch_sampler option is mutually exclusive '",
        "'with batch_size, shuffle, sampler, and '",
        "'drop_last'",
        "'sampler option is mutually exclusive with '",
        "'shuffle'",
        "'num_workers option cannot be negative; '",
        "'use num_workers=0 to disable multi-threading.'",
        "'batch_size'",
        "'sampler'",
        "'drop_last'",
        "'{} attribute should not be set after {} is '",
        "'initialized'",
        "'pin_memory_thread'"
    ],
    "variables": [
        "_use_shared_memory",
        "_use_shared_memory",
        "watchdog",
        "r",
        "idx",
        "batch_indices",
        "samples",
        "r",
        "idx",
        "batch",
        "batch",
        "numpy_type_map",
        "error_msg",
        "elem_type",
        "numel",
        "storage",
        "elem",
        "py_type",
        "transposed",
        "dataset",
        "collate_fn",
        "batch_sampler",
        "num_workers",
        "pin_memory",
        "timeout",
        "sample_iter",
        "worker_init_fn",
        "worker_queue_idx",
        "batches_outstanding",
        "send_idx",
        "rcvd_idx",
        "reorder_dict",
        "workers",
        "index_queues",
        "worker_result_queue",
        "done_event",
        "data_queue",
        "pin_memory_thread",
        "pin_memory_thread",
        "daemon",
        "pin_memory_thread",
        "data_queue",
        "worker_pids_set",
        "indices",
        "batch",
        "batch",
        "batch",
        "idx",
        "batch",
        "idx",
        "next",
        "indices",
        "worker_queue_idx",
        "__initialized",
        "dataset",
        "batch_size",
        "num_workers",
        "collate_fn",
        "pin_memory",
        "drop_last",
        "timeout",
        "worker_init_fn",
        "batch_size",
        "drop_last",
        "sampler",
        "sampler",
        "batch_sampler",
        "sampler",
        "batch_sampler",
        "worker_pids_set",
        "shutdown",
        "worker_result_queue",
        "done_event",
        "base_seed",
        "index_queues",
        "workers",
        "index_queue",
        "w",
        "w",
        "daemon",
        "workers",
        "index_queues",
        "worker_result_queue",
        "done_event",
        "__initialized",
        "shutdown",
        "worker_pids_set"
    ],
    "comments": [
        "Received the final signal",
        "Done event is set. But I haven't received the final signal",
        "(None) yet. I will keep continuing until get it, and skip the",
        "processing steps.",
        "It is important that we don't store exc_info in a variable,",
        "see NOTE [ Python Traceback Reference Cycle Problem ]",
        "Main process will raise KeyboardInterrupt anyways.",
        "Weird things can happen when shutting down, e.g., fd being",
        "closed when tensors are shared via fds.",
        "Haven't seen the final signal yet. Keep getting until None.",
        "If we're in a background process, concatenate directly into a",
        "shared memory tensor to avoid an extra copy",
        "array of string classes and object",
        "scalars",
        "Similar to workers (see comment above), we only register",
        "pin_memory_thread once it is started.",
        "prime the prefetch loop",
        "In the non-timeout case, worker exit is covered by SIGCHLD handler.",
        "But if `pin_memory=True`, we still need account for the possibility",
        "that `pin_memory_thread` dies.",
        "while condition is false, i.e., pin_memory_thread died.",
        "In this case, `self.data_queue` is a `queue.Queue`,. But we don't",
        "need to call `.task_done()` because we don't use `.join()`.",
        "same-process loading",
        "may raise StopIteration",
        "check if the next sample has already been generated",
        "self._shutdown_workers()",
        "not self.shutdown and",
        "store out-of-order samples",
        "Python 2 compatibility",
        "TODO: add limited pickling support for sharing an iterator",
        "across multiple threads for HOGWILD.",
        "Probably the best way to do this is by moving the sample pushing",
        "to a separate thread and then just sharing the data queue",
        "but signalling the end is tricky without a non-blocking API",
        "w = threading.Thread(",
        "Normal exit when last reference is gone / iterator is depleted.",
        "See (1) and the second half of the note.",
        "Removes pids from the C side data structure first so worker",
        "termination afterwards won't trigger false positive error report.",
        "Exit `pin_memory_thread` first because exiting workers may leave",
        "corrupted data in `worker_result_queue` which `pin_memory_thread`",
        "reads from.",
        "Use hasattr in case error happens before we set the attribute.",
        "First time do `worker_result_queue.put` in this process.",
        "`cancel_join_thread` in case that `pin_memory_thread` exited.",
        "Indicate that no more data will be put on this queue by the",
        "current process. This **must** be called after",
        "`pin_memory_thread` is joined because that thread shares the",
        "same pipe handles with this loader thread. If the handle is",
        "closed, Py3 will error in this case, but Py2 will just time",
        "out even if there is data in the queue.",
        "Exit workers now.",
        "Indicate that no more data will be put on this queue by the",
        "current process."
    ],
    "docstrings": [],
    "functions": [
        "_worker_loop",
        "_pin_memory_loop",
        "default_collate",
        "pin_memory_batch",
        "__len__",
        "_get_batch",
        "__next__",
        "__iter__",
        "_put_indices",
        "_process_next_batch",
        "__getstate__",
        "__setattr__",
        "__iter__",
        "__len__",
        "_shutdown_workers",
        "__del__"
    ],
    "classes": [
        "_ForkOnceDataLoaderIter",
        "ForkOnceDataLoader"
    ]
}