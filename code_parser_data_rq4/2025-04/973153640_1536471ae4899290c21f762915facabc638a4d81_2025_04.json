{
    "identifiers": [
        "streamlit",
        "st",
        "google",
        "generativeai",
        "genai",
        "dotenv",
        "load_dotenv",
        "os",
        "pandas",
        "pd",
        "fuzzywuzzy",
        "fuzz",
        "datasets",
        "load_dataset",
        "load_dotenv",
        "os",
        "getenv",
        "GEMINI_API_KEY",
        "st",
        "error",
        "st",
        "stop",
        "genai",
        "configure",
        "api_key",
        "GEMINI_API_KEY",
        "genai",
        "GenerativeModel",
        "e",
        "st",
        "error",
        "e",
        "st",
        "stop",
        "st",
        "cache_data",
        "load_dataset",
        "split",
        "pd",
        "DataFrame",
        "ds",
        "df",
        "rename",
        "columns",
        "column_mapping",
        "df",
        "columns",
        "df",
        "columns",
        "ValueError",
        "df",
        "e",
        "st",
        "error",
        "e",
        "load_simpleqa_dataset",
        "dataset",
        "st",
        "stop",
        "user_query",
        "dataset",
        "threshold",
        "_",
        "row",
        "dataset",
        "iterrows",
        "fuzz",
        "token_sort_ratio",
        "user_query",
        "lower",
        "row",
        "lower",
        "score",
        "best_score",
        "score",
        "row",
        "row",
        "best_score",
        "threshold",
        "best_answer",
        "best_match",
        "best_score",
        "best_match",
        "best_score",
        "user_query",
        "similar_question",
        "similar_question",
        "user_query",
        "similar_question",
        "user_query",
        "model",
        "generate_content",
        "prompt",
        "hasattr",
        "response",
        "response",
        "text",
        "e",
        "e",
        "st",
        "title",
        "st",
        "session_state",
        "st",
        "session_state",
        "st",
        "sidebar",
        "st",
        "header",
        "st",
        "session_state",
        "chat_history",
        "idx",
        "chat",
        "st",
        "session_state",
        "chat_history",
        "st",
        "write",
        "chat",
        "len",
        "chat",
        "st",
        "write",
        "chat",
        "len",
        "chat",
        "st",
        "write",
        "chat",
        "st",
        "markdown",
        "st",
        "write",
        "st",
        "text_input",
        "prompt",
        "st",
        "spinner",
        "find_best_match",
        "prompt",
        "dataset",
        "answer",
        "answer",
        "answer",
        "query_gemini_with_rag",
        "prompt",
        "matched_question",
        "st",
        "session_state",
        "chat_history",
        "append",
        "prompt",
        "response_text",
        "source",
        "st",
        "write",
        "response_text",
        "st",
        "write",
        "source",
        "matched_question",
        "source",
        "st",
        "write",
        "matched_question",
        "match_score"
    ],
    "literals": [
        "\"GEMINI_API_KEY\"",
        "\"⚠️ ERROR: Gemini API key not set in .env file!\"",
        "\"gemini-1.5-pro\"",
        "f\"⚠️ ERROR: Failed to initialize Gemini model - {str(e)}\"",
        "\"basicv8vc/SimpleQA\"",
        "\"test\"",
        "\"problem\"",
        "\"question\"",
        "\"answer\"",
        "\"answer\"",
        "\"question\"",
        "\"answer\"",
        "\"Dataset must have 'question' and 'answer' columns after renaming\"",
        "\"question\"",
        "\"answer\"",
        "f\"Error loading dataset: {str(e)}\"",
        "\"question\"",
        "\"question\"",
        "\"answer\"",
        "f\"Answer the following query: '{user_query}'.\\n\"",
        "f\"Context: A similar question found is '{similar_question}'.\\n\"",
        "f\"Provide a precise and accurate answer.\"",
        "f\"Answer the following query: '{user_query}'.\\nProvide a precise and accurate answer.\"",
        "\"text\"",
        "\"Unexpected API response format\"",
        "f\"Error querying Gemini API: {str(e)}\"",
        "\"SimpleQA Chatbot\"",
        "\"chat_history\"",
        "\"Chat History\"",
        "f\"**You**: {chat['prompt'][:30]}{'...' if len(chat['prompt']) > 30 else ''}\"",
        "'prompt'",
        "'...'",
        "'prompt'",
        "''",
        "f\"**Bot**: {chat['response'][:30]}{'...' if len(chat['response']) > 30 else ''}\"",
        "'response'",
        "'...'",
        "'response'",
        "''",
        "f\"**Source**: {chat['source']}\"",
        "'source'",
        "\"---\"",
        "\"No chats yet.\"",
        "\"Enter your query:\"",
        "\"Generating response...\"",
        "\"Dataset\"",
        "\"Gemini API (RAG)\"",
        "\"prompt\"",
        "\"response\"",
        "\"source\"",
        "f\"**Response**: {response_text}\"",
        "f\"**Source**: {source}\"",
        "\"Gemini API (RAG)\"",
        "f\"**Similar Question Found**: {matched_question} (Score: {match_score})\""
    ],
    "variables": [
        "GEMINI_API_KEY",
        "model",
        "ds",
        "df",
        "column_mapping",
        "df",
        "dataset",
        "best_match",
        "best_score",
        "best_answer",
        "score",
        "best_score",
        "best_match",
        "best_answer",
        "prompt",
        "prompt",
        "response",
        "chat_history",
        "prompt",
        "answer",
        "matched_question",
        "match_score",
        "source",
        "response_text",
        "response_text"
    ],
    "comments": [
        "Load environment variables from .env file",
        "Configuration Check",
        "Configure Gemini API",
        "Load SimpleQA dataset",
        "Load the dataset with the correct split",
        "Explicitly rename columns for this specific dataset",
        "Apply renaming",
        "Verify required columns after renaming",
        "Find best matching question in dataset",
        "Query Gemini API with RAG context",
        "Construct prompt with RAG context if similar question exists",
        "Streamlit App",
        "Initialize session state for chat history",
        "Sidebar for chat history",
        "Input prompt",
        "Send prompt and display response",
        "Check dataset for answer",
        "Fallback to Gemini API with RAG",
        "Store in chat history",
        "Display the latest response"
    ],
    "docstrings": [],
    "functions": [
        "load_simpleqa_dataset",
        "find_best_match",
        "query_gemini_with_rag"
    ],
    "classes": []
}