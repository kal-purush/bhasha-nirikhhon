{
    "identifiers": [
        "fastapi",
        "FastAPI",
        "HTTPException",
        "pydantic",
        "BaseModel",
        "fastapi",
        "middleware",
        "cors",
        "CORSMiddleware",
        "requests",
        "FastAPI",
        "app",
        "add_middleware",
        "CORSMiddleware",
        "allow_origins",
        "allow_credentials",
        "allow_methods",
        "allow_headers",
        "BaseModel",
        "app",
        "get",
        "app",
        "get",
        "requests",
        "get",
        "OLLAMA_TAGS_URL",
        "response",
        "raise_for_status",
        "response",
        "json",
        "data",
        "model",
        "model",
        "data",
        "get",
        "models",
        "models",
        "requests",
        "exceptions",
        "RequestException",
        "e",
        "HTTPException",
        "status_code",
        "detail",
        "e",
        "app",
        "post",
        "request",
        "ChatRequest",
        "get_models",
        "request",
        "model",
        "available_models",
        "HTTPException",
        "status_code",
        "detail",
        "request",
        "model",
        "request",
        "prompt",
        "requests",
        "post",
        "OLLAMA_API_URL",
        "json",
        "ollama_payload",
        "response",
        "raise_for_status",
        "response",
        "json",
        "data",
        "get",
        "requests",
        "exceptions",
        "ConnectionError",
        "HTTPException",
        "status_code",
        "detail",
        "requests",
        "exceptions",
        "RequestException",
        "e",
        "HTTPException",
        "status_code",
        "detail",
        "e"
    ],
    "literals": [
        "\"*\"",
        "\"*\"",
        "\"*\"",
        "\"http://localhost:11434/api/generate\"",
        "\"http://localhost:11434/api/tags\"",
        "\"/\"",
        "\"message\"",
        "\"FastAPI server is running!\"",
        "\"/models/\"",
        "\"Ollama API response:\"",
        "\"model\"",
        "\"models\"",
        "\"Extracted models:\"",
        "\"models\"",
        "f\"Error fetching models: {str(e)}\"",
        "\"/chat/\"",
        "\"models\"",
        "\"Model not found\"",
        "\"model\"",
        "\"prompt\"",
        "\"stream\"",
        "\"response\"",
        "\"response\"",
        "\"Ollama did not return a response.\"",
        "\"Failed to connect to Ollama. Is it running?\"",
        "f\"Ollama API Error: {str(e)}\""
    ],
    "variables": [
        "app",
        "OLLAMA_API_URL",
        "OLLAMA_TAGS_URL",
        "prompt",
        "model",
        "response",
        "data",
        "models",
        "available_models",
        "ollama_payload",
        "response",
        "data"
    ],
    "comments": [
        "CORS Middleware",
        "Ollama API URL",
        "Request model",
        "Print response for debugging",
        "Extract models properly",
        "Debugging output"
    ],
    "docstrings": [],
    "functions": [
        "home",
        "get_models",
        "chat"
    ],
    "classes": [
        "ChatRequest"
    ]
}