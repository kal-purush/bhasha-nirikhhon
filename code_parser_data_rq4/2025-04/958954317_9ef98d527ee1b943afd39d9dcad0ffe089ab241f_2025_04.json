{
    "identifiers": [
        "pytest",
        "torch",
        "vllm",
        "model_executor",
        "layers",
        "lightning_attn",
        "linear_decode_forward_triton",
        "vllm",
        "platforms",
        "current_platform",
        "torch",
        "float32",
        "q",
        "k",
        "v",
        "ed",
        "block_size",
        "kv_history",
        "q",
        "shape",
        "v",
        "shape",
        "q",
        "dtype",
        "torch",
        "zeros",
        "B",
        "H",
        "S",
        "E",
        "dtype",
        "dtype",
        "device",
        "q",
        "device",
        "kv_history",
        "torch",
        "zeros",
        "B",
        "H",
        "D",
        "E",
        "dtype",
        "dtype",
        "device",
        "q",
        "device",
        "kv_history",
        "clone",
        "ed",
        "dim",
        "torch",
        "exp",
        "ed",
        "view",
        "torch",
        "exp",
        "ed",
        "b",
        "B",
        "step",
        "S",
        "q",
        "b",
        "step",
        "k",
        "b",
        "step",
        "v",
        "b",
        "step",
        "h",
        "H",
        "torch",
        "outer",
        "k_bs",
        "h",
        "v_bs",
        "h",
        "decay",
        "h",
        "kv_cache",
        "b",
        "h",
        "kv_outer",
        "torch",
        "matmul",
        "q_bs",
        "h",
        "kv_cache",
        "b",
        "h",
        "kv_cache",
        "unsqueeze",
        "torch",
        "cat",
        "kv_reshaped",
        "kv_reshaped",
        "dim",
        "output",
        "final_kv_cache",
        "q",
        "k",
        "v",
        "kv_caches",
        "slope_rate",
        "slot_idx",
        "q",
        "shape",
        "torch",
        "zeros",
        "B",
        "H",
        "D",
        "dtype",
        "q",
        "dtype",
        "device",
        "q",
        "device",
        "torch",
        "exp",
        "slope_rate",
        "view",
        "b",
        "B",
        "slot_idx",
        "b",
        "item",
        "slot_id",
        "q",
        "b",
        "k",
        "b",
        "v",
        "b",
        "h",
        "H",
        "q_b",
        "h",
        "k_b",
        "h",
        "v_b",
        "h",
        "kv_caches",
        "b",
        "h",
        "torch",
        "outer",
        "k_bh",
        "v_bh",
        "kv_outer",
        "decay",
        "h",
        "kv_cache_old",
        "torch",
        "matmul",
        "q_bh",
        "kv_new",
        "h",
        "D",
        "h",
        "D",
        "out_h",
        "kv_new",
        "output",
        "pytest",
        "mark",
        "parametrize",
        "BATCH_SIZES",
        "pytest",
        "mark",
        "parametrize",
        "NUM_HEADS",
        "pytest",
        "mark",
        "parametrize",
        "HEAD_SIZES",
        "pytest",
        "mark",
        "parametrize",
        "DTYPES",
        "torch",
        "inference_mode",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "torch",
        "dtype",
        "torch",
        "set_default_device",
        "torch",
        "manual_seed",
        "torch",
        "cuda",
        "manual_seed_all",
        "current_platform",
        "seed_everything",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "head_size",
        "dtype",
        "dtype",
        "device",
        "kv_caches",
        "clone",
        "torch",
        "zeros",
        "num_heads",
        "device",
        "h",
        "num_heads",
        "h",
        "torch",
        "arange",
        "batch_size",
        "device",
        "linear_decode_forward_triton",
        "q",
        "k",
        "v",
        "kv_caches",
        "slope_rate",
        "slot_idx",
        "reference_linear_decode",
        "q",
        "k",
        "v",
        "kv_caches_copy",
        "slope_rate",
        "slot_idx",
        "torch",
        "testing",
        "assert_close",
        "triton_output",
        "reference_output",
        "rtol",
        "atol",
        "torch",
        "testing",
        "assert_close",
        "kv_caches",
        "kv_caches_copy",
        "rtol",
        "atol",
        "triton_output",
        "shape",
        "batch_size",
        "num_heads",
        "head_size",
        "pytest",
        "mark",
        "parametrize",
        "NUM_HEADS",
        "pytest",
        "mark",
        "parametrize",
        "HEAD_SIZES",
        "pytest",
        "mark",
        "parametrize",
        "DTYPES",
        "torch",
        "inference_mode",
        "num_heads",
        "head_size",
        "dtype",
        "torch",
        "dtype",
        "torch",
        "set_default_device",
        "torch",
        "manual_seed",
        "torch",
        "cuda",
        "manual_seed_all",
        "current_platform",
        "seed_everything",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "head_size",
        "dtype",
        "dtype",
        "device",
        "kv_caches",
        "clone",
        "torch",
        "zeros",
        "num_heads",
        "device",
        "h",
        "num_heads",
        "h",
        "torch",
        "tensor",
        "device",
        "linear_decode_forward_triton",
        "q",
        "k",
        "v",
        "kv_caches",
        "slope_rate",
        "slot_idx",
        "reference_linear_decode",
        "q",
        "k",
        "v",
        "kv_caches_copy",
        "slope_rate",
        "slot_idx",
        "slot_idx",
        "unsqueeze",
        "expand",
        "num_heads",
        "head_size",
        "triton_output",
        "padding_mask",
        "reference_output",
        "padding_mask",
        "slot_idx",
        "i",
        "batch_size",
        "valid_indices",
        "i",
        "torch",
        "testing",
        "assert_close",
        "kv_caches",
        "i",
        "kv_caches_copy",
        "i",
        "rtol",
        "rtol",
        "atol",
        "atol",
        "torch",
        "testing",
        "assert_close",
        "triton_masked",
        "reference_masked",
        "rtol",
        "rtol",
        "atol",
        "atol",
        "triton_output",
        "shape",
        "batch_size",
        "num_heads",
        "head_size",
        "pytest",
        "mark",
        "parametrize",
        "BATCH_SIZES",
        "pytest",
        "mark",
        "parametrize",
        "NUM_HEADS",
        "pytest",
        "mark",
        "parametrize",
        "HEAD_SIZES",
        "pytest",
        "mark",
        "parametrize",
        "SEQ_LENGTHS",
        "pytest",
        "mark",
        "parametrize",
        "DTYPES",
        "torch",
        "inference_mode",
        "batch_size",
        "num_heads",
        "head_size",
        "seq_len",
        "dtype",
        "torch",
        "dtype",
        "torch",
        "set_default_device",
        "torch",
        "manual_seed",
        "torch",
        "cuda",
        "manual_seed_all",
        "current_platform",
        "seed_everything",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "seq_len",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "seq_len",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "seq_len",
        "head_size",
        "dtype",
        "dtype",
        "torch",
        "zeros",
        "num_heads",
        "device",
        "h",
        "num_heads",
        "h",
        "torch",
        "randn",
        "batch_size",
        "num_heads",
        "head_size",
        "head_size",
        "dtype",
        "dtype",
        "device",
        "kv_history",
        "clone",
        "reference_lightning_attention",
        "q",
        "k",
        "v",
        "ed",
        "kv_history",
        "vllm",
        "model_executor",
        "layers",
        "lightning_attn",
        "lightning_attention",
        "lightning_attention",
        "q",
        "k",
        "v",
        "ed",
        "kv_history_clone",
        "torch",
        "testing",
        "assert_close",
        "ref_output",
        "actual_output",
        "rtol",
        "rtol",
        "atol",
        "atol",
        "torch",
        "testing",
        "assert_close",
        "ref_kv_cache",
        "actual_kv_cache",
        "rtol",
        "rtol",
        "atol",
        "atol",
        "ref_output",
        "shape",
        "batch_size",
        "num_heads",
        "seq_len",
        "head_size",
        "ref_kv_cache",
        "shape",
        "actual_kv_cache",
        "shape"
    ],
    "literals": [
        "\"batch_size\"",
        "\"num_heads\"",
        "\"head_size\"",
        "\"dtype\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"num_heads\"",
        "\"head_size\"",
        "\"dtype\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"batch_size\"",
        "\"num_heads\"",
        "\"head_size\"",
        "\"seq_len\"",
        "\"dtype\"",
        "\"cuda\"",
        "\"cuda\"",
        "\"cuda\""
    ],
    "variables": [
        "NUM_HEADS",
        "HEAD_SIZES",
        "BATCH_SIZES",
        "SEQ_LENGTHS",
        "DTYPES",
        "B",
        "H",
        "S",
        "D",
        "E",
        "dtype",
        "output",
        "kv_cache",
        "kv_cache",
        "decay",
        "decay",
        "q_bs",
        "k_bs",
        "v_bs",
        "kv_outer",
        "kv_cache",
        "b",
        "h",
        "output",
        "b",
        "h",
        "step",
        "kv_reshaped",
        "final_kv_cache",
        "B",
        "H",
        "_",
        "D",
        "output",
        "decay",
        "slot_id",
        "q_b",
        "k_b",
        "v_b",
        "q_bh",
        "k_bh",
        "v_bh",
        "kv_cache_old",
        "kv_outer",
        "kv_new",
        "out_h",
        "output",
        "b",
        "kv_caches",
        "b",
        "h",
        "q",
        "k",
        "v",
        "kv_caches",
        "kv_caches_copy",
        "slope_rate",
        "slope_rate",
        "h",
        "slot_idx",
        "triton_output",
        "reference_output",
        "batch_size",
        "q",
        "k",
        "v",
        "kv_caches",
        "kv_caches_copy",
        "slope_rate",
        "slope_rate",
        "h",
        "slot_idx",
        "triton_output",
        "reference_output",
        "padding_mask",
        "triton_masked",
        "reference_masked",
        "atol",
        "rtol",
        "valid_indices",
        "q",
        "k",
        "v",
        "ed",
        "ed",
        "h",
        "kv_history",
        "kv_history_clone",
        "ref_output",
        "ref_kv_cache",
        "actual_output",
        "actual_kv_cache",
        "atol",
        "rtol"
    ],
    "comments": [
        "SPDX-License-Identifier: Apache-2.0",
        "Use clone() to ensure an independent copy",
        "More efficient implementation",
        "Convert decay factors to matrix form",
        "Process all heads at once for this position",
        "[H, D]",
        "[H, D]",
        "[H, E]",
        "Calculate KV outer products for all heads",
        "Calculate KV outer product",
        "Update KV cache with decay",
        "Note: Using the same order as in the Triton kernel",
        "Calculate attention output",
        "Match the shape returned by the actual implementation",
        "The actual implementation returns a tensor of shape [B, H, 2, D, E]",
        "where dimension 2 contains both KV and KV history",
        "[B, H, 1, D, E]",
        "[B, H, 2, D, E]",
        "Calculate decay factors once (more efficient)",
        "[H, 1, 1]",
        "Process each batch",
        "Skip padding positions",
        "Process all heads at once for this batch",
        "[H, D]",
        "[H, D]",
        "[H, D]",
        "Process each attention head",
        "Get current query, key and value",
        "Get cache",
        "Calculate new key-value outer product",
        "Apply decay and update cache",
        "Calculate output",
        "Update output and cache"
    ],
    "docstrings": [
        "\"\"\"Reference implementation of lightning attention core algorithm\n    \n    The difference from the main implementation is that this processes \n    each step sequentially, instead of using parallelized triton kernels\n    \"\"\"",
        "\"\"\"Reference implementation: linear attention decode function\"\"\""
    ],
    "functions": [
        "reference_lightning_attention",
        "reference_linear_decode",
        "test_linear_decode_forward_triton",
        "test_linear_decode_forward_triton_with_padding",
        "test_lightning_attention_reference"
    ],
    "classes": []
}