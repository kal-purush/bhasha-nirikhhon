{
    "identifiers": [
        "keras",
        "models",
        "Model",
        "Sequential",
        "keras",
        "layers",
        "Input",
        "LSTM",
        "Dense",
        "Embedding",
        "Dropout",
        "Activation",
        "keras",
        "layers",
        "add",
        "dot",
        "concatenate",
        "Permute",
        "vocab_size",
        "query_maxlen",
        "story_maxlen",
        "Input",
        "story_maxlen",
        "Input",
        "query_maxlen",
        "Sequential",
        "input_encoder_m",
        "add",
        "Embedding",
        "input_dim",
        "vocab_size",
        "output_dim",
        "input_encoder_m",
        "add",
        "Dropout",
        "Sequential",
        "input_encoder_c",
        "add",
        "Embedding",
        "input_dim",
        "vocab_size",
        "output_dim",
        "query_maxlen",
        "input_encoder_c",
        "add",
        "Dropout",
        "Sequential",
        "question_encoder",
        "add",
        "Embedding",
        "input_dim",
        "vocab_size",
        "output_dim",
        "input_length",
        "query_maxlen",
        "question_encoder",
        "add",
        "Dropout",
        "input_encoder_m",
        "input_sequence",
        "input_encoder_c",
        "input_sequence",
        "question_encoder",
        "question",
        "dot",
        "input_encoded_m",
        "question_encoded",
        "axes",
        "Activation",
        "match",
        "add",
        "match",
        "input_encoded_c",
        "Permute",
        "response",
        "concatenate",
        "response",
        "question_encoded",
        "LSTM",
        "answer",
        "Dropout",
        "answer",
        "Dense",
        "vocab_size",
        "answer",
        "Activation",
        "answer",
        "Model",
        "input_sequence",
        "question",
        "answer",
        "model"
    ],
    "literals": [
        "'softmax'",
        "'softmax'"
    ],
    "variables": [
        "input_sequence",
        "question",
        "input_encoder_m",
        "input_encoder_c",
        "question_encoder",
        "input_encoded_m",
        "input_encoded_c",
        "question_encoded",
        "match",
        "match",
        "response",
        "response",
        "answer",
        "answer",
        "answer",
        "answer",
        "answer",
        "model"
    ],
    "comments": [
        "-*- coding: utf-8 -*-",
        "DL packages",
        "Training model",
        "",
        "placeholders",
        "encoders",
        "embed the input sequence into a sequence of vectors",
        "output: (samples, story_maxlen, embedding_dim)",
        "embed the input into a sequence of vectors of size query_maxlen",
        "output: (samples, story_maxlen, query_maxlen)",
        "embed the question into a sequence of vectors",
        "output: (samples, query_maxlen, embedding_dim)",
        "encode input sequence and questions (which are indices)",
        "to sequences of dense vectors",
        "compute a 'match' between the first input vector sequence",
        "and the question vector sequence",
        "shape: `(samples, story_maxlen, query_maxlen)`",
        "add the match matrix with the second input vector sequence",
        "(samples, story_maxlen, query_maxlen)",
        "(samples, query_maxlen, story_maxlen)",
        "concatenate the match matrix with the question vector sequence",
        "the original paper uses a matrix multiplication for this reduction step.",
        "we choose to use a RNN instead.",
        "(samples, 32)",
        "one regularization layer -- more would probably be needed.",
        "(samples, vocab_size)",
        "we output a probability distribution over the vocabulary",
        "build the final model"
    ],
    "docstrings": [
        "\"\"\"\nCreated on Thu Mar 28 16:51:16 2019\n\n@author: ramhi\n\"\"\""
    ],
    "functions": [
        "model"
    ],
    "classes": []
}