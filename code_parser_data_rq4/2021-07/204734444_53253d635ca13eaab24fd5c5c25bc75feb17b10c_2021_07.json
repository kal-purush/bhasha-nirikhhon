{
    "identifiers": [
        "warnings",
        "collections",
        "namedtuple",
        "typing",
        "Any",
        "Callable",
        "Dict",
        "NamedTuple",
        "Optional",
        "Tuple",
        "Union",
        "torch",
        "Tensor",
        "captum",
        "_utils",
        "common",
        "_expand_additional_forward_args",
        "_format_additional_forward_args",
        "_reduce_list",
        "captum",
        "attr",
        "Max",
        "Mean",
        "Min",
        "Summarizer",
        "captum",
        "robust",
        "_core",
        "perturbation",
        "Perturbation",
        "NamedTuple",
        "Union",
        "Perturbation",
        "Callable",
        "Dict",
        "Any",
        "inp",
        "isinstance",
        "inp",
        "Tensor",
        "inp",
        "mean",
        "dim",
        "isinstance",
        "inp",
        "agg_metric",
        "elem",
        "elem",
        "inp",
        "inp",
        "forward_func",
        "Callable",
        "metric",
        "Callable",
        "Union",
        "Tensor",
        "Tuple",
        "Union",
        "Tensor",
        "preproc_fn",
        "Callable",
        "forward_func",
        "metric",
        "preproc_fn",
        "agg_metric",
        "Mean",
        "Min",
        "Max",
        "Mean",
        "attack",
        "Union",
        "Perturbation",
        "Callable",
        "name",
        "Optional",
        "num_attempts",
        "apply_before_preproc",
        "attack_kwargs",
        "Optional",
        "Dict",
        "Any",
        "additional_attack_arg_names",
        "Optional",
        "name",
        "attack",
        "__class__",
        "attack_kwargs",
        "additional_attack_arg_names",
        "name",
        "attacks",
        "RuntimeError",
        "format",
        "name",
        "attacks",
        "AttackInfo",
        "attack_fn",
        "attack",
        "name",
        "name",
        "num_attempts",
        "num_attempts",
        "apply_before_preproc",
        "apply_before_preproc",
        "attack_kwargs",
        "attack_kwargs",
        "additional_args",
        "additional_attack_arg_names",
        "summary",
        "Union",
        "Dict",
        "Dict",
        "Dict",
        "Union",
        "Tuple",
        "isinstance",
        "summary",
        "summary",
        "key",
        "summary",
        "s",
        "key",
        "s",
        "summary",
        "out_format",
        "out_format",
        "summary_dict",
        "key",
        "summary_dict",
        "out_metric",
        "Union",
        "Tensor",
        "Tuple",
        "Union",
        "Tensor",
        "out_format",
        "isinstance",
        "out_metric",
        "hasattr",
        "out_metric",
        "namedtuple",
        "out_metric",
        "out_metric",
        "_fields",
        "input_list",
        "Any",
        "additional_forward_args",
        "Optional",
        "Tuple",
        "key_list",
        "batch_summarizers",
        "Dict",
        "Summarizer",
        "metric_kwargs",
        "Dict",
        "Any",
        "additional_forward_args",
        "len",
        "input_list",
        "forward_func",
        "input_list",
        "additional_forward_args",
        "metric",
        "model_out",
        "metric_kwargs",
        "_update_out_format",
        "out_metric",
        "batch_summarizers",
        "key_list",
        "update",
        "out_metric",
        "_reduce_list",
        "input_list",
        "forward_func",
        "batched_inps",
        "additional_forward_args",
        "i",
        "len",
        "input_list",
        "input_list",
        "i",
        "shape",
        "isinstance",
        "input_list",
        "i",
        "Tensor",
        "input_list",
        "i",
        "shape",
        "metric",
        "model_out",
        "current_count",
        "current_count",
        "batch_size",
        "metric_kwargs",
        "_update_out_format",
        "out_metric",
        "batch_summarizers",
        "key_list",
        "i",
        "update",
        "out_metric",
        "current_count",
        "batch_size",
        "inputs",
        "Any",
        "additional_forward_args",
        "Optional",
        "Tuple",
        "perturbations_per_eval",
        "kwargs",
        "Dict",
        "Union",
        "Tensor",
        "Tuple",
        "Tensor",
        "Dict",
        "Union",
        "Tensor",
        "Tuple",
        "Tensor",
        "_format_additional_forward_args",
        "additional_forward_args",
        "_expand_additional_forward_args",
        "additional_forward_args",
        "perturbations_per_eval",
        "perturbations_per_eval",
        "additional_forward_args",
        "preproc_fn",
        "preproc_fn",
        "inputs",
        "inputs",
        "preproc_input",
        "ORIGINAL_KEY",
        "ORIGINAL_KEY",
        "Summarizer",
        "Mean",
        "ORIGINAL_KEY",
        "summary_results",
        "summary_results",
        "Summarizer",
        "stat",
        "stat",
        "aggregate_stats",
        "input_list",
        "key_list",
        "len",
        "input_list",
        "perturbations_per_eval",
        "_evaluate_batch",
        "input_list",
        "expanded_additional_args",
        "key_list",
        "batch_summarizers",
        "kwargs",
        "input_list",
        "key_list",
        "_check_and_evaluate",
        "input_list",
        "key_list",
        "attack_key",
        "attacks",
        "attacks",
        "attack_key",
        "attack",
        "num_attempts",
        "stat",
        "stat",
        "batch_stats",
        "Mean",
        "attack",
        "name",
        "Summarizer",
        "stats",
        "key",
        "attack",
        "additional_args",
        "key",
        "kwargs",
        "warnings",
        "warn",
        "key",
        "attack_key",
        "kwargs",
        "key",
        "_",
        "attack",
        "num_attempts",
        "attack",
        "apply_before_preproc",
        "attack",
        "attack_fn",
        "inputs",
        "additional_attack_args",
        "attack",
        "attack_kwargs",
        "preproc_fn",
        "attacked_inp",
        "preproc_fn",
        "attacked_inp",
        "attack",
        "attack_fn",
        "preproc_input",
        "additional_attack_args",
        "attack",
        "attack_kwargs",
        "input_list",
        "append",
        "preproc_attacked_inp",
        "key_list",
        "append",
        "attack",
        "name",
        "_check_and_evaluate",
        "input_list",
        "key_list",
        "len",
        "input_list",
        "_expand_additional_forward_args",
        "additional_forward_args",
        "len",
        "input_list",
        "_evaluate_batch",
        "input_list",
        "final_add_args",
        "key_list",
        "batch_summarizers",
        "kwargs",
        "_parse_and_update_results",
        "batch_summarizers",
        "batch_summarizers",
        "Dict",
        "Summarizer",
        "Dict",
        "Union",
        "Tuple",
        "Dict",
        "Union",
        "Tuple",
        "ORIGINAL_KEY",
        "_format_summary",
        "batch_summarizers",
        "ORIGINAL_KEY",
        "summary",
        "summary_results",
        "ORIGINAL_KEY",
        "update",
        "metric_aggregator",
        "results",
        "ORIGINAL_KEY",
        "attack_key",
        "attacks",
        "attacks",
        "attack_key",
        "attack",
        "name",
        "_format_summary",
        "batch_summarizers",
        "attack",
        "name",
        "summary",
        "len",
        "results",
        "attack",
        "name",
        "next",
        "iter",
        "results",
        "attack",
        "name",
        "attack",
        "name",
        "summary_results",
        "summary_results",
        "attack",
        "name",
        "Summarizer",
        "stat",
        "stat",
        "aggregate_stats",
        "summary_results",
        "attack",
        "name",
        "update",
        "metric_aggregator",
        "results",
        "attack",
        "name",
        "key",
        "key",
        "results",
        "attack",
        "name",
        "attack",
        "name",
        "key",
        "title",
        "summary_key",
        "summary_results",
        "summary_results",
        "Summarizer",
        "stat",
        "stat",
        "aggregate_stats",
        "summary_results",
        "summary_key",
        "update",
        "metric_aggregator",
        "results",
        "attack",
        "name",
        "key",
        "results",
        "Dict",
        "Dict",
        "Union",
        "Tensor",
        "Tuple",
        "Tensor",
        "key",
        "_format_summary",
        "summary_results",
        "key",
        "summary",
        "key",
        "summary_results"
    ],
    "literals": [
        "\"Original\"",
        "r\"\"\"\n    Allows measuring model robustness for a given attack or set of attacks. This class\n    can be used with any metric(s) as well as any set of attacks, either based on\n    attacks / perturbations from captum.robust such as FGSM or PGD or external\n    augmentation methods or perturbations such as torchvision transforms.\n    \"\"\"",
        "r\"\"\"\n        Args:\n            forward_func (callable or torch.nn.Module): This can either be an instance\n                of pytorch model or any modification of a model's forward\n                function.\n\n            metric (callable): This function is applied to the model output in\n                order to compute the desired performance metric or metrics.\n                This function should have the following signature:\n                    def model_metric(model_out: Tensor, **kwargs: Any)\n                            -> Union[float, Tensor, Tuple[Union[float, Tensor], ...]\n\n                All kwargs provided to evaluate are provided to the metric function,\n                following the model output. A single metric can be returned as\n                a float or tensor, and multiple metrics should be returned as either\n                a tuple or named tuple of floats or tensors. For a tensor metric,\n                the first dimension should match the batch size, corresponding to\n                metrics for each example. Tensor metrics are averaged over the first\n                dimension when aggregating multiple batch results.\n                If tensor metrics represent results for the full batch, the size of the\n                first dimension should be 1.\n\n            preproc_fn (callable, optional): Optional method applied to inputs. Output\n                of preproc_fn is then provided as input to model, in addition to\n                additional_forward_args provided to evaluate.\n        \"\"\"",
        "r\"\"\"\n        Adds attack to be evaluated when calling evaluate.\n\n        Args:\n            attack (perturbation or callable): This can either be an instance\n                of a Captum Perturbation / Attack\n                or any other perturbation or attack function such\n                as a torchvision transform.\n\n            name (optional, str): Name or identifier for attack, used as key for\n                attack results. This defaults to attack.__class__.__name__\n                if not provided and must be unique for all added attacks.\n\n            num_attempts (int): Number of attempts that attack should be\n                repeated. This should only be set to > 1 for non-deterministic\n                attacks. The minimum, maximum, and average (best, worst, and\n                average case) are tracked for attack attempts.\n\n            apply_before_preproc (bool): Defines whether attack should be applied\n                before or after preproc function.\n\n            attack_kwargs (dict): Additional arguments to be provided to given attack.\n                This should be provided as a dictionary of keyword arguments.\n\n            additional_attack_arg_names (list[str]): Any additional arguments for the\n                attack which are specific to the particular input example or batch.\n                An example of this is target, which is necessary for some attacks such\n                as FGSM or PGD. These arguments are included if provided as a kwarg\n                to evaluate.\n        \"\"\"",
        "\"Cannot add attack with same name as existing attack {}\"",
        "r\"\"\"\n        This method reformats a given summary; particularly for tuples,\n        the Summarizer's summary format is a list of dictionaries,\n        each containing the summary for the corresponding elements.\n        We reformat this to return a dictionary with tuples containing\n        the summary results.\n        \"\"\"",
        "\"_fields\"",
        "r\"\"\"\n        Evaluate model and attack performance on provided inputs\n\n        Args:\n\n        inputs (any): Input for which attack metrics\n                are computed. It can be provided as a tensor, tuple of tensors,\n                or any raw input type (e.g. PIL image or text string).\n                This input is provided directly as input to preproc function as well\n                as any attack applied before preprocessing. If no pre-processing\n                function is provided, this input is provided directly to the main\n                model and all attacks.\n\n        additional_forward_args (any, optional): If the forward function\n                requires additional arguments other than the preprocessing\n                outputs (or inputs if preproc_fn is None), this argument\n                can be provided. It must be either a single additional\n                argument of a Tensor or arbitrary (non-tuple) type or a\n                tuple containing multiple additional arguments including\n                tensors or any arbitrary python types. These arguments\n                are provided to forward_func in order following the\n                arguments in inputs.\n                For a tensor, the first dimension of the tensor must\n                correspond to the number of examples. For all other types,\n                the given argument is used for all forward evaluations.\n                Default: None\n        perturbations_per_eval (int, optional): Allows perturbations of multiple\n                attacks to be grouped and evaluated in one call of forward_fn\n                Each forward pass will contain a maximum of\n                perturbations_per_eval * #examples samples.\n                For DataParallel models, each batch is split among the\n                available devices, so evaluations on each available\n                device contain at most\n                (perturbations_per_eval * #examples) / num_devices\n                samples.\n                In order to apply this functionality, the output of preproc_fn\n                (or inputs itself if no preproc_fn is provided) must be a tensor\n                or tuple of tensors.\n                Default: 1\n        kwargs (any, optional): Additional keyword arguments provided to metric function\n                as well as selected attacks based on chosen additional_args\n\n        Returns:\n\n        - **attack results** Dict: str -> Dict[str, Union[Tensor, Tuple[Tensor, ...]]]:\n                Dictionary containing attack results for provided batch.\n                Maps attack name to dictionary,\n                containing best-case, worst-case and average-case results for attack.\n                Dictionary contains keys \"mean\", \"max\" and \"min\" when num_attempts > 1\n                and only \"mean\" for num_attempts = 1, which contains the (single) metric\n                result for the attack attempt.\n                An additional key of 'Original' is included with metric results\n                without any perturbations.\n\n\n        Examples::\n\n        >>> def accuracy_metric(model_out: Tensor, targets: Tensor):\n        >>>     return torch.argmax(model_out, dim=1) == targets).float()\n\n        >>> attack_metric = AttackComparator(model=resnet18,\n                                             metric=accuracy_metric,\n                                             preproc_fn=normalize)\n\n        >>> random_rotation = transforms.RandomRotation()\n        >>> jitter = transforms.ColorJitter()\n\n        >>> attack_metric.add_attack(random_rotation, \"Random Rotation\",\n        >>>                          num_attempts = 5)\n        >>> attack_metric.add_attack((jitter, \"Jitter\", num_attempts = 1)\n        >>> attack_metric.add_attack(FGSM(resnet18), \"FGSM 0.1\", num_attempts = 1,\n        >>>                          apply_before_preproc=False,\n        >>>                          attack_kwargs={epsilon: 0.1},\n        >>>                          additional_args=[\"targets\"])\n\n        >>> for images, labels in dataloader:\n        >>>     batch_results = attack_metric.evaluate(inputs=images, targets=labels)\n        \"\"\"",
        "f\"Additional sample arg {key} not provided for {attack_key}\"",
        "\"mean\"",
        "f\"{attack.name} {key.title()} Attempt\"",
        "r\"\"\"\n        Returns average results over all previous batches evaluated.\n\n        Returns:\n\n            - **summary** Dict: str -> Dict[str, Union[Tensor, Tuple[Tensor, ...]]]:\n                Dictionary containing summarized average attack results.\n                Maps attack name (with \"Mean Attempt\", \"Max Attempt\" and \"Min Attempt\"\n                suffixes if num_attempts > 1) to dictionary containing a key of \"mean\"\n                maintaining summarized results,\n                which is the running mean of results over all batches\n                since construction or previous reset call. Tensor metrics are averaged\n                over dimension 0 for each batch, in order to aggregte metrics collected\n                per batch.\n        \"\"\"",
        "r\"\"\"\n        Reset stored average summary results for previous batches\n        \"\"\""
    ],
    "variables": [
        "ORIGINAL_KEY",
        "attack_fn",
        "name",
        "num_attempts",
        "apply_before_preproc",
        "attack_kwargs",
        "additional_args",
        "forward_func",
        "metric",
        "preproc_fn",
        "attacks",
        "summary_results",
        "metric_aggregator",
        "batch_stats",
        "aggregate_stats",
        "summary_results",
        "out_format",
        "name",
        "attack_kwargs",
        "additional_attack_arg_names",
        "name",
        "summary_dict",
        "summary_dict",
        "key",
        "summary_dict",
        "key",
        "out_format",
        "additional_forward_args",
        "model_out",
        "out_metric",
        "batched_inps",
        "model_out",
        "current_count",
        "batch_size",
        "out_metric",
        "additional_forward_args",
        "expanded_additional_args",
        "preproc_input",
        "preproc_input",
        "preproc_input",
        "input_list",
        "key_list",
        "batch_summarizers",
        "ORIGINAL_KEY",
        "input_list",
        "key_list",
        "attack",
        "stats",
        "stats",
        "batch_summarizers",
        "additional_attack_args",
        "additional_attack_args",
        "key",
        "attacked_inp",
        "preproc_attacked_inp",
        "preproc_attacked_inp",
        "input_list",
        "key_list",
        "final_add_args",
        "results",
        "attack",
        "results",
        "key",
        "summary_key",
        "summary_key",
        "summary_results"
    ],
    "comments": [
        "!/usr/bin/env python3"
    ],
    "docstrings": [],
    "functions": [
        "agg_metric",
        "add_attack",
        "_format_summary",
        "_update_out_format",
        "_evaluate_batch",
        "evaluate",
        "_check_and_evaluate",
        "_parse_and_update_results",
        "summary",
        "reset"
    ],
    "classes": [
        "AttackInfo",
        "AttackComparator"
    ]
}