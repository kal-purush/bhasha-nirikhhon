{
    "identifiers": [
        "luna_core",
        "common",
        "Neo4jConnection",
        "Neo4jConnection",
        "luna_core",
        "common",
        "Node",
        "Node",
        "CONTAINER_TYPES",
        "luna_core",
        "common",
        "config",
        "ConfigSet",
        "os",
        "socket",
        "pathlib",
        "logging",
        "shutil",
        "minio",
        "Minio",
        "concurrent",
        "futures",
        "ThreadPoolExecutor",
        "ProcessPoolExecutor",
        "as_completed",
        "logging",
        "getLogger",
        "store_location",
        "os",
        "path",
        "exists",
        "ConfigSet",
        "name",
        "config_file",
        "get_config_set",
        "data_processing",
        "data_processing",
        "__path__",
        "pathlib",
        "Path",
        "dp_path",
        "parent",
        "ConfigSet",
        "name",
        "config_file",
        "os",
        "path",
        "join",
        "parent_folder",
        "get_config_set",
        "logger",
        "info",
        "store_location",
        "os",
        "makedirs",
        "backend",
        "exist_ok",
        "logger",
        "info",
        "backend",
        "datastore_id",
        "datastore_type",
        "datastore_id",
        "datastore_type",
        "CONTAINER_TYPES",
        "logger",
        "warning",
        "datastore_type",
        "CONTAINER_TYPES",
        "datastore_id",
        "logger",
        "warning",
        "datastore_id",
        "Neo4jConnection",
        "uri",
        "user",
        "pwd",
        "conn",
        "query",
        "datastore_type",
        "datastore_id",
        "res",
        "logger",
        "info",
        "datastore_id",
        "datastore_type",
        "logger",
        "error",
        "node",
        "store_id",
        "Neo4jConnection",
        "uri",
        "user",
        "pwd",
        "conn",
        "query",
        "store_id",
        "node",
        "get_match_str",
        "node",
        "get_map_str",
        "node",
        "get_map_str",
        "res",
        "logger",
        "error",
        "store_id",
        "extra",
        "store_id",
        "res",
        "logger",
        "warning",
        "store_id",
        "extra",
        "store_id",
        "exc",
        "logger",
        "exception",
        "exc",
        "extra",
        "store_id",
        "store_id",
        "namespace_id",
        "data_type",
        "data_tag",
        "realpath",
        "os",
        "path",
        "join",
        "backend",
        "store_id",
        "namespace_id",
        "data_type",
        "data_tag",
        "os",
        "path",
        "exists",
        "dest_dir",
        "os",
        "path",
        "lexists",
        "dest_dir",
        "realpath",
        "os",
        "readlink",
        "dest_dir",
        "RuntimeWarning",
        "dest_dir",
        "dest_dir",
        "filepath",
        "store_id",
        "namespace_id",
        "data_type",
        "data_tag",
        "metadata",
        "symlink",
        "os",
        "path",
        "join",
        "backend",
        "store_id",
        "namespace_id",
        "data_type",
        "data_tag",
        "symlink",
        "os",
        "makedirs",
        "pathlib",
        "Path",
        "dest_dir",
        "parent",
        "exist_ok",
        "os",
        "path",
        "lexists",
        "dest_dir",
        "os",
        "remove",
        "dest_dir",
        "logger",
        "info",
        "dest_dir",
        "filepath",
        "os",
        "symlink",
        "filepath",
        "dest_dir",
        "os",
        "makedirs",
        "dest_dir",
        "exist_ok",
        "logger",
        "info",
        "filepath",
        "dest_dir",
        "shutil",
        "copy",
        "filepath",
        "dest_dir",
        "Node",
        "data_type",
        "data_tag",
        "metadata",
        "node",
        "set_namespace",
        "namespace_id",
        "store_id",
        "logger",
        "info",
        "node",
        "_write_to_graph_store",
        "node",
        "store_id",
        "dest_dir",
        "iostream",
        "store_id",
        "namespace_id",
        "data_type",
        "data_tag",
        "metadata",
        "dtype",
        "os",
        "path",
        "join",
        "store_id",
        "namespace_id",
        "data_type",
        "os",
        "path",
        "join",
        "dest_path_dir",
        "data_tag",
        "os",
        "path",
        "join",
        "backend",
        "dest_path_dir",
        "os",
        "path",
        "join",
        "backend",
        "dest_path_file",
        "os",
        "makedirs",
        "dest_dir",
        "exist_ok",
        "logger",
        "info",
        "dest_file",
        "open",
        "dest_file",
        "dtype",
        "fp",
        "fp",
        "write",
        "iostream",
        "Node",
        "data_type",
        "data_tag",
        "metadata",
        "node",
        "set_namespace",
        "namespace_id",
        "store_id",
        "logger",
        "info",
        "node",
        "_write_to_graph_store",
        "node",
        "store_id",
        "dest_file",
        "container_id",
        "logger",
        "info",
        "container_id",
        "isinstance",
        "ConfigSet",
        "get_config_set",
        "logger",
        "debug",
        "Neo4jConnection",
        "uri",
        "user",
        "pwd",
        "logger",
        "debug",
        "_conn",
        "test_connection",
        "get",
        "logger",
        "debug",
        "Minio",
        "access_key",
        "secret_key",
        "secure",
        "bucket",
        "_client",
        "list_buckets",
        "logger",
        "debug",
        "bucket",
        "name",
        "logger",
        "debug",
        "logger",
        "warning",
        "logger",
        "warning",
        "socket",
        "gethostname",
        "logger",
        "debug",
        "_host",
        "namespace_id",
        "Node",
        "namespace_id",
        "_conn",
        "query",
        "cohort",
        "get_create_str",
        "len",
        "create_res",
        "logger",
        "info",
        "namespace_id",
        "namespace_id",
        "namespace_id",
        "Node",
        "namespace_id",
        "namespace_id",
        "lower",
        "replace",
        "logger",
        "debug",
        "namespace_id",
        "_conn",
        "query",
        "_namespace_node",
        "get_match_str",
        "len",
        "match_res",
        "RuntimeError",
        "namespace_id",
        "get",
        "_client",
        "bucket_exists",
        "_bucket_id",
        "_client",
        "make_bucket",
        "_bucket_id",
        "container_id",
        "container_type",
        "container_type",
        "logger",
        "warning",
        "container_type",
        "container_id",
        "logger",
        "warning",
        "container_id",
        "Node",
        "container_type",
        "container_id",
        "node",
        "set_namespace",
        "_namespace_id",
        "_conn",
        "query",
        "node",
        "get_create_str",
        "len",
        "create_res",
        "logger",
        "info",
        "container_id",
        "container_type",
        "logger",
        "error",
        "container_id",
        "logger",
        "info",
        "container_id",
        "isinstance",
        "container_id",
        "container_id",
        "Node",
        "container_id",
        "node",
        "set_namespace",
        "_namespace_id",
        "node",
        "get_address",
        "node",
        "get_address",
        "isinstance",
        "container_id",
        "container_id",
        "container_id",
        "replace",
        "isinstance",
        "container_id",
        "container_id",
        "RuntimeError",
        "_conn",
        "query",
        "match_clause",
        "res",
        "len",
        "res",
        "logger",
        "warning",
        "container_id",
        "res",
        "res",
        "res",
        "res",
        "res",
        "res",
        "_qualifiedpath",
        "logger",
        "warning",
        "logger",
        "info",
        "_type",
        "_datastore_id",
        "address",
        "logger",
        "debug",
        "_attached",
        "_attached",
        "name",
        "isAttached",
        "_datastore_id",
        "name",
        "_namespace_id",
        "logger",
        "debug",
        "query",
        "_conn",
        "query",
        "query",
        "res",
        "logger",
        "warning",
        "name",
        "len",
        "res",
        "logger",
        "warning",
        "name",
        "len",
        "res",
        "logger",
        "warning",
        "name",
        "Node",
        "res",
        "res",
        "res",
        "items",
        "logger",
        "debug",
        "logger",
        "debug",
        "node",
        "node",
        "set_data",
        "node",
        "properties",
        "get",
        "node",
        "set_aux",
        "node",
        "properties",
        "get",
        "node",
        "staticmethod",
        "container_id",
        "pipeline",
        "func",
        "pipeline",
        "func",
        "func",
        "cohort_id",
        "container_id",
        "container_id",
        "method_data",
        "pipeline",
        "run",
        "_namespace_id",
        "_name",
        "pipeline",
        "pipeline",
        "executor",
        "isinstance",
        "executor",
        "ProcessPoolExecutor",
        "executor",
        "submit",
        "run",
        "_namespace_id",
        "_name",
        "pipeline",
        "pipeline",
        "client",
        "dask",
        "distributed",
        "Client",
        "isinstance",
        "client",
        "Client",
        "client",
        "submit",
        "bootstrap",
        "_name",
        "func",
        "pipeline",
        "func",
        "func",
        "client",
        "submit",
        "_namespace_id",
        "_name",
        "semaphore",
        "future",
        "future",
        "node",
        "Node",
        "isinstance",
        "node",
        "Node",
        "isAttached",
        "logger",
        "info",
        "node",
        "node",
        "set_namespace",
        "_namespace_id",
        "_name",
        "_datastore_id",
        "node",
        "data",
        "get",
        "node",
        "properties",
        "_bucket_id",
        "node",
        "properties",
        "_name",
        "node",
        "name",
        "pathlib",
        "Path",
        "node",
        "data",
        "data_path",
        "is_file",
        "node",
        "objects",
        "append",
        "data_path",
        "data_path",
        "is_dir",
        "path",
        "data_path",
        "glob",
        "node",
        "objects",
        "append",
        "path",
        "logger",
        "info",
        "len",
        "node",
        "objects",
        "node",
        "aux",
        "get",
        "node",
        "properties",
        "_bucket_id",
        "node",
        "properties",
        "_name",
        "node",
        "name",
        "node",
        "objects",
        "append",
        "pathlib",
        "Path",
        "node",
        "aux",
        "logger",
        "info",
        "len",
        "node",
        "objects",
        "logger",
        "info",
        "node",
        "get_address",
        "_conn",
        "query",
        "node",
        "_datastore_id",
        "node",
        "get_match_str",
        "node",
        "get_map_str",
        "node",
        "get_map_str",
        "get",
        "ThreadPoolExecutor",
        "max_workers",
        "node",
        "properties",
        "get",
        "node",
        "properties",
        "get",
        "p",
        "node",
        "objects",
        "executor",
        "submit",
        "_client",
        "fput_object",
        "object_bucket",
        "object_folder",
        "p",
        "name",
        "p",
        "part_size",
        "future_uploads",
        "append",
        "future",
        "len",
        "future_uploads",
        "future",
        "as_completed",
        "future_uploads",
        "future",
        "result",
        "logger",
        "exception",
        "n_count_futures",
        "n_count_futures",
        "logger",
        "info",
        "data",
        "n_count_futures",
        "n_count_futures",
        "logger",
        "info",
        "n_count_futures",
        "n_total_futures",
        "n_count_futures",
        "logger",
        "info",
        "n_count_futures",
        "n_total_futures",
        "logger",
        "info",
        "n_count_futures",
        "n_total_futures",
        "logger",
        "info",
        "executor",
        "executor",
        "shutdown",
        "logger",
        "info",
        "args",
        "logger",
        "warning",
        "args",
        "logger",
        "warning"
    ],
    "literals": [
        "'conf/datastore.cfg'",
        "'STORE_CFG'",
        "'conf/datastore.cfg'",
        "\"STORE_CFG\"",
        "'STORE_CFG'",
        "'conf/datastore.default.yml'",
        "\"STORE_CFG\"",
        "f\"Configured datastore with {self.params}\"",
        "f\"Datstore file backend= {self.backend}\"",
        "f\"DataStore type [{datastore_type}] invalid, please choose from [{CONTAINER_TYPES}]\"",
        "\":\"",
        "f\"Invalid datastore_id [{datastore_id}], only use alphanumeric characters\"",
        "'GRAPH_URI'",
        "'GRAPH_USER'",
        "'GRAPH_PASSWORD'",
        "f\"\"\" MERGE (datastore:globals:{datastore_type}{{qualified_address:'{datastore_id}'}}) RETURN count(datastore)\"\"\"",
        "'count(datastore)'",
        "f\"DataStore [{datastore_id}] of type [{datastore_type}] created or matched successfully!\"",
        "\"The datastore {node} could not be created or found\"",
        "'GRAPH_URI'",
        "'GRAPH_USER'",
        "'GRAPH_PASSWORD'",
        "f\"\"\"\n                MATCH (datastore) WHERE datastore.qualified_address = '{store_id}'\n                MERGE (datastore)-[:HAS_DATA]->(da:{node.get_match_str()})\n                    ON MATCH  SET da = {node.get_map_str()}\n                    ON CREATE SET da = {node.get_map_str()}\n                RETURN count(datastore)\"\"\"",
        "f\"Tried adding data to {store_id}, however query failed, this data will not be available!\"",
        "'store_id'",
        "'count(datastore)'",
        "f\"Tried adding data to {store_id}, however datastore did not exist, this data will not be available!\"",
        "'store_id'",
        "f\"On write, encountered {exc}, continuing...\"",
        "'store_id'",
        "'data'",
        "f\"Data not found at {dest_dir}\"",
        "'data'",
        "f\"Create symlink {dest_dir} -> {filepath}\"",
        "f\"Save {filepath} -> {dest_dir}\"",
        "'GRAPH_STORE_ENABLED'",
        "f\"Adding: {node}\"",
        "'w'",
        "f\"Save -> {dest_file}\"",
        "'GRAPH_STORE_ENABLED'",
        "f\"Adding: {node}\"",
        "f\"Bootstrapping pipeline for {container_id}\"",
        "\"APP_CFG\"",
        "\"Connecting to: %s\"",
        "'GRAPH_URI'",
        "'GRAPH_URI'",
        "'GRAPH_USER'",
        "'GRAPH_PASSWORD'",
        "\"Connection test: %s\"",
        "'OBJECT_STORE_ENABLED'",
        "\"Connecting to: %s\"",
        "'MINIO_URI'",
        "'MINIO_URI'",
        "'MINIO_USER'",
        "'MINIO_PASSWORD'",
        "\"Found bucket %s\"",
        "\"OBJECT_STORE_ENABLED=True\"",
        "'OBJECT_STORE_ENABLED'",
        "\"Could not connect to object store\"",
        "\"Set OBJECT_STORE_ENABLED=False\"",
        "'OBJECT_STORE_ENABLED'",
        "\"Running on: %s\"",
        "\"cohort\"",
        "f\"\"\" MERGE (co:{cohort.get_create_str()}) RETURN co\"\"\"",
        "f\"Namespace [{namespace_id}] created successfully\"",
        "\"cohort\"",
        "'_'",
        "'-'",
        "f\"Checking if [{namespace_id}] exists...\"",
        "f\"\"\" MATCH (co:{self._namespace_node.get_match_str()}) RETURN co\"\"\"",
        "f\"Namespace [{namespace_id}] does not exist, call .createNamespace() first!\"",
        "'OBJECT_STORE_ENABLED'",
        "'generic'",
        "'patient'",
        "'accession'",
        "'scan'",
        "'slide'",
        "'parquet'",
        "f\"DataStore type [{container_type}] invalid, please choose from ['generic', 'patient', 'accession', 'scan', 'slide', 'parquet']\"",
        "\":\"",
        "f\"Invalid container_id [{container_id}], only use alphanumeric characters\"",
        "f\"\"\" MERGE (container:{node.get_create_str()}) RETURN container\"\"\"",
        "f\"DataStore [{container_id}] of type [{container_type}] created or matched successfully!\"",
        "\"The container does not exists\"",
        "\"Lookup ID: %s\"",
        "\"uid://\"",
        "\"generic\"",
        "f\"\"\"WHERE container.qualified_address = '{node.get_address()}' \"\"\"",
        "\"uid://\"",
        "f\"\"\"WHERE id(container) = {container_id.replace('uid://', '')} \"\"\"",
        "'uid://'",
        "''",
        "f\"\"\"WHERE id(container) = {container_id} \"\"\"",
        "\"Invalid container_id type not (str, int)\"",
        "f\"\"\"\n            MATCH (container) {match_clause}\n            RETURN id(container), labels(container), container.type, container.name, container.namespace, container.qualified_address\"\"\"",
        "f\"DataStore [{container_id}] does not exist, you can try creating it first with createContainer()\"",
        "\"id(container)\"",
        "\"container.name\"",
        "\"container.qualified_address\"",
        "\"container.type\"",
        "\"labels(container)\"",
        "\"container.qualified_address\"",
        "\"Found, however not valid container object, containers must have a name, namespace, and qualified path\"",
        "\"Successfully attached to %s container id=%s @ %s\"",
        "\"Attached: %s\"",
        "f\"\"\"MATCH (container)-[:HAS_DATA]-(data:{type}) WHERE id(container) = {self._datastore_id} AND data.name='{type}-{name}' AND data.namespace='{self._namespace_id}' RETURN data\"\"\"",
        "f\"get() query failed, data.name='{type}-{name}' returning None\"",
        "f\"get() found no nodes, data.name='{type}-{name}' returning None\"",
        "f\"get() found many nodes (?), data.name='{type}-{name}' returning None\"",
        "'data'",
        "'type'",
        "'data'",
        "'name'",
        "'data'",
        "\"Query Successful:\"",
        "'data'",
        "'aux'",
        "f\"Adding node: {node}\"",
        "\"OBJECT_STORE_ENABLED\"",
        "'object_bucket'",
        "f\"{self._bucket_id}\"",
        "'object_folder'",
        "f\"{self._name}/{node.name}\"",
        "\"*.*\"",
        "\"Node has %s pending object commits\"",
        "\"OBJECT_STORE_ENABLED\"",
        "'object_bucket'",
        "f\"{self._bucket_id}\"",
        "'object_folder'",
        "f\"{self._name}/{node.name}\"",
        "\"Node has %s pending object commits\"",
        "\"Adding: %s\"",
        "f\"\"\"\n            MATCH (container) WHERE id(container) = {node._datastore_id}\n            MERGE (container)-[:HAS_DATA]->(da:{node.get_match_str()})\n                ON MATCH  SET da = {node.get_map_str()}\n                ON CREATE SET da = {node.get_map_str()}\n            \"\"\"",
        "\"OBJECT_STORE_ENABLED\"",
        "\"object_bucket\"",
        "\"object_folder\"",
        "f\"{object_folder}/{p.name}\"",
        "'Bad upload: generated an exception:'",
        "\"Upload successful with etag: %s\"",
        "\"Uploaded [%s/%s]\"",
        "\"Uploaded [%s/%s]\"",
        "\"Uploaded [%s/%s]\"",
        "\"Shutdown executor %s\"",
        "\"Done saving all records!!\"",
        "\"Datastore.add() has been depreciated\"",
        "\"Datastore.saveAll() has been depreciated\""
    ],
    "variables": [
        "logger",
        "dp_path",
        "parent_folder",
        "backend",
        "datastore_id",
        "conn",
        "res",
        "conn",
        "res",
        "dest_dir",
        "dest_dir",
        "dest_dir",
        "node",
        "dest_path_dir",
        "dest_path_file",
        "dest_dir",
        "dest_file",
        "node",
        "_conn",
        "_client",
        "_host",
        "_attached",
        "cohort",
        "create_res",
        "_namespace_id",
        "_namespace_node",
        "_bucket_id",
        "match_res",
        "node",
        "create_res",
        "_attached",
        "node",
        "match_clause",
        "match_clause",
        "match_clause",
        "res",
        "_datastore_id",
        "_name",
        "_qualifiedpath",
        "_type",
        "_labels",
        "address",
        "_attached",
        "query",
        "res",
        "node",
        "future",
        "future",
        "node",
        "_datastore_id",
        "node",
        "objects",
        "data_path",
        "future_uploads",
        "executor",
        "object_bucket",
        "object_folder",
        "future",
        "n_count_futures",
        "n_total_futures",
        "data"
    ],
    "comments": [
        "Configure our connection",
        "if realpath is true, return path to data instead of symlink location",
        "TODO: worried about schema issues? like making sure name, namespace, type and qualified path are present, neo4j offers schema enforcment.",
        "TODO: testing",
        "TODO: error checking",
        "Connect to graph DB",
        "portable to *docker* containers",
        "Figure out how to match the node",
        "Run query",
        "Check if the results are singleton (they should be... since we only query unique IDs!!!)",
        "Set some potentially import parameters",
        "Containers need to have a qualified path",
        "Let us know attaching was a success! :)",
        "Catches bad queries",
        "If successfull query, reconstruct a Node object",
        "Decorate with the container namespace",
        "Set node data object(s) only if there is a path and the object store is enabled",
        "TODO: enable extention in glob via something?",
        "Set node aux object only if a path and the object store is enabled",
        "Add to node commit dictonary"
    ],
    "docstrings": [
        "\"\"\"\n        :params: datastore_id - unique container ID\n        \"params: datastore_type - the type of the container\n        \"\"\"",
        "\"\"\" Saves the 'node' to a datastore managed in the graph DB \"\"\"",
        "\"\"\" Looks up and returns the path of data given the store_id, namespace_id, data_type, and data_tag \"\"\"",
        "\"\"\" Puts the file at filepath at the proper location given a store_id, namespace_id, data_type, and data_tag, and save metadata to DB \"\"\"",
        "\"\"\" Writes iostream at the proper location given a store_id, namespace_id, data_type, and data_tag, and save metadata to DB \"\"\"",
        "\"\"\"\n    DataStore: an abstraction with an id, name, namespace, type, and a list of associated data nodes\n\n    Interfaces with a metadata store (graph DB) and raw file stores (gpfs, potentially others)\n\n    Handles the matching and creation of metadata\n\n    Example usage:\n    $ container = data_processing.common.GraphEnum.DataStore( params ).setNamespace(\"test\").setContainer(\"1.2.840...\")\n        > Connecting to: neo4j://localhost:7687\n        > Connection successfull: True\n        > Running on: localhost\n        > Lookup ID: 1.2.840...\n        > Found: [<Record id(container)=7091 labels(container)=['scan'] container.type='scan' container.name='1.2.840...>]\n        > Match on: WHERE id(container) = 7091\n        > Successfully attached to: scan 1.2.840...\n\n    $ node = Node(\"dicom\", \"DCM-0123\", {\"Modality\":\"CT\", \"path\":\"file:/some/path/1.dcm\"})\n\n    $ container.put(node)\n        > Adding: test-0000\n          DataStore has 1 pending commits\n\n    $\n        > Committing dicom:globals{ hash: 'abc123' name: 'my-dicom', qualified_address: 'test::1.2.840::my-dicom', namespace: 'test', type: 'dicom' , path: 'file:/some/path/1.dcm'}\n\n    $ container.get(\"dicom\", \"my-dicom\").path\n        > /some/path/1.dcm\n\n    $ container.get(\"dicom\", \"my-dicom\").properties['Modality']\n        > 'CT'\n\n    The container includes a logging method:\n    $ container.logger.info(\"I am processing the CT\")\n        > 'yyyy-mm-dd h:m:s,ms - DataStore [1] - INFO - I am processing the CT'\n\n\n    \"\"\"",
        "\"\"\"\n        Initialize the container object.\n            Connects to the graph DB\n            Figure out what host this code is running on\n\n        :params: params - dictonary of important configuration, right now, only the graph URI connection parameters are needed.\n        \"\"\"",
        "\"\"\"\n        Creates a namesapce, if it doesn't exist, else, tells you it exists\n\n        :params: namespace_id - namespace value\n        \"\"\"",
        "\"\"\"\n        Sets the namespace for this container's commits, if it exists\n\n        :params: namespace_id - namespace value\n        \"\"\"",
        "\"\"\"\n        Checks if the node referenced by container_id is a valid container, queries the metastore for relevant metadata\n\n        :params: container_id - unique container ID\n        \"params: type - the type of the container\n        \"\"\"",
        "\"\"\"\n        Checks if the node referenced by container_id is a valid datastore, queries the metastore for relevant metadata\n\n        :params: container_id - the unique container ID, either as an integer (neo4j autopopulated ID) or as a string (the Qualified Path)\n        \"\"\"",
        "\"\"\"\n        Returns true if container was properly attached (i.e. checks in setDatastore succeeded), else False\n        \"\"\"",
        "\"\"\"\n        Query graph DB container node for dependent data nodes, and return one\n        Parses the path field URL for various cases, and sets the node.data an node.aux attribute with a corrected path\n        Note: namespace is not a default filter for get nodes, but is for adding them (i.e., one can write data under a different namespace)\n\n        :params: type - the type of data designed\n            e.g. radiomics, mha, dicom, png, svs, geojson, etc.\n        :params: name - can be used to filter nodes\n            e.g. name of the node in the subspace of the container (e.g. generate-mhd)\n        :example: get(\"mhd\", \"generate-mhd\") gets data of type \"mhd\" generated from the method \"generate-mhd\" in this container's context/subspace\n        \"\"\"",
        "\"\"\"\n        Runner for pipelined jobs\n        \"\"\"",
        "\"\"\"\n        Run a pipeline in the main thread, blocking.\n\n        :params: pipeline - an ordered list of (function, params) tuples to execute\n        \"\"\"",
        "\"\"\"\n        Use a process pool executor to run full pipelines in background\n\n        :params: pipeline - an ordered list of (function, params) tuples to execute\n        :params: executor - a ProcessPoolExecutor passed from a parent script\n        \"\"\"",
        "\"\"\"\n        Submit functions to dask workers.\n        Dask can track dependencies via a semaphore future, so we pass that explicitly and submit each function individually\n\n        :params: pipeline - an ordered list of (function, params) tuples to execute\n        :params: client - a dask client\n        \"\"\"",
        "\"\"\"\n        Adds a node to a temporary dictonary that will be used to save/commit nodes to the relevant databases\n        If you add the same node under the same name, no change as the\n        Decorates the node with the container's namespace\n\n        :param: node - node object\n        \"\"\""
    ],
    "functions": [
        "ensure_datastore",
        "_write_to_graph_store",
        "get",
        "put",
        "write",
        "bootstrap",
        "createNamespace",
        "setNamespace",
        "createDatastore",
        "setDatastore",
        "isAttached",
        "get",
        "run",
        "runLocal",
        "runProcessPoolExecutor",
        "runDaskDistributed",
        "put",
        "add",
        "saveAll"
    ],
    "classes": [
        "DataStore_v2",
        "DataStore"
    ]
}