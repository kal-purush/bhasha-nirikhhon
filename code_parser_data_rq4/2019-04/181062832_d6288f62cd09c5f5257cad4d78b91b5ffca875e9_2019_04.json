{
    "identifiers": [
        "csv",
        "cv2",
        "numpy",
        "np",
        "keras",
        "models",
        "Sequential",
        "keras",
        "layers",
        "Dense",
        "Flatten",
        "Lambda",
        "Conv2D",
        "MaxPooling2D",
        "Activation",
        "Cropping2D",
        "Dropout",
        "BatchNormalization",
        "sklearn",
        "model_selection",
        "train_test_split",
        "sklearn",
        "utils",
        "shuffle",
        "matplotlib",
        "pyplot",
        "imread",
        "math",
        "ceil",
        "data_path",
        "split_ratio",
        "correction_factor",
        "data_path",
        "split_ratio",
        "correction_factor",
        "training_samples",
        "validation_samples",
        "split_data",
        "sample",
        "i",
        "sample",
        "i",
        "split",
        "imread",
        "data_path",
        "image_filename",
        "images",
        "append",
        "image",
        "sample",
        "measurement",
        "correction_factor",
        "measurement",
        "correction_factor",
        "measurements",
        "append",
        "measurement",
        "measurements",
        "append",
        "left_measurement",
        "measurements",
        "append",
        "right_measurement",
        "images",
        "measurements",
        "open",
        "data_path",
        "csvfile",
        "csv",
        "reader",
        "csvfile",
        "next",
        "reader",
        "line",
        "reader",
        "lines",
        "append",
        "line",
        "lines",
        "train_test_split",
        "import_data",
        "test_size",
        "split_ratio",
        "training_samples",
        "validation_samples",
        "samples",
        "batch_size",
        "len",
        "samples",
        "shuffle",
        "samples",
        "offset",
        "n_samples",
        "batch_size",
        "samples",
        "offset",
        "offset",
        "batch_size",
        "sample",
        "batch_samples",
        "process_sample",
        "sample",
        "images",
        "extend",
        "sample_images",
        "measurements",
        "extend",
        "sample_measurements",
        "image",
        "measurement",
        "images",
        "measurements",
        "augmented_images",
        "append",
        "image",
        "augmented_images",
        "append",
        "np",
        "fliplr",
        "image",
        "augmented_measurements",
        "append",
        "measurement",
        "augmented_measurements",
        "append",
        "measurement",
        "np",
        "array",
        "augmented_images",
        "np",
        "array",
        "augmented_measurements",
        "X_train",
        "y_train",
        "batch_size",
        "batch_size",
        "data_generator",
        "samples",
        "validation_samples",
        "batch_size",
        "batch_size",
        "ceil",
        "len",
        "validation_samples",
        "batch_size",
        "batch_size",
        "batch_size",
        "data_generator",
        "samples",
        "training_samples",
        "batch_size",
        "batch_size",
        "ceil",
        "len",
        "training_samples",
        "batch_size",
        "input_shape",
        "input_shape",
        "Sequential",
        "model",
        "add",
        "Lambda",
        "x",
        "x",
        "input_shape",
        "input_shape",
        "model",
        "add",
        "Cropping2D",
        "cropping",
        "model",
        "add",
        "Conv2D",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "MaxPooling2D",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Conv2D",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "MaxPooling2D",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Conv2D",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "MaxPooling2D",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Conv2D",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Conv2D",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Flatten",
        "model",
        "add",
        "Dense",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Dense",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Dense",
        "model",
        "add",
        "BatchNormalization",
        "model",
        "add",
        "Activation",
        "model",
        "add",
        "Dense",
        "layer",
        "model",
        "layers",
        "layer",
        "output_shape",
        "model",
        "compile",
        "loss",
        "optimizer",
        "model",
        "DataUtil",
        "ModelUtil",
        "batch_size",
        "n_epoch",
        "dataUtil",
        "training_generator",
        "batch_size",
        "dataUtil",
        "validation_generator",
        "batch_size",
        "training_step_size",
        "validation_step_size",
        "modelUtil",
        "getModel",
        "model",
        "fit_generator",
        "training_generator",
        "steps_per_epoch",
        "training_step_size",
        "validation_data",
        "validation_generator",
        "validation_steps",
        "validation_step_size",
        "epochs",
        "n_epoch",
        "verbose",
        "model",
        "save",
        "PipeLine",
        "pipeline",
        "run"
    ],
    "literals": [
        "'./data/'",
        "'/'",
        "'IMG/'",
        "'driving_log.csv'",
        "'relu'",
        "'relu'",
        "'relu'",
        "'relu'",
        "'relu'",
        "'relu'",
        "'relu'",
        "'relu'",
        "'Printing Network Layers.....'",
        "'mse'",
        "'adam'",
        "'model.h5'",
        "\"__main__\""
    ],
    "variables": [
        "data_path",
        "split_ratio",
        "correction_factor",
        "images",
        "measurements",
        "image_filename",
        "image",
        "measurement",
        "left_measurement",
        "right_measurement",
        "reader",
        "lines",
        "training_samples",
        "validation_samples",
        "n_samples",
        "batch_samples",
        "images",
        "measurements",
        "sample_images",
        "sample_measurements",
        "augmented_images",
        "augmented_measurements",
        "X_train",
        "y_train",
        "batch_size",
        "batch_size",
        "input_shape",
        "model",
        "dataUtil",
        "modelUtil",
        "training_generator",
        "training_step_size",
        "validation_generator",
        "validation_step_size",
        "model",
        "pipeline"
    ],
    "comments": [
        "Add correction to the left and right steering angle",
        "fetch batch from samples",
        "Augment the data by flipping the image horizontally",
        "divide the batch size by six because for one line of input (i.e. csv file line)",
        "we create 6 data sample using data augmentation",
        "divide the batch size by six because for one line of input (i.e. csv file line)",
        "we create 6 data sample using data augmentation",
        "Zero mean normalization of data",
        "Crop the image to remove the things that are not relevent like trees etc.",
        "Model Architecture",
        "Add batch normalization for regularization to prevent overfitting",
        "Add relu actionvation for non-linearity",
        "Fit model using keras fit generator"
    ],
    "docstrings": [
        "\"\"\"\n    @param: sample\n    sample is the csv file line contains the path of the center, left, and right\n    image with steering angle\n\n    return: center, left, and right image with there corresponding steering angle \n            with correction\n    \"\"\"",
        "\"\"\"\n    Import csv file and return the list of the lines \n    \"\"\"",
        "\"\"\"\n    Split data into training and validation set with size of validation set equal to self.split_ratio\n    \"\"\"",
        "\"\"\"\n    Data generator function to load and preprocess the data on fly\n    \"\"\""
    ],
    "functions": [
        "process_sample",
        "import_data",
        "split_data",
        "data_generator",
        "validation_generator",
        "training_generator",
        "getModel",
        "run"
    ],
    "classes": [
        "DataUtil",
        "ModelUtil",
        "PipeLine"
    ]
}