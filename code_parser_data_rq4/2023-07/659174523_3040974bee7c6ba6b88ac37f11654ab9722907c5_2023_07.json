{
    "identifiers": [
        "typing",
        "Any",
        "Dict",
        "Optional",
        "Tuple",
        "torch",
        "lightning",
        "LightningDataModule",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "Dataset",
        "random_split",
        "ConcatDataset",
        "data",
        "components",
        "deepPocketDataset",
        "DeepPocketLoadingEncoderFeatureDataset",
        "typing",
        "LightningDataModule",
        "numpy",
        "np",
        "model",
        "torch",
        "nn",
        "Module",
        "data_dir",
        "train_val_test_split",
        "Tuple",
        "batch_size",
        "num_workers",
        "pin_memory",
        "paths",
        "save_hyperparameters",
        "logger",
        "model",
        "paths",
        "Optional",
        "Dataset",
        "Optional",
        "Dataset",
        "Optional",
        "Dataset",
        "stage",
        "Optional",
        "data_train",
        "data_val",
        "data_test",
        "path",
        "paths",
        "model",
        "model",
        "loudOnlyEncoder",
        "path",
        "model",
        "freeze",
        "DeepPocketLoadingEncoderFeatureDataset",
        "path",
        "model",
        "transform",
        "random_split",
        "dataset",
        "dataset",
        "lengths",
        "hparams",
        "train_val_test_split",
        "generator",
        "torch",
        "Generator",
        "manual_seed",
        "train_datasets",
        "append",
        "train_dataset",
        "val_datasets",
        "append",
        "val_dataset",
        "test_datasets",
        "append",
        "test_dataset",
        "ConcatDataset",
        "train_datasets",
        "ConcatDataset",
        "val_datasets",
        "ConcatDataset",
        "test_datasets",
        "DataLoader",
        "dataset",
        "data_train",
        "batch_size",
        "hparams",
        "batch_size",
        "num_workers",
        "hparams",
        "num_workers",
        "pin_memory",
        "hparams",
        "pin_memory",
        "shuffle",
        "DataLoader",
        "dataset",
        "data_val",
        "batch_size",
        "hparams",
        "batch_size",
        "num_workers",
        "hparams",
        "num_workers",
        "pin_memory",
        "hparams",
        "pin_memory",
        "shuffle",
        "DataLoader",
        "dataset",
        "data_test",
        "batch_size",
        "hparams",
        "batch_size",
        "num_workers",
        "hparams",
        "num_workers",
        "pin_memory",
        "hparams",
        "pin_memory",
        "shuffle",
        "stage",
        "Optional",
        "state_dict",
        "Dict",
        "Any",
        "DeepPocketMultiAssetDataModule"
    ],
    "literals": [
        "\"data/\"",
        "\"modelCheckPoint\"",
        "\"__main__\""
    ],
    "variables": [
        "model",
        "paths",
        "data_train",
        "data_val",
        "data_test",
        "train_datasets",
        "val_datasets",
        "test_datasets",
        "model",
        "dataset",
        "train_dataset",
        "val_dataset",
        "test_dataset",
        "data_train",
        "data_val",
        "data_test",
        "_"
    ],
    "comments": [
        "this line allows to access init params with 'self.hparams' attribute",
        "also ensures init params will be stored in ckpt",
        "data transformations",
        "self.transforms = transforms.Compose(",
        "[transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]",
        ")",
        "@property",
        "def num_classes(self):",
        "return 10",
        "load and split datasets only if not loaded already"
    ],
    "docstrings": [
        "\"\"\"\n\n    A DataModule implements 6 key methods:\n        def prepare_data(self):\n            # things to do on 1 GPU/TPU (not on every GPU/TPU in DDP)\n            # download data, pre-process, split, save to disk, etc...\n        def setup(self, stage):\n            # things to do on every process in DDP\n            # load data, set variables, etc...\n        def train_dataloader(self):\n            # return train dataloader\n        def val_dataloader(self):\n            # return validation dataloader\n        def test_dataloader(self):\n            # return test dataloader\n        def teardown(self):\n            # called on every process in DDP\n            # clean up after fit or test\n\n    This allows you to share a full dataset without explaining how to download,\n    split, transform and process the data.\n\n    Read the docs:\n        https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n    \"\"\"",
        "\"\"\"Download data if needed.\n\n        Do not use it to assign state (self.x = y).\n        \"\"\"",
        "\"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n\n        This method is called by lightning with both `trainer.fit()` and `trainer.test()`, so be\n        careful not to execute things like random split twice!\n        \"\"\"",
        "\"\"\"Clean up after fit or test.\"\"\"",
        "\"\"\"Extra things to save to checkpoint.\"\"\"",
        "\"\"\"Things to do when loading checkpoint.\"\"\""
    ],
    "functions": [
        "prepare_data",
        "setup",
        "train_dataloader",
        "val_dataloader",
        "test_dataloader",
        "teardown",
        "state_dict",
        "load_state_dict"
    ],
    "classes": [
        "DeepPocketMultiAssetDataModule"
    ]
}