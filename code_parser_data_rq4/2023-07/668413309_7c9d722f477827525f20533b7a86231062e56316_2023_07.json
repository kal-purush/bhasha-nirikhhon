{
    "identifiers": [
        "config",
        "DEVICE",
        "PATH_TO_MODEL",
        "TRANSFORM_TRAIN",
        "segmentation_models_pytorch",
        "smp",
        "torch",
        "PIL",
        "Image",
        "numpy",
        "np",
        "matplotlib",
        "pyplot",
        "plt",
        "smp",
        "Unet",
        "encoder_name",
        "encoder_weights",
        "in_channels",
        "classes",
        "model",
        "load_state_dict",
        "torch",
        "load",
        "PATH_TO_MODEL",
        "model",
        "to",
        "DEVICE",
        "model",
        "eval",
        "Image",
        "open",
        "TRANSFORM_TRAIN",
        "image",
        "torch",
        "tensor",
        "np",
        "array",
        "pil_img",
        "dtype",
        "torch",
        "float32",
        "permute",
        "unsqueeze",
        "to",
        "DEVICE",
        "model",
        "img",
        "pred",
        "cpu",
        "detach",
        "numpy",
        "squeeze",
        "pred_np",
        "threshold",
        "astype",
        "np",
        "uint8",
        "Image",
        "fromarray",
        "mask_binary",
        "plt",
        "subplots",
        "figsize",
        "axes",
        "imshow",
        "img",
        "axes",
        "set_title",
        "axes",
        "axis",
        "axes",
        "imshow",
        "mask_pil",
        "cmap",
        "axes",
        "set_title",
        "axes",
        "axis",
        "plt",
        "show"
    ],
    "literals": [
        "\"resnet34\"",
        "\"imagenet\"",
        "'./airbus-ship-detection/test_v2/00c3db267.jpg'",
        "'image'",
        "\"Input Image\"",
        "\"off\"",
        "'gray'",
        "\"Segmentation Mask\"",
        "\"off\""
    ],
    "variables": [
        "model",
        "pil_img",
        "img",
        "pred",
        "pred_np",
        "threshold",
        "mask_binary",
        "mask_pil",
        "fig",
        "axes"
    ],
    "comments": [
        "choose encoder, e.g. mobilenet_v2 or efficientnet-b7",
        "use `imagenet` pre-trained weights for encoder initialization",
        "model input channels (1 for gray-scale images, 3 for RGB, etc.)",
        "model output channels (number of classes in your dataset)",
        "Convert the prediction tensor to a NumPy array and squeeze the batch dimension (if present)",
        "Assuming your model outputs the segmentation mask, you can use a threshold to convert it to binary (0 or 1)",
        "Convert the mask to a PIL image",
        "Visualize the image and mask side by side"
    ],
    "docstrings": [],
    "functions": [],
    "classes": []
}