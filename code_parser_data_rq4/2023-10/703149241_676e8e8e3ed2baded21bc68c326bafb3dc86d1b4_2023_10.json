{
    "identifiers": [
        "Conversation",
        "Metadata",
        "getMatchesFromEmbeddings",
        "summarizeLongDocument",
        "templates",
        "PineconeClient",
        "ConversationChain",
        "LLMChain",
        "ChatOpenAI",
        "ChatOpenAICallOptions",
        "OpenAIEmbeddings",
        "OpenAI",
        "ChatPromptTemplate",
        "MessagesPlaceholder",
        "PromptTemplate",
        "AIMessage",
        "BaseMessageChunk",
        "ChainValues",
        "HumanMessage",
        "StringOutputParser",
        "RunnableSequence",
        "SqlDatabase",
        "NextRequest",
        "NextResponse",
        "DataSource",
        "chatOpenAI",
        "embedder",
        "initPineconeClient",
        "llm",
        "BufferMemory",
        "ChatMessageHistory",
        "request",
        "request",
        "ChatOpenAI",
        "process",
        "PromptTemplate",
        "LLMChain",
        "model",
        "questionGeneratorTemplate",
        "fasterChain",
        "body",
        "body",
        "body",
        "text",
        "DataSource",
        "process",
        "process",
        "process",
        "process",
        "process",
        "SqlDatabase",
        "datasource",
        "db",
        "PromptTemplate",
        "body",
        "RunnableSequence",
        "schema",
        "body",
        "input",
        "input",
        "prompt",
        "model",
        "StringOutputParser",
        "sqlQueryGeneratorChain",
        "body",
        "result",
        "result",
        "handleRequest",
        "body",
        "PromptTemplate",
        "RunnableSequence",
        "input",
        "input",
        "sqlQueryGeneratorChain",
        "templates",
        "input",
        "input",
        "input",
        "input",
        "input",
        "db",
        "input",
        "res",
        "res",
        "res",
        "err",
        "err",
        "finalResponsePrompt",
        "model",
        "fullChain",
        "body",
        "finalResponse",
        "NextResponse",
        "body",
        "finalResponse",
        "error",
        "error",
        "NextResponse",
        "body",
        "chatWithHistory",
        "model",
        "question",
        "HumanMessage",
        "AIMessage",
        "BufferMemory",
        "ChatMessageHistory",
        "pastMessages",
        "PromptTemplate",
        "templates",
        "ChatPromptTemplate",
        "MessagesPlaceholder",
        "ConversationChain",
        "model",
        "chatPrompt",
        "chain",
        "question",
        "response",
        "NextResponse",
        "question",
        "response",
        "input",
        "model",
        "PromptTemplate",
        "LLMChain",
        "model",
        "chain",
        "input",
        "result",
        "input",
        "result",
        "handleRequest",
        "initPineconeClient",
        "Conversation",
        "conversation",
        "conversation",
        "prompt",
        "LLMChain",
        "PromptTemplate",
        "templates",
        "inquiryChain",
        "prompt",
        "inquiryChainResult",
        "inquiry",
        "embedder",
        "inquiry",
        "getMatchesFromEmbeddings",
        "embeddings",
        "pinecone",
        "matches",
        "matches",
        "match",
        "match",
        "url",
        "urls",
        "matches",
        "matches",
        "match",
        "match",
        "url",
        "url",
        "text",
        "text",
        "PromptTemplate",
        "templates",
        "LLMChain",
        "promptTemplate",
        "chatOpenAI",
        "docs",
        "allDocs",
        "summarizeLongDocument",
        "allDocs",
        "allDocs",
        "chain",
        "summary",
        "prompt",
        "response",
        "NextResponse",
        "prompt",
        "response",
        "error",
        "error"
    ],
    "literals": [
        "\"@/lib/conversation\"",
        "\"@/lib/matches\"",
        "\"@/lib/summarizer\"",
        "\"@/lib/templates\"",
        "\"@pinecone-database/pinecone\"",
        "\"langchain/chains\"",
        "\"langchain/chat_models/openai\"",
        "\"langchain/embeddings/openai\"",
        "\"langchain/llms/openai\"",
        "\"langchain/prompts\"",
        "\"langchain/schema\"",
        "\"langchain/schema/output_parser\"",
        "\"langchain/schema/runnable\"",
        "\"langchain/sql_db\"",
        "\"next/server\"",
        "\"typeorm\"",
        "'../../../lib/initializations'",
        "\"langchain/memory\"",
        "\"POST\"",
        "\"gpt-3.5-turbo\"",
        "Given the following conversation and a follow up question, rephrase the follow up question base on the chat history adding the missing data.\n  ----------\n  CHAT HISTORY: {chatHistory}\n  ----------\n  FOLLOWUP QUESTION: {question}\n  ----------\n  Standalone question:",
        "'text-generated'",
        "\"postgres\"",
        "\"conversations\"",
        "Based on the table schema and chat history below, write a postgres SQL query that would answer the user's question and do not mention that you do a sql query in the answer, if you do not have all data necessary to write:\n{schema}\n{history}\n\nQuestion: {question}\nSQL Query:",
        "'history'",
        "\"\\nSQLResult:\"",
        "'query'",
        "'SELECT'",
        "Based on the table schema below, question, postgres sql query, and sql response, write a natural language response, is the response is a list or table, please write a response in markdown format when show the list or table in a separate line, if there are no data, please write a short message to express that there are no data:\n        {schema}\n\n        Question: {question}\n        SQL Query: {query}\n        SQL Response: {response}",
        "\"SQL\"",
        "'res'",
        "\"SQL\"",
        "\"OpenAI\"",
        "\"SQL\"",
        "'final response'",
        "\"POST\"",
        "\"[USERS_POST123]\"",
        "'Sorry, I am not able to answer your question.'",
        "string",
        "\"What is the name of the first project?\"",
        "\"The first project name is: Project 10.\"",
        "\"system\"",
        "The following is a conversation between a human and an AI. The AI is an expert in sql and will create an sql query to answer the human's question following the rules bellow:\n        - The AI will only answer if the question is a valid sql query.\n        - The AI will complete the query base on the conversation history.\n        - The AI will use the following database schema: \n        Database schemaCREATE TABLE \"public\".\"conversations\" (\n        id bigint NOT NULL, created_at timestamp with time zone NOT NULL, entry character varying , speaker character varying ) \n        SELECT * FROM \"public\".\"conversations\" LIMIT 3;\n         id created_at entry speaker\n        CREATE TABLE \"public\".\"logic\" (\n        logic_id integer NOT NULL, prerequisite_task_id integer , dependent_task_id integer ) \n        SELECT * FROM \"public\".\"logic\" LIMIT 3;\n         logic_id prerequisite_task_id dependent_task_id\n         1 1 2\n         2 2 3\n         3 3 4\n        CREATE TABLE \"public\".\"projects\" (\n        project_id integer NOT NULL, project_name character varying ) \n        SELECT * FROM \"public\".\"projects\" LIMIT 3;\n         project_id project_name\n         1 High-rise Building Construction Project\n         2 Residential Complex Construction Project\n         3 Bridge Construction Project\n        CREATE TABLE \"public\".\"resource_assignments\" (\n        assignment_id integer NOT NULL, task_id integer , resource_name character varying , assignment_duration integer ) \n        SELECT * FROM \"public\".\"resource_assignments\" LIMIT 3;\n         assignment_id task_id resource_name assignment_duration\n         1 1 Excavator Operator 2\n         2 2 Construction Worker 2\n         3 3 Bricklayer 2\n        CREATE TABLE \"public\".\"tasks\" (\n        task_id integer NOT NULL, task_name character varying , project_id integer , commencement_date date , conclusion_date date , duration integer ) \n        SELECT * FROM \"public\".\"tasks\" LIMIT 3;\n         task_id task_name project_id commencement_date conclusion_date duration\n         1 Excavation 1 Wed Oct 11 2023 00:00:00 GMT-0500 (Eastern Standard Time) Sat Oct 14 2023 00:00:00 GMT-0500 (Eastern Standard Time) 3\n         2 Foundation Construction 1 Wed Oct 18 2023 00:00:00 GMT-0500 (Eastern Standard Time) Sat Oct 21 2023 00:00:00 GMT-0500 (Eastern Standard Time) 3\n         3 Wall Construction 1 Wed Oct 25 2023 00:00:00 GMT-0500 (Eastern Standard Time) Sat Oct 28 2023 00:00:00 GMT-0500 (Eastern Standard Time) 3\n      \n          - The AI response with the sql query that answers the question\n          - The AI will not mention that it is doing a sql query\n          - The AI will not mention the database schema\n          - The AI return only the sql query",
        "\"history\"",
        "\"human\"",
        "\"{input}\"",
        "'response'",
        "string",
        "\"Respond the question with short answer and be nice\\n Question: {question}\"",
        "\"question\"",
        "'result'",
        "'Answer: '",
        "''",
        "string",
        "\"user\"",
        "\"userPrompt\"",
        "\"conversationHistory\"",
        "\"summaries\"",
        "\"question\"",
        "\"conversationHistory\"",
        "\"urls\"",
        "\"\\n\"",
        "\"response\"",
        "\"error\""
    ],
    "variables": [
        "maxDuration",
        "body",
        "model",
        "questionGeneratorTemplate",
        "fasterChain",
        "datasource",
        "db",
        "schema",
        "prompt",
        "sqlQueryGeneratorChain",
        "result",
        "finalResponsePrompt",
        "fullChain",
        "finalResponse",
        "chatWithHistory",
        "pastMessages",
        "memory",
        "prompt",
        "chatPrompt",
        "chain",
        "response",
        "template",
        "prompt",
        "chain",
        "result",
        "handleRequest",
        "pinecone",
        "conversation",
        "conversationHistory",
        "inquiryChain",
        "inquiryChainResult",
        "inquiry",
        "embeddings",
        "matches",
        "urls",
        "metadata",
        "metadata",
        "docs",
        "metadata",
        "metadata",
        "_",
        "text",
        "promptTemplate",
        "chain",
        "allDocs",
        "summary",
        "response"
    ],
    "comments": [
        "return await chatWithHistory(model, body.message);",
        "console.log('datasource', datasource);",
        "console.log('schema', schema);\n    await fs.writeFile('./schema.json', schema);\n    \n\n    if (!schema) {\n      throw new Error(\"No schema found\");\n      return;\n    }",
        "new HumanMessage(\"Give me the tasks of the project.\"),\n    new AIMessage(\"To retrieve the tasks of a specific project, I need the project ID. Could you please provide me with the project ID?\"),",
        "let summarizedCount = 0;",
        "Retrieve the conversation log and save the user's prompt",
        "Build an LLM chain that will improve the user prompt",
        "Embed the user's intent and query the Pinecone index"
    ],
    "docstrings": [],
    "functions": [
        "POST",
        "chat"
    ],
    "classes": []
}