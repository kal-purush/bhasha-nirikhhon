{
    "identifiers": [
        "os",
        "torch",
        "PIL",
        "Image",
        "matplotlib",
        "pyplot",
        "plt",
        "torchvision",
        "transforms",
        "preprocess",
        "get_loader",
        "model_path",
        "image_folder",
        "dataset_path",
        "captions_file",
        "device",
        "torch",
        "load",
        "model_path",
        "model",
        "eval",
        "model",
        "to",
        "device",
        "transforms",
        "Compose",
        "transforms",
        "Resize",
        "transforms",
        "ToTensor",
        "transforms",
        "Normalize",
        "mean",
        "std",
        "get_loader",
        "root_dir",
        "dataset_path",
        "captions_file",
        "captions_file",
        "transform",
        "transform",
        "batch_size",
        "dataset",
        "vocab",
        "filename",
        "os",
        "path",
        "join",
        "image_folder",
        "filename",
        "Image",
        "open",
        "img_path",
        "convert",
        "transform",
        "image",
        "unsqueeze",
        "to",
        "device",
        "model",
        "caption_image",
        "image_tensor",
        "vocab",
        "join",
        "generated_caption",
        "filename",
        "caption_text",
        "plt",
        "figure",
        "figsize",
        "plt",
        "imshow",
        "image",
        "plt",
        "title",
        "caption_text",
        "plt",
        "axis",
        "plt",
        "savefig",
        "os",
        "path",
        "join",
        "image_folder",
        "filename",
        "plt",
        "close",
        "torch",
        "device",
        "torch",
        "cuda",
        "is_available",
        "test_specific_images",
        "model_path",
        "test_image_folder",
        "dataset_path",
        "captions_file",
        "device"
    ],
    "literals": [
        "'boy.png'",
        "'boat.png'",
        "'dog.jpg'",
        "'horse.png'",
        "'biker.jpg'",
        "'man_bench.jpg'",
        "\"RGB\"",
        "\" \"",
        "f\"Image: {filename}\"",
        "f\"Caption: {caption_text}\"",
        "\"-\"",
        "'off'",
        "f\"captioned_{filename}\"",
        "\"__main__\"",
        "\"checkpoints/best_model.pt\"",
        "\"test_images\"",
        "\"data/images/\"",
        "\"data/text.csv\"",
        "\"cuda\"",
        "\"cpu\""
    ],
    "variables": [
        "model",
        "transform",
        "_",
        "dataset",
        "vocab",
        "img_path",
        "image",
        "image_tensor",
        "generated_caption",
        "caption_text",
        "model_path",
        "test_image_folder",
        "dataset_path",
        "captions_file",
        "device"
    ],
    "comments": [
        "Load the model",
        "Define image preprocessing (same as training)",
        "Get the dataset (just to access the vocabulary)",
        "Doesn't matter here",
        "Access the vocabulary from the dataset",
        "Process each image in the folder",
        "Load and process image",
        "Generate caption",
        "Display results",
        "Optionally save the captioned image",
        "Parameters",
        "Folder with your 4 test images",
        "Original training images path",
        "Original captions file",
        "Run test"
    ],
    "docstrings": [
        "\"\"\"\n    Very simple script to test specific images using the trained model\n    \n    Args:\n        model_path: Path to the trained model\n        image_folder: Folder containing test images\n        dataset_path: Path to the original dataset (to get the vocabulary)\n        captions_file: Original captions file path\n        device: Device to run inference on\n    \"\"\""
    ],
    "functions": [
        "test_specific_images"
    ],
    "classes": []
}