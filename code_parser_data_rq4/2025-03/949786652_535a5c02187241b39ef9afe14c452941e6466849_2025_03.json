{
    "identifiers": [
        "os",
        "argparse",
        "logging",
        "json",
        "pathlib",
        "Path",
        "numpy",
        "np",
        "torch",
        "torch",
        "nn",
        "functional",
        "F",
        "torch",
        "distributions",
        "Categorical",
        "torch",
        "utils",
        "tensorboard",
        "SummaryWriter",
        "utils",
        "dataset_PriorGPT",
        "AASeqDictionary_con",
        "Experience",
        "utils",
        "utils",
        "unique",
        "fraction_valid_seqs",
        "set_random_seed",
        "utils",
        "dataset_PriorGPT",
        "rnn_start_token_vector",
        "model",
        "minGPT",
        "load_gpt_model",
        "save_gpt_model",
        "agent",
        "scoring_functions",
        "ScoringFunctions",
        "agent",
        "scoring",
        "template",
        "FVTemplate",
        "pickle",
        "time",
        "kwargs",
        "k",
        "v",
        "kwargs",
        "items",
        "setattr",
        "k",
        "v",
        "experience",
        "filename",
        "open",
        "filename",
        "f",
        "pickle",
        "dump",
        "experience",
        "f",
        "filename",
        "open",
        "filename",
        "f",
        "pickle",
        "load",
        "f",
        "experience",
        "seed",
        "device",
        "filename",
        "seed",
        "device",
        "np",
        "random",
        "get_state",
        "torch",
        "get_rng_state",
        "torch",
        "cuda",
        "get_rng_state_all",
        "device",
        "open",
        "filename",
        "f",
        "pickle",
        "dump",
        "random_state",
        "f",
        "optimizer",
        "decrease_by",
        "param_group",
        "optimizer",
        "param_groups",
        "param_group",
        "decrease_by",
        "optimizer",
        "initial_lr",
        "final_lr",
        "step",
        "total_steps",
        "factor",
        "np",
        "cos",
        "np",
        "pi",
        "step",
        "total_steps",
        "factor",
        "final_lr",
        "initial_lr",
        "final_lr",
        "cosine_decay",
        "param_group",
        "optimizer",
        "param_groups",
        "step_lr",
        "filename",
        "open",
        "filename",
        "f",
        "pickle",
        "load",
        "f",
        "np",
        "random",
        "set_state",
        "random_state",
        "torch",
        "manual_seed",
        "random_state",
        "random_state",
        "torch",
        "cuda",
        "manual_seed",
        "random_state",
        "torch",
        "cuda",
        "manual_seed_all",
        "random_state",
        "torch",
        "set_rng_state",
        "random_state",
        "torch",
        "cuda",
        "set_rng_state_all",
        "random_state",
        "optimizer",
        "filename",
        "open",
        "filename",
        "f",
        "pickle",
        "dump",
        "optimizer",
        "state_dict",
        "f",
        "optimizer",
        "filename",
        "open",
        "filename",
        "f",
        "pickle",
        "load",
        "f",
        "optimizer",
        "load_state_dict",
        "state_dict",
        "row",
        "row",
        "row",
        "row",
        "row",
        "row",
        "her2",
        "mhc2",
        "fv_net_charge",
        "fv_net_charge",
        "fv_csp",
        "hisum",
        "hisum",
        "logging",
        "getLogger",
        "pandas",
        "prior_path",
        "agent_path",
        "exp_path",
        "seed_state_path",
        "opt_path",
        "seed",
        "save_dir",
        "device",
        "learning_rate",
        "batch_size",
        "n_steps",
        "sigma",
        "max_seq_len",
        "score_fns",
        "weights",
        "score_type",
        "df_min_score",
        "experience_replay",
        "exp_max_size",
        "logger",
        "info",
        "prior_path",
        "agent_path",
        "exp_path",
        "save_dir",
        "seed_state_path",
        "opt_path",
        "seed",
        "device",
        "learning_rate",
        "batch_size",
        "n_steps",
        "sigma",
        "experience_replay",
        "experience_replay",
        "Experience",
        "max_size",
        "exp_max_size",
        "max_seq_len",
        "AASeqDictionary_con",
        "set_random_seed",
        "seed",
        "device",
        "prior_model",
        "agent_model",
        "load_pretrain_models",
        "prior_model",
        "hasattr",
        "prior_model",
        "prior_model",
        "agent_model",
        "hasattr",
        "agent_model",
        "agent_model",
        "TrainerConfig",
        "learning_rate",
        "learning_rate",
        "lr_decay",
        "agent_model",
        "configure_optimizers",
        "tconf",
        "opt_path",
        "load_optimizer_state_from_pkl",
        "optimizer",
        "opt_path",
        "torch",
        "nn",
        "DataParallel",
        "agent_model",
        "to",
        "device",
        "torch",
        "nn",
        "DataParallel",
        "prior_model",
        "to",
        "device",
        "pandas",
        "DataFrame",
        "score_fns",
        "FVTemplate",
        "ScoringFunctions",
        "score_fns",
        "weights",
        "weights",
        "template",
        "herceptin",
        "score_type",
        "SummaryWriter",
        "save_dir",
        "logger",
        "info",
        "Path",
        "prior_path",
        "with_suffix",
        "logger",
        "info",
        "device",
        "load_gpt_model",
        "model_def",
        "prior_path",
        "device",
        "copy_to_cpu",
        "load_gpt_model",
        "model_def",
        "agent_path",
        "device",
        "copy_to_cpu",
        "exp_path",
        "load_experience",
        "exp_path",
        "seed_state_path",
        "load_random_state",
        "seed_state_path",
        "prior",
        "agent",
        "device",
        "inputs",
        "targets",
        "torch",
        "zeros",
        "inputs",
        "size",
        "to",
        "device",
        "target_expanded",
        "scatter_",
        "targets",
        "contiguous",
        "view",
        "detach",
        "torch",
        "sum",
        "target_expanded",
        "inputs",
        "loss",
        "model",
        "num_samples",
        "rnn_start_token_vector",
        "num_samples",
        "device",
        "torch",
        "zeros",
        "num_samples",
        "to",
        "device",
        "torch",
        "LongTensor",
        "to",
        "device",
        "values",
        "view",
        "expand",
        "num_samples",
        "torch",
        "cat",
        "x",
        "values",
        "dim",
        "x",
        "torch",
        "zeros",
        "num_samples",
        "to",
        "device",
        "step",
        "max_seq_len",
        "model",
        "x",
        "F",
        "softmax",
        "logits",
        "dim",
        "step",
        "step",
        "Categorical",
        "probs",
        "prob",
        "sample",
        "squeeze",
        "step",
        "torch",
        "full",
        "num_samples",
        "to",
        "device",
        "step",
        "torch",
        "full",
        "num_samples",
        "to",
        "device",
        "step",
        "torch",
        "full",
        "num_samples",
        "to",
        "device",
        "torch",
        "cat",
        "sequences",
        "sampled_idx",
        "view",
        "sequences",
        "log_probs",
        "nll_loss",
        "prob",
        "log",
        "sampled_idx",
        "sequences",
        "detach",
        "log_probs",
        "model",
        "sample_idxes",
        "sample_idxes",
        "to",
        "device",
        "x",
        "size",
        "torch",
        "zeros",
        "num_samples",
        "to",
        "device",
        "step",
        "seq_length",
        "model",
        "x",
        "step",
        "F",
        "log_softmax",
        "logits",
        "dim",
        "squeeze",
        "log_probs",
        "nll_loss",
        "log_prob",
        "x",
        "step",
        "log_probs",
        "loss",
        "agent_likelihoods",
        "prior_likelihoods",
        "seqs",
        "scores",
        "len",
        "experience",
        "experience",
        "sample",
        "len",
        "exp_smiles",
        "torch",
        "LongTensor",
        "values",
        "view",
        "expand",
        "nums",
        "torch",
        "cat",
        "values",
        "exp_smiles",
        "dim",
        "likelihood",
        "agent_model",
        "exp_smiles",
        "exp_prior_likelihoods",
        "sigma",
        "exp_scores",
        "torch",
        "from_numpy",
        "exp_augmented_likelihood",
        "to",
        "device",
        "torch",
        "pow",
        "exp_augmented_likelihood",
        "exp_agent_likelihoods",
        "torch",
        "cat",
        "loss",
        "exp_loss",
        "torch",
        "cat",
        "agent_likelihoods",
        "exp_agent_likelihoods",
        "prior_likelihoods",
        "data",
        "cpu",
        "numpy",
        "seqs",
        "scores",
        "prior_likelihoods",
        "experience",
        "add_experience",
        "new_experience",
        "loss",
        "agent_likelihoods",
        "step",
        "scores_df",
        "agent_likelihoods",
        "prior_likelihoods",
        "augmented_likelihoods",
        "step",
        "np",
        "ones",
        "len",
        "scores_df",
        "agent_likelihoods",
        "data",
        "cpu",
        "numpy",
        "prior_likelihoods",
        "data",
        "cpu",
        "numpy",
        "augmented_likelihoods",
        "data",
        "cpu",
        "numpy",
        "scores_df",
        "apply",
        "calculate_is_success",
        "axis",
        "pandas",
        "concat",
        "final_df",
        "scores_df",
        "ignore_index",
        "param",
        "prior_model",
        "parameters",
        "logger",
        "info",
        "step",
        "n_steps",
        "time",
        "time",
        "sample",
        "agent_model",
        "batch_size",
        "unique",
        "sample_idxes",
        "sample_idxes",
        "uniq_ids",
        "sd",
        "matrix_to_seqs_final",
        "uniq_token_seqs",
        "uniq_ids",
        "agent_likelihoods",
        "idxs",
        "sample_idxes",
        "idxs",
        "likelihood",
        "prior_model",
        "mid_sample_idxs",
        "scoring_function",
        "scores",
        "seqs",
        "step",
        "score_type",
        "score_type",
        "scores_df",
        "score_type",
        "to_numpy",
        "prior_likelihoods",
        "sigma",
        "torch",
        "from_numpy",
        "scores",
        "to",
        "device",
        "torch",
        "pow",
        "augmented_likelihoods",
        "agent_likelihoods",
        "experience_replay",
        "replay_experience",
        "loss",
        "agent_likelihoods",
        "prior_likelihoods",
        "seqs",
        "scores",
        "loss",
        "mean",
        "loss",
        "agent_likelihoods",
        "mean",
        "optimizer",
        "zero_grad",
        "loss",
        "backward",
        "torch",
        "nn",
        "utils",
        "clip_grad_norm_",
        "agent_model",
        "parameters",
        "tconf",
        "grad_norm_clip",
        "optimizer",
        "step",
        "logger",
        "info",
        "step",
        "fraction_valid_seqs",
        "seqs",
        "max",
        "scores",
        "scores",
        "mean",
        "writer",
        "add_scalar",
        "fraction_valid_seqs",
        "seqs",
        "step",
        "writer",
        "add_scalar",
        "max",
        "scores",
        "step",
        "writer",
        "add_scalar",
        "scores",
        "mean",
        "step",
        "i",
        "seqs",
        "i",
        "save_step",
        "step",
        "scores_df",
        "agent_likelihoods",
        "prior_likelihoods",
        "augmented_likelihoods",
        "step",
        "save_gpt_model",
        "agent_model",
        "save_dir",
        "step",
        "save_experience",
        "experience",
        "save_dir",
        "step",
        "save_random_state",
        "seed",
        "device",
        "save_dir",
        "step",
        "save_optimizer_state_as_pkl",
        "optimizer",
        "save_dir",
        "step",
        "final_df",
        "to_csv",
        "os",
        "path",
        "join",
        "save_dir",
        "step",
        "index",
        "time",
        "time",
        "ed",
        "st"
    ],
    "literals": [
        "'../'",
        "'wb'",
        "'rb'",
        "'seed'",
        "'device'",
        "'numpy_random_state'",
        "'torch_random_state'",
        "'torch_cuda_random_state'",
        "'cuda'",
        "'wb'",
        "'lr'",
        "'lr'",
        "'rb'",
        "'numpy_random_state'",
        "'seed'",
        "'device'",
        "'cuda'",
        "'seed'",
        "'seed'",
        "'torch_random_state'",
        "'torch_cuda_random_state'",
        "'wb'",
        "'rb'",
        "'raw_HER2'",
        "'raw_MHC2'",
        "'raw_FvNetCharge'",
        "'raw_FvCSP'",
        "'raw_HISum'",
        "'TRUE'",
        "'FALSE'",
        "'cuda'",
        "'weight'",
        "\"Initializing agent trainer...\"",
        "\"module\"",
        "\"module\"",
        "'HER2'",
        "'EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLEWVARIYPTNGYTRYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCSRWGGDGFYAMDYWGQGTLVTVSS'",
        "'DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKLLIYSASFLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQHYTTPPTFGQGTKVEIK'",
        "'SRWGGDGFYAMDY'",
        "'EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLEWVARIYPTNGYTRYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYC'",
        "'WGQGTLVTVSS'",
        "'QDVNTA'",
        "'QQHYTTPPT'",
        "'SR'",
        "'Y'",
        "\"Loading pretrained models\"",
        "'.json'",
        "f\"Loading prior & agent to device {self.device}\"",
        "f\"Device '{self.device}' or model not available\"",
        "'step'",
        "'agent_likelihood'",
        "'prior_likelihood'",
        "'augmented_likelihood'",
        "'is_success'",
        "\"Starting training agent...\"",
        "f\"Step {step}, Valid %: {fraction_valid_seqs(seqs) * 100:4.1f}, \"",
        "f\"Max score: {max(scores):6.2f}, Mean score: {scores.mean():6.2f}, \"",
        "'Valid (%)'",
        "'Max score'",
        "'Mean score'",
        "f'{self.save_dir}/model/'",
        "f'Agent_mpo_{step+1}'",
        "f'{self.save_dir}/state/experience_data_{step+1}.pkl'",
        "f'{self.save_dir}/state/random_state_{step+1}.pkl'",
        "f'{self.save_dir}/state/optimizer_state_{step+1}.pkl'",
        "f'{self.save_dir}/model/'",
        "f\"mpo_{step+1}_step_scores.csv\"",
        "f'use time {ed-st}s'"
    ],
    "variables": [
        "learning_rate",
        "betas",
        "grad_norm_clip",
        "weight_decay",
        "lr_decay",
        "warmup_tokens",
        "final_tokens",
        "output_dir",
        "experience",
        "random_state",
        "cosine_decay",
        "step_lr",
        "param_group",
        "random_state",
        "state_dict",
        "her2",
        "mhc2",
        "fv_net_charge",
        "fv_csp",
        "hisum",
        "logger",
        "prior_path",
        "agent_path",
        "exp_path",
        "save_dir",
        "seed_state_path",
        "opt_path",
        "seed",
        "device",
        "learning_rate",
        "batch_size",
        "n_steps",
        "sigma",
        "experience_replay",
        "experience",
        "max_seq_len",
        "sd",
        "prior_model",
        "agent_model",
        "tconf",
        "optimizer",
        "agent_model",
        "prior_model",
        "final_df",
        "score_fns",
        "weights",
        "herceptin",
        "scoring_function",
        "score_type",
        "writer",
        "model_def",
        "prior",
        "agent",
        "experience",
        "target_expanded",
        "loss",
        "x",
        "finished",
        "values",
        "values",
        "x",
        "sequences",
        "log_probs",
        "logits",
        "_",
        "prob",
        "sampled_idx",
        "sampled_idx",
        "sampled_idx",
        "sampled_idx",
        "sequences",
        "x",
        "x",
        "num_samples",
        "seq_length",
        "log_probs",
        "logits",
        "_",
        "log_prob",
        "exp_smiles",
        "exp_scores",
        "exp_prior_likelihoods",
        "nums",
        "values",
        "values",
        "exp_smiles",
        "exp_agent_likelihoods",
        "exp_augmented_likelihood",
        "exp_augmented_likelihood",
        "exp_loss",
        "loss",
        "agent_likelihoods",
        "prior_likelihoods",
        "new_experience",
        "scores_df",
        "scores_df",
        "scores_df",
        "scores_df",
        "scores_df",
        "final_df",
        "param",
        "requires_grad",
        "st",
        "sample_idxes",
        "agent_likelihoods",
        "uniq_ids",
        "uniq_token_seqs",
        "seqs",
        "idxs",
        "agent_likelihoods",
        "mid_sample_idxs",
        "prior_likelihoods",
        "scores_df",
        "scores",
        "augmented_likelihoods",
        "loss",
        "loss",
        "agent_likelihood",
        "loss",
        "ed"
    ],
    "comments": [
        "optimization parameters",
        "only applied on matmul weights",
        "learning rate decay params: linear warmup followed by cosine decay to 10% of original",
        "these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere",
        "(at what point we reach 10% of original LR)",
        "checkpoint settings",
        "print(\"load TrainerConfig......\")",
        "Init experience",
        "Use adamW with lr_decay",
        "Enable using multiple GPUs",
        "weight",
        "One_hot encoding",
        "only for last time-step",
        "batch_size个S(18)",
        "batch_size个R(4)",
        "batch_size个R(4)",
        "update log_probs",
        "Sample experiences and update loss",
        "Add new experience",
        "Sample from agent",
        "Remove duplicates",
        "Penalize small likelihoods, stimulate learning"
    ],
    "docstrings": [
        "\"\"\"Multiplies the learning rate of the optimizer by 1 - decrease_by\"\"\"",
        "\"\"\"\n    Modified Cosine annealing decay from initial_lr to final_lr, with the rapid drop-off point shifted.\n    The `factor` parameter controls how much the decay is shifted.\n    \"\"\"",
        "\"\"\"\n            Custom Negative Log Likelihood loss that returns loss per example, rather than for the entire batch.\n\n            Args:\n                inputs : (batch_size, num_classes) *Log probabilities of each class*\n                targets: (batch_size) *Target class index*\n\n            Outputs:\n                loss : (batch_size) *Loss for each example*\n        \"\"\"",
        "\"\"\"\n            Sample molecules from agent and calculate likelihood\n            Args:\n                model: model to sample from\n                num_samples: number of samples to produce for each step, i.e. batch_size\n\n            Returns:\n                sample_idxes: a list of SMILES indexes, with no beginning nor end symbols\n                log_probs: log likelihood for SMILES generated\n            \"\"\"",
        "\"\"\"\n        Retrieves the likelihood of a given sequence\n            Args: x\n                model: GPT model to calculate likelihood\n                sample_idxes: A list of smiles of batch_size length\n                device: Device used\n            Outputs:\n                log_probs : (batch_size) Log likelihood for each example\n        \"\"\"",
        "\"\"\"\n            Save step to a CSV file\n        \"\"\""
    ],
    "functions": [
        "save_experience",
        "load_experience",
        "save_random_state",
        "decrease_learning_rate",
        "modified_cosine_annealing_decay",
        "load_random_state",
        "save_optimizer_state_as_pkl",
        "load_optimizer_state_from_pkl",
        "calculate_is_success",
        "load_pretrain_models",
        "nll_loss",
        "sample",
        "likelihood",
        "replay_experience",
        "save_step",
        "train"
    ],
    "classes": [
        "TrainerConfig",
        "AgentTrainer"
    ]
}