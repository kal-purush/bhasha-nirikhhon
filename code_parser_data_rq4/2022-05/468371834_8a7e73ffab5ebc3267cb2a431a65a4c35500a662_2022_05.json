{
    "identifiers": [
        "torch",
        "tensor",
        "torch",
        "utils",
        "data",
        "Dataset",
        "tokens",
        "labels",
        "tokenizer",
        "test_split",
        "len",
        "tokens",
        "length",
        "test_split",
        "tokens",
        "div",
        "labels",
        "div",
        "tokens",
        "div",
        "labels",
        "div",
        "TextDataset",
        "tokenizer",
        "trainTokens",
        "truncation",
        "padding",
        "max_length",
        "TOKENIZER_MAX_LENGTH",
        "return_tensors",
        "trainLabels",
        "TextDataset",
        "tokenizer",
        "testTokens",
        "truncation",
        "padding",
        "max_length",
        "TOKENIZER_MAX_LENGTH",
        "return_tensors",
        "testLabels",
        "trainDataset",
        "testDataset",
        "Dataset",
        "tokens",
        "labels",
        "tokens",
        "labels",
        "idx",
        "key",
        "val",
        "idx",
        "clone",
        "detach",
        "key",
        "val",
        "tokens",
        "items",
        "tensor",
        "labels",
        "idx",
        "item",
        "len",
        "labels"
    ],
    "literals": [
        "\"pt\"",
        "\"pt\"",
        "'labels'"
    ],
    "variables": [
        "TOKENIZER_MAX_LENGTH",
        "length",
        "div",
        "trainTokens",
        "trainLabels",
        "testTokens",
        "testLabels",
        "trainDataset",
        "testDataset",
        "tokens",
        "labels",
        "item",
        "item"
    ],
    "comments": [],
    "docstrings": [],
    "functions": [
        "createDatasets",
        "__getitem__",
        "__len__"
    ],
    "classes": [
        "TextDataset"
    ]
}