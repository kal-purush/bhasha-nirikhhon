{
    "identifiers": [
        "google",
        "colab",
        "drive",
        "drive",
        "mount",
        "ip",
        "install",
        "preprocess",
        "glob",
        "os",
        "os",
        "listdir",
        "numpy",
        "np",
        "pandas",
        "pd",
        "matplotlib",
        "pyplot",
        "plt",
        "random",
        "shuffle",
        "pickle",
        "datetime",
        "preprocess",
        "pp",
        "cv2",
        "pathlib",
        "Path",
        "tensorflow",
        "keras",
        "keras",
        "datasets",
        "cifar10",
        "tensorflow",
        "keras",
        "models",
        "layers",
        "tensorflow",
        "keras",
        "models",
        "Model",
        "Sequential",
        "keras",
        "layers",
        "Input",
        "Dense",
        "Dropout",
        "Flatten",
        "Activation",
        "keras",
        "layers",
        "Conv2D",
        "Convolution2D",
        "MaxPooling2D",
        "MaxPool2D",
        "keras",
        "layers",
        "convolutional",
        "ZeroPadding2D",
        "tensorflow",
        "keras",
        "layers",
        "BatchNormalization",
        "keras",
        "utils",
        "np_utils",
        "tensorflow",
        "keras",
        "optimizers",
        "keras",
        "preprocessing",
        "sequence",
        "keras",
        "preprocessing",
        "image",
        "ImageDataGenerator",
        "PIL",
        "Image",
        "data_path",
        "os",
        "chdir",
        "img_path",
        "os",
        "path",
        "abspath",
        "os",
        "getcwd",
        "ImageDataGenerator",
        "rotation_range",
        "width_shift_range",
        "height_shift_range",
        "rescale",
        "shear_range",
        "zoom_range",
        "horizontal_flip",
        "ImageDataGenerator",
        "rescale",
        "train_datagen",
        "flow_from_directory",
        "target_size",
        "batch_size",
        "batch_size",
        "shuffle",
        "class_mode",
        "test_datagen",
        "flow_from_directory",
        "target_size",
        "batch_size",
        "batch_size",
        "class_mode",
        "shuffle",
        "test_datagen",
        "flow_from_directory",
        "target_size",
        "batch_size",
        "class_mode",
        "shuffle",
        "i",
        "plt",
        "subplot",
        "i",
        "train_generator",
        "next",
        "images",
        "astype",
        "plt",
        "imshow",
        "image",
        "tensorflow",
        "tf",
        "Model",
        "Denoise",
        "tf",
        "keras",
        "Sequential",
        "layers",
        "Input",
        "shape",
        "layers",
        "Conv2D",
        "activation",
        "padding",
        "strides",
        "tf",
        "keras",
        "Sequential",
        "layers",
        "Conv2DTranspose",
        "kernel_size",
        "strides",
        "activation",
        "padding",
        "layers",
        "Conv2D",
        "kernel_size",
        "activation",
        "padding",
        "x",
        "encoder",
        "x",
        "decoder",
        "encoded",
        "decoded",
        "Denoise",
        "tensorflow",
        "keras",
        "layers",
        "losses",
        "autoencoder",
        "compile",
        "optimizer",
        "loss",
        "losses",
        "MeanSquaredError",
        "metrics",
        "autoencoder",
        "fit",
        "train_generator",
        "steps_per_epoch",
        "batch_size",
        "epochs",
        "validation_data",
        "validation_generator",
        "validation_steps",
        "batch_size",
        "autoencoder",
        "predict",
        "test_generator",
        "google",
        "colab",
        "files",
        "max",
        "n",
        "plt",
        "figure",
        "figsize",
        "w",
        "i",
        "n",
        "plt",
        "subplot",
        "n",
        "i",
        "test_generator",
        "next",
        "plt",
        "imshow",
        "x",
        "reshape",
        "ax",
        "get_xaxis",
        "set_visible",
        "ax",
        "get_yaxis",
        "set_visible",
        "plt",
        "subplot",
        "n",
        "i",
        "n",
        "plt",
        "imshow",
        "decoded_imgs",
        "i",
        "reshape",
        "ax",
        "get_xaxis",
        "set_visible",
        "ax",
        "get_yaxis",
        "set_visible",
        "plt",
        "savefig"
    ],
    "literals": [
        "'/content/drive'",
        "'put your dataset path here'",
        "'./train'",
        "'input'",
        "'./validation'",
        "'input'",
        "'./test'",
        "'uint8'",
        "'relu'",
        "'same'",
        "'relu'",
        "'same'",
        "'sigmoid'",
        "'same'",
        "'adam'",
        "'accuracy'",
        "'/content/drive/MyDrive/newly_organized_pngs/denoise6.png'"
    ],
    "variables": [
        "data_path",
        "img_path",
        "batch_size",
        "train_datagen",
        "test_datagen",
        "train_generator",
        "validation_generator",
        "test_generator",
        "images",
        "labels",
        "image",
        "encoder",
        "decoder",
        "encoded",
        "decoded",
        "autoencoder",
        "h2",
        "decoded_imgs",
        "n",
        "w",
        "ax",
        "x",
        "ax"
    ],
    "comments": [
        "connects colab to your google drive",
        "skip if your dataset is not on google drive or you're not using colab",
        "Commented out IPython magic to ensure Python compatibility.",
        "%load_ext tensorboard",
        "changes the current working directory to the file path specified. This directory should be the directory of data you plan on using for the model'",
        "# this is the augmentation configuration we will use for training",
        "fill_mode = \"nearest\",",
        "validation_split = 0.2",
        "this is the augmentation configuration we will use for testing:",
        "only rescaling",
        "this is a generator that will read pictures found in",
        "subfolers of 'data/train', and indefinitely generate",
        "batches of augmented image data",
        "this is the target directory",
        "all images will be resized to 256x256",
        "this needs to be changed",
        "The inputs should be noisy images, and labels should be clean versions of those images",
        "this is a similar generator, for validation data",
        "this is a similar generator, for validation data",
        "creating the denoising autoencoder",
        "layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),",
        "layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2),",
        "layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),",
        "layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),",
        "use fit instead of fit_generator",
        "denoised images from test dataset",
        "create a visual that shows the original and denoised images next to each other,",
        "then saves the figure so the differences can be observed",
        "Original images",
        "Reconstructed images",
        "files.download('denoise.png')"
    ],
    "docstrings": [],
    "functions": [
        "call"
    ],
    "classes": [
        "Denoise"
    ]
}