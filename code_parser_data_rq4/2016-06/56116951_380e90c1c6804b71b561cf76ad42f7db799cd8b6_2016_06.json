{
    "identifiers": [
        "print_function",
        "six",
        "moves",
        "xrange",
        "six",
        "moves",
        "cPickle",
        "pickle",
        "cbtest",
        "utils",
        "ns_add",
        "ns_merge",
        "Namespace",
        "cbtest",
        "layers",
        "log",
        "dot",
        "mean",
        "softmax",
        "Embed",
        "floatX",
        "stack",
        "LSTM",
        "MemoryLayer",
        "LinearLayer",
        "position_encoding",
        "LSTMq",
        "cbtest",
        "optimizers",
        "optimizers",
        "gzip",
        "os",
        "numpy",
        "theano",
        "theano",
        "tensor",
        "T",
        "time",
        "seqs",
        "labels",
        "maxlen",
        "len",
        "s",
        "s",
        "seqs",
        "maxlen",
        "l",
        "s",
        "y",
        "lengths",
        "seqs",
        "labels",
        "l",
        "maxlen",
        "new_seqs",
        "append",
        "s",
        "new_labels",
        "append",
        "y",
        "new_lengths",
        "append",
        "l",
        "new_lengths",
        "new_labels",
        "new_seqs",
        "len",
        "lengths",
        "len",
        "seqs",
        "numpy",
        "max",
        "lengths",
        "numpy",
        "zeros",
        "n_samples",
        "maxlen",
        "astype",
        "idx",
        "s",
        "seqs",
        "lengths",
        "idx",
        "s",
        "x",
        "labels",
        "dataset",
        "default_dataset",
        "origin",
        "os",
        "path",
        "split",
        "dataset",
        "data_dir",
        "os",
        "path",
        "isfile",
        "dataset",
        "os",
        "path",
        "join",
        "os",
        "path",
        "split",
        "dataset",
        "os",
        "path",
        "isfile",
        "new_path",
        "data_file",
        "default_dataset",
        "new_path",
        "os",
        "path",
        "isfile",
        "dataset",
        "data_file",
        "default_dataset",
        "six",
        "moves",
        "urllib",
        "origin",
        "urllib",
        "request",
        "urlretrieve",
        "origin",
        "dataset",
        "dataset",
        "path",
        "n_words",
        "valid_portion",
        "maxlen",
        "sort_by_len",
        "get_dataset_file",
        "path",
        "path",
        "endswith",
        "gzip",
        "open",
        "path",
        "open",
        "path",
        "pickle",
        "load",
        "f",
        "pickle",
        "load",
        "f",
        "f",
        "close",
        "maxlen",
        "x",
        "y",
        "train_set",
        "train_set",
        "len",
        "x",
        "maxlen",
        "new_train_set_x",
        "append",
        "x",
        "new_train_set_y",
        "append",
        "y",
        "new_train_set_x",
        "new_train_set_y",
        "new_train_set_x",
        "new_train_set_y",
        "train_set",
        "len",
        "train_set_x",
        "numpy",
        "random",
        "permutation",
        "n_samples",
        "numpy",
        "round",
        "n_samples",
        "valid_portion",
        "train_set_x",
        "s",
        "s",
        "sidx",
        "n_train",
        "train_set_y",
        "s",
        "s",
        "sidx",
        "n_train",
        "train_set_x",
        "s",
        "s",
        "sidx",
        "n_train",
        "train_set_y",
        "s",
        "s",
        "sidx",
        "n_train",
        "train_set_x",
        "train_set_y",
        "valid_set_x",
        "valid_set_y",
        "x",
        "w",
        "n_words",
        "w",
        "w",
        "sen",
        "sen",
        "x",
        "test_set",
        "valid_set",
        "train_set",
        "remove_unk",
        "train_set_x",
        "remove_unk",
        "valid_set_x",
        "remove_unk",
        "test_set_x",
        "seq",
        "sorted",
        "len",
        "seq",
        "key",
        "x",
        "len",
        "seq",
        "x",
        "sort_by_len",
        "len_argsort",
        "test_set_x",
        "test_set_x",
        "i",
        "i",
        "sorted_index",
        "test_set_y",
        "i",
        "i",
        "sorted_index",
        "len_argsort",
        "valid_set_x",
        "valid_set_x",
        "i",
        "i",
        "sorted_index",
        "valid_set_y",
        "i",
        "i",
        "sorted_index",
        "len_argsort",
        "train_set_x",
        "train_set_x",
        "i",
        "i",
        "sorted_index",
        "train_set_y",
        "i",
        "i",
        "sorted_index",
        "train_set_x",
        "train_set_y",
        "valid_set_x",
        "valid_set_y",
        "test_set_x",
        "test_set_y",
        "train",
        "valid",
        "test",
        "n",
        "minibatch_size",
        "shuffle",
        "numpy",
        "arange",
        "n",
        "dtype",
        "shuffle",
        "numpy",
        "random",
        "shuffle",
        "idx_list",
        "i",
        "n",
        "minibatch_size",
        "minibatches",
        "append",
        "idx_list",
        "minibatch_start",
        "minibatch_start",
        "minibatch_size",
        "minibatch_start",
        "minibatch_size",
        "minibatch_start",
        "n",
        "minibatches",
        "append",
        "idx_list",
        "minibatch_start",
        "len",
        "minibatches",
        "minibatches",
        "tparams",
        "s",
        "t",
        "tparams",
        "t",
        "set_value",
        "s",
        "tparams",
        "t",
        "tparams",
        "new_params",
        "append",
        "t",
        "get_value",
        "new_params",
        "ns",
        "T",
        "matrix",
        "dtype",
        "T",
        "vector",
        "dtype",
        "x",
        "shape",
        "x",
        "shape",
        "Embed",
        "ns",
        "n_words",
        "ns",
        "dim_proj",
        "extend",
        "embed_layer",
        "embed_layer",
        "x",
        "flatten",
        "reshape",
        "n_samples",
        "n_timesteps",
        "ns",
        "dim_proj",
        "LSTM",
        "ns",
        "dim_proj",
        "extend",
        "lstm",
        "lstm",
        "v0",
        "dimshuffle",
        "mean",
        "v1",
        "axis",
        "LinearLayer",
        "ns",
        "dim_proj",
        "ns",
        "ydim",
        "extend",
        "linear",
        "softmax",
        "linear",
        "proj",
        "theano",
        "x",
        "prob",
        "name",
        "theano",
        "x",
        "prob",
        "argmax",
        "axis",
        "name",
        "floatX",
        "prob",
        "dtype",
        "floatX",
        "log",
        "prob",
        "T",
        "arange",
        "n_samples",
        "y",
        "off",
        "mean",
        "optimizers",
        "Adam",
        "loss",
        "alpha",
        "floatX",
        "ns",
        "lrate",
        "theano",
        "inputs",
        "x",
        "y",
        "outputs",
        "loss",
        "updates",
        "updates",
        "on_unused_input",
        "ns",
        "ns",
        "decay_c",
        "theano",
        "shared",
        "floatX",
        "ns",
        "decay_c",
        "name",
        "weight_decay",
        "linear",
        "W",
        "sum",
        "weight_decay",
        "decay_c",
        "loss",
        "weight_decay",
        "Namespace",
        "fprop",
        "fprop",
        "pred",
        "pred",
        "bprop",
        "bprop",
        "x",
        "x",
        "y",
        "y",
        "loss",
        "loss",
        "pred",
        "prepare_data",
        "data",
        "iterator",
        "verbose",
        "_",
        "valid_index",
        "iterator",
        "prepare_data",
        "data",
        "t",
        "t",
        "valid_index",
        "numpy",
        "array",
        "data",
        "valid_index",
        "maxlen",
        "pred",
        "x",
        "numpy",
        "array",
        "data",
        "valid_index",
        "valid_err",
        "preds",
        "targets",
        "sum",
        "floatX",
        "valid_err",
        "len",
        "data",
        "valid_err",
        "ns",
        "load_data",
        "prepare_data",
        "load_data",
        "n_words",
        "ns",
        "n_words",
        "valid_portion",
        "maxlen",
        "ns",
        "maxlen",
        "ns",
        "test_size",
        "numpy",
        "arange",
        "len",
        "test",
        "numpy",
        "random",
        "shuffle",
        "idx",
        "idx",
        "ns",
        "test_size",
        "test",
        "n",
        "n",
        "idx",
        "test",
        "n",
        "n",
        "idx",
        "min",
        "min",
        "test",
        "numpy",
        "max",
        "train",
        "build_model",
        "ns_add",
        "ns",
        "ydim",
        "ydim",
        "get_minibatches_idx",
        "len",
        "valid",
        "ns",
        "valid_batch_size",
        "get_minibatches_idx",
        "len",
        "test",
        "ns",
        "valid_batch_size",
        "len",
        "train",
        "len",
        "valid",
        "len",
        "test",
        "ns",
        "validFreq",
        "len",
        "train",
        "ns",
        "batch_size",
        "ns",
        "saveFreq",
        "len",
        "train",
        "ns",
        "batch_size",
        "time",
        "time",
        "eidx",
        "ns",
        "max_epochs",
        "get_minibatches_idx",
        "len",
        "train",
        "ns",
        "batch_size",
        "shuffle",
        "_",
        "train_index",
        "kf",
        "uidx",
        "train",
        "t",
        "t",
        "train_index",
        "train",
        "t",
        "t",
        "train_index",
        "prepare_data",
        "x",
        "y",
        "n_samples",
        "x",
        "shape",
        "m",
        "bprop",
        "x",
        "y",
        "numpy",
        "isnan",
        "cost",
        "numpy",
        "isinf",
        "cost",
        "cost",
        "numpy",
        "mod",
        "uidx",
        "ns",
        "dispFreq",
        "eidx",
        "uidx",
        "cost",
        "ns",
        "saveto",
        "numpy",
        "mod",
        "uidx",
        "ns",
        "saveFreq",
        "best_p",
        "best_p",
        "unzip",
        "m",
        "numpy",
        "savez",
        "ns",
        "saveto",
        "history_errs",
        "history_errs",
        "pickle",
        "dump",
        "ns",
        "open",
        "ns",
        "saveto",
        "numpy",
        "mod",
        "uidx",
        "ns",
        "validFreq",
        "pred_error",
        "m",
        "pred",
        "prepare_data",
        "train",
        "kf",
        "pred_error",
        "m",
        "pred",
        "prepare_data",
        "valid",
        "kf_valid",
        "pred_error",
        "m",
        "pred",
        "prepare_data",
        "test",
        "kf_test",
        "history_errs",
        "append",
        "valid_err",
        "test_err",
        "best_p",
        "valid_err",
        "numpy",
        "array",
        "history_errs",
        "min",
        "unzip",
        "m",
        "train_err",
        "valid_err",
        "test_err",
        "len",
        "history_errs",
        "ns",
        "patience",
        "valid_err",
        "numpy",
        "array",
        "history_errs",
        "ns",
        "patience",
        "min",
        "bad_counter",
        "bad_counter",
        "ns",
        "patience",
        "n_samples",
        "estop",
        "KeyboardInterrupt",
        "time",
        "time",
        "best_p",
        "zipp",
        "best_p",
        "m",
        "unzip",
        "m",
        "use_noise",
        "set_value",
        "get_minibatches_idx",
        "len",
        "train",
        "ns",
        "batch_size",
        "pred_error",
        "f_pred",
        "prepare_data",
        "train",
        "kf_train_sorted",
        "pred_error",
        "f_pred",
        "prepare_data",
        "valid",
        "kf_valid",
        "pred_error",
        "f_pred",
        "prepare_data",
        "test",
        "kf_test",
        "train_err",
        "valid_err",
        "test_err",
        "ns",
        "saveto",
        "numpy",
        "savez",
        "ns",
        "saveto",
        "best_p",
        "train_err",
        "train_err",
        "valid_err",
        "valid_err",
        "test_err",
        "test_err",
        "history_errs",
        "history_errs",
        "eidx",
        "end_time",
        "start_time",
        "eidx",
        "end_time",
        "start_time",
        "file",
        "sys",
        "stderr",
        "train_err",
        "valid_err",
        "test_err",
        "Namespace",
        "dim_proj",
        "patience",
        "max_epochs",
        "dispFreq",
        "decay_c",
        "lrate",
        "n_words",
        "saveto",
        "validFreq",
        "saveFreq",
        "maxlen",
        "batch_size",
        "valid_batch_size",
        "dataset",
        "test_size",
        "train_lstm",
        "param"
    ],
    "literals": [
        "'int64'",
        "\"\"",
        "\"..\"",
        "\"data\"",
        "'Downloading data from %s'",
        "\"imdb.pkl\"",
        "\"imdb.pkl\"",
        "\"http://www.iro.umontreal.ca/~lisa/deep/data/imdb.pkl\"",
        "\".gz\"",
        "'rb'",
        "'rb'",
        "\"int32\"",
        "'x'",
        "'int64'",
        "'y'",
        "'int64'",
        "'fprop'",
        "'fpred'",
        "'float16'",
        "'ignore'",
        "'decay_c'",
        "'using decay_c'",
        "'decay_c'",
        "'Loading data'",
        "'Building model'",
        "'Optimization'",
        "\"%d train examples\"",
        "\"%d valid examples\"",
        "\"%d test examples\"",
        "'bad cost detected: '",
        "'Epoch '",
        "'Update '",
        "'Cost '",
        "'Saving...'",
        "'%s.pkl'",
        "'wb'",
        "'Done'",
        "'Train '",
        "'Valid '",
        "'Test '",
        "'Early Stop!'",
        "'Seen %d samples'",
        "\"Training interupted\"",
        "'Train '",
        "'Valid '",
        "'Test '",
        "'The code run for %d epochs, with %f sec/epochs'",
        "'Training took %.1fs'",
        "'__main__'",
        "'lstm_model.npz'",
        "'imdb'"
    ],
    "variables": [
        "lengths",
        "new_seqs",
        "new_labels",
        "new_lengths",
        "lengths",
        "labels",
        "seqs",
        "n_samples",
        "maxlen",
        "x",
        "x",
        "idx",
        "data_dir",
        "data_file",
        "new_path",
        "dataset",
        "path",
        "f",
        "f",
        "train_set",
        "test_set",
        "new_train_set_x",
        "new_train_set_y",
        "train_set",
        "train_set_x",
        "train_set_y",
        "n_samples",
        "sidx",
        "n_train",
        "valid_set_x",
        "valid_set_y",
        "train_set_x",
        "train_set_y",
        "train_set",
        "valid_set",
        "test_set_x",
        "test_set_y",
        "valid_set_x",
        "valid_set_y",
        "train_set_x",
        "train_set_y",
        "train_set_x",
        "valid_set_x",
        "test_set_x",
        "sorted_index",
        "test_set_x",
        "test_set_y",
        "sorted_index",
        "valid_set_x",
        "valid_set_y",
        "sorted_index",
        "train_set_x",
        "train_set_y",
        "train",
        "valid",
        "test",
        "idx_list",
        "minibatches",
        "minibatch_start",
        "new_params",
        "x",
        "y",
        "n_timesteps",
        "n_samples",
        "embed_layer",
        "v0",
        "lstm",
        "v1",
        "proj",
        "linear",
        "prob",
        "fprop",
        "pred",
        "off",
        "off",
        "loss",
        "updates",
        "bprop",
        "decay_c",
        "weight_decay",
        "valid_err",
        "x",
        "y",
        "preds",
        "targets",
        "valid_err",
        "train",
        "valid",
        "test",
        "idx",
        "idx",
        "test",
        "ydim",
        "m",
        "kf_valid",
        "kf_test",
        "history_errs",
        "best_p",
        "bad_count",
        "ns",
        "validFreq",
        "ns",
        "saveFreq",
        "uidx",
        "estop",
        "start_time",
        "n_samples",
        "kf",
        "y",
        "x",
        "x",
        "y",
        "cost",
        "train_err",
        "valid_err",
        "test_err",
        "best_p",
        "bad_counter",
        "estop",
        "end_time",
        "best_p",
        "kf_train_sorted",
        "train_err",
        "valid_err",
        "test_err",
        "param"
    ],
    "comments": [
        "x: a list of sentences",
        "Check if dataset is in the data directory.",
        "",
        "LOAD DATA #",
        "",
        "Load the dataset",
        "split training set into validation set",
        "Make a minibatch out of what is left",
        "TODO: average over only non-zero elements. will it help?",
        "avoid nan.",
        "The test set is sorted by size, but we want to keep random",
        "size example.  So we must select a random selection of the",
        "examples.",
        "0 is not used.",
        "the number of update done",
        "early stop",
        "Get new shuffled index for the training set.",
        "Select the random examples for this minibatch",
        "Get the data in numpy.ndarray format",
        "This swap the axis!",
        "Return something of shape (minibatch maxlen, n samples)",
        "word embeding dimension and LSTM number of hidden units.",
        "Number of epoch to wait before early stop if no progress",
        "The maximum number of epoch to run",
        "Display to stdout the training progress every N updates",
        "Weight decay for the classifier applied to the U weights.",
        "Learning rate for sgd (not used for adadelta and rmsprop)",
        "Vocabulary size",
        "optimizer=adadelta,  # sgd, adadelta and rmsprop available, sgd very hard to use, not recommanded (probably need momentum and decaying learning rate).",
        "The best model will be saved there",
        "Compute the validation error after this number of update.",
        "Save the parameters after every saveFreq updates",
        "Sequence longer then this get ignored",
        "The batch size during training.",
        "The batch size used for validation/test set.",
        "Parameter for extra option",
        "If >0, we keep only this number of test example."
    ],
    "docstrings": [
        "\"\"\"Create the matrices from the datasets.\n\n    This pad each sequence to the same lenght: the lenght of the\n    longuest sequence or maxlen.\n\n    if maxlen is set, we will cut all sequence to this maximum\n    lenght.\n\n    This swap the axis!\n    \"\"\"",
        "'''Look for it as if it was a full path, if not, try local file,\n    if not try in the data directory.\n\n    Download dataset if it is not present\n\n    '''",
        "'''Loads the dataset\n\n    :type path: String\n    :param path: The path to the dataset (here IMDB)\n    :type n_words: int\n    :param n_words: The number of word to keep in the vocabulary.\n        All extra words are set to unknow (1).\n    :type valid_portion: float\n    :param valid_portion: The proportion of the full train set used for\n        the validation set.\n    :type maxlen: None or positive int\n    :param maxlen: the max sequence length we use in the train/valid set.\n    :type sort_by_len: bool\n    :name sort_by_len: Sort by the sequence lenght for the train,\n        valid and test set. This allow faster execution as it cause\n        less padding per minibatch. Another mechanism must be used to\n        shuffle the train set at each epoch.\n\n    '''",
        "\"\"\"\n    Used to shuffle the dataset at each iteration.\n    \"\"\"",
        "\"\"\"\n    When we reload the model. Needed for the GPU stuff.\n    \"\"\"",
        "\"\"\"\n    When we pickle the model. Needed for the GPU stuff.\n    \"\"\"",
        "\"\"\"\n    Just compute the error\n    f_pred: Theano fct computing the prediction\n    prepare_data: usual prepare_data for that dataset.\n    \"\"\""
    ],
    "functions": [
        "prepare_data",
        "get_dataset_file",
        "load_data",
        "remove_unk",
        "len_argsort",
        "get_minibatches_idx",
        "zipp",
        "unzip",
        "build_model",
        "pred_error",
        "train_lstm"
    ],
    "classes": []
}