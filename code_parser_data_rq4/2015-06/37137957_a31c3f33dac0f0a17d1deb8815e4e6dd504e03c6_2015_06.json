{
    "identifiers": [
        "numpy",
        "np",
        "matplotlib",
        "pyplot",
        "plt",
        "scipy",
        "optimize",
        "opt",
        "sys",
        "x",
        "mu",
        "sigma",
        "x",
        "shape",
        "np",
        "ones",
        "m",
        "n",
        "i",
        "n",
        "mu",
        "append",
        "np",
        "mean",
        "x",
        "i",
        "sigma",
        "append",
        "np",
        "std",
        "x",
        "i",
        "x",
        "i",
        "mu",
        "i",
        "sigma",
        "i",
        "xnorm",
        "theta",
        "len",
        "mu",
        "i",
        "n",
        "theta",
        "theta",
        "i",
        "mu",
        "i",
        "sigma",
        "i",
        "i",
        "n",
        "i",
        "theta",
        "i",
        "sigma",
        "i",
        "theta",
        "theta",
        "np",
        "linspace",
        "num",
        "theta",
        "theta",
        "xpoints",
        "theta",
        "plt",
        "figure",
        "plt",
        "plot",
        "xpoints",
        "ypoints",
        "plt",
        "ylim",
        "plt",
        "xlim",
        "plt",
        "show",
        "x",
        "theta",
        "np",
        "dot",
        "x",
        "theta",
        "np",
        "exp",
        "z",
        "sgmd",
        "theta",
        "x",
        "y",
        "x",
        "shape",
        "np",
        "dot",
        "y",
        "T",
        "np",
        "log",
        "sigmoid",
        "x",
        "theta",
        "np",
        "dot",
        "y",
        "T",
        "np",
        "log",
        "sigmoid",
        "x",
        "theta",
        "J_pos",
        "J_neg",
        "m",
        "J",
        "theta",
        "x",
        "y",
        "x",
        "shape",
        "sigmoid",
        "x",
        "theta",
        "m",
        "h",
        "y",
        "m",
        "np",
        "dot",
        "x",
        "T",
        "delta",
        "flatten",
        "grad",
        "x",
        "y",
        "np",
        "where",
        "y",
        "np",
        "where",
        "y",
        "plt",
        "scatter",
        "x",
        "admitted",
        "x",
        "admitted",
        "marker",
        "c",
        "s",
        "label",
        "plt",
        "scatter",
        "x",
        "rejected",
        "x",
        "rejected",
        "marker",
        "c",
        "s",
        "label",
        "plt",
        "xlabel",
        "plt",
        "ylabel",
        "plt",
        "legend",
        "x",
        "theta",
        "sigmoid",
        "x",
        "theta",
        "p",
        "p",
        "y",
        "np",
        "loadtxt",
        "delimiter",
        "dat",
        "shape",
        "np",
        "ones",
        "m",
        "n",
        "dat",
        "dat",
        "m",
        "np",
        "zeros",
        "n",
        "visualization",
        "xdata",
        "ydata",
        "feature_norm",
        "xdata",
        "cost_function",
        "init_theta",
        "xdata",
        "ydata",
        "opt",
        "fmin_bfgs",
        "cost_function",
        "init_theta",
        "fprime",
        "gradient",
        "args",
        "xdata",
        "ydata",
        "full_output",
        "disp",
        "theta_min",
        "j_min",
        "unnormalize_theta",
        "theta_min",
        "boundary_lines",
        "un_theta",
        "np",
        "array",
        "xtest",
        "prediction",
        "xtest",
        "un_theta",
        "result"
    ],
    "literals": [
        "\"visualize the original data\"",
        "'o'",
        "'y'",
        "'admitted'",
        "'+'",
        "'k'",
        "'rejected'",
        "\"Exam 1 score\"",
        "\"Exam 2 score\"",
        "\"The admission probability is: \"",
        "\"ex2data1.txt\"",
        "','",
        "\"initial cost function value:\"",
        "\"final theta value:\"",
        "\"the minimum cost function value:\"",
        "\"(1: admitted, 0: not admitted) The student will be: %01d\""
    ],
    "variables": [
        "m",
        "n",
        "xnorm",
        "mu",
        "sigma",
        "xnorm",
        "i",
        "n",
        "theta",
        "num",
        "xpoints",
        "ypoints",
        "z",
        "sgmd",
        "m",
        "n",
        "J_pos",
        "J_neg",
        "J",
        "m",
        "n",
        "h",
        "h",
        "shape",
        "delta",
        "grad",
        "admitted",
        "rejected",
        "p",
        "y",
        "y",
        "dat",
        "m",
        "n",
        "xdata",
        "xdata",
        "ydata",
        "ydata",
        "shape",
        "init_theta",
        "xdata",
        "theta_min",
        "j_min",
        "un_theta",
        "xtest",
        "xtest",
        "result"
    ],
    "comments": [
        "mean values of each feature",
        "standard deviation of each feature",
        "unnormalize theta_0",
        "unnormalize other thetas",
        "number of points",
        "dimesion = m x 1",
        "return value is m x 1",
        "when h(x) is greater than 0.5",
        "plt.show()",
        "",
        "Main Program                    #",
        "",
        "get the number of rows m and number of columns n",
        "get x data",
        "m x n array",
        "",
        "get y data",
        "m x 1",
        "n x 1",
        "check what data looks like call \"visualization\"",
        "normalize the features",
        "check if the cost function is correct, should be 0.693",
        "minimize the theta sets using scipy fmin_bfgs algorithm",
        "unnormalize theta values, not scalable in this case",
        "plot the boundary lines",
        "Test your program, should report 0.776"
    ],
    "docstrings": [
        "'''\n    Machine Learning on Coursera (Andrew Ng)\n    Exercise 2.1: logistic regression\n\n    use scipy optimization function package scipy.optimize, package fmin_bfgs to minimize \n    the function and get the opmitized papameter (theta) values\n    \n    data set needed: 'ex2data1.txt'\n    \n    @yingtang \n\nnote: feature normalization is necessary\n\n'''",
        "'''feature normalization'''",
        "'''note that the first column of X are all ones'''",
        "'''\n    we obtained theata with the normailzed features\n\n    now we keep the feature normalized and get back the unormalized values of theta\n    '''",
        "'''\n    plot the boudary lines of the classification\n    boundary is determined when sigmoid function is of value 0.5\n\n    for the data with two features\n    '''",
        "\"\"\"compute the sigmoid function\"\"\"",
        "'''cost function of the logistic regression'''",
        "\"\"\"compute the gradient of the cost function\"\"\""
    ],
    "functions": [
        "feature_norm",
        "unnormalize_theta",
        "boundary_lines",
        "sigmoid",
        "cost_function",
        "gradient",
        "visualization",
        "prediction"
    ],
    "classes": []
}