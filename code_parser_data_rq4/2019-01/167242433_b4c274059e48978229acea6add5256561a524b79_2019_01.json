{
    "identifiers": [
        "flask",
        "Flask",
        "flask",
        "render_template",
        "flask",
        "jsonify",
        "flask",
        "request",
        "tensorflow",
        "tf",
        "tf",
        "enable_eager_execution",
        "tensorflow",
        "keras",
        "keras",
        "models",
        "load_model",
        "functools",
        "Flask",
        "keras",
        "models",
        "load_model",
        "app",
        "route",
        "render_template",
        "app",
        "route",
        "methods",
        "jsonify",
        "hello_world",
        "model",
        "start_string",
        "request",
        "json",
        "model",
        "start_string",
        "char2idx",
        "s",
        "s",
        "start_string",
        "tf",
        "expand_dims",
        "input_eval",
        "model",
        "reset_states",
        "i",
        "num_generate",
        "model",
        "input_eval",
        "tf",
        "squeeze",
        "predictions",
        "predictions",
        "temperature",
        "tf",
        "multinomial",
        "predictions",
        "num_samples",
        "numpy",
        "tf",
        "expand_dims",
        "predicted_id",
        "text_generated",
        "append",
        "idx2char",
        "predicted_id",
        "start_string",
        "join",
        "text_generated"
    ],
    "literals": [
        "'sample.h5'",
        "'/'",
        "'index.html'",
        "'/query'",
        "'POST'",
        "'query'",
        "' '",
        "'H'",
        "'W'",
        "'d'",
        "'e'",
        "'l'",
        "'o'",
        "'r'",
        "' '",
        "'H'",
        "'W'",
        "'d'",
        "'e'",
        "'l'",
        "'o'",
        "'r'",
        "''"
    ],
    "variables": [
        "app",
        "model",
        "char2idx",
        "idx2char",
        "num_generate",
        "input_eval",
        "input_eval",
        "text_generated",
        "temperature",
        "predictions",
        "predictions",
        "predictions",
        "predicted_id",
        "input_eval"
    ],
    "comments": [
        "Number of characters to generate",
        "Converting our start string to numbers (vectorizing)",
        "Here batch size == 1",
        "remove the batch dimension",
        "predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[-1,0].eval()"
    ],
    "docstrings": [],
    "functions": [
        "index",
        "query",
        "hello_world"
    ],
    "classes": []
}