{
    "identifiers": [
        "streamlit",
        "st",
        "openai",
        "llama_index",
        "SimpleDirectoryReader",
        "ServiceContext",
        "OpenAIEmbedding",
        "PromptHelper",
        "VectorStoreIndex",
        "set_global_service_context",
        "Document",
        "llama_index",
        "llms",
        "OpenAI",
        "llama_index",
        "text_splitter",
        "SentenceSplitter",
        "llama_index",
        "storage",
        "storage_context",
        "StorageContext",
        "st",
        "set_page_config",
        "page_title",
        "page_icon",
        "layout",
        "initial_sidebar_state",
        "menu_items",
        "st",
        "markdown",
        "unsafe_allow_html",
        "st",
        "title",
        "st",
        "markdown",
        "unsafe_allow_html",
        "st",
        "secrets",
        "openai_key",
        "st",
        "session_state",
        "keys",
        "st",
        "session_state",
        "st",
        "cache_resource",
        "show_spinner",
        "st",
        "spinner",
        "text",
        "SimpleDirectoryReader",
        "input_dir",
        "recursive",
        "reader",
        "load_data",
        "OpenAI",
        "model",
        "temperature",
        "st",
        "session_state",
        "llm_temp",
        "max_tokens",
        "top_p",
        "st",
        "session_state",
        "llm_top_p",
        "system_prompt",
        "OpenAIEmbedding",
        "embed_batch_size",
        "SentenceSplitter",
        "chunk_size",
        "chunk_overlap",
        "PromptHelper",
        "context_window",
        "num_output",
        "chunk_overlap_ratio",
        "chunk_size_limit",
        "ServiceContext",
        "from_defaults",
        "llm",
        "llm",
        "embed_model",
        "embed_model",
        "text_splitter",
        "text_splitter",
        "prompt_helper",
        "prompt_helper",
        "VectorStoreIndex",
        "from_documents",
        "docs",
        "service_context",
        "service_context",
        "show_progress",
        "index",
        "format",
        "st",
        "session_state",
        "llm_temp",
        "format",
        "st",
        "session_state",
        "llm_top_p",
        "st",
        "markdown",
        "unsafe_allow_html",
        "st",
        "sidebar",
        "st",
        "sidebar",
        "image",
        "st",
        "title",
        "st",
        "slider",
        "label",
        "key",
        "min_value",
        "max_value",
        "step",
        "value",
        "on_change",
        "print_llm_state",
        "st",
        "slider",
        "label",
        "key",
        "min_value",
        "max_value",
        "step",
        "value",
        "on_change",
        "print_llm_state",
        "load_data",
        "st",
        "session_state",
        "keys",
        "st",
        "session_state",
        "index",
        "as_chat_engine",
        "chat_mode",
        "verbose",
        "prompt",
        "st",
        "chat_input",
        "st",
        "session_state",
        "messages",
        "append",
        "prompt",
        "message",
        "st",
        "session_state",
        "messages",
        "st",
        "chat_message",
        "message",
        "st",
        "write",
        "message",
        "st",
        "session_state",
        "messages",
        "st",
        "chat_message",
        "st",
        "spinner",
        "st",
        "session_state",
        "chat_engine",
        "chat",
        "prompt",
        "st",
        "write",
        "response",
        "response",
        "response",
        "response",
        "st",
        "session_state",
        "messages",
        "append",
        "message"
    ],
    "literals": [
        "\"Theo The Thesis Chatbot\"",
        "\":book:\"",
        "\"centered\"",
        "\"auto\"",
        "\"Hi, I'm Theo the Thesis Chatbot!\"",
        "'<p class=\"big-font\">By Adam Goodkind <br> For my thesis \\\n            <a href=\"https://adamgoodkind.com/files/Goodkind_Dissertation.pdf\"><em>Predicting Social Dynamics in Interactions Using Keystroke Patterns</em></a></p>'",
        "\"messages\"",
        "\"role\"",
        "\"assistant\"",
        "\"content\"",
        "\"Ask me a question about Adam's thesis!\"",
        "\"I'm reading all 227 pages of Adam's thesis â€“ hang tight! This might take a moment.\"",
        "\"./data\"",
        "\"gpt-4\"",
        "\"llm_temp: {}\"",
        "\"llm_top_p: {}\"",
        "\"./images/theo_icon.jpeg\"",
        "\"How creative do you want me to be in my answers?\"",
        "\"**Temperature**: Randomness of my word choices, \\\n                                from predictable (0) to imaginative (1)\"",
        "\"llm_temp\"",
        "\"**Nucleus Sampling**: The size (proportion) of \\\n                                the word pool to sample from\"",
        "\"llm_top_p\"",
        "\"chat_engine\"",
        "\"condense_question\"",
        "\"Your question\"",
        "\"role\"",
        "\"user\"",
        "\"content\"",
        "\"role\"",
        "\"content\"",
        "\"role\"",
        "\"assistant\"",
        "\"assistant\"",
        "\"Thinking...\"",
        "\"role\"",
        "\"assistant\"",
        "\"content\""
    ],
    "variables": [
        "openai",
        "api_key",
        "messages",
        "reader",
        "docs",
        "llm",
        "embed_model",
        "text_splitter",
        "prompt_helper",
        "service_context",
        "index",
        "llm_temperature",
        "lmm_top_p",
        "index",
        "chat_engine",
        "response",
        "message"
    ],
    "comments": [
        "from pinecone import Pinecone",
        "from llama_index.vector_stores import PineconeVectorStore",
        "st.write(\"By Adam Goodkind, for his thesis [*Predicting Social Dynamics in Interactions Using Keystroke Patterns*](https://adamgoodkind.com/files/Goodkind_Dissertation.pdf)\")",
        "st.header(\"By Adam Goodkind, for his thesis [*Predicting Social Dynamics in Interactions Using Keystroke Patterns*](https://adamgoodkind.com/files/Goodkind_Dissertation.pdf)\")",
        "access key from .streamlit/secrets.toml",
        "initiate a Pinecone client",
        "pinecone_client = Pinecone(api_key=st.secrets.PINECONE_API_KEY)",
        "pinecone_index = pinecone_client.Index(\"theo\")",
        "Initialize the chat messages history",
        "parameters for the Service Context",
        "the Service Context is a bundle used for indexing and querying",
        "# Set the global service context to the cre",
        "# Create a PineconeVectorStore using the specified pinecone_index",
        "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)",
        "# Create a StorageContext using the created PineconeVectorStore",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)",
        "# Use the chunks of documents and the storage_context to create the index",
        "index = VectorStoreIndex.from_documents(",
        "docs,",
        "storage_context=storage_context",
        ")",
        "st.markdown(\" <style> div[class^='st-emotion-cache-6qob1r'] { padding-top: 0rem; } </style> \", unsafe_allow_html=True)",
        "st.write(\"Have fun with the settings below. [OpenAI](https://platform.openai.com/docs/api-reference/chat/create) \\",
        "recommends only adjusting one setting at a time (usually temperature)/\")",
        "st.caption(\"It's usually best to keep this at 1.0\")",
        "Initialize the chat engine",
        "Prompt for user input and save to chat history",
        "Display the prior chat messages",
        "If last message is not from assistant, generate a new response",
        "Add response to message history"
    ],
    "docstrings": [
        "\"\"\"\n<style>\n.big-font {\n    font-size:20px !important;\n}\n</style>\n\"\"\"",
        "\"\"\"\n                        You are a smart and educated person, \n                        and your job is to answer questions about Adam's thesis. \n                        Assume that all questions are related to Adam's entire thesis. \n                        But if the thesis doesn't have the answer, try looking to\n                        your general knowledge.\n                        But make sure your answers are complete but also concise.\n                        \"\"\"",
        "\"\"\"\n    <style>\n        [data-testid=stSidebar] [data-testid=stImage]{\n            text-align: center;\n            display: block;\n            margin-left: auto;\n            margin-right: auto;\n            width: 100%;\n        }\n    </style>\n    \"\"\""
    ],
    "functions": [
        "load_data",
        "print_llm_state"
    ],
    "classes": []
}