{
    "identifiers": [
        "random",
        "numpy",
        "np",
        "os",
        "sys",
        "torch",
        "pytorch_pretrained_bert",
        "BertTokenizer",
        "utils",
        "data_dir",
        "bert_model_dir",
        "token_pad_idx",
        "data_dir",
        "batch_size",
        "max_len",
        "device",
        "seed",
        "load_tags",
        "tag",
        "idx",
        "idx",
        "tag",
        "tags",
        "idx",
        "tag",
        "idx",
        "tag",
        "tags",
        "tag2idx",
        "idx2tag",
        "tag2idx",
        "BertTokenizer",
        "from_pretrained",
        "bert_model_dir",
        "do_lower_case",
        "os",
        "path",
        "join",
        "data_dir",
        "open",
        "file_path",
        "file",
        "tag",
        "file",
        "tags",
        "append",
        "tag",
        "strip",
        "tags",
        "sentences_file",
        "tags_file",
        "d",
        "open",
        "sentences_file",
        "file",
        "line",
        "file",
        "line",
        "split",
        "sentences",
        "append",
        "tokenizer",
        "convert_tokens_to_ids",
        "tokens",
        "open",
        "tags_file",
        "file",
        "line",
        "file",
        "tag2idx",
        "get",
        "tag",
        "tag",
        "line",
        "strip",
        "split",
        "tags",
        "append",
        "tag_seq",
        "len",
        "sentences",
        "len",
        "tags",
        "i",
        "len",
        "sentences",
        "len",
        "tags",
        "i",
        "len",
        "sentences",
        "i",
        "sentences",
        "tags",
        "len",
        "sentences",
        "data_type",
        "data_type",
        "os",
        "path",
        "join",
        "data_dir",
        "data_type",
        "os",
        "path",
        "join",
        "data_dir",
        "data_type",
        "load_sentences_tags",
        "sentences_file",
        "tags_path",
        "data",
        "ValueError",
        "data",
        "data",
        "shuffle",
        "data",
        "shuffle",
        "random",
        "seed",
        "seed",
        "random",
        "shuffle",
        "order",
        "i",
        "data",
        "batch_size",
        "data",
        "idx",
        "idx",
        "order",
        "i",
        "batch_size",
        "i",
        "batch_size",
        "data",
        "idx",
        "idx",
        "order",
        "i",
        "batch_size",
        "i",
        "batch_size",
        "len",
        "sentences",
        "max",
        "len",
        "s",
        "s",
        "sentences",
        "min",
        "batch_max_len",
        "max_len",
        "token_pad_idx",
        "np",
        "ones",
        "batch_len",
        "max_len",
        "tag_pad_idx",
        "np",
        "ones",
        "batch_len",
        "max_len",
        "j",
        "batch_len",
        "len",
        "sentences",
        "j",
        "cur_len",
        "max_len",
        "batch_data",
        "j",
        "cur_len",
        "sentences",
        "j",
        "batch_tags",
        "j",
        "cur_len",
        "tags",
        "j",
        "sentences",
        "j",
        "max_len",
        "tags",
        "j",
        "max_len",
        "torch",
        "tensor",
        "batch_data",
        "dtype",
        "torch",
        "torch",
        "tensor",
        "batch_tags",
        "dtype",
        "torch",
        "batch_data",
        "to",
        "device",
        "batch_tags",
        "to",
        "device",
        "batch_data",
        "batch_tags"
    ],
    "literals": [
        "'O'",
        "'tags.txt'",
        "'r'",
        "'r'",
        "'r'",
        "' '",
        "'data'",
        "'tags'",
        "'size'",
        "'train'",
        "'val'",
        "'test'",
        "'sentences.txt'",
        "'tags.txt'",
        "\"data type not in ['train', 'val', 'test']\"",
        "'size'",
        "'size'",
        "'data'",
        "'tags'"
    ],
    "variables": [
        "data_dir",
        "batch_size",
        "max_len",
        "device",
        "seed",
        "token_pad_idx",
        "tags",
        "tag2idx",
        "idx2tag",
        "tag2idx",
        "idx2tag",
        "tag_pad_idx",
        "tokenizer",
        "tags",
        "file_path",
        "sentences",
        "tags",
        "tokens",
        "tag_seq",
        "d",
        "d",
        "d",
        "data",
        "sentences_file",
        "tags_path",
        "order",
        "sentences",
        "tags",
        "batch_len",
        "batch_max_len",
        "max_len",
        "batch_data",
        "batch_tags",
        "cur_len",
        "batch_data",
        "j",
        "batch_tags",
        "j",
        "batch_data",
        "batch_tags",
        "batch_data",
        "batch_tags"
    ],
    "comments": [
        "replace each token by its index",
        "replace each tag by its index",
        "checks to ensure there is a tag for each token",
        "print(sentences[i], tags[i])",
        "storing sentences and tags in dict d",
        "make a list that decides the order in which we go over the data- this avoids explicit shuffling of data",
        "one pass over data",
        "fetch sentences and tags",
        "batch length",
        "compute length of longest sentence in batch",
        "prepare a numpy array with the data, initialising the data with pad_idx",
        "copy the data to the numpy array",
        "since all data are indices, we convert them to torch LongTensors",
        "shift tensors to GPU if available"
    ],
    "docstrings": [
        "\"\"\"Data loader\"\"\"",
        "\"\"\"Loads sentences and tags from their corresponding files. \n            Maps tokens and tags to their indices and stores them in the provided dict d.\n        \"\"\"",
        "\"\"\"Loads the data for each type in types from data_dir.\n\n        Args:\n            data_type: (str) has one of 'train', 'val', 'test' depending on which data is required.\n        Returns:\n            data: (dict) contains the data with tags for each type in types.\n        \"\"\"",
        "\"\"\"Returns a generator that yields batches data with tags.\n\n        Args:\n            data: (dict) contains data which has keys 'data', 'tags' and 'size'\n            shuffle: (bool) whether the data should be shuffled\n            \n        Yields:\n            batch_data: (tensor) shape: (batch_size, max_len)\n            batch_tags: (tensor) shape: (batch_size, max_len)\n        \"\"\""
    ],
    "functions": [
        "load_tags",
        "load_sentences_tags",
        "load_data",
        "data_iterator"
    ],
    "classes": [
        "DataLoader"
    ]
}