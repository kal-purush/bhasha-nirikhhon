{
    "identifiers": [
        "typing",
        "random",
        "cv2",
        "numpy",
        "np",
        "core",
        "transforms_interface",
        "ImageOnlyTransform",
        "to_tuple",
        "functional",
        "clipped",
        "clipped",
        "img",
        "np",
        "ndarray",
        "target_img",
        "np",
        "ndarray",
        "beta",
        "np",
        "ndarray",
        "np",
        "fft",
        "fft2",
        "img",
        "astype",
        "np",
        "float32",
        "axes",
        "np",
        "fft",
        "fft2",
        "target_img",
        "astype",
        "np",
        "float32",
        "axes",
        "np",
        "abs",
        "fft_src",
        "np",
        "angle",
        "fft_src",
        "np",
        "abs",
        "fft_trg",
        "np",
        "fft",
        "fftshift",
        "amplitude_src",
        "axes",
        "np",
        "fft",
        "fftshift",
        "amplitude_trg",
        "axes",
        "amplitude_src",
        "shape",
        "np",
        "floor",
        "min",
        "height",
        "width",
        "beta",
        "astype",
        "np",
        "floor",
        "height",
        "width",
        "astype",
        "center_y",
        "border",
        "center_y",
        "border",
        "center_x",
        "border",
        "center_x",
        "border",
        "y1",
        "y2",
        "x1",
        "x2",
        "amplitude_trg",
        "y1",
        "y2",
        "x1",
        "x2",
        "np",
        "fft",
        "ifftshift",
        "amplitude_src",
        "axes",
        "np",
        "fft",
        "ifft2",
        "amplitude_src",
        "np",
        "exp",
        "phase_src",
        "axes",
        "np",
        "real",
        "src_image_transformed",
        "src_image_transformed",
        "ImageOnlyTransform",
        "reference_images",
        "blend_ratio",
        "read_fn",
        "cv2",
        "imread",
        "p",
        "p",
        "p",
        "reference_images",
        "read_fn",
        "blend_ratio",
        "img",
        "reference_image",
        "blend_ratio",
        "skimage",
        "exposure",
        "match_histograms",
        "random",
        "random",
        "p",
        "cv2",
        "resize",
        "reference_image",
        "dsize",
        "img",
        "shape",
        "img",
        "shape",
        "match_histograms",
        "img",
        "reference_image",
        "multichannel",
        "cv2",
        "addWeighted",
        "matched",
        "blend_ratio",
        "img",
        "blend_ratio",
        "img",
        "read_fn",
        "random",
        "choice",
        "reference_images",
        "random",
        "uniform",
        "blend_ratio",
        "blend_ratio",
        "ImageOnlyTransform",
        "beta_limit",
        "always_apply",
        "p",
        "FDA",
        "always_apply",
        "always_apply",
        "p",
        "p",
        "to_tuple",
        "beta_limit",
        "low",
        "img",
        "target_image",
        "beta",
        "fourier_domain_adaptation",
        "img",
        "img",
        "target_img",
        "target_image",
        "beta",
        "beta",
        "cv2",
        "resize",
        "target_img",
        "dsize",
        "img",
        "shape",
        "img",
        "shape",
        "target_img",
        "shape",
        "img",
        "shape",
        "ValueError",
        "format",
        "img",
        "shape",
        "target_img",
        "shape",
        "target_img",
        "random",
        "uniform",
        "beta_limit",
        "beta_limit",
        "property"
    ],
    "literals": [
        "\"HistogramMatching\"",
        "\"FDA\"",
        "\"fourier_domain_adaptation\"",
        "\"reference_image\"",
        "\"blend_ratio\"",
        "\"blend_ratio\"",
        "\"image\"",
        "\"target_image\"",
        "\"The source and target images must contain the same shape,\"",
        "\" but got {} and {} respectively.\"",
        "\"target_image\"",
        "\"beta\"",
        "\"image\"",
        "\"target_image\"",
        "\"beta_limit\""
    ],
    "variables": [
        "__all__",
        "fft_src",
        "fft_trg",
        "amplitude_src",
        "phase_src",
        "amplitude_trg",
        "amplitude_src",
        "amplitude_trg",
        "height",
        "width",
        "border",
        "center_x",
        "center_y",
        "y1",
        "y2",
        "x1",
        "x2",
        "amplitude_src",
        "amplitude_src",
        "src_image_transformed",
        "src_image_transformed",
        "reference_images",
        "read_fn",
        "blend_ratio",
        "reference_image",
        "matched",
        "img",
        "beta_limit",
        "img",
        "target_img",
        "target_img"
    ],
    "comments": [
        "get fft of both source and target",
        "extract amplitude and phase of both fft-s",
        "mutate the amplitude part of source with target",
        "get mutated image"
    ],
    "docstrings": [
        "\"\"\"\n    Fourier Domain Adaptation from https://github.com/YanchaoYang/FDA\n\n    Args:\n        img:  source image\n        target_img:  target image for domain adaptation\n        beta: coefficient from source paper\n\n    Returns:\n        transformed image\n\n    \"\"\"",
        "\"\"\"\n    Apply histogram matching. It manipulates the pixels of an input image so that its histogram matches\n    the histogram of the reference image. If the images have multiple channels, the matching is done independently\n    for each channel, as long as the number of channels is equal in the input image and the reference.\n\n    Histogram matching can be used as a lightweight normalisation for image processing,\n    such as feature matching, especially in circumstances where the images have been taken from different\n    sources or in different conditions (i.e. lighting).\n\n    See:\n        https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_histogram_matching.html\n\n    Args:\n        reference_images (List[str]): List of file paths for reference images.\n        blend_ratio (float, float): Tuple of min and max blend ratio. Matched image will be blended with original\n            with random blend factor for increased diversity of generated images.\n        read_fn (Callable): Used-defined function to read image. Function should get image path and return numpy\n            array of image pixels.\n        p (float): probability of applying the transform. Default: 1.0.\n\n    Targets:\n        image\n\n    Image types:\n        uint8, uint16, float32\n    \"\"\"",
        "\"\"\"\n    Fourier Domain Adaptation from https://github.com/YanchaoYang/FDA\n    Simple \"style transfer\".\n    Important: you need to pass target image as a parameter `target_image` in __call__, see example\n\n    Args:\n        beta_limit (float or tuple of float): coefficient beta from paper. Recommended less 0.3.\n\n    Targets:\n        image\n\n    Image types:\n        uint8, float32\n\n    Reference:\n        https://github.com/YanchaoYang/FDA\n        https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FDA_Fourier_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2020_paper.pdf\n\n    Example:\n        >>> import numpy as np\n        >>> import albumentations as A\n        >>> image = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n        >>> target_image = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n        >>> aug = A.Compose([A.FDA(p=1)])\n        >>> result = aug(image=image, target_image=target_image)\n\n    \"\"\""
    ],
    "functions": [
        "fourier_domain_adaptation",
        "apply",
        "get_params",
        "get_transform_init_args_names",
        "apply",
        "get_params_dependent_on_targets",
        "get_params",
        "targets_as_params",
        "get_transform_init_args_names"
    ],
    "classes": [
        "HistogramMatching",
        "FDA"
    ]
}