{
    "identifiers": [
        "pickle",
        "batch_size",
        "is_pretrain",
        "max",
        "epoch_num"
    ],
    "literals": [
        "\"./word2vec/pretrain_emb.alltrain.256d.npy\"",
        "'./corpus/seg_test.txt'",
        "'./results/test_result.json'",
        "'./corpus/seg_train.txt'",
        "'./pickles/params.pkl'",
        "'./pickles/index2word.all.pkl'",
        "'./pickles/word2index.all.pkl'",
        "'fastText'",
        "'TextCNN'",
        "'TextRCNN'",
        "'TextRNN'",
        "'HAN'",
        "'CNNWithDoc2Vec'",
        "'RCNNWithDoc2Vec'",
        "'CNNInception'"
    ],
    "variables": [
        "has_cuda",
        "is_training",
        "is_pretrain",
        "force_word2index",
        "embedding_path",
        "test_path",
        "result_path",
        "data_path",
        "model_path",
        "index2word_path",
        "word2index_path",
        "model_names",
        "batch_size",
        "step",
        "num_workers",
        "vocab_size",
        "min_count",
        "max_text_len",
        "embedding_size",
        "num_class",
        "learning_rate",
        "learning_rate2",
        "learning_rate2",
        "lr_decay",
        "begin_epoch",
        "weight_decay",
        "dropout_rate",
        "epoch_num",
        "epoch_step",
        "han_batch_size",
        "num_sentences",
        "sequence_length",
        "word_hidden_size",
        "sentence_hidden_size",
        "word_context_size",
        "sentence_context_size",
        "loss_weight_value"
    ],
    "comments": [
        "embedding_path = \"./word2vec/pretrain_emb.128d.npy\"",
        "test_path = './corpus/test_preprocessed.txt'",
        "data_path = './corpus/train_m_preprocessed.txt'",
        "64 if has cuda",
        "3000 // batch_size if has cuda",
        "0.0 if pre train emb",
        "HAN",
        "20"
    ],
    "docstrings": [],
    "functions": [],
    "classes": [
        "Config"
    ]
}