{
    "identifiers": [
        "time",
        "numpy",
        "np",
        "h5py",
        "matplotlib",
        "pyplot",
        "plt",
        "scipy",
        "PIL",
        "Image",
        "scipy",
        "ndimage",
        "pnp_app_utils",
        "plt",
        "rcParams",
        "plt",
        "rcParams",
        "plt",
        "rcParams",
        "load_data",
        "plt",
        "imshow",
        "train_x_orig",
        "index",
        "astype",
        "np",
        "uint8",
        "plt",
        "show",
        "train_y",
        "index",
        "train_y",
        "index",
        "input",
        "train_x_orig",
        "shape",
        "test_x_orig",
        "shape",
        "val_x_orig",
        "shape",
        "train_x_orig",
        "shape",
        "train_x_orig",
        "shape",
        "m_train",
        "m_val",
        "m_test",
        "num_px_x",
        "num_px_y",
        "train_x_orig",
        "shape",
        "train_y",
        "shape",
        "val_x_orig",
        "shape",
        "val_y",
        "shape",
        "test_x_orig",
        "shape",
        "test_y",
        "shape",
        "input",
        "train_x_orig",
        "reshape",
        "train_x_orig",
        "shape",
        "T",
        "val_x_orig",
        "reshape",
        "val_x_orig",
        "shape",
        "T",
        "test_x_orig",
        "reshape",
        "test_x_orig",
        "shape",
        "T",
        "train_x_flatten",
        "val_x_flatten",
        "test_x_flatten",
        "train_x",
        "shape",
        "val_x",
        "shape",
        "test_x",
        "shape",
        "input",
        "num_px_x",
        "num_px_y",
        "n_x",
        "n_h",
        "n_y",
        "X",
        "Y",
        "layer_dims",
        "learning_rate",
        "num_iterations",
        "print_cost",
        "np",
        "random",
        "seed",
        "X",
        "shape",
        "layer_dims",
        "initialize_parameters",
        "n_x",
        "n_h",
        "n_y",
        "parameters",
        "parameters",
        "parameters",
        "parameters",
        "i",
        "num_iterations",
        "linear_activation_forward",
        "X",
        "W1",
        "b1",
        "linear_activation_forward",
        "A1",
        "W2",
        "b2",
        "compute_cost",
        "A2",
        "Y",
        "np",
        "divide",
        "Y",
        "A2",
        "np",
        "divide",
        "Y",
        "A2",
        "linear_activation_backward",
        "dA2",
        "cache2",
        "linear_activation_backward",
        "dA1",
        "cache1",
        "dW1",
        "db1",
        "dW2",
        "db2",
        "update_parameters",
        "parameters",
        "grads",
        "learning_rate",
        "parameters",
        "parameters",
        "parameters",
        "parameters",
        "print_cost",
        "i",
        "format",
        "i",
        "np",
        "squeeze",
        "cost",
        "print_cost",
        "i",
        "costs",
        "append",
        "cost",
        "plt",
        "plot",
        "np",
        "squeeze",
        "costs",
        "plt",
        "ylabel",
        "plt",
        "xlabel",
        "plt",
        "title",
        "learning_rate",
        "plt",
        "show",
        "parameters",
        "input",
        "two_layer_model",
        "train_x",
        "train_y",
        "layer_dims",
        "n_x",
        "n_h",
        "n_y",
        "learning_rate",
        "num_iterations",
        "print_cost",
        "input",
        "predict",
        "train_x",
        "train_y",
        "parameters",
        "predict",
        "val_x",
        "val_y",
        "parameters",
        "predict",
        "test_x",
        "test_y",
        "parameters",
        "input",
        "num_px_x",
        "num_px_y",
        "X",
        "Y",
        "layers_dims",
        "learning_rate",
        "lambd",
        "num_iterations",
        "print_cost",
        "initialize_parameters_deep",
        "layers_dims",
        "i",
        "num_iterations",
        "L_model_forward",
        "X",
        "parameters",
        "compute_cost_with_regularization",
        "AL",
        "Y",
        "parameters",
        "lambd",
        "L_model_backward_with_reg",
        "AL",
        "Y",
        "caches",
        "lambd",
        "update_parameters",
        "parameters",
        "grads",
        "learning_rate",
        "print_cost",
        "i",
        "i",
        "cost",
        "print_cost",
        "i",
        "costs",
        "append",
        "cost",
        "plt",
        "plot",
        "np",
        "squeeze",
        "costs",
        "plt",
        "ylabel",
        "plt",
        "xlabel",
        "plt",
        "title",
        "learning_rate",
        "plt",
        "show",
        "parameters",
        "X",
        "Y",
        "layers_dims",
        "learning_rate",
        "mini_batch_size",
        "lambd",
        "num_iterations",
        "print_cost",
        "initialize_parameters_deep",
        "layers_dims",
        "i",
        "num_iterations",
        "seed",
        "random_mini_batches",
        "X",
        "Y",
        "mini_batch_size",
        "seed",
        "minibatch",
        "minibatches",
        "L_model_forward",
        "X",
        "parameters",
        "compute_cost_with_regularization",
        "AL",
        "Y",
        "parameters",
        "lambd",
        "L_model_backward_with_reg",
        "AL",
        "Y",
        "caches",
        "lambd",
        "update_parameters",
        "parameters",
        "grads",
        "learning_rate",
        "print_cost",
        "i",
        "i",
        "cost",
        "print_cost",
        "i",
        "costs",
        "append",
        "cost",
        "plt",
        "plot",
        "np",
        "squeeze",
        "costs",
        "plt",
        "ylabel",
        "plt",
        "xlabel",
        "plt",
        "title",
        "learning_rate",
        "plt",
        "show",
        "parameters",
        "input",
        "L_layer_model",
        "train_x",
        "train_y",
        "layers_dims",
        "learning_rate",
        "lambd",
        "num_iterations",
        "print_cost",
        "input",
        "predict",
        "train_x",
        "train_y",
        "parameters",
        "predict",
        "val_x",
        "val_y",
        "parameters",
        "predict",
        "test_x",
        "test_y",
        "parameters"
    ],
    "literals": [
        "'figure.figsize'",
        "'image.interpolation'",
        "'nearest'",
        "'image.cmap'",
        "'gray'",
        "\"Loading a sample image from training set...\"",
        "\"y = 0, so this picture does not contain a person.\"",
        "\"y = 1, so this picture does contain a person.\"",
        "\"\\nPress Enter to continue.\"",
        "\"Some information about this dataset: \"",
        "\"Number of training examples: \"",
        "\"Number of validation examples: \"",
        "\"Number of testing examples: \"",
        "\"Each image is of size: (\"",
        "\", \"",
        "\", 3)\"",
        "\"train_x_orig shape: \"",
        "\"train_y shape: \"",
        "\"val_x_orig shape: \"",
        "\"val_y shape: \"",
        "\"test_x_orig shape: \"",
        "\"test_y shape: \"",
        "\"\\nPress Enter to continue.\"",
        "\"Now we will flatten the shapes of the train, test, and val data set.\"",
        "\"train_x's shape: \"",
        "\"val_x's shape: \"",
        "\"test_x's shape: \"",
        "\"\\nNow we will train a two-layer neural network to identify people in photos. Press Enter to continue.\"",
        "\"W1\"",
        "\"b1\"",
        "\"W2\"",
        "\"b2\"",
        "\"relu\"",
        "\"sigmoid\"",
        "\"sigmoid\"",
        "\"relu\"",
        "'dW1'",
        "'db1'",
        "'dW2'",
        "'db2'",
        "\"W1\"",
        "\"b1\"",
        "\"W2\"",
        "\"b2\"",
        "\"Cost after iteration {}: {}\"",
        "'cost'",
        "'iterations (per tens)'",
        "\"Learning rate =\"",
        "\"\\nModel is set up. Now we shall train the model. Press Enter to continue.\"",
        "\"\\nModel is set up. Now we will run the two-layer model to predict on the training and validation sets. Press Enter to continue.\"",
        "\"\\nTime to define a five-layer model. Press Enter to continue.\"",
        "\"Cost after iteration %i: %f\"",
        "'cost'",
        "'iterations (per tens)'",
        "\"Learning rate =\"",
        "\"Cost after iteration %i: %f\"",
        "'cost'",
        "'iterations (per tens)'",
        "\"Learning rate =\"",
        "\"\\nNow we will train a five-layer neural network to identify people in photos. Press Enter to continue.\"",
        "\"\\nModel is trained. Now we will use it to predict images. Press Enter to continue.\"",
        "\"Accuracy on training set: \"",
        "\"Accuracy on validation set: \"",
        "\"Accuracy on test set: \""
    ],
    "variables": [
        "train_x_orig",
        "train_y",
        "val_x_orig",
        "val_y",
        "test_x_orig",
        "test_y",
        "index",
        "m_train",
        "m_test",
        "m_val",
        "num_px_x",
        "num_px_y",
        "train_x_flatten",
        "val_x_flatten",
        "test_x_flatten",
        "train_x",
        "val_x",
        "test_x",
        "n_x",
        "n_h",
        "n_y",
        "layer_dims",
        "grads",
        "costs",
        "m",
        "n_x",
        "n_h",
        "n_y",
        "parameters",
        "W1",
        "b1",
        "W2",
        "b2",
        "A1",
        "cache1",
        "A2",
        "cache2",
        "cost",
        "dA2",
        "dA1",
        "dW2",
        "db2",
        "dA0",
        "dW1",
        "db1",
        "grads",
        "grads",
        "grads",
        "grads",
        "parameters",
        "W1",
        "b1",
        "W2",
        "b2",
        "parameters",
        "predictions_train",
        "predictions_val",
        "predictions_test",
        "layers_dims",
        "costs",
        "parameters",
        "AL",
        "caches",
        "cost",
        "grads",
        "parameters",
        "costs",
        "seed",
        "parameters",
        "seed",
        "minibatches",
        "AL",
        "caches",
        "cost",
        "grads",
        "parameters",
        "parameters",
        "pred_train",
        "pred_val",
        "pred_test"
    ],
    "comments": [
        "THIS LEARNING ALGORITHM DECIDES WHETHER AN IMAGE CONTAINS A PERSON OR NOT",
        "INPUT: IMAGE",
        "OUTPUT: Y/N AS TO WHETHER IT CONTAINS A PERSON",
        "get_ipython().magic('matplotlib inline')",
        "set default size of plots",
        "np.random.seed(1)",
        "Load the training and test sets",
        "Load a sample image and show it",
        "This index value can be set to anything between 1 and 915",
        "Explore your dataset",
        "Reshape the training, val, and test examples",
        "Standardize data to have feature values between 0 and 1.",
        "Constants for the two-layer model",
        "number of input units",
        "number of hidden units",
        "number of output units",
        "Two layer model",
        "Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.",
        "Arguments:",
        "X -- input data, of shape (n_x, number of examples)",
        "Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)",
        "layer_dims -- dimensions of the layers (n_x, n_h, n_y)",
        "num_iterations -- number of iterations of the optimization loop",
        "learning_rate -- learning rate of the gradient descent update rule",
        "print_cost -- If set to True, this will print the cost every 100 iterations",
        "Returns:",
        "parameters -- a dictionary containing W1, W2, b1, and b2",
        "to keep track of the cost",
        "number of examples",
        "Get W1, b1, W2 and b2 from the dictionary parameters.",
        "Loop (gradient descent)",
        "Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID",
        "Compute cost",
        "Initializing backward propagation",
        "Backward propagation",
        "Set grads",
        "Update parameters",
        "Retrieve W1, b1, W2, b2 from parameters",
        "Print the cost every 100 training example",
        "plot the cost",
        "L-layer model (5 layers in this case)",
        "Define constants",
        "Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.",
        "Arguments:",
        "X -- data, numpy array of shape (number of examples, num_px * num_px * 3)",
        "Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)",
        "layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).",
        "learning_rate -- learning rate of the gradient descent update rule",
        "num_iterations -- number of iterations of the optimization loop",
        "print_cost -- if True, it prints the cost every 100 steps",
        "Returns:",
        "parameters -- parameters learnt by the model. They can then be used to predict.",
        "Parameters initialization.",
        "Loop (gradient descent)",
        "Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.",
        "Compute cost.",
        "Backward propagation.",
        "Update parameters.",
        "Print the cost every 100 training example",
        "plot the cost",
        "Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.",
        "Arguments:",
        "X -- data, numpy array of shape (number of examples, num_px * num_px * 3)",
        "Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)",
        "layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).",
        "learning_rate -- learning rate of the gradient descent update rule",
        "num_iterations -- number of iterations of the optimization loop",
        "print_cost -- if True, it prints the cost every 100 steps",
        "Returns:",
        "parameters -- parameters learnt by the model. They can then be used to predict.",
        "Parameters initialization.",
        "Loop (gradient descent)",
        "Define the random minibatches. (Seed is included so that it reshuffles different for every iteration)",
        "Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.",
        "Compute cost.",
        "Backward propagation.",
        "Update parameters.",
        "Print the cost every 100 training example",
        "plot the cost",
        "Train the model",
        "parameters = L_layer_model_with_batches(train_x, train_y, layers_dims, learning_rate = 0.009, mini_batch_size = 64, lambd = 0.8, num_iterations = 1000, print_cost = True)",
        "Output the predictions"
    ],
    "docstrings": [],
    "functions": [
        "two_layer_model",
        "L_layer_model",
        "L_layer_model_with_batches"
    ],
    "classes": []
}