{
    "identifiers": [
        "pandas",
        "pd",
        "numpy",
        "np",
        "random",
        "gc",
        "time",
        "shutil",
        "re",
        "os",
        "tqdm",
        "tqdm",
        "glob",
        "parameter",
        "Parameter",
        "utils",
        "KFold",
        "Parameter",
        "seed",
        "mode",
        "os",
        "path",
        "exists",
        "pd",
        "read_pickle",
        "read_json_data",
        "mode",
        "pd",
        "read_csv",
        "pd",
        "read_csv",
        "train_orders",
        "split",
        "train_orders",
        "explode",
        "column",
        "len",
        "train_orders",
        "train_orders",
        "groupby",
        "by",
        "rank",
        "ascending",
        "method",
        "astype",
        "train_orders",
        "train_orders",
        "train_orders",
        "train_df",
        "merge",
        "train_orders",
        "on",
        "how",
        "train_df",
        "merge",
        "train_ancestors",
        "on",
        "how",
        "train_df",
        "to_pickle",
        "KFold",
        "seed",
        "parameter",
        "k_folds",
        "group_split",
        "train_df",
        "group_col",
        "preprocess_df",
        "train_df",
        "pd",
        "concat",
        "train_df",
        "train_df",
        "train_df",
        "train_df",
        "sample",
        "frac",
        "reset_index",
        "drop",
        "train_df",
        "groupby",
        "by",
        "cumcount",
        "train_df",
        "groupby",
        "by",
        "transform",
        "train_df",
        "loc",
        "train_df",
        "train_df",
        "train_df",
        "copy",
        "get_truncated_df",
        "train_df",
        "cell_count",
        "parameter",
        "cell_count",
        "train_df",
        "train_df",
        "shape",
        "train_df",
        "code_df_valid",
        "mode",
        "sorted",
        "glob",
        "glob",
        "parameter",
        "data_dir",
        "format",
        "mode",
        "pd",
        "concat",
        "pd",
        "read_json",
        "path",
        "dtype",
        "assign",
        "id",
        "path",
        "split",
        "split",
        "rename_axis",
        "path",
        "tqdm",
        "paths_train",
        "reset_index",
        "drop",
        "res",
        "res",
        "df",
        "df",
        "groupby",
        "by",
        "transform",
        "df",
        "fillna",
        "astype",
        "df",
        "groupby",
        "by",
        "transform",
        "df",
        "df",
        "df",
        "df",
        "df",
        "apply",
        "x",
        "x",
        "lower",
        "strip",
        "df",
        "apply",
        "x",
        "preprocess_text",
        "x",
        "df",
        "replace",
        "df",
        "replace",
        "df",
        "apply",
        "x",
        "re",
        "sub",
        "x",
        "df",
        "re",
        "nltk",
        "stem",
        "WordNetLemmatizer",
        "WordNetLemmatizer",
        "re",
        "sub",
        "replace",
        "re",
        "sub",
        "re",
        "sub",
        "flags",
        "re",
        "I",
        "lower",
        "df",
        "cell_count",
        "id_col",
        "group_col",
        "max_random_cnt",
        "expand_ratio",
        "df",
        "df",
        "cell_count",
        "reset_index",
        "drop",
        "tmp1",
        "loc",
        "df",
        "df",
        "cell_count",
        "reset_index",
        "drop",
        "tmp1",
        "_",
        "df_g",
        "tmp2",
        "groupby",
        "by",
        "group_col",
        "df_g",
        "sample",
        "frac",
        "reset_index",
        "drop",
        "min",
        "cell_count",
        "len",
        "df_g",
        "cell_count",
        "max",
        "step",
        "i",
        "len",
        "df_g",
        "step",
        "df_g",
        "iloc",
        "i",
        "i",
        "cell_count",
        "len",
        "res_tmp",
        "cell_count",
        "df_g",
        "iloc",
        "cell_count",
        "res_tmp",
        "loc",
        "id_col_count",
        "id_col_count",
        "res",
        "append",
        "res_tmp",
        "i",
        "cell_count",
        "len",
        "df_g",
        "len",
        "df_g",
        "cell_count",
        "len",
        "df_g",
        "cell_count",
        "expand_ratio",
        "min",
        "random_cnt",
        "max_random_cnt",
        "i",
        "random_cnt",
        "df_g",
        "sample",
        "n",
        "cell_count",
        "reset_index",
        "drop",
        "res_tmp",
        "loc",
        "id_col_count",
        "id_col_count",
        "res",
        "append",
        "res_tmp",
        "pd",
        "concat",
        "res",
        "reset_index",
        "drop",
        "res",
        "sort_values",
        "by",
        "id_col",
        "ascending",
        "res",
        "groupby",
        "by",
        "id_col",
        "as_index",
        "sort",
        "agg",
        "res"
    ],
    "literals": [
        "'../input/ai4codetrainpicklefile/train_df.pkl'",
        "'../input/ai4codetrainpicklefile/train_df.pkl'",
        "'train'",
        "'../input/AI4Code/'",
        "'train_orders.csv'",
        "'../input/AI4Code/'",
        "'train_ancestors.csv'",
        "'cell_id'",
        "'cell_order'",
        "'cell_id'",
        "'flag'",
        "'rank'",
        "'id'",
        "'flag'",
        "'first'",
        "'flag'",
        "'cell_order'",
        "'id'",
        "'cell_id'",
        "'left'",
        "'id'",
        "'ancestor_id'",
        "'id'",
        "'left'",
        "'train_df.pkl'",
        "'ancestor_id'",
        "'cell_type'",
        "'cell_type'",
        "'rank2'",
        "'id'",
        "'cell_type'",
        "'id'",
        "'cell_type'",
        "'cell_id'",
        "'count'",
        "'cell_type'",
        "'rank2'",
        "'cell_type'",
        "'id'",
        "'cell_id'",
        "'rank2'",
        "'train'",
        "'{}/*.json'",
        "'cell_type'",
        "'category'",
        "'source'",
        "'str'",
        "'/'",
        "'.'",
        "'cell_id'",
        "'id'",
        "'cell_id'",
        "'cell_type'",
        "'source'",
        "'cell_count'",
        "'id'",
        "'cell_id'",
        "'count'",
        "'cell_type'",
        "'cell_type'",
        "'code'",
        "'markdown'",
        "'markdown_count'",
        "'id'",
        "'cell_type'",
        "'sum'",
        "'code_count'",
        "'cell_count'",
        "'markdown_count'",
        "'rank'",
        "'rank'",
        "'cell_count'",
        "'source'",
        "'source'",
        "'source'",
        "'source'",
        "'source'",
        "'source'",
        "\"[SEP]\"",
        "\"\"",
        "'source'",
        "'source'",
        "\"[CLS]\"",
        "\"\"",
        "'source'",
        "'source'",
        "' +'",
        "' '",
        "r'\\W'",
        "' '",
        "'_'",
        "' '",
        "r'\\s+[a-zA-Z]\\s+'",
        "' '",
        "r'\\s+'",
        "' '",
        "'id2'",
        "'id'",
        "'cell_count'",
        "'cell_count'",
        "'id'",
        "'cell_type'",
        "'rank2'",
        "'id'",
        "'fold_flag'",
        "'cell_count'",
        "'markdown_count'",
        "'code_count'",
        "'cell_id'",
        "'cell_type'",
        "'source'",
        "'rank'",
        "'rank2'"
    ],
    "variables": [
        "parameter",
        "train_df",
        "train_df",
        "train_orders",
        "train_ancestors",
        "train_orders",
        "train_orders",
        "train_orders",
        "train_orders",
        "train_df",
        "train_df",
        "train_df",
        "train_df",
        "train_df",
        "train_df",
        "code_df_valid",
        "train_df",
        "paths_train",
        "res",
        "res",
        "df",
        "df",
        "df",
        "df",
        "df",
        "df",
        "df",
        "df",
        "df",
        "df",
        "stemmer",
        "tmp1",
        "id_col",
        "tmp2",
        "res",
        "df_g",
        "step",
        "step",
        "id_col_count",
        "res_tmp",
        "res_tmp",
        "id_col",
        "random_cnt",
        "random_cnt",
        "res_tmp",
        "id_col",
        "res",
        "res",
        "res"
    ],
    "comments": [
        "from unidecode import unidecode",
        "`1qtrain_df = preprocess_features(train_df)",
        "train_df = preprocess_features(train_df)",
        "train_df['source_length'] = train_df['source'].apply(len)",
        "train_df['id_length'] = train_df.groupby(by=['id'])['source_length'].transform('sum')",
        "for col in ['cell_count','markdown_count', 'code_count']:",
        "train_df[col] = (train_df[col] - train_df[col].mean())/ train_df[col].std()",
        "train_df[col] = np.clip(train_df[col].fillna(0.0), -3, 3)",
        "train_df['flag'] = train_df['cell_type'].apply(lambda x:np.sum(x))",
        "train_df = train_df[train_df['flag']>0]",
        "del train_df['flag']",
        "[:100]",
        "df['source'] = df['cell_type'] + ' ' + df['source']",
        "df.loc[df['cell_type']==0, 'source'] = df.loc[df['cell_type']==0, 'rank'] + ' ' + df.loc[df['cell_type']==0, 'source']",
        "df['source'] = df['source'].replace(\"\\\\n\", \"\\n\")",
        "df['source'] = df['source'].str.replace(\"\\n\", \"\")",
        "df['source'] = df['source'].replace(\"#\", \"\")",
        "df['source'] = df['source'].apply(lambda x: unidecode(x))",
        "from https://www.kaggle.com/code/ilyaryabov/fastttext-sorting-with-cosine-distance-algo",
        "Remove all the special characters",
        "remove all single characters",
        "# Remove single characters from the start",
        "document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)",
        "Substituting multiple spaces with single space",
        "# Removing prefixed 'b'",
        "document = re.sub(r'^b\\s+', '', document)",
        "Converting to Lowercase",
        "return document",
        "# Lemmatization",
        "tokens = document.split()",
        "tokens = [stemmer.lemmatize(word) for word in tokens]",
        "# tokens = [word for word in tokens if len(word) > 3]",
        "preprocessed_text = ' '.join(tokens)",
        "def get_truncated_df(df, cell_count=128, id_col='id2', group_col='id', max_random_cnt=500, expand_ratio=10):",
        "tmp1 = df[df['cell_count'] <= cell_count].reset_index(drop=True)",
        "tmp1.loc[:, id_col] = 0",
        "tmp2 = df[df['cell_count'] > cell_count].reset_index(drop=True)",
        "# print(tmp1.shape,tmp2.shape)",
        "res = [tmp1]",
        "for _, df_g in tmp2.groupby(by=group_col):",
        "# print(df_g.columns)",
        "df_g = df_g.sample(frac=1.0).reset_index(drop=True)",
        "# index_list = range(len(df_g))",
        "step = min(cell_count // 2, len(df_g) - cell_count)",
        "step = max(step, 1)",
        "id_col_count = 0",
        "for i in range(0, len(df_g), step):",
        "# indexes = [i] + list(np.random.choice([j for j in index_list if j!=i],cell_count-1, replace=False))",
        "# indexes = range(i,i+cell_count)",
        "# print(indexes,i,len(df_g),index_list)",
        "res_tmp = df_g.iloc[i:i + cell_count]  # .copy()",
        "# if len(res_tmp) == cell_count:",
        "res_tmp.loc[:, id_col] = id_col_count",
        "id_col_count += 1",
        "res.append(res_tmp)",
        "",
        "random_cnt = int(len(df_g) // cell_count * expand_ratio)",
        "random_cnt = min(random_cnt, max_random_cnt)  # todo",
        "if random_cnt > 0:",
        "for i in range(random_cnt):",
        "res_tmp = df_g.sample(n=cell_count).reset_index(drop=True)",
        "res_tmp.loc[:, id_col] = id_col_count",
        "id_col_count += 1",
        "res.append(res_tmp)",
        "",
        "res = pd.concat(res).reset_index(drop=True)",
        "sort_flag = range(len(res))",
        "np.random.shuffle(sort_flag)",
        "res.loc[res['cell_type'] == 0, 'sort_flag'] = 0",
        "res = res.sort_values(by=['id', id_col, 'cell_type', 'rank'], ascending=True)",
        "res = res.groupby(by=['id', id_col, 'fold_flag', 'cell_count'], as_index=False, sort=False)[",
        "['cell_id', 'cell_type', 'source', 'rank']].agg(list)",
        "return res",
        "print(tmp1.shape,tmp2.shape)",
        "print(df_g.columns)",
        ".copy()",
        "if len(res_tmp) == cell_count:",
        "todo"
    ],
    "docstrings": [],
    "functions": [
        "get_data",
        "read_json_data",
        "preprocess_df",
        "preprocess_text",
        "get_truncated_df"
    ],
    "classes": []
}