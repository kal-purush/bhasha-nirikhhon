{
    "identifiers": [
        "datetime",
        "datetime",
        "now",
        "checkGoal",
        "datetime",
        "datetime",
        "now",
        "mission_xml",
        "mission_xml",
        "mission_type",
        "mission_type",
        "mission_seed",
        "mission_seed",
        "student_guid",
        "student_guid",
        "action_count",
        "reward",
        "datetime_",
        "reward_cumulative",
        "reward",
        "reward_cumulative",
        "round",
        "abs",
        "reward_cumulative",
        "abs",
        "round",
        "reward_cumulative",
        "x",
        "x",
        "rem_goal",
        "x",
        "rem_timeout",
        "x",
        "mission_type",
        "mission_seed",
        "agent_type",
        "mission_type",
        "agent_type",
        "lower",
        "agent_type",
        "lower",
        "random",
        "seed",
        "mission_seed",
        "abs",
        "round",
        "random",
        "gauss",
        "round",
        "abs",
        "random",
        "gauss",
        "round",
        "abs",
        "random",
        "gauss",
        "round",
        "random",
        "randrange",
        "random",
        "randrange",
        "nir",
        "get",
        "mission_type",
        "mission_seed",
        "msize",
        "get",
        "mission_type",
        "msize",
        "get",
        "mission_type",
        "n_intermediate_rewards",
        "mtimeout",
        "get",
        "mission_type_tmp",
        "reward_waypoint",
        "reward_sendcommand",
        "reward_goal",
        "reward_timeout",
        "xml_str",
        "msize",
        "get",
        "mission_type",
        "reward_goal",
        "reward_waypoint",
        "n_intermediate_rewards",
        "reward_timeout",
        "reward_sendcommand",
        "mtimeout",
        "get",
        "mission_type_tmp",
        "agent_host",
        "port",
        "agent_type",
        "mission_type",
        "mission_seed",
        "movement_type",
        "GetMissionInstance",
        "mission_type",
        "mission_seed",
        "agent_type",
        "MalmoPython",
        "MissionSpec",
        "mission_xml",
        "my_mission",
        "forceWorldReset",
        "my_mission",
        "setModeToCreative",
        "agent_type",
        "lower",
        "msize",
        "my_mission",
        "observeGrid",
        "n",
        "n",
        "n",
        "n",
        "my_mission",
        "requestVideoWithDepth",
        "agent_type",
        "lower",
        "msize",
        "my_mission",
        "observeGrid",
        "n",
        "n",
        "n",
        "n",
        "my_mission",
        "requestVideo",
        "agent_type",
        "lower",
        "my_mission",
        "observeGrid",
        "n",
        "n",
        "n",
        "n",
        "my_mission",
        "requestVideoWithDepth",
        "agent_type",
        "lower",
        "my_mission",
        "observeGrid",
        "n",
        "n",
        "n",
        "n",
        "my_mission",
        "requestVideoWithDepth",
        "my_mission",
        "observeGrid",
        "n",
        "n",
        "n",
        "n",
        "my_mission",
        "requestVideoWithDepth",
        "movement_type",
        "lower",
        "my_mission",
        "allowAllAbsoluteMovementCommands",
        "movement_type",
        "lower",
        "my_mission",
        "allowContinuousMovementCommand",
        "my_mission",
        "allowContinuousMovementCommand",
        "my_mission",
        "allowContinuousMovementCommand",
        "my_mission",
        "allowContinuousMovementCommand",
        "my_mission",
        "allowContinuousMovementCommand",
        "movement_type",
        "lower",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "allowDiscreteMovementCommand",
        "my_mission",
        "getAsXML",
        "MalmoPython",
        "MissionRecordSpec",
        "my_mission_record",
        "recordRewards",
        "my_mission_record",
        "recordMP4",
        "retry",
        "max_retries",
        "agent_host",
        "startMission",
        "my_mission",
        "my_mission_record",
        "RuntimeError",
        "e",
        "retry",
        "max_retries",
        "e",
        "exit",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "state_t",
        "has_mission_begun",
        "sys",
        "stdout",
        "write",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "error",
        "state_t",
        "errors",
        "error",
        "text",
        "final_xml",
        "reward_goal",
        "reward_intermediate",
        "n_intermediate_rewards",
        "reward_timeout",
        "reward_sendcommand",
        "timeout",
        "node_colors",
        "G",
        "locations",
        "node_labels",
        "node_label_pos",
        "edge_labels",
        "plt",
        "figure",
        "figsize",
        "nx",
        "draw",
        "G",
        "pos",
        "locations",
        "node_color",
        "node_colors",
        "node",
        "node",
        "G",
        "nodes",
        "nx",
        "draw_networkx_labels",
        "G",
        "pos",
        "node_label_pos",
        "labels",
        "node_labels",
        "font_size",
        "label",
        "set_bbox",
        "facecolor",
        "edgecolor",
        "label",
        "node_label_handles",
        "values",
        "nx",
        "draw_networkx_edge_labels",
        "G",
        "pos",
        "locations",
        "edge_labels",
        "edge_labels",
        "font_size",
        "lines",
        "Line2D",
        "color",
        "marker",
        "markersize",
        "markerfacecolor",
        "lines",
        "Line2D",
        "color",
        "marker",
        "markersize",
        "markerfacecolor",
        "lines",
        "Line2D",
        "color",
        "marker",
        "markersize",
        "markerfacecolor",
        "lines",
        "Line2D",
        "color",
        "marker",
        "markersize",
        "markerfacecolor",
        "lines",
        "Line2D",
        "color",
        "marker",
        "markersize",
        "markerfacecolor",
        "plt",
        "legend",
        "white_circle",
        "orange_circle",
        "red_circle",
        "gray_circle",
        "green_circle",
        "numpoints",
        "prop",
        "loc",
        "plt",
        "show",
        "problem",
        "solution",
        "initial_node_colors",
        "initial_node_colors",
        "problem",
        "initial",
        "node",
        "solution",
        "final_colors",
        "user_input",
        "algorithm",
        "problem",
        "user_input",
        "iteration",
        "show_map",
        "all_node_colors",
        "iteration",
        "Visualize",
        "Visualize",
        "all_node_colors",
        "algorithm",
        "problem",
        "node",
        "solution",
        "all_node_colors",
        "append",
        "final_path_colors",
        "problem",
        "solution",
        "len",
        "all_node_colors",
        "i",
        "slider",
        "max",
        "i",
        "widgets",
        "IntSlider",
        "min",
        "max",
        "step",
        "value",
        "widgets",
        "interactive",
        "slider_callback",
        "iteration",
        "slider",
        "display",
        "slider_visual",
        "widgets",
        "ToggleButton",
        "value",
        "widgets",
        "interactive",
        "visualize_callback",
        "Visualize",
        "button",
        "display",
        "button_visual",
        "agent_host",
        "agent_port",
        "mission_type",
        "mission_seed",
        "solution_report",
        "state_space_graph",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "solution_report",
        "solution_report",
        "setMissionType",
        "mission_type",
        "solution_report",
        "setMissionSeed",
        "mission_seed",
        "idx_requested_action",
        "noise_level",
        "len",
        "AGENT_ALLOWED_ACTIONS",
        "noise_level",
        "n",
        "np",
        "ones",
        "n",
        "noise_level",
        "np",
        "random",
        "choice",
        "n",
        "p",
        "pp",
        "flatten",
        "AGENT_ALLOWED_ACTIONS",
        "idx_actual",
        "agent_host",
        "sendCommand",
        "actual_action",
        "actual_action",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "init_mission",
        "agent_host",
        "agent_port",
        "AGENT_NAME",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "solution_report",
        "setMissionXML",
        "mission_xml",
        "time",
        "sleep",
        "solution_report",
        "start",
        "agent_host",
        "setObservationsPolicy",
        "MalmoPython",
        "ObservationsPolicy",
        "LATEST_OBSERVATION_ONLY",
        "agent_host",
        "setVideoPolicy",
        "MalmoPython",
        "VideoPolicy",
        "LATEST_FRAME_ONLY",
        "agent_host",
        "setRewardsPolicy",
        "MalmoPython",
        "RewardsPolicy",
        "KEEP_ALL_REWARDS",
        "agent_host",
        "getWorldState",
        "state_t",
        "is_mission_running",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "reward_t",
        "state_t",
        "rewards",
        "reward_t",
        "getValue",
        "reward_cumulative",
        "reward_t",
        "getValue",
        "solution_report",
        "addReward",
        "reward_t",
        "getValue",
        "datetime",
        "datetime",
        "now",
        "reward_cumulative",
        "error",
        "state_t",
        "errors",
        "error",
        "text",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "observations",
        "text",
        "json",
        "loads",
        "msg",
        "oracle",
        "get",
        "grid",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "state_t",
        "number_of_video_frames_since_last_state",
        "state_t",
        "video_frames",
        "frame",
        "state_t",
        "number_of_video_frames_since_last_state",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "number_of_rewards_since_last_state",
        "xpos",
        "ypos",
        "zpos",
        "yaw",
        "pitch",
        "agent_host",
        "agent_port",
        "mission_type",
        "mission_seed",
        "solution_report",
        "state_space",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "state_space",
        "solution_report",
        "solution_report",
        "setMissionType",
        "mission_type",
        "solution_report",
        "setMissionSeed",
        "mission_seed",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "init_mission",
        "agent_host",
        "agent_port",
        "AGENT_NAME",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "solution_report",
        "setMissionXML",
        "mission_xml",
        "time",
        "sleep",
        "solution_report",
        "start",
        "agent_host",
        "setObservationsPolicy",
        "MalmoPython",
        "ObservationsPolicy",
        "LATEST_OBSERVATION_ONLY",
        "agent_host",
        "setVideoPolicy",
        "MalmoPython",
        "VideoPolicy",
        "LATEST_FRAME_ONLY",
        "agent_host",
        "setRewardsPolicy",
        "MalmoPython",
        "RewardsPolicy",
        "KEEP_ALL_REWARDS",
        "UndirectedGraph",
        "state_space",
        "state_actions",
        "nx",
        "Graph",
        "n",
        "p",
        "state_space",
        "state_locations",
        "items",
        "G",
        "add_node",
        "n",
        "n",
        "node_colors",
        "k",
        "v",
        "v",
        "k",
        "v",
        "state_space",
        "state_locations",
        "items",
        "node",
        "maze_map",
        "nodes",
        "maze_map",
        "get",
        "node",
        "connection",
        "connections",
        "keys",
        "connections",
        "connection",
        "G",
        "add_edge",
        "node",
        "connection",
        "node",
        "connection",
        "distance",
        "state_space",
        "start_loc",
        "state_space",
        "start_loc",
        "state_space",
        "goal_loc",
        "state_space",
        "goal_loc",
        "GraphProblem",
        "initial_state",
        "goal_state",
        "maze_map",
        "maze_problem",
        "initial",
        "maze_problem",
        "goal",
        "astar_search",
        "problem",
        "maze_problem",
        "h",
        "node",
        "node",
        "parent",
        "solution_path",
        "append",
        "cnode",
        "cnode",
        "state",
        "initial_state",
        "cnode",
        "parent",
        "solution_path",
        "append",
        "cnode",
        "solution_path",
        "solution_path",
        "deepcopy",
        "solution_path",
        "agent_host",
        "getWorldState",
        "state_space",
        "start_loc",
        "state_space",
        "start_loc",
        "state_t",
        "is_mission_running",
        "solution_path_local",
        "pop",
        "target_node",
        "state",
        "state_space",
        "state_locations",
        "get",
        "target_node",
        "state",
        "xz_new",
        "xz_new",
        "x_old",
        "x_new",
        "z_old",
        "z_new",
        "x_new",
        "x_old",
        "x_new",
        "x_old",
        "z_new",
        "z_old",
        "agent_host",
        "sendCommand",
        "command",
        "x_new",
        "z_new",
        "RuntimeError",
        "e",
        "e",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "reward_t",
        "state_t",
        "rewards",
        "reward_t",
        "getValue",
        "reward_cumulative",
        "reward_t",
        "getValue",
        "solution_report",
        "addReward",
        "reward_t",
        "getValue",
        "datetime",
        "datetime",
        "now",
        "reward_cumulative",
        "error",
        "state_t",
        "errors",
        "error",
        "text",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "observations",
        "text",
        "json",
        "loads",
        "msg",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "state_t",
        "number_of_video_frames_since_last_state",
        "state_t",
        "video_frames",
        "state_t",
        "number_of_video_frames_since_last_state",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "number_of_rewards_since_last_state",
        "xpos",
        "ypos",
        "zpos",
        "yaw",
        "pitch",
        "problem",
        "h",
        "memoize",
        "h",
        "problem",
        "h",
        "best_first_graph_search",
        "problem",
        "n",
        "n",
        "path_cost",
        "h",
        "n",
        "iterations",
        "all_node_colors",
        "node",
        "problem",
        "f",
        "initial_node_colors",
        "memoize",
        "f",
        "Node",
        "problem",
        "initial",
        "node",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "problem",
        "goal_test",
        "node",
        "state",
        "node",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "iterations",
        "all_node_colors",
        "node",
        "PriorityQueue",
        "min",
        "f",
        "frontier",
        "append",
        "node",
        "node",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "frontier",
        "frontier",
        "pop",
        "node",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "problem",
        "goal_test",
        "node",
        "state",
        "node",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "iterations",
        "all_node_colors",
        "node",
        "explored",
        "add",
        "node",
        "state",
        "child",
        "node",
        "expand",
        "problem",
        "child",
        "state",
        "explored",
        "child",
        "frontier",
        "frontier",
        "append",
        "child",
        "child",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "child",
        "frontier",
        "frontier",
        "child",
        "f",
        "child",
        "f",
        "incumbent",
        "frontier",
        "incumbent",
        "frontier",
        "append",
        "child",
        "child",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "node",
        "state",
        "iterations",
        "all_node_colors",
        "append",
        "node_colors",
        "agent_host",
        "agent_port",
        "mission_type",
        "mission_seed",
        "solution_report",
        "state_space_graph",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "state_space",
        "solution_report",
        "solution_report",
        "setMissionType",
        "mission_type",
        "solution_report",
        "setMissionSeed",
        "mission_seed",
        "idx_request_action",
        "noise_level",
        "len",
        "AGENT_ALLOWED_ACTIONS",
        "noise_level",
        "n",
        "np",
        "ones",
        "n",
        "noise_level",
        "np",
        "random",
        "choice",
        "n",
        "p",
        "pp",
        "flatten",
        "AGENT_ALLOWED_ACTIONS",
        "idx_actual",
        "agent_host",
        "sendCommand",
        "actual_action",
        "actual_action",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "init_mission",
        "agent_host",
        "agent_port",
        "AGENT_NAME",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "solution_report",
        "setMissionXML",
        "mission_xml",
        "agent_host",
        "setObservationsPolicy",
        "MalmoPython",
        "ObservationsPolicy",
        "LATEST_OBSERVATION_ONLY",
        "agent_host",
        "setVideoPolicy",
        "MalmoPython",
        "VideoPolicy",
        "LATEST_FRAME_ONLY",
        "agent_host",
        "setRewardsPolicy",
        "MalmoPython",
        "RewardsPolicy",
        "KEEP_ALL_REWARDS",
        "agent_host",
        "getWorldState",
        "state_t",
        "is_mission_running",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "state_t",
        "is_mission_running",
        "random",
        "randint",
        "AGENT_ALLOWED_ACTIONS",
        "actionIdx",
        "__ExecuteActionForRandomAgentWithNoisyTransitionModel__",
        "actionIdx",
        "actual_action",
        "reward_t",
        "state_t",
        "rewards",
        "reward_cumulative",
        "reward_t",
        "getValue",
        "solution_report",
        "addReward",
        "reward_t",
        "getValue",
        "datetime",
        "datetime",
        "now",
        "reward_t",
        "getValue",
        "reward_cumulative",
        "error",
        "state_t",
        "errors",
        "error",
        "text",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "observations",
        "text",
        "json",
        "loads",
        "msg",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "oracle",
        "get",
        "state_t",
        "number_of_video_frames_since_last_state",
        "state_t",
        "video_frames",
        "state_t",
        "number_of_video_frames_since_last_state",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "number_of_rewards_since_last_state",
        "xpos",
        "ypos",
        "zpos",
        "yaw",
        "pitch",
        "reward_cumulative",
        "agent_host",
        "agent_port",
        "mission_type",
        "mission_seed",
        "solution_report",
        "state_space_graph",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "StateSpace",
        "solution_report",
        "solution_report",
        "setMissionType",
        "mission_type",
        "solution_report",
        "setMissionSeed",
        "mission_seed",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "init_mission",
        "agent_host",
        "agent_port",
        "AGENT_NAME",
        "mission_type",
        "mission_seed",
        "AGENT_MOVEMENT_TYPE",
        "solution_report",
        "setMissionXML",
        "mission_xml",
        "agent_host",
        "setObservationsPolicy",
        "MalmoPython",
        "ObservationsPolicy",
        "LATEST_OBSERVATION_ONLY",
        "agent_host",
        "setVideoPolicy",
        "MalmoPython",
        "VideoPolicy",
        "LATEST_FRAME_ONLY",
        "agent_host",
        "setRewardsPolicy",
        "MalmoPython",
        "RewardsPolicy",
        "KEEP_ALL_REWARDS",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "state_t",
        "is_mission_running",
        "agent_host",
        "sendCommand",
        "time",
        "sleep",
        "agent_host",
        "sendCommand",
        "time",
        "sleep",
        "agent_host",
        "getWorldState",
        "state_t",
        "number_of_observations_since_last_state",
        "state_t",
        "observations",
        "text",
        "json",
        "loads",
        "msg",
        "oracle_and_internal",
        "get",
        "oracle_and_internal",
        "get",
        "oracle_and_internal",
        "get",
        "oracle_and_internal",
        "get",
        "oracle_and_internal",
        "get",
        "oracle_and_internal",
        "get",
        "grid",
        "full_state_map_raw",
        "replace",
        "full_state_map_raw",
        "replace",
        "full_state_map_raw",
        "replace",
        "full_state_map_raw",
        "replace",
        "full_state_map_raw",
        "replace",
        "full_state_map_raw",
        "split",
        "aa",
        "word",
        "vocs",
        "i",
        "len",
        "aa",
        "aa",
        "i",
        "word",
        "vocs",
        "index",
        "word",
        "np",
        "asarray",
        "aa",
        "math",
        "sqrt",
        "X",
        "size",
        "np",
        "reshape",
        "X",
        "nn",
        "nn",
        "DO_PLOT",
        "yaw",
        "plt",
        "figure",
        "plt",
        "imshow",
        "X",
        "astype",
        "interpolation",
        "plt",
        "show",
        "vocs",
        "index",
        "vocs",
        "index",
        "vocs",
        "index",
        "vocs",
        "index",
        "math",
        "floor",
        "xpos",
        "math",
        "floor",
        "zpos",
        "i_z",
        "len",
        "X",
        "j_x",
        "len",
        "X",
        "X",
        "i_z",
        "j_x",
        "state_impossible",
        "X",
        "i_z",
        "j_x",
        "state_wall",
        "j_x",
        "offset_x",
        "i_z",
        "offset_z",
        "j_x",
        "offset_x",
        "i_z",
        "offset_z",
        "X",
        "i_z",
        "j_x",
        "state_initial",
        "state_id",
        "state_space_locations",
        "state_id",
        "X",
        "i_z",
        "j_x",
        "state_goal",
        "state_id",
        "state_space_locations",
        "state_id",
        "state_id",
        "state_space_locations",
        "action",
        "actions",
        "actions",
        "get",
        "action",
        "state_space_locations",
        "get",
        "state_id",
        "state_loc",
        "delta",
        "state_loc",
        "delta",
        "state_loc_post_action",
        "state_loc_post_action",
        "state_space_locations",
        "get",
        "state_id_post_action",
        "possible_states",
        "agent_host",
        "sendCommand",
        "time",
        "sleep",
        "state_space",
        "state_space_actions",
        "state_space",
        "state_space_locations",
        "state_space",
        "state_initial_id",
        "state_space",
        "loc_start",
        "state_space",
        "state_goal_id",
        "state_space",
        "loc_goal",
        "reward_goal",
        "state_space",
        "state_space_rewards",
        "state_space",
        "n_intermediate_rewards",
        "state_space",
        "reward_timeout",
        "state_space",
        "timeout",
        "state_space",
        "reward_sendcommand",
        "os",
        "sys",
        "time",
        "random",
        "random",
        "shuffle",
        "json",
        "argparse",
        "pickle",
        "datetime",
        "math",
        "numpy",
        "np",
        "copy",
        "deepcopy",
        "hashlib",
        "numpy",
        "np",
        "matplotlib",
        "pyplot",
        "plt",
        "matplotlib",
        "image",
        "mpimg",
        "networkx",
        "nx",
        "matplotlib",
        "lines",
        "argparse",
        "ArgumentParser",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_AGENT_NAME",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_MISSION_TYPE",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_MISSION_SEED_MAX",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_REPEATS",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_STUDENT_GUID",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_MALMO_PATH",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_PORT",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_AIMA_PATH",
        "parser",
        "add_argument",
        "help",
        "DEFAULT_SAVE_PATH",
        "parser",
        "parse_args",
        "args",
        "os",
        "getcwd",
        "sys",
        "version",
        "args",
        "malmopath",
        "os",
        "environ",
        "os",
        "environ",
        "sys",
        "path",
        "append",
        "DEFAULT_AIMA_PATH",
        "search",
        "args",
        "malmopath",
        "sys",
        "path",
        "append",
        "args",
        "malmopath",
        "MalmoPython",
        "args",
        "agentname",
        "args",
        "missionseedmax",
        "args",
        "nrepeats",
        "args",
        "missiontype",
        "args",
        "studentguid",
        "args",
        "malmopath",
        "args",
        "malmoport",
        "cmd",
        "MalmoPython",
        "AgentHost",
        "i_training_seed",
        "args",
        "missionseedmax",
        "args",
        "agentname",
        "lower",
        "SolutionReport",
        "AgentHelper",
        "agent_host",
        "args",
        "malmoport",
        "args",
        "missiontype",
        "i_training_seed",
        "helper_solution_report",
        "helper_agent",
        "run_agent",
        "i_rep",
        "args",
        "nrepeats",
        "SolutionReport",
        "solution_report",
        "setStudentGuid",
        "args",
        "studentguid",
        "args",
        "agentname",
        "args",
        "missiontype",
        "i_training_seed",
        "args",
        "agentname",
        "helper_agent",
        "deepcopy",
        "helper_agent",
        "state_space",
        "eval",
        "agent_name",
        "solution_report",
        "start",
        "agent_to_be_evaluated",
        "run_agent",
        "solution_report",
        "stop",
        "solution_report",
        "reward_cumulative",
        "solution_report",
        "end_datetime_wallclock",
        "solution_report",
        "start_datetime_wallclock",
        "total_seconds",
        "solution_report",
        "action_count",
        "solution_report",
        "is_goal",
        "solution_report",
        "is_timeout",
        "args",
        "resultpath",
        "args",
        "studentguid",
        "agent_name",
        "args",
        "missiontype",
        "i_training_seed",
        "i_rep",
        "open",
        "fn_result",
        "pickle",
        "dump",
        "agent_to_be_evaluated",
        "solution_report",
        "foutput",
        "foutput",
        "close",
        "time",
        "sleep"
    ],
    "literals": [
        "'Unknown'",
        "'small'",
        "'medium'",
        "'large'",
        "'small'",
        "'medium'",
        "'large'",
        "'helper'",
        "'small'",
        "'medium'",
        "'large'",
        "'helper'",
        "'Unknown'",
        "'Unknown'",
        "'Continuous'",
        "'random'",
        "'grid'",
        "'simple'",
        "'grid'",
        "'realistic'",
        "'grid'",
        "'helper'",
        "'grid'",
        "'grid'",
        "'absolute'",
        "'continuous'",
        "'move'",
        "'strafe'",
        "'pitch'",
        "'turn'",
        "'crouch'",
        "'discrete'",
        "'turn'",
        "'move'",
        "'movenorth'",
        "'moveeast'",
        "'movesouth'",
        "'movewest'",
        "'look'",
        "'tmp'",
        "\".tgz\"",
        "\"Error starting mission:\"",
        "\"Waiting for the mission to start \"",
        "\".\"",
        "\"Error:\"",
        "\"Mission started (xml returned)... \"",
        "'white'",
        "'none'",
        "\"white\"",
        "'o'",
        "\"white\"",
        "\"white\"",
        "'o'",
        "\"orange\"",
        "\"white\"",
        "'o'",
        "\"red\"",
        "\"white\"",
        "'o'",
        "\"gray\"",
        "\"white\"",
        "'o'",
        "\"green\"",
        "'Un-explored'",
        "'Frontier'",
        "'Currently exploring'",
        "'Explored'",
        "'Solution path'",
        "'size'",
        "\"returns a node_colors dict of the final path provided the problem and solution\"",
        "\"green\"",
        "\"green\"",
        "'Discrete'",
        "'Realistic'",
        "\"movenorth 1\"",
        "\"movesouth 1\"",
        "\"movewest 1\"",
        "\"moveeast 1\"",
        "'Generate and load the '",
        "' mission with seed '",
        "' allowing '",
        "' movements'",
        "\"Reward_t:\"",
        "\"Cummulative reward so far:\"",
        "\"Error:\"",
        "u'grid'",
        "u'XPos'",
        "u'ZPos'",
        "u'YPos'",
        "u'Yaw'",
        "u'Pitch'",
        "\"Percept: video,observations,rewards received:\"",
        "\"\\tcoordinates (x,y,z,yaw,pitch):\"",
        "\" \"",
        "\" \"",
        "\" \"",
        "\" \"",
        "'Discrete'",
        "'Simple'",
        "'Generate and load the '",
        "' mission with seed '",
        "' allowing '",
        "' movements'",
        "\"white\"",
        "\"Done creating the graph object\"",
        "'S_'",
        "'_'",
        "'S_'",
        "'_'",
        "\"Initial state:\"",
        "\"Goal state:\"",
        "\"----------------------------------------\"",
        "\"Identified goal state:\"",
        "\"----------------------------------------\"",
        "\"Solution trace:\"",
        "\"----------------------------------------\"",
        "\"Final solution path:\"",
        "\"Action_t: Goto state \"",
        "\"moveeast\"",
        "\"movewest\"",
        "\"movesouth\"",
        "\"movenorth\"",
        "\" 1\"",
        "\"Failed to send command:\"",
        "\"Reward_t:\"",
        "\"Cummulative reward so far:\"",
        "\"Error:\"",
        "u'grid'",
        "u'XPos'",
        "u'ZPos'",
        "u'YPos'",
        "u'Yaw'",
        "u'Pitch'",
        "\"Percept: video,observations,rewards received:\"",
        "\"\\tcoordinates (x,y,z,yaw,pitch):\"",
        "\" \"",
        "\" \"",
        "\" \"",
        "\" \"",
        "'h'",
        "'f'",
        "\"red\"",
        "\"green\"",
        "\"orange\"",
        "\"red\"",
        "\"green\"",
        "\"orange\"",
        "\"orange\"",
        "\"gray\"",
        "'Discrete'",
        "'Random'",
        "\"movenorth 1\"",
        "\"movesouth 1\"",
        "\"movewest 1\"",
        "\"moveeast 1\"",
        "'Generate and load the '",
        "' mission with seed '",
        "' allowing '",
        "' movements'",
        "\"Requested Action:\"",
        "\"Actual Action:\"",
        "\"Reward_t:\"",
        "\"Cummulative reward so far:\"",
        "\"Error:\"",
        "u'grid'",
        "u'XPos'",
        "u'ZPos'",
        "u'YPos'",
        "u'Yaw'",
        "u'Pitch'",
        "\"Percept: video,observations,rewards received:\"",
        "\"\\tcoordinates (x,y,z,yaw,pitch):\"",
        "\" \"",
        "\" \"",
        "\" \"",
        "\" \"",
        "\"Summary:\"",
        "\"Cumulative reward = \"",
        "'Helper'",
        "'Absolute'",
        "'Generate and load the '",
        "' mission with seed '",
        "' allowing '",
        "' movements'",
        "\"setPitch 20\"",
        "\"setYaw -90\"",
        "u'grid'",
        "u'XPos'",
        "u'ZPos'",
        "u'YPos'",
        "u'Yaw'",
        "u'Pitch'",
        "\"[\"",
        "\"\"",
        "\"]\"",
        "\"\"",
        "\"u'\"",
        "\"\"",
        "\"'\"",
        "\"\"",
        "\" \"",
        "\"\"",
        "\",\"",
        "'float'",
        "'none'",
        "\"stained_hardened_clay\"",
        "\"stone\"",
        "\"emerald_block\"",
        "\"redstone_block\"",
        "\"S_\"",
        "\"_\"",
        "\"west\"",
        "\"east\"",
        "\"north\"",
        "\"south\"",
        "\"S_\"",
        "\"_\"",
        "\"tp \"",
        "\" \"",
        "\" \"",
        "\"__main__\"",
        "'2140845p'",
        "'Realistic'",
        "'/Users/Antreas/Desktop/University_Of_Glasgow/Year_4/AI/Malmo-0.30.0-Mac-64bit_withBoost/'",
        "'/Users/Antreas/Desktop/University_Of_Glasgow/Year_4/AI/aima-python/'",
        "'small'",
        "'./results/'",
        "\"-a\"",
        "\"--agentname\"",
        "\"path for the malmo pyhton examples\"",
        "\"-t\"",
        "\"--missiontype\"",
        "\"mission type (small,medium,large)\"",
        "\"-s\"",
        "\"--missionseedmax\"",
        "\"maximum mission seed value (integer)\"",
        "\"-n\"",
        "\"--nrepeats\"",
        "\"repeat of a specific agent (if stochastic behavior)\"",
        "\"-g\"",
        "\"--studentguid\"",
        "\"student guid\"",
        "\"-p\"",
        "\"--malmopath\"",
        "\"path for the malmo pyhton examples\"",
        "\"-x\"",
        "\"--malmoport\"",
        "\"special port for the Minecraft client\"",
        "\"-o\"",
        "\"--aimapath\"",
        "\"path for the aima toolbox (optional)\"",
        "\"-r\"",
        "\"--resultpath\"",
        "\"the path where the results are saved\"",
        "\"Working dir:\"",
        "\"Python version:\"",
        "\"malmopath:\"",
        "\"JAVA_HOME:'\"",
        "\"JAVA_HOME\"",
        "\"'\"",
        "\"MALMO_XSD_PATH:'\"",
        "\"MALMO_XSD_PATH\"",
        "\"'\"",
        "'Add Malmo Python API/lib to the Python environment ['",
        "'/Python_Examples'",
        "']'",
        "'Python_Examples/'",
        "'Import the Malmo module...'",
        "'python myagents.py -a '",
        "' -s '",
        "' -n '",
        "' -t '",
        "' -g '",
        "' -p '",
        "' -x '",
        "'Instantiate an agent interface/api to Malmo'",
        "'simple'",
        "'Get state-space representation using a AgentHelper...[note in v0.30 there is now an faster way of getting the state-space ]'",
        "'Setup the performance log...'",
        "'Get an instance of the specific '",
        "' agent with the agent_host and load the '",
        "' mission with seed '",
        "'Agent'",
        "'(agent_host,args.malmoport,args.missiontype,i_training_seed,solution_report,state_space)'",
        "'Run the agent, time it and log the performance...'",
        "\"\\n---------------------------------------------\"",
        "\"| Solution Report Summary: \"",
        "\"|\\tCumulative reward = \"",
        "\"|\\tDuration (wallclock) = \"",
        "\"|\\tNumber of reported actions = \"",
        "\"|\\tFinal goal reached = \"",
        "\"|\\tTimeout = \"",
        "\"---------------------------------------------\\n\"",
        "'Save the solution report to a specific file for later analysis and reporting...'",
        "'solution_'",
        "'_'",
        "'_'",
        "'_'",
        "'_'",
        "'.pkl'",
        "'wb'",
        "'Sleep a sec to make sure the client is ready for next mission/agent variation...'",
        "\"------------------------------------------------------------------------------\\n\"",
        "\"Done\""
    ],
    "variables": [
        "start_datetime_wallclock",
        "end_datetime_wallclock",
        "action_count",
        "reward_cumulative",
        "mission_xml",
        "mission_type",
        "mission_seed",
        "student_guid",
        "mission_xml_as_expected",
        "is_goal",
        "is_timeout",
        "start_datetime_wallclock",
        "end_datetime_wallclock",
        "mission_xml",
        "mission_type",
        "mission_seed",
        "student_guid",
        "mission_xml_as_expected",
        "x",
        "rem_goal",
        "rem_timeout",
        "is_goal",
        "is_goal",
        "is_timeout",
        "is_timeout",
        "state_locations",
        "state_actions",
        "start_id",
        "goal_id",
        "start_loc",
        "goal_loc",
        "reward_states_n",
        "reward_states",
        "reward_sendcommand",
        "reward_timeout",
        "timeout",
        "msize",
        "mtimeout",
        "nir",
        "mission_type_tmp",
        "mission_type_tmp",
        "reward_goal",
        "reward_waypoint",
        "reward_timeout",
        "reward_sendcommand",
        "n_intermediate_rewards",
        "xml_str",
        "mission_xml",
        "msize",
        "reward_goal",
        "reward_intermediate",
        "n_intermediate_rewards",
        "reward_timeout",
        "reward_sendcommand",
        "timeout",
        "my_mission",
        "n",
        "n",
        "n",
        "n",
        "n",
        "final_xml",
        "my_mission_record",
        "max_retries",
        "state_t",
        "state_t",
        "node_label_handles",
        "white_circle",
        "orange_circle",
        "red_circle",
        "gray_circle",
        "green_circle",
        "final_colors",
        "final_colors",
        "final_colors",
        "node",
        "button",
        "value",
        "iterations",
        "all_node_colors",
        "node",
        "solution",
        "slider",
        "max",
        "slider",
        "value",
        "slider",
        "slider_visual",
        "button",
        "button_visual",
        "AGENT_MOVEMENT_TYPE",
        "AGENT_NAME",
        "AGENT_ALLOWED_ACTIONS",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "state_space",
        "solution_report",
        "n",
        "pp",
        "pp",
        "idx_request_action",
        "idx_actual",
        "actual_action",
        "mission_xml",
        "state_t",
        "reward_cumulative",
        "state_t",
        "xpos",
        "ypos",
        "zpos",
        "yaw",
        "pitch",
        "msg",
        "oracle",
        "grid",
        "xpos",
        "zpos",
        "ypos",
        "yaw",
        "pitch",
        "frame",
        "AGENT_MOVEMENT_TYPE",
        "AGENT_NAME",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "state_space",
        "solution_report",
        "mission_xml",
        "maze_map",
        "G",
        "node_labels",
        "node_colors",
        "node_labels",
        "n",
        "node_colors",
        "n",
        "initial_node_colors",
        "node_label_pos",
        "edge_labels",
        "connections",
        "distance",
        "edge_labels",
        "initial_state",
        "goal_state",
        "maze_problem",
        "all_node_colors",
        "iterations",
        "all_node_colors",
        "node",
        "solution_path",
        "cnode",
        "cnode",
        "solution_path_local",
        "reward_cumulative",
        "state_t",
        "x_old",
        "z_old",
        "target_node",
        "xz_new",
        "x_new",
        "z_new",
        "command",
        "command",
        "command",
        "command",
        "x_old",
        "z_old",
        "state_t",
        "xpos",
        "ypos",
        "zpos",
        "yaw",
        "pitch",
        "msg",
        "oracle",
        "grid",
        "xpos",
        "zpos",
        "ypos",
        "yaw",
        "pitch",
        "frame",
        "h",
        "iterations",
        "all_node_colors",
        "node",
        "iterations",
        "all_node_colors",
        "node_colors",
        "f",
        "node",
        "node_colors",
        "node_colors",
        "frontier",
        "node_colors",
        "explored",
        "node",
        "node_colors",
        "node_colors",
        "node_colors",
        "incumbent",
        "node_colors",
        "node_colors",
        "AGENT_MOVEMENT_TYPE",
        "AGENT_NAME",
        "AGENT_ALLOWED_ACTIONS",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "state_space",
        "solution_report",
        "n",
        "pp",
        "pp",
        "idx_request_action",
        "idx_actual",
        "actual_action",
        "mission_xml",
        "reward_goal",
        "reward_intermediate",
        "n_intermediate_rewards",
        "reward_timeout",
        "reward_sendcommand",
        "timeout",
        "reward_cumulative",
        "state_t",
        "state_t",
        "actionIdx",
        "actual_action",
        "xpos",
        "ypos",
        "zpos",
        "yaw",
        "pitch",
        "msg",
        "oracle",
        "grid",
        "xpos",
        "zpos",
        "ypos",
        "yaw",
        "pitch",
        "frame",
        "AGENT_NAME",
        "AGENT_MOVEMENT_TYPE",
        "DO_PLOT",
        "agent_host",
        "agent_port",
        "mission_seed",
        "mission_type",
        "state_space",
        "solution_report",
        "mission_xml",
        "reward_goal",
        "reward_intermediate",
        "n_intermediate_rewards",
        "reward_timeout",
        "reward_sendcommand",
        "timeout",
        "state_t",
        "state_t",
        "msg",
        "oracle_and_internal",
        "grid",
        "xpos",
        "zpos",
        "ypos",
        "yaw",
        "pitch",
        "full_state_map_raw",
        "full_state_map_raw",
        "full_state_map_raw",
        "full_state_map_raw",
        "full_state_map_raw",
        "full_state_map_raw",
        "aa",
        "vocs",
        "aa",
        "i",
        "X",
        "nn",
        "X",
        "imgplot",
        "state_wall",
        "state_impossible",
        "state_initial",
        "state_goal",
        "offset_x",
        "offset_z",
        "state_space_locations",
        "state_id",
        "state_space_locations",
        "state_id",
        "state_initial_id",
        "loc_start",
        "state_goal_id",
        "loc_goal",
        "actions",
        "state_space_actions",
        "possible_states",
        "delta",
        "state_loc",
        "state_loc_post_action",
        "state_id_post_action",
        "possible_states",
        "state_id_post_action",
        "state_space_actions",
        "state_id",
        "state_actions",
        "state_locations",
        "start_id",
        "start_loc",
        "goal_id",
        "goal_loc",
        "state_space_rewards",
        "state_space_rewards",
        "state_goal_id",
        "reward_states",
        "reward_states_n",
        "reward_timeout",
        "timeout",
        "reward_sendcommand",
        "state_space",
        "DEFAULT_STUDENT_GUID",
        "DEFAULT_AGENT_NAME",
        "DEFAULT_MALMO_PATH",
        "DEFAULT_AIMA_PATH",
        "DEFAULT_MISSION_TYPE",
        "DEFAULT_MISSION_SEED_MAX",
        "DEFAULT_REPEATS",
        "DEFAULT_PORT",
        "DEFAULT_SAVE_PATH",
        "parser",
        "args",
        "cmd",
        "agent_host",
        "helper_solution_report",
        "helper_agent",
        "helper_agent",
        "solution_report",
        "agent_name",
        "state_space",
        "state_space",
        "agent_to_be_evaluated",
        "fn_result",
        "foutput"
    ],
    "comments": [
        "----------------------------------------------------------------------------------------------------------------#",
        "Please do not modify this custom class !",
        "-- It is not included for simplifity --#",
        "-- It is not included for simplifity --#",
        "----------------------------------------------------------------------------------------------------------------#",
        "The id assigned to the start state",
        "The id assigned to the goal state",
        "The real word coordinates of the start state",
        "The real word coordinates of the goal state",
        "----------------------------------------------------------------------------------------------------------------#",
        "Size of the problem",
        "Timelimit",
        "Number of intermediate rewards",
        "-- Define various parameters used in the generation of the mission --#",
        "-- HINT: It is crucial that you understand the details of the mission, this will require some knowledge of uncertainty/probability and random variables --#",
        "How many intermediate rewards...?",
        "----------------------------------------------------------------------------------------------------------------#",
        "This function initialized the mission based on the input arguments",
        "-- Set up the mission via XML definition --#",
        "-- Enforce the specific restriction for the assessed exercise --#",
        "-- If you want a super agent, define one for you self  --#",
        "n=1 means local info only !",
        "-- Define a custom agent and add the sensors you need --#",
        "-- Add support for the specific movement type requested (and given the constraints of the assignment) --#",
        "-- See e.g. http://microsoft.github.io/malmo/0.17.0/Schemas/MissionHandlers.html   --#",
        "-- Get the resulting xml (and return in order to check that conditions match the report) --#",
        "Set up a recording for later inspection",
        "-- Attempt to start a mission --#",
        "-- Loop until mission starts: --#",
        "set the size of the plot",
        "draw the graph (both nodes and edges) with locations",
        "draw labels for nodes",
        "add a white bounding box behind the node labels",
        "add edge lables to the graph",
        "add a legend",
        "get initial node colors",
        "color all the nodes in solution and starting node to green",
        "don't show graph for the first time running the cell calling this function",
        "time.sleep(3.)",
        "--------------------------------------------------------------------------------------",
        "-- This class implements the Realistic Agent --#",
        "HINT: You can change this if you want {Absolute, Discrete, Continuous}",
        "NOTE: The Realistic can not know anything about the state_space a prior i !",
        "Python is call by reference !",
        "----------------------------------------------------------------------------------------------------------------#",
        "sample from the distribution of actions",
        "----------------------------------------------------------------------------------------------------------------#",
        "-- Load and init mission --#",
        "INSERT YOUR SOLUTION HERE (REWARDS MUST BE UPDATED IN THE solution_report)",
        "",
        "NOTICE: YOUR FINAL AGENT MUST MAKE USE OF THE FOLLOWING NOISY TRANSISION MODEL",
        "ExecuteActionForRealisticAgentWithNoisyTransitionModel(idx_requested_action, 0.05)",
        "FOR DEVELOPMENT IT IS RECOMMENDED TO FIST USE A NOISE FREE VERSION, i.e.",
        "ExecuteActionForRealisticAgentWithNoisyTransitionModel(idx_requested_action, 0.0)",
        "Wait 0.5 sec",
        "Get the world state",
        "Collect the number of rewards and add to reward_cumulative",
        "Note: Since we only observe the sensors and environment every a number of rewards may have accumulated in the buffer",
        "Check if anything went wrong along the way",
        "Handle the sensor input",
        "Has any Oracle-like and/or internal sensor observations come in?",
        "Get the detailed for the last observed state",
        "Parse the Oracle JSON",
        "Orcale",
        "",
        "GPS-like sensor",
        "Position in 2D plane, 1st axis",
        "Position in 2D plane, 2nd axis (yes Z!)",
        "Height as measured from surface! (yes Y!)",
        "Standard \"internal\" sensory inputs",
        "Yaw",
        "Pitch",
        "Vision",
        "Have any Vision percepts been registred ?",
        "-- Print some of the state information --#",
        "--------------------------------------------------------------------------------------",
        "-- This class implements the Simple Agent --#",
        "HINT: You can change this if you want {Absolute, Discrete, Continuous}",
        "Python calls by reference !",
        "-- Load and init mission --#",
        "-- Define local capabilities of the agent (sensors)--#",
        "INSERT: YOUR SOLUTION HERE (REMEMBER TO MANUALLY UPDATE THE solution_report DEPENDING ON YOU SOLUTION)",
        "initialise a graph",
        "add nodes from locations",
        "add nodes to node_labels",
        "node_colors to color nodes while exploring the map",
        "we'll save the initial node colors to a dict for later use",
        "positions for node labels",
        "spec the position of the labels relative to the nodes",
        "use this while labeling edges",
        "add edges between nodes in the map - UndirectedGraph defined in search.py",
        "add edges to the graph",
        "add distances to edge_labels",
        "show_map(node_colors, G, state_space.state_locations, node_labels, node_label_pos, edge_labels)",
        "-- Trace the solution --#",
        "show_map(final_path_colors(maze_problem, node.solution(), self.initial_node_colors), G, state_space.state_locations, node_labels, node_label_pos, edge_labels)",
        "Wait 0.5 sec",
        "Get the world state",
        "Collect the number of rewards and add to reward_cumulative",
        "Note: Since we only observe the sensors and environment every a number of rewards may have accumulated in the buffer",
        "Check if anything went wrong along the way",
        "Handle the sensor input",
        "Has any Oracle-like and/or internal sensor observations come in?",
        "Get the detailed for the last observed state",
        "Parse the Oracle JSON",
        "Orcale",
        "",
        "GPS-like sensor",
        "Position in 2D plane, 1st axis",
        "Position in 2D plane, 2nd axis (yes Z!)",
        "Height as measured from surface! (yes Y!)",
        "Standard \"internal\" sensory inputs",
        "Yaw",
        "Pitch",
        "Vision",
        "Have any Vision percepts been registred ?",
        "-- Print some of the state information --#",
        "we use these two variables at the time of visualisations",
        "--------------------------------------------------------------------------------------",
        "-- This class implements a basic, suboptimal Random Agent. The purpurpose is to provide a baseline for other agent to beat. --#",
        "Python makes call by reference !",
        "sample from the distrbution of actions",
        "-- Load and init mission --#",
        "-- Define local capabilities of the agent (sensors)--#",
        "Fix the randomness of the agent by seeding the random number generator",
        "Main loop:",
        "Wait 0.5 sec",
        "Get the world state",
        "Now try to execute the action givne a noisy transition model",
        "Collect the number of rewards and add to reward_cumulative",
        "Note: Since we only observe the sensors and environment every a number of rewards may have accumulated in the buffer",
        "Check if anything went wrong along the way",
        "Handle the sensor input",
        "Has any Oracle-like and/or internal sensor observations come in?",
        "Get the detailed for the last observed state",
        "Parse the Oracle JSON",
        "Orcale",
        "",
        "GPS-like sensor",
        "Position in 2D plane, 1st axis",
        "Position in 2D plane, 2nd axis (yes Z!)",
        "Height as measured from surface! (yes Y!)",
        "Standard \"internal\" sensory inputs",
        "Yaw",
        "Pitch",
        "Vision",
        "Have any Vision percepts been registred ?",
        "-- Print some of the state information --#",
        "--------------------------------------------------------------------------------------------",
        "Summary",
        "--------------------------------------------------------------------------------------",
        "-- This class implements a helper Agent for deriving the state-space representation ---#",
        "Note the helper needs absolute movements",
        "Python is call by reference !",
        "-- Load and init the Helper mission --#",
        "-- Define local capabilities of the agent (sensors)--#",
        "-- Get the state of the world along with internal agent state...--#",
        "-- Get a state-space model by observing the Orcale/GridObserver--#",
        "-- Make sure we look in the right direction when observing the surrounding (otherwise the coordinate system will rotated by the Yaw !) --#",
        "Look East (towards +x (east) and +z (south) on the right, i.e. a std x,y coordinate system) yaw=-90",
        "-- Basic map --#",
        "Get the details for the last observed state",
        "Parse the Oracle JSON",
        "-- Parste the JOSN string, Note there are better ways of doing this! --#",
        "Note: this matrix/table is index as z,x",
        "-- Visualize the discrete state-space --#",
        "-- Define the unique states available --#",
        "-- Extract state-space --#",
        "create a dict",
        "-- Generate state / action list --#",
        "First define the set of actions in the defined coordinate system",
        "-- Check if a specific action is possible --#",
        "-- Check if the new possible state is in the state_space, i.e., is accessible --#",
        "-- Add the possible actions for this state to the global dict --#",
        "-- Kill the agent/mission --#",
        "-- Save the info an instance of the StateSpace class --",
        "-- Reward location and values --#",
        "OPTIONAL: If you want to account for the intermediate rewards",
        "in the Random/Simple agent (or in your analysis) you can",
        "obtain ground-truth by teleporting with the tp command",
        "to all states and detect whether you recieve recieve a",
        "diamond or not using the inventory field in the oracle variable",
        "",
        "As default the state_space_rewards is just set to contain",
        "the goal state which is found above.",
        "",
        "HINT: You can insert your own code for getting",
        "the location of the intermediate rewards",
        "and populate the state_space_rewards dict",
        "with more information (optional).",
        "WARNING: This is a bit tricky, please consult tutors before starting",
        "-- Set the values in the state_space container --#",
        "-- End if observations --#",
        "--------------------------------------------------------------------------------------------",
        "-- The main entry point if you run the module as a script--#",
        "-- Define default arguments, in case you run the module as a script --#",
        "HINT: Currently choose between {Random,Simple, Realistic}",
        "HINT: Change this to your own path",
        "HINT: Change this to your own path, forward slash only, should be the 2.7 version from https://www.dropbox.com/s/vulnv2pkbv8q92u/aima-python_python_v27_r001.zip?dl=0) or for Python 3.x get it from https://github.com/aimacode/aima-python",
        "HINT: Choose between {small,medium,large}",
        "HINT: How many different instances of the given mission (i.e. maze layout)",
        "HINT: How many repetitions of the same maze layout",
        "-- Import required modules --#",
        "-- Define the commandline arguments required to run the agents from command line --#",
        "-- Display infor about the system --#",
        "-- Add the Malmo path  --#",
        "-- Import the Malmo Python wrapper/module --#",
        "-- OPTIONAL: Import the AIMA tools (for representing the state-space)--#",
        "print('Add AIMA lib to the Python environment ['+args.aimapath+']')",
        "sys.path.append(args.aimapath+'/')",
        "from search import *",
        "-- Create the command line string for convenience --#",
        "-- Run the agent a number of times (it only makes a difference if you agent has some random elemnt to it, initalizaiton, behavior, etc.) --#",
        "-- HINT: It is quite important that you understand the need for the loops  --#",
        "-- HINT: Depending on how you implement your realistic agent in terms of restarts and repeats, you may want to change the way the loops operate --#",
        "-- Itereate a few different layout of the same mission stype --#",
        "-- Observe the full state space a prior i (only allowed for the simple agent!) ? --#",
        "-- Repeat the same instance (size and seed) multiple times --#",
        "start the timer (may be overwritten in the agent to provide a fair comparison)",
        "stop the timer",
        "Save the solution information in a specific file, HiNT:  It can be loaded with pickle.load(output) with read permissions to the file",
        "You can reload the results for this instance using...",
        "finput = open(fn_result+'.pkl', 'rb')",
        "res =  pickle.load(finput)",
        "finput.close()"
    ],
    "docstrings": [
        "\"\"\" \n Artificial Inteligence (H)\n Assessed Exercise 2017/2018\n\n Tested with Python 2.7\n \n Solution Template (revision a)\n\"\"\"",
        "\"\"\" Constructor for the solution info \n        class which is used to store a summary of \n        the mission and agent performance \"\"\"",
        "\"\"\" This function is part of the final check\"\"\"",
        "\"\"\" This function checks if the goal has been reached based on the expected reward structure (will not work if you change the mission xml!)\"\"\"",
        "\"\"\" This is a datatype used to collect a number of important aspects of the environment\n    It can be constructed online or be created offline using the Helper Agent\n    \n    You are welcome to modify or change it as you see fit\n    \n    \"\"\"",
        "\"\"\" Constructor for the local state-space representation derived from the Orcale\"\"\"",
        "\"\"\" Creates a specific instance of a given mission type \"\"\"",
        "'''<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n        <Mission xmlns=\"http://ProjectMalmo.microsoft.com\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n          <About>\n            <Summary>Mission for assessed exercise 2016/2017 University of Glasgow</Summary>\n          </About>\n          <ServerSection>\n            <ServerInitialConditions>\n              <Time>\n                <StartTime>6000</StartTime>\n                <AllowPassageOfTime>false</AllowPassageOfTime>\n              </Time>\n              <Weather>clear</Weather>\n              <AllowSpawning>false</AllowSpawning>\n            </ServerInitialConditions>\n            <ServerHandlers>\n              <FlatWorldGenerator generatorString=\"3;7,220*1,5*3,2;3;,biome_1\" />      \n              <MazeDecorator>\n                <Seed>'''",
        "'''</Seed>\n                <SizeAndPosition length=\"'''",
        "'''\" width=\"'''",
        "'''\" yOrigin=\"215\" zOrigin=\"0\" xOrigin=\"0\" height=\"180\"/>        \n                <GapProbability variance=\"0.3\">0.2</GapProbability>        \n                <MaterialSeed>1</MaterialSeed>\n                <AllowDiagonalMovement>false</AllowDiagonalMovement>\n                <StartBlock fixedToEdge=\"true\" type=\"emerald_block\" height=\"1\"/>\n                <EndBlock fixedToEdge=\"false\" type=\"redstone_block\" height=\"12\"/>\n                <PathBlock type=\"glowstone\" colour=\"WHITE ORANGE MAGENTA LIGHT_BLUE YELLOW LIME PINK GRAY SILVER CYAN PURPLE BLUE BROWN GREEN RED BLACK\" height=\"1\"/>\n                <FloorBlock type=\"air\"/>\n                <SubgoalBlock type=\"glowstone\"/>        \n                <GapBlock type=\"stained_hardened_clay\" colour=\"WHITE ORANGE MAGENTA LIGHT_BLUE YELLOW LIME PINK GRAY SILVER CYAN PURPLE BLUE BROWN GREEN RED BLACK\" height=\"3\"/>\n                <Waypoints quantity=\"'''",
        "'''\">\n                  <WaypointItem type=\"diamond_block\"/>          \n                </Waypoints>      \n              </MazeDecorator>      \n              <ServerQuitFromTimeUp timeLimitMs=\"'''",
        "'''\" description=\"out_of_time\"/>\n              <ServerQuitWhenAnyAgentFinishes />\n            </ServerHandlers>\n          </ServerSection>\n          <AgentSection>\n            <Name>My Agent</Name>\n            <AgentStart>\n              <Placement x=\"0\" y=\"216\" z=\"90\"/> <!-- will be overwritten by MazeDecorator -->\n            </AgentStart>\n            <AgentHandlers>\n              <ObservationFromFullStats/>\n              <ObservationFromRecentCommands/>\n              <ObservationFromFullInventory/>\n              <RewardForCollectingItem>                \n                <Item reward=\"'''",
        "'''\" type=\"diamond_block\"/>        \n              </RewardForCollectingItem>\n              <RewardForSendingCommand reward=\"'''",
        "'''\"/>              \n              <RewardForMissionEnd rewardForDeath=\"-1000000\">\n                <Reward description=\"found_goal\" reward=\"'''",
        "'''\" />                \n                <Reward description=\"out_of_time\" reward=\"'''",
        "'''\" />\n              </RewardForMissionEnd>\n              <AgentQuitFromTouchingBlockType>\n                <Block type=\"redstone_block\" description=\"found_goal\" />\n              </AgentQuitFromTouchingBlockType>                           \n            </AgentHandlers>    \n          </AgentSection>\n        </Mission>'''",
        "\"\"\" Generate, and load the mission and return the agent host \"\"\"",
        "\"\"\" Constructor for the realistic agent \"\"\"",
        "\"\"\" Creates a well-defined transition model with a certain noise level \"\"\"",
        "\"\"\" Run the Realistic agent and log the performance and resource use \"\"\"",
        "\"\"\" Constructor for the simple agent \"\"\"",
        "\"\"\" Run the Simple agent and log the performance and resource use \"\"\"",
        "\"\"\"A* search is best-first graph search with f(n) = g(n)+h(n).\n        You need to specify the h function when you call astar_search, or\n        else in your Problem subclass.\"\"\"",
        "\"\"\"Search the nodes with the lowest f scores first.\n        You specify the function f(node) that you want to minimize; for example,\n        if f is a heuristic estimate to the goal, then we have greedy best\n        first search; if f is node.depth then we have breadth-first search.\n        There is a subtlety: the line \"f = memoize(f, 'f')\" means that the f\n        values will be cached on the nodes as they are computed. So after doing\n        a best first search you can examine the f values of the path returned.\"\"\"",
        "\"\"\" Constructor for the Random agent \"\"\"",
        "\"\"\" Creates a well-defined transition model with a certain noise level \"\"\"",
        "\"\"\" Run the Random agent and log the performance and resource use \"\"\"",
        "\"\"\" This agent determines the state space for use by the actual problem solving agent. Enabeling do_plot will allow you to visualize the results \"\"\"",
        "\"\"\" Constructor for the helper agent \"\"\"",
        "\"\"\" Run the Helper agent to get the state-space \"\"\""
    ],
    "functions": [
        "start",
        "stop",
        "setMissionXML",
        "setMissionType",
        "setMissionSeed",
        "setStudentGuid",
        "addAction",
        "addReward",
        "checkMissionXML",
        "checkGoal",
        "GetMissionInstance",
        "init_mission",
        "show_map",
        "final_path_colors",
        "display_visual",
        "slider_callback",
        "visualize_callback",
        "__ExecuteActionForRealisticAgentWithNoisyTransitionModel__",
        "run_agent",
        "run_agent",
        "astar_search",
        "best_first_graph_search",
        "__ExecuteActionForRandomAgentWithNoisyTransitionModel__",
        "run_agent",
        "run_agent"
    ],
    "classes": [
        "SolutionReport",
        "StateSpace",
        "AgentRealistic",
        "AgentSimple",
        "AgentRandom",
        "AgentHelper"
    ]
}