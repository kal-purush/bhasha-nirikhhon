{
    "identifiers": [
        "org",
        "apache",
        "spark",
        "SparkConf",
        "org",
        "apache",
        "spark",
        "SparkContext",
        "org",
        "apache",
        "spark",
        "api",
        "java",
        "JavaRDD",
        "org",
        "apache",
        "spark",
        "api",
        "java",
        "JavaSparkContext",
        "org",
        "datavec",
        "api",
        "records",
        "reader",
        "RecordReader",
        "org",
        "datavec",
        "api",
        "records",
        "reader",
        "impl",
        "csv",
        "CSVRecordReader",
        "org",
        "datavec",
        "api",
        "transform",
        "TransformProcess",
        "org",
        "datavec",
        "api",
        "transform",
        "condition",
        "ConditionOp",
        "org",
        "datavec",
        "api",
        "transform",
        "condition",
        "column",
        "CategoricalColumnCondition",
        "org",
        "datavec",
        "api",
        "transform",
        "condition",
        "column",
        "DoubleColumnCondition",
        "org",
        "datavec",
        "api",
        "transform",
        "ConditionFilter",
        "org",
        "datavec",
        "api",
        "transform",
        "schema",
        "Schema",
        "org",
        "datavec",
        "api",
        "transform",
        "transform",
        "condition",
        "ConditionalReplaceValueTransform",
        "org",
        "datavec",
        "api",
        "transform",
        "transform",
        "time",
        "DeriveColumnsFromTimeTransform",
        "org",
        "datavec",
        "api",
        "transform",
        "transform",
        "time",
        "StringToTimeTransform",
        "org",
        "datavec",
        "api",
        "util",
        "ClassPathResource",
        "org",
        "datavec",
        "api",
        "writable",
        "DoubleWritable",
        "org",
        "datavec",
        "api",
        "writable",
        "Writable",
        "org",
        "datavec",
        "spark",
        "functions",
        "RecordReaderFunction",
        "org",
        "datavec",
        "spark",
        "transform",
        "SparkTransformExecutor",
        "org",
        "datavec",
        "spark",
        "transform",
        "misc",
        "StringToWritablesFunction",
        "org",
        "datavec",
        "spark",
        "transform",
        "misc",
        "WritablesToStringFunction",
        "org",
        "joda",
        "time",
        "DateTimeFieldType",
        "org",
        "joda",
        "time",
        "DateTimeZone",
        "java",
        "util",
        "Arrays",
        "java",
        "util",
        "java",
        "util",
        "args",
        "inputDataSchema",
        "addColumnString",
        "addColumnsString",
        "addColumnInteger",
        "addColumnCategorical",
        "Arrays",
        "asList",
        "addColumnDouble",
        "addColumnCategorical",
        "Arrays",
        "asList",
        "build",
        "inputDataSchema",
        "inputDataSchema",
        "numColumns",
        "inputDataSchema",
        "getColumnNames",
        "inputDataSchema",
        "getColumnTypes",
        "tp",
        "inputDataSchema",
        "removeColumns",
        "ConditionOp",
        "NotInSet",
        "Arrays",
        "asList",
        "conditionalReplaceValueTransform",
        "ConditionOp",
        "LessThan",
        "stringToTimeTransform",
        "DateTimeZone",
        "UTC",
        "renameColumn",
        "transform",
        "addIntegerDerivedColumn",
        "DateTimeFieldType",
        "hourOfDay",
        "build",
        "removeColumns",
        "build",
        "outputSchema",
        "tp",
        "getFinalSchema",
        "outputSchema",
        "conf",
        "conf",
        "setMaster",
        "conf",
        "setAppName",
        "sc",
        "conf",
        "directory",
        "getFile",
        "getParent",
        "stringData",
        "sc",
        "textFile",
        "directory",
        "rr",
        "parsedInputData",
        "stringData",
        "rr",
        "exec",
        "processedData",
        "exec",
        "execute",
        "parsedInputData",
        "tp",
        "processedAsString",
        "processedData",
        "processedCollected",
        "processedAsString",
        "collect",
        "inputDataCollected",
        "stringData",
        "collect",
        "s",
        "inputDataCollected",
        "s",
        "s",
        "processedCollected",
        "s"
    ],
    "literals": [
        "\"DateTimeString\"",
        "\"CustomerID\"",
        "\"MerchantID\"",
        "\"NumItemsInTransaction\"",
        "\"MerchantCountryCode\"",
        "\"USA\"",
        "\"CAN\"",
        "\"FR\"",
        "\"MX\"",
        "\"TransactionAmountUSD\"",
        "\"FraudLabel\"",
        "\"Fraud\"",
        "\"Legit\"",
        "\"Input data schema details:\"",
        "\"\\n\\nOther information obtainable from schema:\"",
        "\"Number of columns: \"",
        "\"Column names: \"",
        "\"Column types: \"",
        "\"CustomerID\"",
        "\"MerchantID\"",
        "\"MerchantCountryCode\"",
        "\"USA\"",
        "\"MX\"",
        "\"TransactionAmountUSD\"",
        "\"TransactionAmountUSD\"",
        "\"DateTimeString\"",
        "\"YYYY-MM-DD HH:mm:ss.SSS\"",
        "\"DateTimeString\"",
        "\"DateTime\"",
        "\"DateTime\"",
        "\"HourOfDay\"",
        "\"DateTime\"",
        "\"\\n\\n\\nSchema after transforming data:\"",
        "\"local[*]\"",
        "\"DataVec Example\"",
        "\"exampledata.csv\"",
        "\",\"",
        "\"\\n\\n---- Original Data ----\"",
        "\"\\n\\n---- Processed Data ----\"",
        "\"\\n\\nDONE\""
    ],
    "variables": [],
    "comments": [
        "You can defined the directory of the path according to your convinience",
        "processedAsString.saveAsTextFile(\"file://your/local/save/path/here\");   //To save locally",
        "processedAsString.saveAsTextFile(\"hdfs://your/hdfs/save/path/here\");   //To save to hdfs"
    ],
    "docstrings": [],
    "functions": [
        "main"
    ],
    "classes": [
        "BasicDataVecExample"
    ]
}