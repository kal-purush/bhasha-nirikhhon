{
    "identifiers": [
        "org",
        "firstinspires",
        "ftc",
        "teamcode",
        "Autonomous",
        "OpenCV",
        "com",
        "qualcomm",
        "robotcore",
        "eventloop",
        "opmode",
        "LinearOpMode",
        "com",
        "qualcomm",
        "robotcore",
        "eventloop",
        "opmode",
        "TeleOp",
        "org",
        "firstinspires",
        "ftc",
        "robotcore",
        "external",
        "hardware",
        "camera",
        "WebcamName",
        "org",
        "opencv",
        "core",
        "Core",
        "org",
        "opencv",
        "core",
        "Mat",
        "org",
        "opencv",
        "core",
        "Rect",
        "org",
        "opencv",
        "core",
        "Scalar",
        "org",
        "opencv",
        "imgproc",
        "Imgproc",
        "org",
        "openftc",
        "easyopencv",
        "OpenCvCamera",
        "org",
        "openftc",
        "easyopencv",
        "OpenCvCameraFactory",
        "org",
        "openftc",
        "easyopencv",
        "OpenCvCameraRotation",
        "org",
        "openftc",
        "easyopencv",
        "OpenCvPipeline",
        "org",
        "openftc",
        "easyopencv",
        "OpenCvWebcam",
        "TeleOp",
        "webcam",
        "Override",
        "cameraMonitorViewId",
        "hardwareMap",
        "appContext",
        "getResources",
        "getIdentifier",
        "hardwareMap",
        "appContext",
        "getPackageName",
        "webcam",
        "OpenCvCameraFactory",
        "getInstance",
        "createWebcam",
        "hardwareMap",
        "get",
        "cameraMonitorViewId",
        "webcam",
        "setPipeline",
        "webcam",
        "setMillisecondsPermissionTimeout",
        "webcam",
        "openCameraDeviceAsync",
        "Override",
        "webcam",
        "startStreaming",
        "OpenCvCameraRotation",
        "UPRIGHT",
        "Override",
        "errorCode",
        "telemetry",
        "addLine",
        "telemetry",
        "update",
        "waitForStart",
        "opModeIsActive",
        "telemetry",
        "addData",
        "webcam",
        "getFrameCount",
        "telemetry",
        "addData",
        "format",
        "webcam",
        "getFps",
        "telemetry",
        "addData",
        "webcam",
        "getTotalFrameTimeMs",
        "telemetry",
        "addData",
        "webcam",
        "getPipelineTimeMs",
        "telemetry",
        "addData",
        "webcam",
        "getOverheadTimeMs",
        "telemetry",
        "addData",
        "webcam",
        "getCurrentPipelineMaxFps",
        "telemetry",
        "update",
        "gamepad1",
        "a",
        "webcam",
        "stopStreaming",
        "sleep",
        "viewportPaused",
        "centerRect",
        "rightRect",
        "rectColor",
        "centerCrop",
        "rightCrop",
        "centerAvg",
        "rightAvg",
        "Override",
        "input",
        "Imgproc",
        "rectangle",
        "input",
        "centerRect",
        "rectColor",
        "Imgproc",
        "rectangle",
        "input",
        "rightRect",
        "rectColor",
        "centerCrop",
        "input",
        "submat",
        "centerRect",
        "rightCrop",
        "input",
        "submat",
        "rightRect",
        "centerRGBavg",
        "Core",
        "mean",
        "centerCrop",
        "rightRGBavg",
        "Core",
        "mean",
        "rightCrop",
        "centerAvg",
        "centerRGBavg",
        "val",
        "centerRGBavg",
        "val",
        "centerRGBavg",
        "val",
        "rightAvg",
        "rightRGBavg",
        "val",
        "rightRGBavg",
        "val",
        "rightRGBavg",
        "val",
        "threshold",
        "centerAvg",
        "rightAvg",
        "centerAvg",
        "threshold",
        "telemetry",
        "addLine",
        "rightAvg",
        "centerAvg",
        "rightAvg",
        "threshold",
        "telemetry",
        "addLine",
        "telemetry",
        "addLine",
        "telemetry",
        "addLine",
        "centerAvg",
        "telemetry",
        "addLine",
        "rightAvg",
        "input",
        "Override",
        "viewportPaused",
        "viewportPaused",
        "viewportPaused",
        "webcam",
        "pauseViewport",
        "webcam",
        "resumeViewport"
    ],
    "literals": [
        "\"cameraMonitorViewId\"",
        "\"id\"",
        "\"Webcam 1\"",
        "\"Waiting for start\"",
        "\"Frame Count\"",
        "\"FPS\"",
        "\"%.2f\"",
        "\"Total frame time ms\"",
        "\"Pipeline time ms\"",
        "\"Overhead time ms\"",
        "\"Theoretical max FPS\"",
        "\"Prop Location: Center\"",
        "\"Prop Location: Right\"",
        "\"Prop Location: Left\"",
        "\"Center: \"",
        "\"Right: \""
    ],
    "variables": [
        "webcam",
        "viewportPaused",
        "centerCrop",
        "rightCrop",
        "centerAvg",
        "rightAvg"
    ],
    "comments": [
        "OR...  Do Not Activate the Camera Monitor View",
        "webcam = OpenCvCameraFactory.getInstance().createWebcam(hardwareMap.get(WebcamName.class, \"Webcam 1\"));",
        "Timeout for obtaining permission is configurable. Set before opening.",
        "webcam.closeCameraDevice();",
        "Defining a rectangle example: Rect exampleRect = new Rect ( x starting location, y starting location, width, height)",
        "creating a variable to store the color of the rectangle",
        "empty matrix",
        "empty matrix",
        "grabs the pixels ONLY in the sub matrix (centerRect or rightRect)",
        "average RGB of the sub matrix",
        "algorithm for detecting blue",
        "the value at which we say, neither pixel region is red (must be on the left)"
    ],
    "docstrings": [
        "* Copyright (c) 2019 OpenFTC Team\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.",
        "* Instantiate an OpenCvCamera object for the camera we'll be using.\n         * In this sample, we're using a webcam. Note that you will need to\n         * make sure you have added the webcam to your configuration file and\n         * adjusted the name here to match what you named it in said config file.\n         *\n         * We pass it the view that we wish to use for camera monitor (on\n         * the RC phone). If no camera monitor is desired, use the alternate\n         * single-parameter constructor instead (commented out below)",
        "* Specify the image processing pipeline we wish to invoke upon receipt\n         * of a frame from the camera. Note that switching pipelines on-the-fly\n         * (while a streaming session is in flight) *IS* supported.",
        "* Open the connection to the camera device. New in v1.4.0 is the ability\n         * to open the camera asynchronously, and this is now the recommended way\n         * to do it. The benefits of opening async include faster init time, and\n         * better behavior when pressing stop during init (i.e. less of a chance\n         * of tripping the stuck watchdog)\n         *\n         * If you really want to open synchronously, the old method is still available.",
        "* Tell the webcam to start streaming images to us! Note that you must make sure\n                 * the resolution you specify is supported by the camera. If it is not, an exception\n                 * will be thrown.\n                 *\n                 * Keep in mind that the SDK's UVC driver (what OpenCvWebcam uses under the hood) only\n                 * supports streaming from the webcam in the uncompressed YUV image format. This means\n                 * that the maximum resolution you can stream at and still get up to 30FPS is 480p (640x480).\n                 * Streaming at e.g. 720p will limit you to up to 10FPS and so on and so forth.\n                 *\n                 * Also, we specify the rotation that the webcam is used in. This is so that the image\n                 * from the camera sensor can be rotated such that it is always displayed with the image upright.\n                 * For a front facing camera, rotation is defined assuming the user is looking at the screen.\n                 * For a rear facing camera or a webcam, rotation is defined assuming the camera is facing\n                 * away from the user.",
        "* This will be called if the camera could not be opened",
        "* Wait for the user to press start on the Driver Station",
        "* Send some stats to the telemetry",
        "* NOTE: stopping the stream from the camera early (before the end of the OpMode\n             * when it will be automatically stopped for you) *IS* supported. The \"if\" statement\n             * below will stop streaming from the camera when the \"A\" button on gamepad 1 is pressed.",
        "* IMPORTANT NOTE: calling stopStreaming() will indeed stop the stream of images\n                 * from the camera (and, by extension, stop calling your vision pipeline). HOWEVER,\n                 * if the reason you wish to stop the stream early is to switch use of the camera\n                 * over to, say, Vuforia or TFOD, you will also need to call closeCameraDevice()\n                 * (commented out below), because according to the Android Camera API documentation:\n                 *         \"Your application should only have one Camera object active at a time for\n                 *          a particular hardware camera.\"\n                 *\n                 * NB: calling closeCameraDevice() will internally call stopStreaming() if applicable,\n                 * but it doesn't hurt to call it anyway, if for no other reason than clarity.\n                 *\n                 * NB2: if you are stopping the camera stream to simply save some processing power\n                 * (or battery power) for a short while when you do not need your vision pipeline,\n                 * it is recommended to NOT call closeCameraDevice() as you will then need to re-open\n                 * it the next time you wish to activate your vision pipeline, which can take a bit of\n                 * time. Of course, this comment is irrelevant in light of the use case described in\n                 * the above \"important note\".",
        "* For the purposes of this sample, throttle ourselves to 10Hz loop to avoid burning\n             * excess CPU cycles for no reason. (By default, telemetry is only sent to the DS at 4Hz\n             * anyway). Of course in a real OpMode you will likely not want to do this.",
        "* An example image processing pipeline to be run upon receipt of each frame from the camera.\n     * Note that the processFrame() method is called serially from the frame worker thread -\n     * that is, a new camera frame will not come in while you're still processing a previous one.\n     * In other words, the processFrame() method will never be called multiple times simultaneously.\n     *\n     * However, the rendering of your processed image to the viewport is done in parallel to the\n     * frame worker thread. That is, the amount of time it takes to render the image to the\n     * viewport does NOT impact the amount of frames per second that your pipeline can process.\n     *\n     * IMPORTANT NOTE: this pipeline is NOT invoked on your OpMode thread. It is invoked on the\n     * frame worker thread. This should not be a problem in the vast majority of cases. However,\n     * if you're doing something weird where you do need it synchronized with your OpMode thread,\n     * then you will need to account for that accordingly.",
        "* NOTE: if you wish to use additional Mat objects in your processing pipeline, it is\n         * highly recommended to declare them here as instance variables and re-use them for\n         * each invocation of processFrame(), rather than declaring them as new local variables\n         * each time through processFrame(). This removes the danger of causing a memory leak\n         * by forgetting to call mat.release(), and it also reduces memory pressure by not\n         * constantly allocating and freeing large chunks of memory.",
        "* IMPORTANT NOTE: the input Mat that is passed in as a parameter to this method\n             * will only dereference to the same image for the duration of this particular\n             * invocation of this method. That is, if for some reason you'd like to save a copy\n             * of this particular frame for later use, you will need to either clone it or copy\n             * it to another Mat.",
        "* NOTE: to see how to get data from your pipeline to your OpMode as well as how\n             * to change which stage of the pipeline is rendered to the viewport when it is\n             * tapped, please see {@link PipelineStageSwitchingExample}",
        "* The viewport (if one was specified in the constructor) can also be dynamically \"paused\"\n             * and \"resumed\". The primary use case of this is to reduce CPU, memory, and power load\n             * when you need your vision pipeline running, but do not require a live preview on the\n             * robot controller screen. For instance, this could be useful if you wish to see the live\n             * camera preview as you are initializing your robot, but you no longer require the live\n             * preview after you have finished your initialization process; pausing the viewport does\n             * not stop running your pipeline.\n             *\n             * Here we demonstrate dynamically pausing/resuming the viewport when the user taps it"
    ],
    "functions": [
        "runOpMode",
        "onOpened",
        "onError",
        "Mat",
        "processFrame",
        "onViewportTapped"
    ],
    "classes": [
        "PropDetection_Blue",
        "SamplePipeline"
    ]
}