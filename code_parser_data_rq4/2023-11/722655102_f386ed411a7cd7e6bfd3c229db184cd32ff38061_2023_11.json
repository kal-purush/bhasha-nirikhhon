{
    "identifiers": [
        "openai",
        "OpenAI",
        "json",
        "OpenAI",
        "location",
        "unit",
        "location",
        "lower",
        "json",
        "dumps",
        "location",
        "lower",
        "json",
        "dumps",
        "location",
        "lower",
        "json",
        "dumps",
        "json",
        "dumps",
        "location",
        "client",
        "chat",
        "completions",
        "create",
        "model",
        "messages",
        "messages",
        "tools",
        "tools",
        "tool_choice",
        "response",
        "choices",
        "message",
        "response_message",
        "tool_calls",
        "tool_calls",
        "get_current_weather",
        "messages",
        "append",
        "response_message",
        "tool_call",
        "tool_calls",
        "tool_call",
        "name",
        "available_functions",
        "function_name",
        "json",
        "loads",
        "tool_call",
        "arguments",
        "function_to_call",
        "location",
        "function_args",
        "get",
        "unit",
        "function_args",
        "get",
        "messages",
        "append",
        "tool_call",
        "id",
        "function_name",
        "function_response",
        "client",
        "chat",
        "completions",
        "create",
        "model",
        "messages",
        "messages",
        "second_response",
        "run_conversation",
        "stage2_results"
    ],
    "literals": [
        "\"fahrenheit\"",
        "\"tokyo\"",
        "\"location\"",
        "\"Tokyo\"",
        "\"temperature\"",
        "\"10\"",
        "\"unit\"",
        "\"celsius\"",
        "\"san francisco\"",
        "\"location\"",
        "\"San Francisco\"",
        "\"temperature\"",
        "\"72\"",
        "\"unit\"",
        "\"fahrenheit\"",
        "\"paris\"",
        "\"location\"",
        "\"Paris\"",
        "\"temperature\"",
        "\"22\"",
        "\"unit\"",
        "\"celsius\"",
        "\"location\"",
        "\"temperature\"",
        "\"unknown\"",
        "\"role\"",
        "\"user\"",
        "\"content\"",
        "\"What's the weather like in San Francisco, Tokyo, and Paris?\"",
        "\"type\"",
        "\"function\"",
        "\"function\"",
        "\"name\"",
        "\"get_current_weather\"",
        "\"description\"",
        "\"Get the current weather in a given location\"",
        "\"parameters\"",
        "\"type\"",
        "\"object\"",
        "\"properties\"",
        "\"location\"",
        "\"type\"",
        "\"string\"",
        "\"description\"",
        "\"The city and state, e.g. San Francisco, CA\"",
        "\"unit\"",
        "\"type\"",
        "\"string\"",
        "\"enum\"",
        "\"celsius\"",
        "\"fahrenheit\"",
        "\"required\"",
        "\"location\"",
        "\"gpt-3.5-turbo-1106\"",
        "\"auto\"",
        "\"get_current_weather\"",
        "\"location\"",
        "\"unit\"",
        "\"tool_call_id\"",
        "\"role\"",
        "\"tool\"",
        "\"name\"",
        "\"content\"",
        "\"gpt-3.5-turbo-1106\""
    ],
    "variables": [
        "client",
        "messages",
        "tools",
        "response",
        "response_message",
        "tool_calls",
        "available_functions",
        "function_name",
        "function_to_call",
        "function_args",
        "function_response",
        "second_response",
        "stage2_results"
    ],
    "comments": [
        "Example dummy function hard coded to return the same weather",
        "In production, this could be your backend API or an external API",
        "Send the conversation and description of available function call(s) to the model",
        "Stage 1 chat.completions",
        "auto is default, but we'll be explicit",
        "Step 2: check if the model wanted to call a function. The model describes the function calls it wants to make",
        "for this_call in tool_calls:",
        "print(\"this_call\", this_call.function)",
        "this_call Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather')",
        "this_call Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather')",
        "this_call Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather')",
        "Note: the JSON response may not always be valid; be sure to handle errors",
        "Note: get_current_weather is an actual pointer to the function defined at the top",
        "only one function in this example, but you can have multiple",
        "extend conversation with assistant's reply",
        "Assemble each function call described in output of Stage 1",
        "Note: function_to_call is an actual pointer to the function defined at the top",
        "Make the function call",
        "Append each function call and its return value to the Stage 1 message",
        "eo loop",
        "Call chat.completions on the Stage 1 message + Stage 1 completions + all function calls and their return values",
        "Stage 2 chat.completions",
        "return Stage 2"
    ],
    "docstrings": [
        "\"\"\"\nOpenAI_Functions.py\n\n23 November 2023\n\nhttps://platform.openai.com/docs/guides/function-calling\n\n\"\"\"",
        "\"\"\"Get the current weather in a given location\"\"\""
    ],
    "functions": [
        "get_current_weather",
        "run_conversation"
    ],
    "classes": []
}