{
    "identifiers": [
        "torch",
        "torch",
        "nn",
        "nn",
        "transformers",
        "modeling_bert",
        "BertPreTrainedModel",
        "transformers",
        "modeling_roberta",
        "RobertaModel",
        "RobertaConfig",
        "torchcrf",
        "CRF",
        "IntentClassifier",
        "SlotClassifier",
        "BertPreTrainedModel",
        "config",
        "args",
        "intent_label_lst",
        "slot_label_lst",
        "JointBERT",
        "config",
        "args",
        "len",
        "intent_label_lst",
        "len",
        "slot_label_lst",
        "RobertaModel",
        "config",
        "config",
        "IntentClassifier",
        "config",
        "hidden_size",
        "num_intent_labels",
        "args",
        "dropout_rate",
        "SlotClassifier",
        "config",
        "hidden_size",
        "num_slot_labels",
        "args",
        "dropout_rate",
        "args",
        "use_crf",
        "CRF",
        "num_tags",
        "num_slot_labels",
        "batch_first",
        "input_ids",
        "attention_mask",
        "token_type_ids",
        "intent_label_ids",
        "slot_labels_ids",
        "bert",
        "input_ids",
        "attention_mask",
        "attention_mask",
        "token_type_ids",
        "token_type_ids",
        "outputs",
        "outputs",
        "intent_classifier",
        "pooled_output",
        "slot_classifier",
        "sequence_output",
        "intent_label_ids",
        "num_intent_labels",
        "nn",
        "MSELoss",
        "intent_loss_fct",
        "intent_logits",
        "view",
        "intent_label_ids",
        "view",
        "nn",
        "CrossEntropyLoss",
        "intent_loss_fct",
        "intent_logits",
        "view",
        "num_intent_labels",
        "intent_label_ids",
        "view",
        "total_loss",
        "intent_loss",
        "slot_labels_ids",
        "args",
        "use_crf",
        "crf",
        "slot_logits",
        "slot_labels_ids",
        "mask",
        "attention_mask",
        "reduction",
        "slot_loss",
        "nn",
        "CrossEntropyLoss",
        "ignore_index",
        "args",
        "ignore_index",
        "attention_mask",
        "attention_mask",
        "view",
        "slot_logits",
        "view",
        "num_slot_labels",
        "active_loss",
        "slot_labels_ids",
        "view",
        "active_loss",
        "slot_loss_fct",
        "active_logits",
        "active_labels",
        "slot_loss_fct",
        "slot_logits",
        "view",
        "num_slot_labels",
        "slot_labels_ids",
        "view",
        "total_loss",
        "args",
        "slot_loss_coef",
        "slot_loss",
        "intent_logits",
        "slot_logits",
        "outputs",
        "total_loss",
        "outputs",
        "outputs"
    ],
    "literals": [
        "'mean'"
    ],
    "variables": [
        "args",
        "num_intent_labels",
        "num_slot_labels",
        "bert",
        "intent_classifier",
        "slot_classifier",
        "crf",
        "outputs",
        "sequence_output",
        "pooled_output",
        "intent_logits",
        "slot_logits",
        "total_loss",
        "intent_loss_fct",
        "intent_loss",
        "intent_loss_fct",
        "intent_loss",
        "slot_loss",
        "slot_loss",
        "slot_loss_fct",
        "active_loss",
        "active_logits",
        "active_labels",
        "slot_loss",
        "slot_loss",
        "outputs",
        "outputs"
    ],
    "comments": [
        "Load pretrained bert",
        "sequence_output, pooled_output, (hidden_states), (attentions)",
        "[CLS]",
        "1. Intent Softmax",
        "2. Slot Softmax",
        "negative log-likelihood",
        "Only keep active parts of the loss",
        "add hidden states and attention if they are here",
        "(loss), logits, (hidden_states), (attentions) # Logits is a tuple of intent and slot logits"
    ],
    "docstrings": [],
    "functions": [
        "forward"
    ],
    "classes": [
        "JointRoBERTa"
    ]
}