{
    "identifiers": [
        "math",
        "typing",
        "Any",
        "Callable",
        "Optional",
        "Tuple",
        "Union",
        "numpy",
        "np",
        "torch",
        "torch",
        "nn",
        "Sequential",
        "inputs",
        "torch",
        "Tensor",
        "Tuple",
        "torch",
        "Tensor",
        "torch",
        "Tensor",
        "i",
        "_modules",
        "values",
        "inputs",
        "log_det_jacobian",
        "log_det_jacobian_",
        "inputs",
        "log_det_jacobian",
        "torch",
        "nn",
        "Sequential",
        "args",
        "Any",
        "res",
        "Optional",
        "BNAF",
        "args",
        "res",
        "res",
        "torch",
        "nn",
        "Parameter",
        "torch",
        "nn",
        "init",
        "normal_",
        "torch",
        "Tensor",
        "inputs",
        "torch",
        "Tensor",
        "Tuple",
        "torch",
        "Tensor",
        "torch",
        "Tensor",
        "inputs",
        "_modules",
        "values",
        "outputs",
        "grad",
        "grad",
        "len",
        "grad",
        "shape",
        "grad",
        "view",
        "grad",
        "shape",
        "inputs",
        "shape",
        "outputs",
        "shape",
        "AssertionError",
        "grad",
        "RuntimeError",
        "res",
        "inputs",
        "outputs",
        "torch",
        "nn",
        "functional",
        "softplus",
        "grad",
        "squeeze",
        "sum",
        "res",
        "gate",
        "sigmoid",
        "outputs",
        "gate",
        "sigmoid",
        "inputs",
        "torch",
        "nn",
        "functional",
        "softplus",
        "grad",
        "squeeze",
        "gate",
        "torch",
        "nn",
        "functional",
        "softplus",
        "gate",
        "sum",
        "outputs",
        "grad",
        "squeeze",
        "sum",
        "format",
        "res",
        "torch",
        "nn",
        "Module",
        "in_features",
        "p",
        "Optional",
        "Union",
        "Permutation",
        "in_features",
        "p",
        "np",
        "random",
        "permutation",
        "in_features",
        "p",
        "reversed",
        "in_features",
        "p",
        "inputs",
        "torch",
        "Tensor",
        "Tuple",
        "torch",
        "Tensor",
        "torch",
        "Tensor",
        "inputs",
        "p",
        "format",
        "in_features",
        "p",
        "torch",
        "nn",
        "Module",
        "in_features",
        "out_features",
        "dim",
        "bias",
        "MaskedWeight",
        "in_features",
        "out_features",
        "dim",
        "in_features",
        "out_features",
        "dim",
        "torch",
        "zeros",
        "out_features",
        "in_features",
        "i",
        "dim",
        "i",
        "out_features",
        "dim",
        "i",
        "out_features",
        "dim",
        "i",
        "in_features",
        "dim",
        "torch",
        "nn",
        "init",
        "xavier_uniform_",
        "torch",
        "Tensor",
        "out_features",
        "dim",
        "i",
        "in_features",
        "dim",
        "torch",
        "nn",
        "Parameter",
        "weight",
        "torch",
        "nn",
        "Parameter",
        "torch",
        "nn",
        "init",
        "uniform_",
        "torch",
        "Tensor",
        "out_features",
        "log",
        "torch",
        "nn",
        "Parameter",
        "torch",
        "nn",
        "init",
        "uniform_",
        "torch",
        "Tensor",
        "out_features",
        "math",
        "sqrt",
        "out_features",
        "math",
        "sqrt",
        "out_features",
        "bias",
        "torch",
        "zeros_like",
        "weight",
        "i",
        "dim",
        "i",
        "out_features",
        "dim",
        "i",
        "out_features",
        "dim",
        "i",
        "in_features",
        "dim",
        "i",
        "in_features",
        "dim",
        "register_buffer",
        "mask_d",
        "torch",
        "ones_like",
        "weight",
        "i",
        "dim",
        "i",
        "out_features",
        "dim",
        "i",
        "out_features",
        "dim",
        "i",
        "in_features",
        "dim",
        "register_buffer",
        "mask_o",
        "Any",
        "torch",
        "exp",
        "_weight",
        "mask_d",
        "_weight",
        "mask_o",
        "w",
        "sum",
        "keepdim",
        "_diag_weight",
        "exp",
        "w",
        "w_squared_norm",
        "sqrt",
        "_diag_weight",
        "_weight",
        "torch",
        "log",
        "w_squared_norm",
        "w",
        "t",
        "wpl",
        "t",
        "mask_d",
        "t",
        "view",
        "dim",
        "in_features",
        "dim",
        "out_features",
        "dim",
        "inputs",
        "torch",
        "Tensor",
        "grad",
        "Optional",
        "torch",
        "Tensor",
        "torch",
        "Tensor",
        "get_weights",
        "wpl",
        "transpose",
        "unsqueeze",
        "repeat",
        "inputs",
        "shape",
        "inputs",
        "matmul",
        "w",
        "bias",
        "torch",
        "logsumexp",
        "g",
        "unsqueeze",
        "grad",
        "transpose",
        "unsqueeze",
        "grad",
        "g",
        "format",
        "in_features",
        "out_features",
        "dim",
        "isinstance",
        "bias",
        "torch",
        "nn",
        "Tanh",
        "inputs",
        "torch",
        "Tensor",
        "grad",
        "Optional",
        "torch",
        "Tensor",
        "Tuple",
        "torch",
        "Tensor",
        "torch",
        "Tensor",
        "inputs",
        "math",
        "log",
        "torch",
        "nn",
        "functional",
        "softplus",
        "inputs",
        "torch",
        "tanh",
        "inputs",
        "g",
        "view",
        "grad",
        "shape",
        "grad",
        "grad",
        "g",
        "torch",
        "optim",
        "Optimizer",
        "Any",
        "lr",
        "betas",
        "Tuple",
        "eps",
        "weight_decay",
        "amsgrad",
        "polyak",
        "lr",
        "ValueError",
        "format",
        "lr",
        "eps",
        "ValueError",
        "format",
        "eps",
        "betas",
        "ValueError",
        "format",
        "betas",
        "betas",
        "ValueError",
        "format",
        "betas",
        "polyak",
        "ValueError",
        "format",
        "polyak",
        "lr",
        "lr",
        "betas",
        "betas",
        "eps",
        "eps",
        "weight_decay",
        "weight_decay",
        "amsgrad",
        "amsgrad",
        "polyak",
        "polyak",
        "Adam",
        "defaults",
        "state",
        "Any",
        "Adam",
        "__setstate__",
        "state",
        "group",
        "param_groups",
        "group",
        "setdefault",
        "closure",
        "Optional",
        "Callable",
        "Optional",
        "closure",
        "closure",
        "group",
        "param_groups",
        "p",
        "group",
        "p",
        "grad",
        "p",
        "grad",
        "data",
        "grad",
        "is_sparse",
        "RuntimeError",
        "group",
        "state",
        "p",
        "len",
        "state",
        "torch",
        "zeros_like",
        "p",
        "data",
        "torch",
        "zeros_like",
        "p",
        "data",
        "torch",
        "zeros_like",
        "p",
        "data",
        "amsgrad",
        "torch",
        "zeros_like",
        "p",
        "data",
        "state",
        "state",
        "amsgrad",
        "state",
        "group",
        "state",
        "group",
        "grad",
        "add_",
        "group",
        "p",
        "data",
        "exp_avg",
        "mul_",
        "beta1",
        "add_",
        "beta1",
        "grad",
        "exp_avg_sq",
        "mul_",
        "beta2",
        "addcmul_",
        "beta2",
        "grad",
        "grad",
        "amsgrad",
        "torch",
        "max",
        "max_exp_avg_sq",
        "exp_avg_sq",
        "max_exp_avg_sq",
        "max_exp_avg_sq",
        "sqrt",
        "add_",
        "group",
        "exp_avg_sq",
        "sqrt",
        "add_",
        "group",
        "beta1",
        "state",
        "beta2",
        "state",
        "group",
        "math",
        "sqrt",
        "bias_correction2",
        "bias_correction1",
        "p",
        "data",
        "addcdiv_",
        "step_size",
        "exp_avg",
        "denom",
        "defaults",
        "polyak",
        "state",
        "polyak",
        "p",
        "data",
        "loss",
        "group",
        "param_groups",
        "p",
        "group",
        "state",
        "p",
        "p",
        "data",
        "state",
        "group",
        "param_groups",
        "p",
        "group",
        "state",
        "p",
        "torch",
        "optim",
        "lr_scheduler",
        "ReduceLROnPlateau",
        "args",
        "Any",
        "early_stopping",
        "Optional",
        "kwargs",
        "Any",
        "early_stopping",
        "Any",
        "args",
        "kwargs",
        "metrics",
        "Any",
        "epoch",
        "Optional",
        "callback_best",
        "Optional",
        "Callable",
        "callback_reduce",
        "Optional",
        "Callable",
        "metrics",
        "epoch",
        "last_epoch",
        "epoch",
        "is_better",
        "current",
        "best",
        "current",
        "callback_best",
        "callback_best",
        "num_bad_epochs",
        "early_stopping_counter",
        "in_cooldown",
        "cooldown_counter",
        "num_bad_epochs",
        "patience",
        "callback_reduce",
        "callback_reduce",
        "_reduce_lr",
        "epoch",
        "cooldown",
        "early_stopping_counter",
        "early_stopping"
    ],
    "literals": [
        "\"gated\"",
        "\"Incompatible shapes for input and output in BNAF model for Domias.\"",
        "\"Invalid grad\"",
        "\"normal\"",
        "\"gated\"",
        "\"BNAF(res={})\"",
        "\"flip\"",
        "\"Permutation(in_features={}, p={})\"",
        "\"mask_d\"",
        "\"mask_o\"",
        "\"MaskedWeight(in_features={}, out_features={}, dim={}, bias={})\"",
        "\"Invalid learning rate: {}\"",
        "\"Invalid epsilon value: {}\"",
        "\"Invalid beta parameter at index 0: {}\"",
        "\"Invalid beta parameter at index 1: {}\"",
        "\"Invalid polyak decay term: {}\"",
        "\"amsgrad\"",
        "\"params\"",
        "\"Adam does not support sparse gradients, please consider SparseAdam instead\"",
        "\"amsgrad\"",
        "\"step\"",
        "\"exp_avg\"",
        "\"exp_avg_sq\"",
        "\"exp_avg_param\"",
        "\"max_exp_avg_sq\"",
        "\"exp_avg\"",
        "\"exp_avg_sq\"",
        "\"max_exp_avg_sq\"",
        "\"betas\"",
        "\"step\"",
        "\"weight_decay\"",
        "\"weight_decay\"",
        "\"eps\"",
        "\"eps\"",
        "\"step\"",
        "\"step\"",
        "\"lr\"",
        "\"polyak\"",
        "\"exp_avg_param\"",
        "\"exp_avg_param\"",
        "\"params\"",
        "\"exp_avg_param\"",
        "\"exp_avg_param\"",
        "\"params\"",
        "\"exp_avg_param\""
    ],
    "variables": [
        "log_det_jacobian",
        "inputs",
        "log_det_jacobian_",
        "log_det_jacobian",
        "res",
        "gate",
        "outputs",
        "grad",
        "outputs",
        "grad",
        "grad",
        "in_features",
        "p",
        "p",
        "p",
        "weight",
        "weight",
        "_weight",
        "_diag_weight",
        "bias",
        "mask_d",
        "mask_d",
        "mask_o",
        "mask_o",
        "w",
        "w_squared_norm",
        "w",
        "wpl",
        "w",
        "wpl",
        "g",
        "g",
        "defaults",
        "loss",
        "loss",
        "grad",
        "amsgrad",
        "state",
        "state",
        "state",
        "state",
        "state",
        "state",
        "exp_avg",
        "exp_avg_sq",
        "max_exp_avg_sq",
        "beta1",
        "beta2",
        "denom",
        "denom",
        "bias_correction1",
        "bias_correction2",
        "step_size",
        "polyak",
        "state",
        "state",
        "p",
        "data",
        "state",
        "p",
        "data",
        "early_stopping",
        "early_stopping_counter",
        "last_epoch",
        "cooldown_counter",
        "cooldown",
        "wait",
        "best",
        "current",
        "epoch",
        "last_epoch",
        "best",
        "num_bad_epochs",
        "early_stopping_counter",
        "num_bad_epochs",
        "cooldown_counter",
        "num_bad_epochs"
    ],
    "comments": [
        "from BNAF (De Cao et al., 2018), https://github.com/nicola-decao/BNAF",
        "stdlib",
        "third party",
        "State initialization",
        "Exponential moving average of gradient values",
        "Exponential moving average of squared gradient values",
        "Exponential moving average of param",
        "Maintains max of all exp. moving avg. of sq. grad. values",
        "Decay the first and second moment running average coefficient",
        "Maintains the maximum of all 2nd moment running avg. till now",
        "Use the max. for normalizing running avg. of gradient",
        "ignore any bad epochs in cooldown"
    ],
    "docstrings": [
        "\"\"\"\n    Class that extends ``torch.nn.Sequential`` for computing the output of\n    the function alongside with the log-det-Jacobian of such transformation.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.Tensor``, required.\n            The input tensor.\n        Returns\n        -------\n        The output tensor and the log-det-Jacobian of this transformation.\n        \"\"\"",
        "\"\"\"\n    Class that extends ``torch.nn.Sequential`` for constructing a Block Neural\n    Normalizing Flow.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        *args : ``Iterable[torch.nn.Module]``, required.\n            The modules to use.\n        res : ``str``, optional (default = None).\n            Which kind of residual connection to use. ``res = None`` is no residual\n            connection, ``res = 'normal'`` is ``x + f(x)`` and ``res = 'gated'`` is\n            ``a * x + (1 - a) * f(x)`` where ``a`` is a learnable parameter.\n        \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.Tensor``, required.\n            The input tensor.\n        Returns\n        -------\n        The output tensor and the log-det-Jacobian of this transformation.\n        \"\"\"",
        "\"\"\"\n    Module that outputs a permutation of its input.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        in_features : ``int``, required.\n            The number of input features.\n        p : ``list`` or ``str``, optional (default = None)\n            The list of indeces that indicate the permutation. When ``p`` is not a\n            list, if ``p = 'flip'``the tensor is reversed, if ``p = None`` a random\n            permutation is applied.\n        \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.Tensor``, required.\n            The input tensor.\n        Returns\n        -------\n        The permuted tensor and the log-det-Jacobian of this permutation.\n        \"\"\"",
        "\"\"\"\n    Module that implements a linear layer with block matrices with positive diagonal blocks.\n    Moreover, it uses Weight Normalization (https://arxiv.org/abs/1602.07868) for stability.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        in_features : ``int``, required.\n            The number of input features per each dimension ``dim``.\n        out_features : ``int``, required.\n            The number of output features per each dimension ``dim``.\n        dim : ``int``, required.\n            The number of dimensions of the input of the flow.\n        bias : ``bool``, optional (default = True).\n            Whether to add a parametrizable bias.\n        \"\"\"",
        "\"\"\"\n        Computes the weight matrix using masks and weight normalization.\n        It also compute the log diagonal blocks of it.\n        \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.Tensor``, required.\n            The input tensor.\n        grad : ``torch.Tensor``, optional (default = None).\n            The log diagonal block of the partial Jacobian of previous transformations.\n        Returns\n        -------\n        The output tensor and the log diagonal blocks of the partial log-Jacobian of previous\n        transformations combined with this transformation.\n        \"\"\"",
        "\"\"\"\n    Class that extends ``torch.nn.Tanh`` additionally computing the log diagonal\n    blocks of the Jacobian.\n    \"\"\"",
        "\"\"\"\n        Parameters\n        ----------\n        inputs : ``torch.Tensor``, required.\n            The input tensor.\n        grad : ``torch.Tensor``, optional (default = None).\n            The log diagonal blocks of the partial Jacobian of previous transformations.\n        Returns\n        -------\n        The output tensor and the log diagonal blocks of the partial log-Jacobian of previous\n        transformations combined with this transformation.\n        \"\"\"",
        "\"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"",
        "\"\"\"\n        Swapping the running average of params and the current params for saving parameters using polyak averaging\n        \"\"\""
    ],
    "functions": [
        "forward",
        "forward",
        "_get_name",
        "forward",
        "__repr__",
        "get_weights",
        "forward",
        "__repr__",
        "forward",
        "__setstate__",
        "step",
        "swap",
        "substitute",
        "step"
    ],
    "classes": [
        "Sequential",
        "BNAF",
        "Permutation",
        "MaskedWeight",
        "Tanh",
        "Adam",
        "ReduceLROnPlateau"
    ]
}