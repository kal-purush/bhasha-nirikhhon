{
    "identifiers": [
        "time",
        "cv2",
        "numpy",
        "np",
        "json",
        "img1",
        "img1",
        "shape",
        "np",
        "maximum",
        "width",
        "height",
        "height",
        "width",
        "np",
        "array",
        "focal_length",
        "center",
        "focal_length",
        "center",
        "dtype",
        "K",
        "img1pts",
        "img2pts",
        "K",
        "R",
        "t",
        "triangulateFunc",
        "cv2",
        "convertPointsToHomogeneous",
        "img1pts",
        "cv2",
        "convertPointsToHomogeneous",
        "img2pts",
        "np",
        "linalg",
        "inv",
        "K",
        "dot",
        "img1ptsHom",
        "T",
        "T",
        "np",
        "linalg",
        "inv",
        "K",
        "dot",
        "img2ptsHom",
        "T",
        "T",
        "cv2",
        "convertPointsFromHomogeneous",
        "img1ptsNorm",
        "cv2",
        "convertPointsFromHomogeneous",
        "img2ptsNorm",
        "triangulateFunc",
        "np",
        "eye",
        "np",
        "hstack",
        "R",
        "t",
        "img1ptsNorm",
        "T",
        "img2ptsNorm",
        "T",
        "cv2",
        "convertPointsFromHomogeneous",
        "pts4d",
        "T",
        "pts3d",
        "img1",
        "img2",
        "cv2",
        "SIFT_create",
        "algorithm",
        "detectAndCompute",
        "img1",
        "algorithm",
        "detectAndCompute",
        "img2",
        "keypt1",
        "descr1",
        "keypt2",
        "descr2",
        "keypt1",
        "descr1",
        "keypt2",
        "descr2",
        "algorithm",
        "FLANN_INDEX_KDTREE",
        "trees",
        "checks",
        "cv2",
        "FlannBasedMatcher",
        "index_params",
        "search_params",
        "flann",
        "knnMatch",
        "descr1",
        "descr2",
        "k",
        "i",
        "m",
        "n",
        "matches",
        "m",
        "distance",
        "n",
        "distance",
        "pts2",
        "append",
        "keypt2",
        "m",
        "trainIdx",
        "pt",
        "pts1",
        "append",
        "keypt1",
        "m",
        "queryIdx",
        "pt",
        "np",
        "int32",
        "pts1",
        "np",
        "int32",
        "pts2",
        "pts1",
        "pts2",
        "img1",
        "pts1",
        "pts2",
        "cv2",
        "findFundamentalMat",
        "pts1",
        "pts2",
        "cv2",
        "RANSAC",
        "camera_internals_if_we_DONT_know_K",
        "img1",
        "K",
        "T",
        "dot",
        "F",
        "dot",
        "K",
        "cv2",
        "recoverPose",
        "E",
        "pts1",
        "pts2",
        "K",
        "getTriangulatedPoints",
        "pts1",
        "pts2",
        "K",
        "R",
        "t",
        "cv2",
        "triangulatePoints",
        "pts3d",
        "cv2",
        "imread",
        "cv2",
        "imread",
        "sift",
        "img1",
        "img2",
        "matching",
        "keypoints1",
        "descriptors1",
        "keypoints2",
        "descriptors2",
        "firstReconstruction",
        "img1",
        "pts1",
        "pts2",
        "pts3D",
        "i",
        "img_to_3d_points",
        "len",
        "pts3D",
        "pts3D",
        "time",
        "sleep"
    ],
    "literals": [
        "\"double\"",
        "'img/base/img08_V2_1_face_Pol_sense_sostre.jpeg'",
        "'img/base/img08_V2_2_face_Pol_sense_sostre.jpeg'",
        "'__main__'",
        "\"Len pts3D: \""
    ],
    "variables": [
        "width",
        "height",
        "_",
        "focal_length",
        "center",
        "K",
        "img1ptsHom",
        "img2ptsHom",
        "img1ptsNorm",
        "img2ptsNorm",
        "img1ptsNorm",
        "img2ptsNorm",
        "pts4d",
        "pts3d",
        "algorithm",
        "keypt1",
        "descr1",
        "keypt2",
        "descr2",
        "FLANN_INDEX_KDTREE",
        "index_params",
        "search_params",
        "flann",
        "matches",
        "pts1",
        "pts2",
        "pts1",
        "pts2",
        "F",
        "mask",
        "K",
        "E",
        "_",
        "R",
        "t",
        "mask",
        "pts3d",
        "img1",
        "img2",
        "keypoints1",
        "descriptors1",
        "keypoints2",
        "descriptors2",
        "pts1",
        "pts2",
        "pts3D",
        "pts3D"
    ],
    "comments": [
        "import plotly.graph_objects as go",
        "===========================================================",
        "FUNCIONS ÚTILS PER ELS MÒDULS PRINCIPALS",
        "USEFUL FUNCTIONS FOR THE MAIN MODULES",
        "===========================================================",
        "Calcula el valor K donat una imatge si no coneixem cap valor de la càmera.",
        "Calculate the K value given an image if we don't know any values of the camera.",
        "Funció necessaria per tal de calcular els punts 3d donats uns punts 2D, conf de la càmera i una funció de",
        "triangulació.",
        "Function needed to calculate 3d points given 2d points, camera conf and a triangulation function.",
        "================================================================",
        "MÒDULS DE SOFTWARE PRINCIPALS:",
        "PRINCIPAL SOFTWARE MODULES:",
        "================================================================",
        "Aplicar l'algorisme SIFT donades dues imatges per tal de poder trobar els punts característics i descriptors els",
        "quals retornarem (útils per a fer el matching).",
        "Apply the SIFT algorithm given two images in order to find the key points and descriptors",
        "which we will return (useful for matching).",
        "Find Keypoints and descriptors with SIFT",
        "Donats els resultats del SIFT, és a dir els keypoints i els descriptors de cada imatge, es realitza el matching",
        "mitjançant FLANN (utilitzat per fer cerques ràpides entre veïns (coincidència de descriptors -> match)). Com que hi",
        "ha molts matches amb valors incorrectes, es fa el Lowe's ratio test per filtrar els matches i quedar-nos amb",
        "els matches confiables o \"good matches\", els quals retornem.",
        "Given the SIFT results, i.e. the keypoints and descriptors of each image, the matching is performed via FLANN (used",
        "to do fast neighbor searches (descriptor match -> match)). As there there are many matches with incorrect values,",
        "the Lowe's ratio test is performed to filter the matches and leave us with the reliable matches or \"good matches\",",
        "which we return.",
        "FLANN parameters:",
        "Ratio test as per Lowe's paper:",
        "Funció mitjançant la qual es fa una primera reconstrucció, obtenint un mapa de punts 3D (\"\"\" finalment visualitzant",
        "una primera reconstrucció en el navegador mitjançant el mapa de punts calculat\"\"\"). Retorna un array amb els punts 3D.",
        "Function through which a first reconstruction is made, obtaining a 3D point map, (\"\"\"finally viewing",
        "a first reconstruction in the browser using the calculated point map. \"\"\"). Returns an array with the 3D points.",
        "RANSAC",
        "CAMERA PARAMETERS",
        "Estimate the Essential Matrix:",
        "Check for cheirality condition"
    ],
    "docstrings": [
        "\"\"\"\n    # REMINDER: If you want to visualize the points, you must uncomment the third import (plotly.graph_objects as go)\n    Visualitzar els punts 3D\n    fig = go.Figure(data=[go.Scatter3d(x=pts3d[:, 0], y=pts3d[:, 1], z=pts3d[:, 2], mode='markers', marker=dict(\n        size=2,\n        color='red',\n        opacity=0.8\n    ))])\n    fig.update_layout(autosize=False, width=900, height=900)\n    fig.show()\n    \"\"\"",
        "\"\"\"\"\"\"",
        "\"\"\"\n        coords = pts3D.tolist()\n        coordenadas = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]\n        coords_json = json.dumps(coords)\n        # print(coords_json)\n        # return pts3D\n        \"\"\""
    ],
    "functions": [
        "camera_internals_if_we_DONT_know_K",
        "getTriangulatedPoints",
        "sift",
        "matching",
        "firstReconstruction",
        "img_to_3d_points"
    ],
    "classes": []
}