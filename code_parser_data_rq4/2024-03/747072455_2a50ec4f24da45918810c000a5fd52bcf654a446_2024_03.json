{
    "identifiers": [
        "torch",
        "tqdm",
        "tqdm",
        "fpn_transformer",
        "fpn_transformer",
        "Transformer",
        "fpn_transformer",
        "fpn_process",
        "create_dataloader",
        "create_masks",
        "create_folder_if_not_exists",
        "torch",
        "nn",
        "functional",
        "F",
        "torch",
        "optim",
        "optim",
        "os",
        "torch",
        "device",
        "torch",
        "cuda",
        "is_available",
        "src_lang",
        "tgt_lang",
        "src_path",
        "tgt_path",
        "batch_size",
        "learning_rate",
        "epoch_nums",
        "weights_path",
        "create_dataloader",
        "src_lang",
        "tgt_lang",
        "src_path",
        "tgt_path",
        "batch_size",
        "Transformer",
        "src_vocab_size",
        "tgt_vocab_size",
        "max_seq_len",
        "to",
        "device",
        "sum",
        "p",
        "numel",
        "p",
        "tqdm",
        "model",
        "parameters",
        "desc",
        "p",
        "requires_grad",
        "total_params",
        "total_params",
        "optim",
        "Adam",
        "model",
        "parameters",
        "lr",
        "learning_rate",
        "betas",
        "epoch_cur",
        "epoch_nums",
        "batch",
        "tqdm",
        "dataloader",
        "desc",
        "epoch_cur",
        "epoch_nums",
        "batch",
        "to",
        "device",
        "batch",
        "to",
        "device",
        "create_masks",
        "src",
        "tgt",
        "src_mask",
        "to",
        "device",
        "tgt_mask",
        "to",
        "device",
        "model",
        "src",
        "tgt",
        "src_mask",
        "tgt_mask",
        "tgt",
        "view",
        "pred",
        "view",
        "len",
        "reshape_tgt",
        "F",
        "cross_entropy",
        "reshape_pred",
        "reshape_tgt",
        "ignore_index",
        "loss",
        "backward",
        "optimizer",
        "step",
        "epoch_loss",
        "loss",
        "item",
        "step",
        "epoch_loss",
        "step",
        "epoch_cur",
        "epoch_nums",
        "epoch_loss",
        "epoch_cur",
        "create_folder_if_not_exists",
        "weights_path",
        "torch",
        "save",
        "model",
        "state_dict",
        "os",
        "path",
        "join",
        "weights_path",
        "epoch_cur",
        "train",
        "for_test"
    ],
    "literals": [
        "'cuda'",
        "'cpu'",
        "'model initialization...'",
        "'caculating trainable parameters...'",
        "f'###### total trainable parameter: {total_params}({(total_params / 1000000000):.3f}B) ######'",
        "f'[{epoch_cur + 1}/{epoch_nums}] training...'",
        "'src'",
        "'tgt'",
        "f'[{epoch_cur + 1}/{epoch_nums}], train loss: {epoch_loss}, saving {epoch_cur + 1} state dict...'",
        "f'{epoch_cur + 1}_statedict.pth'",
        "'en'",
        "'fr'",
        "'data/test-en2fr/english.txt'",
        "'data/test-en2fr/french.txt'",
        "'weights'",
        "'__main__'"
    ],
    "variables": [
        "device",
        "dataloader",
        "src_vocab_size",
        "tgt_vocab_size",
        "max_seq_len",
        "model",
        "total_params",
        "optimizer",
        "epoch_loss",
        "step",
        "src",
        "tgt",
        "src_mask",
        "tgt_mask",
        "pred",
        "reshape_tgt",
        "reshape_pred",
        "loss"
    ],
    "comments": [
        "'data/en2zh/old/version1/english.txt'",
        "model = Transformer(10000, 10000, 1024, 5, 8, 0.1, 200).to(device)",
        "test()"
    ],
    "docstrings": [],
    "functions": [
        "train",
        "for_test"
    ],
    "classes": []
}