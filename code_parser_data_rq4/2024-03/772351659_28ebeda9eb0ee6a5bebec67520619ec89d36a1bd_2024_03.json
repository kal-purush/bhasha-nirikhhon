{
    "identifiers": [
        "pandas",
        "pd",
        "datasets",
        "load_dataset",
        "transformers",
        "BertTokenizer",
        "AutoTokenizer",
        "torch",
        "numpy",
        "np",
        "utils",
        "torch",
        "utils",
        "data",
        "Dataset",
        "DataLoader",
        "models",
        "pd",
        "read_csv",
        "TRAIN_PATH",
        "encoding",
        "pd",
        "read_csv",
        "VAL_PATH",
        "encoding",
        "pd",
        "read_csv",
        "TEST_PATH",
        "encoding",
        "AutoTokenizer",
        "from_pretrained",
        "get_categories",
        "df_train",
        "process_data",
        "df_train",
        "categories",
        "SentimentDataCollator",
        "tokenizer",
        "DataLoader",
        "dataset",
        "batch_size",
        "collate_fn",
        "data_collator",
        "ABSA_Tree_transfomer",
        "vocab_size",
        "tokenizer",
        "vocab_size",
        "N",
        "d_model",
        "d_ff",
        "h",
        "dropout",
        "num_categories",
        "len",
        "categories",
        "no_cuda",
        "model",
        "to",
        "device",
        "batch",
        "tqdm",
        "dataloader",
        "batch",
        "to",
        "device",
        "batch",
        "to",
        "device",
        "batch",
        "to",
        "device",
        "model",
        "inputs",
        "mask",
        "categories",
        "output",
        "shape"
    ],
    "literals": [
        "'./data/UIT-ViSFD/Train.csv'",
        "'./data/UIT-ViSFD/Dev.csv'",
        "'./data/UIT-ViSFD/Test.csv'",
        "'utf8'",
        "'utf8'",
        "'utf8'",
        "'vinai/phobert-base'",
        "'cuda'",
        "'input_ids'",
        "'attention_mask'",
        "'labels'"
    ],
    "variables": [
        "TRAIN_PATH",
        "VAL_PATH",
        "TEST_PATH",
        "df_train",
        "df_val",
        "df_test",
        "tokenizer",
        "categories",
        "dataset",
        "data_collator",
        "dataloader",
        "model",
        "device",
        "inputs",
        "mask",
        "labels",
        "output"
    ],
    "comments": [
        "class PositionalEncoding(nn.Module):",
        "def __init__(self, d_model, max_len=512):",
        "super(PositionalEncoding, self).__init__()",
        "self.dropout = nn.Dropout(p=0.1)",
        "# Compute the positional encodings once in log space",
        "pe = torch.zeros(max_len, d_model)",
        "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)",
        "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))",
        "pe[:, 0::2] = torch.sin(position * div_term)",
        "pe[:, 1::2] = torch.cos(position * div_term)",
        "pe = pe.unsqueeze(0)  # Add batch dimension",
        "self.register_buffer('pe', pe)",
        "def forward(self, x):",
        "# Ensure that positional encoding matches the shape of the input tensor x",
        "pe = self.pe[:, :x.size(1)]  # Slice positional encoding along the sequence length dimension",
        "pe = pe.expand(x.size(0), -1, -1)  # Expand positional encoding to match batch size",
        "pe = pe.to(x.device)  # Move positional encoding to the same device as input tensor",
        "x = x + pe",
        "return self.dropout(x)",
        "# Example usage:",
        "d_model = 768  # Dimensionality of the model",
        "max_len = 128 # Maximum sequence length",
        "positional_encoding = PositionalEncoding(d_model, max_len)",
        "# Assuming x is your input tensor of shape (batch_size, sequence_length, d_model)",
        "x = torch.randn(32, 128, d_model).cuda() # Example input tensor",
        "output = positional_encoding(x)",
        "print(output)"
    ],
    "docstrings": [],
    "functions": [],
    "classes": []
}