{
    "identifiers": [
        "Runtime",
        "InteropServices",
        "agora",
        "rtc",
        "MEDIA_SOURCE_TYPE",
        "AUDIO_PLAYOUT_SOURCE",
        "AUDIO_RECORDING_SOURCE",
        "PRIMARY_CAMERA_SOURCE",
        "SECONDARY_CAMERA_SOURCE",
        "PRIMARY_SCREEN_SOURCE",
        "SECONDARY_SCREEN_SOURCE",
        "CUSTOM_VIDEO_SOURCE",
        "MEDIA_PLAYER_SOURCE",
        "RTC_IMAGE_PNG_SOURCE",
        "RTC_IMAGE_JPEG_SOURCE",
        "RTC_IMAGE_GIF_SOURCE",
        "REMOTE_VIDEO_SOURCE",
        "TRANSCODED_VIDEO_SOURCE",
        "UNKNOWN_MEDIA_SOURCE",
        "AUDIO_FRAME_TYPE",
        "FRAME_TYPE_PCM16",
        "VIDEO_BUFFER_TYPE",
        "VIDEO_BUFFER_RAW_DATA",
        "VIDEO_BUFFER_ARRAY",
        "VIDEO_BUFFER_TEXTURE",
        "VIDEO_FRAME_TYPE",
        "FRAME_TYPE_YUV420",
        "FRAME_TYPE_YUV422",
        "FRAME_TYPE_RGBA",
        "FRAME_TYPE_BGRA",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisAudioFrame",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisVideoFrame",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisWindowCollection",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisDisplayCollection",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisWindow",
        "MarshalAs",
        "UnmanagedType",
        "ByValTStr",
        "SizeConst",
        "MarshalAs",
        "UnmanagedType",
        "ByValTStr",
        "SizeConst",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisDisplay",
        "StructLayout",
        "LayoutKind",
        "Sequential",
        "IrisRect",
        "AudioRoute",
        "ROUTE_DEFAULT",
        "ROUTE_HEADSET",
        "ROUTE_EARPIECE",
        "ROUTE_HEADSETNOMIC",
        "ROUTE_SPEAKERPHONE",
        "ROUTE_LOUDSPEAKER",
        "ROUTE_HEADSETBLUETOOTH",
        "ROUTE_HDMI",
        "ROUTE_USB",
        "BYTES_PER_SAMPLE",
        "TWO_BYTES_PER_SAMPLE",
        "sample_rate",
        "channels",
        "frames_per_buffer",
        "sample_rate",
        "sample_rate",
        "channels",
        "channels",
        "frames_per_buffer",
        "frames_per_buffer",
        "RAW_AUDIO_FRAME_OP_MODE_TYPE",
        "RAW_AUDIO_FRAME_OP_MODE_READ_ONLY",
        "RAW_AUDIO_FRAME_OP_MODE_READ_WRITE",
        "MAX_METADATA_SIZE_TYPE",
        "MAX_METADATA_SIZE_IN_BYTE",
        "VIDEO_PIXEL_FORMAT",
        "VIDEO_PIXEL_UNKNOWN",
        "VIDEO_PIXEL_I420",
        "VIDEO_PIXEL_BGRA",
        "VIDEO_PIXEL_NV21",
        "VIDEO_PIXEL_RGBA",
        "VIDEO_PIXEL_NV12",
        "VIDEO_TEXTURE_2D",
        "VIDEO_TEXTURE_OES",
        "VIDEO_PIXEL_I422",
        "RENDER_MODE_TYPE",
        "RENDER_MODE_HIDDEN",
        "RENDER_MODE_FIT",
        "RENDER_MODE_ADAPTIVE",
        "EGL_CONTEXT_TYPE",
        "EGL_CONTEXT10",
        "EGL_CONTEXT14",
        "VIDEO_BUFFER_TYPE",
        "VIDEO_PIXEL_FORMAT",
        "format",
        "buffer",
        "stride",
        "height",
        "timestamp",
        "eglContext",
        "EGL_CONTEXT_TYPE",
        "eglType",
        "textureId",
        "metadata_buffer",
        "metadata_size",
        "cropLeft",
        "cropTop",
        "cropRight",
        "cropBottom",
        "rotation",
        "format",
        "format",
        "buffer",
        "buffer",
        "stride",
        "stride",
        "height",
        "height",
        "cropLeft",
        "cropLeft",
        "cropTop",
        "cropTop",
        "cropRight",
        "cropRight",
        "cropBottom",
        "cropBottom",
        "rotation",
        "rotation",
        "timestamp",
        "timestamp",
        "eglContext",
        "eglContext",
        "eglType",
        "eglType",
        "textureId",
        "textureId",
        "metadata_buffer",
        "metadata_buffer",
        "metadata_size",
        "metadata_size",
        "AUDIO_FRAME_TYPE",
        "samplesPerChannel",
        "bytesPerSample",
        "channels",
        "samplesPerSec",
        "buffer",
        "renderTimeMs",
        "avsync_type",
        "samplesPerChannel",
        "samplesPerChannel",
        "bytesPerSample",
        "bytesPerSample",
        "channels",
        "channels",
        "samplesPerSec",
        "samplesPerSec",
        "buffer",
        "buffer",
        "renderTimeMs",
        "renderTimeMs",
        "avsync_type",
        "avsync_type",
        "VideoSourceType",
        "kVideoSourceCameraPrimary",
        "kVideoSourceCamera",
        "kVideoSourceCameraPrimary",
        "kVideoSourceCameraSecondary",
        "kVideoSourceScreenPrimary",
        "kVideoSourceScreen",
        "kVideoSourceScreenPrimary",
        "kVideoSourceScreenSecondary",
        "kVideoSourceCustom",
        "kVideoSourceMediaPlayer",
        "kVideoSourceRtmImagePng",
        "kVideoSourceRtcImageJpeg",
        "kVideoSourceRtcImageGif",
        "kVideoSourceRemote",
        "kVideoSourceTranscoded",
        "kVideoSourceUnknown"
    ],
    "literals": [],
    "variables": [
        "AUDIO_FRAME_TYPE",
        "samples",
        "bytes_per_sample",
        "channels",
        "samples_per_sec",
        "IntPtr",
        "buffer",
        "buffer_length",
        "render_time_ms",
        "av_sync_type",
        "VIDEO_FRAME_TYPE",
        "width",
        "height",
        "y_stride",
        "u_stride",
        "v_stride",
        "IntPtr",
        "y_buffer",
        "IntPtr",
        "u_buffer",
        "IntPtr",
        "v_buffer",
        "y_buffer_length",
        "u_buffer_length",
        "v_buffer_length",
        "rotation",
        "render_time_ms",
        "av_sync_type",
        "IntPtr",
        "windows",
        "length",
        "IntPtr",
        "displays",
        "length",
        "id",
        "name",
        "owner_name",
        "IrisRect",
        "bounds",
        "IrisRect",
        "work_area",
        "id",
        "scale",
        "IrisRect",
        "bounds",
        "IrisRect",
        "work_area",
        "rotation",
        "x",
        "y",
        "width",
        "height",
        "sample_rate",
        "channels",
        "frames_per_buffer",
        "VIDEO_BUFFER_TYPE",
        "VIDEO_PIXEL_FORMAT",
        "format",
        "buffer",
        "stride",
        "height",
        "cropLeft",
        "cropTop",
        "cropRight",
        "cropBottom",
        "rotation",
        "timestamp",
        "eglContext",
        "EGL_CONTEXT_TYPE",
        "eglType",
        "textureId",
        "metadata_buffer",
        "metadata_size",
        "VIDEO_PIXEL_FORMAT",
        "width",
        "height",
        "yStride",
        "uStride",
        "vStride",
        "yBuffer",
        "IntPtr",
        "yBufferPtr",
        "uBuffer",
        "IntPtr",
        "uBufferPtr",
        "vBuffer",
        "IntPtr",
        "vBufferPtr",
        "rotation",
        "renderTimeMs",
        "avsync_type",
        "metadata_buffer",
        "metadata_size",
        "AUDIO_FRAME_TYPE",
        "samplesPerChannel",
        "bytesPerSample",
        "channels",
        "samplesPerSec",
        "buffer",
        "IntPtr",
        "bufferPtr",
        "renderTimeMs",
        "avsync_type"
    ],
    "comments": [
        "AgoraMediaBase.cs",
        "",
        "Created by YuGuo Chen on October 11, 2021.",
        "",
        "Copyright © 2021 Agora. All rights reserved.",
        "",
        "0: PCM16.",
        "PCM 16bit little endian",
        "The video buffer type.",
        "1: The video buffer in the format of raw data.",
        "The video frame type.",
        "0: YUV420.",
        "YUV 420 format",
        "YUV 422 format",
        "RGBA format",
        "BGRA format",
        "",
        "",
        "",
        "0: Read-only mode: Users only read the\n            agora::media::IAudioFrameObserver::AudioFrame data without modifying\n            anything. For example, when users acquire data with the Agora SDK then push\n            the RTMP streams.",
        "2: Read and write mode: Users read the data from AudioFrame, modify it,\n            and then play it. For example, when users have their own sound-effect\n            processing module and do some voice pre-processing such as a voice change.",
        "The external video frame.",
        "The buffer type. See #VIDEO_BUFFER_TYPE",
        "The pixel format. See #VIDEO_PIXEL_FORMAT",
        "The video buffer.",
        "Line spacing of the incoming video frame, which must be in pixels instead of bytes. For textures, it is the width of the texture.",
        "Height of the incoming video frame.",
        "[Raw data related parameter] The number of pixels trimmed from the left. The default value is 0.",
        "[Raw data related parameter] The number of pixels trimmed from the top. The default value is 0.",
        "[Raw data related parameter] The number of pixels trimmed from the right. The default value is 0.",
        "[Raw data related parameter] The number of pixels trimmed from the bottom. The default value is 0.",
        "[Raw data related parameter] The clockwise rotation of the video frame. You can set the rotation angle as 0, 90, 180, or 270. The default value is 0.",
        "Timestamp of the incoming video frame (ms). An incorrect timestamp results in frame loss or unsynchronized audio and video.",
        "Video frame containing the Agora RTC SDK's encoded video data.",
        "The video frame type: #VIDEO_PIXEL_FORMAT.",
        "Width (pixel) of the video frame.",
        "Height (pixel) of the video frame.",
        "Line span of the Y buffer within the YUV data.",
        "stride of Y data buffer",
        "Line span of the U buffer within the YUV data.",
        "stride of U data buffer",
        "Line span of the V buffer within the YUV data.",
        "stride of V data buffer",
        "Pointer to the Y buffer pointer within the YUV data.",
        "Y data buffer",
        "Pointer to the U buffer pointer within the YUV data.",
        "U data buffer",
        "Pointer to the V buffer pointer within the YUV data.",
        "V data buffer",
        "Set the rotation of this frame before rendering the video. Supports 0, 90, 180, 270 degrees clockwise.",
        "Set the rotation of this frame before rendering the video. Supports 0, 90, 180, 270 degrees clockwise.",
        "rotation of this frame (0, 90, 180, 270)",
        "The timestamp of the external audio frame. It is mandatory. You can use this parameter for the following purposes:\n         * - Restore the order of the captured audio frame.\n         * - Synchronize audio and video frames in video-related scenarios, including scenarios where external video sources are used.\n         * @note This timestamp is for rendering the video stream, and not for capturing the video stream.",
        "Reserved for future use.",
        "Definition of AudioFrame",
        "The type of the audio frame. See #AUDIO_FRAME_TYPE",
        "The number of samples per channel in the audio frame.",
        "number of samples for each channel in this frame",
        "The number of bytes per audio sample, which is usually 16-bit (2-byte).",
        "number of bytes per sample: 2 for PCM16",
        "The number of audio channels.\n\t\t - 1: Mono\n\t\t - 2: Stereo (the data is interleaved)",
        "number of channels (data are interleaved if stereo)",
        "The sample rate.",
        "sampling rate",
        "The data buffer of the audio frame. When the audio frame uses a stereo channel, the data buffer is interleaved.\n\t\t The size of the data buffer is as follows: `buffer` = `samples` × `channels` × `bytesPerSample`.",
        "data buffer",
        "The timestamp of the external audio frame. You can use this parameter for the following purposes:\n\t\t - Restore the order of the captured audio frame.\n\t\t - Synchronize audio and video frames in video-related scenarios, including where external video sources are used.",
        "Reserved parameter.",
        "Video captured by the camera.",
        "Video captured by the secondary camera.",
        "Video for screen sharing.",
        "Video for secondary screen sharing.",
        "Not define.",
        "Video for media player sharing.",
        "Video for png image.",
        "Video for png image.",
        "Video for png image.",
        "Remote video received from network.",
        "Video for transcoded."
    ],
    "docstrings": [
        "* 0: The audio playback device.",
        "* 1: Microphone.",
        "* 2: Video captured by primary camera.",
        "* 3: Video captured by secondary camera.",
        "* 4: Video captured by primary screen capturer.",
        "* 5: Video captured by secondary screen capturer.",
        "* 6: Video captured by custom video source.",
        "* 7: Video for media player sharing.",
        "* 8: Video for png image.",
        "* 9: Video for jpeg image.",
        "* 10: Video for gif image.",
        "* 11: Remote video received from network.",
        "* 12: Video for transcoded.",
        "* 100: unknown media source.",
        "* 2: The same as VIDEO_BUFFER_RAW_DATA.",
        "* 3: The video buffer in the format of texture.",
        "* 1: YUV422.",
        "* 2: RGBA",
        "* 2: BGRA",
        "* Audio routes.",
        "* -1: The default audio route.",
        "* The headset.",
        "* The earpiece.",
        "* The headset with no microphone.",
        "* The speakerphone.",
        "* The loudspeaker.",
        "* The Bluetooth headset.",
        "* The HDMI",
        "* The USB",
        "* Bytes per sample",
        "* two bytes per sample",
        "* The maximum metadata size.",
        "* Video pixel formats.",
        "* 0: Unknown format.",
        "* 1: I420.",
        "* 2: BGRA.",
        "* 3: NV21.",
        "* 4: RGBA.",
        "* 8: NV12.",
        "* 10: GL_TEXTURE_2D",
        "* 11: GL_TEXTURE_OES",
        "* 16: I422.",
        "* The video display mode.",
        "* 1: Uniformly scale the video until it fills the visible boundaries\n        * (cropped). One dimension of the video may have clipped contents.",
        "* 2: Uniformly scale the video until one of its dimension fits the boundary\n        * (zoomed to fit). Areas that are not filled due to the disparity in the\n        * aspect ratio will be filled with black.",
        "* @deprecated\n        * 3: This mode is deprecated.",
        "* The EGL context type.",
        "* 0: When using the OpenGL interface (javax.microedition.khronos.egl.*) defined by Khronos",
        "* 0: When using the OpenGL interface (android.opengl.*) defined by Android",
        "* [Texture-related parameter]\n        * When using the OpenGL interface (javax.microedition.khronos.egl.*) defined by Khronos, set EGLContext to this field.\n        * When using the OpenGL interface (android.opengl.*) defined by Android, set EGLContext to this field.",
        "* [Texture related parameter] Texture ID used by the video frame.",
        "* [Texture related parameter] Incoming 4 &times; 4 transformational matrix. The typical value is a unit matrix.",
        "* [Texture related parameter] The MetaData buffer.\n        *  The default value is NULL",
        "* [Texture related parameter] The MetaData size.\n        *  The default value is 0",
        "* [Texture related parameter] The MetaData buffer.\n        *  The default value is NULL",
        "* [Texture related parameter] The MetaData size.\n        *  The default value is 0",
        "* Video source types definition.\n    *"
    ],
    "functions": [
        "AudioParameters",
        "AudioParameters",
        "ExternalVideoFrame",
        "ExternalVideoFrame",
        "AudioFrame",
        "AudioFrame"
    ],
    "classes": [
        "AudioParameters",
        "ExternalVideoFrame",
        "VideoFrame",
        "AudioFrame"
    ]
}