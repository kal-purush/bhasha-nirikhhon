{
    "identifiers": [
        "absolute_import",
        "division",
        "print_function",
        "tensorflow",
        "tf",
        "guessnet",
        "GuessNet",
        "random",
        "math",
        "array",
        "tensorflow",
        "examples",
        "tutorials",
        "mnist",
        "input_data",
        "input_data",
        "read_data_sets",
        "one_hot",
        "IMAGE_SIZE",
        "IMAGE_SIZE",
        "tf",
        "placeholder",
        "tf",
        "float32",
        "IMAGE_PIXELS",
        "tf",
        "placeholder",
        "tf",
        "float32",
        "GUESS_COUNT_PER_INPUT",
        "ONE_HOT_RANDOM_SIZE",
        "tf",
        "reshape",
        "one_hot_random",
        "shape",
        "BATCH_SIZE",
        "GUESS_COUNT_PER_INPUT",
        "ONE_HOT_RANDOM_SIZE",
        "__guess",
        "compressed",
        "tf",
        "reshape",
        "guesses_compressed",
        "shape",
        "BATCH_SIZE",
        "GUESS_COUNT_PER_INPUT",
        "IMAGE_PIXELS",
        "__generate",
        "guesses",
        "__guess_mask",
        "__error",
        "guesses",
        "one_hot_random_compressed",
        "tf",
        "Variable",
        "tf",
        "truncated_normal",
        "ONE_HOT_RANDOM_SIZE",
        "IMAGE_PIXELS",
        "stddev",
        "tf",
        "Variable",
        "tf",
        "constant",
        "shape",
        "IMAGE_PIXELS",
        "tf",
        "nn",
        "relu",
        "tf",
        "matmul",
        "one_hot_random_compressed",
        "W1",
        "b1",
        "guesses",
        "tf",
        "tile",
        "tf",
        "expand_dims",
        "original",
        "GUESS_COUNT_PER_INPUT",
        "tf",
        "reduce_mean",
        "tf",
        "square",
        "guesses",
        "original_x_guess_count",
        "axis",
        "error",
        "tf",
        "expand_dims",
        "tf",
        "reduce_max",
        "error",
        "axis",
        "tf",
        "exp",
        "tf",
        "exp",
        "maximum_error",
        "error",
        "tf",
        "expand_dims",
        "tf",
        "reduce_sum",
        "grounded_error",
        "axis",
        "grounded_error",
        "scale",
        "guesses",
        "guesses_mask",
        "tf",
        "matmul",
        "tf",
        "expand_dims",
        "guesses_mask",
        "guesses",
        "tf",
        "squeeze",
        "masked",
        "axis",
        "GuessNetMark1Mnist",
        "net",
        "layers",
        "tf",
        "reduce_mean",
        "tf",
        "nn",
        "softmax_cross_entropy_with_logits",
        "labels",
        "net",
        "original",
        "logits",
        "layers",
        "tf",
        "train",
        "GradientDescentOptimizer",
        "minimize",
        "cross_entropy",
        "tf",
        "summary",
        "scalar",
        "cross_entropy",
        "tf",
        "summary",
        "image",
        "tf",
        "reshape",
        "layers",
        "BATCH_SIZE",
        "IMAGE_SIZE",
        "IMAGE_SIZE",
        "tf",
        "summary",
        "merge_all",
        "tf",
        "global_variables_initializer",
        "tf",
        "Session",
        "sess",
        "sess",
        "run",
        "init",
        "tf",
        "summary",
        "FileWriter",
        "graph",
        "tf",
        "get_default_graph",
        "i",
        "mnist",
        "train",
        "next_batch",
        "BATCH_SIZE",
        "net",
        "one_hot_random",
        "GuessNet",
        "get_one_hot_random",
        "shape",
        "BATCH_SIZE",
        "GUESS_COUNT_PER_INPUT",
        "ONE_HOT_RANDOM_SIZE",
        "net",
        "original",
        "batch_original",
        "sess",
        "run",
        "merged",
        "train_step",
        "feed_dict",
        "feed_dict",
        "sess",
        "run",
        "cross_entropy",
        "feed_dict",
        "feed_dict",
        "writer",
        "add_summary",
        "summary",
        "i",
        "writer",
        "flush",
        "error"
    ],
    "literals": [
        "'MNIST_data'",
        "'cross_entropy'",
        "'guess'",
        "'/code/logs'"
    ],
    "variables": [
        "mnist",
        "IMAGE_SIZE",
        "IMAGE_PIXELS",
        "ONE_HOT_RANDOM_SIZE",
        "GUESS_COUNT_PER_INPUT",
        "BATCH_SIZE",
        "original",
        "one_hot_random",
        "compressed",
        "guesses_compressed",
        "guesses",
        "W1",
        "b1",
        "original_x_guess_count",
        "maximum_error",
        "grounded_error",
        "scale",
        "masked",
        "net",
        "layers",
        "cross_entropy",
        "train_step",
        "merged",
        "init",
        "writer",
        "batch_original",
        "_",
        "feed_dict",
        "summary",
        "_",
        "error"
    ],
    "comments": [
        "tf.matmul(maximum_error, error)",
        "Train",
        "print(sess.run([layers], feed_dict=feed_dict))"
    ],
    "docstrings": [
        "\"\"\"\ndef layer(batch_size):\n    guess = []\n    error = []\n    for i in range(GUESS_COUNT_PER_INPUT):\n        guess.append(cell(tf_get_element_at(one_hot_random, i, [batch_size, ONE_HOT_RANDOM_SIZE])))\n        error.append(tf.reduce_mean(500 - tf.abs(guess[i] - original), 1))\n\n    #transposed_error = tf.transpose(tf.pack(error))\n    #normalized_error = tf.reduce_max(transposed_error, axis=1) - transposed_error# - tf.reduce_min(transposed_error, axis=1)\n    #normalized_error = 1 - tf.truediv((transposed_error - tf.reduce_min(transposed_error, axis=1)), tf.reduce_max(transposed_error, axis=1))\n\n    normalized_error = tf.transpose(tf.pack(error)) #tf.nn.softmax(pack, dim=0)\n    guess_reshaped = tf.transpose(guess, perm=[1,2,0])\n    error_reshaped = tf.expand_dims(normalized_error, 2)\n\n    return tf.squeeze(tf.matmul(guess_reshaped, error_reshaped), axis=2)\n\n\n\n    #return tf.reduce_sum(guess_sum, axis=0)\n    #softmax_error = tf.nn.softmax(tf.pack(error), dim=0)\n    #return tf.squeeze(tf.matmul(tf.expand_dims(softmax_error, 1), guess), axis=1)\n\n    #error_reshaped = tf.expand_dims(tf.transpose(softmax_error),1)\n    #guess_reshaped = tf.transpose(guess, perm=[1,0,2])\n\n    #return tf.squeeze(tf.matmul(error_reshaped, guess_reshaped), axis=1)\n    #result before softmax [batch, GUESS_COUNT_PER_INPUT]\n\n\nlayer1 = layer(BATCH_SIZE)\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=original, logits=layer1))\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n\n\ntf.summary.scalar('cross_entropy', cross_entropy)\nimg = tf.reshape(layer1, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1])\ntf.summary.image('guess', img)\nmerged = tf.summary.merge_all()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    writer = tf.summary.FileWriter('/code/logs', graph=tf.get_default_graph())\n\n    # Train\n    for i in range(340):\n        batch_original, _ = mnist.train.next_batch(BATCH_SIZE)\n        feed_dict = {one_hot_random: get_one_hot_random_batch(BATCH_SIZE), original: batch_original}\n        summary, _ = sess.run([merged, train_step], feed_dict=feed_dict)\n        error = sess.run(cross_entropy, feed_dict=feed_dict)\n        writer.add_summary(summary, i)\n        writer.flush()\n        print(error)\n\n    writer.close()\n\"\"\""
    ],
    "functions": [
        "layers",
        "__guess",
        "__error",
        "__guess_mask",
        "__generate"
    ],
    "classes": [
        "GuessNetMark1Mnist"
    ]
}