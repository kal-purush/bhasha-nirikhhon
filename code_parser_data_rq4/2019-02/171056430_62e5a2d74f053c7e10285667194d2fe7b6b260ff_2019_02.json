{
    "identifiers": [
        "os",
        "tensorflow",
        "tf",
        "keras",
        "models",
        "Model",
        "keras",
        "models",
        "load_model",
        "keras",
        "optimizers",
        "Adam",
        "keras",
        "losses",
        "sparse_categorical_crossentropy",
        "keras",
        "preprocessing",
        "sequence",
        "pad_sequences",
        "numpy",
        "np",
        "glob",
        "re",
        "pickle",
        "nltk",
        "tokenize",
        "sent_tokenize",
        "word_tokenize",
        "data",
        "file",
        "folder",
        "os",
        "path",
        "join",
        "folder",
        "file",
        "open",
        "location",
        "ff",
        "pickle",
        "dump",
        "data",
        "ff",
        "protocol",
        "pickle",
        "HIGHEST_PROTOCOL",
        "file",
        "folder",
        "os",
        "path",
        "join",
        "folder",
        "file",
        "open",
        "location",
        "ff",
        "pickle",
        "load",
        "ff",
        "data",
        "data",
        "sent",
        "line",
        "re",
        "split",
        "data",
        "line",
        "sent",
        "sent_tokenize",
        "line",
        "strip",
        "sent",
        "text",
        "join",
        "c",
        "c",
        "text",
        "c",
        "punctuation",
        "text",
        "text",
        "re",
        "sub",
        "text",
        "text",
        "text",
        "ord",
        "ch",
        "harakat",
        "ch",
        "text",
        "text",
        "join",
        "c",
        "c",
        "text",
        "ord",
        "c",
        "harakat",
        "text",
        "join",
        "chr",
        "item",
        "item",
        "harakat",
        "sentence",
        "ch",
        "reversed",
        "sentence",
        "ord",
        "ch",
        "harakat",
        "current_haraka",
        "ord",
        "ch",
        "connector",
        "chr",
        "connector",
        "current_haraka",
        "chr",
        "connector",
        "current_haraka",
        "current_haraka",
        "ch",
        "current_haraka",
        "output",
        "insert",
        "current_haraka",
        "output",
        "input_sent",
        "output_sent",
        "character",
        "haraka",
        "input_sent",
        "output_sent",
        "haraka",
        "replace",
        "replace",
        "replace",
        "character",
        "haraka",
        "ord",
        "haraka",
        "connector",
        "harakat_stack",
        "pop",
        "combine",
        "haraka",
        "harakat_stack",
        "push",
        "combine",
        "harakat_stack",
        "push",
        "haraka",
        "len",
        "input_sent",
        "harakat_stack",
        "size",
        "index",
        "input_length",
        "output_length",
        "harakat_stack",
        "push",
        "character",
        "haraka",
        "input_sent",
        "harakat_stack",
        "to_array",
        "text",
        "character",
        "haraka",
        "text",
        "size",
        "item",
        "stack",
        "append",
        "item",
        "stack",
        "pop",
        "size",
        "stack",
        "len",
        "stack",
        "len",
        "stack",
        "stack",
        "folder_location",
        "folder_location",
        "os",
        "path",
        "join",
        "folder_location",
        "os",
        "path",
        "join",
        "model_folder",
        "os",
        "path",
        "join",
        "folder_location",
        "load_binary",
        "dictionary_folder",
        "load_binary",
        "dictionary_folder",
        "input_vocab_to_int",
        "output_int_to_vocab",
        "load_model",
        "model_location",
        "tf",
        "get_default_graph",
        "model",
        "graph",
        "input_sent",
        "input_sent",
        "len",
        "input_sent",
        "max_sentence",
        "format",
        "max_sentence",
        "input_sent",
        "__preprocess",
        "input_sent",
        "input_sent",
        "dictionary",
        "input_vocab_to_int",
        "get",
        "ch",
        "input_vocab_to_int",
        "ch",
        "sent",
        "sent",
        "input_sent",
        "__pad_size",
        "input_letters_ids",
        "max_sentence",
        "input_letters_ids",
        "logits",
        "join",
        "dictionary",
        "prediction",
        "prediction",
        "np",
        "argmax",
        "logits",
        "text",
        "replace",
        "input_sent",
        "output_sent",
        "combine_text_with_harakat",
        "input_sent",
        "output_sent",
        "input_sent",
        "clear_tashkel",
        "input_sent",
        "x",
        "length",
        "pad_sequences",
        "x",
        "maxlen",
        "length",
        "padding"
    ],
    "literals": [
        "'.pickle'",
        "'wb'",
        "'.pickle'",
        "'rb'",
        "\"[\\n,،]+\"",
        "\"\"",
        "r\"[a-zA-Z0-9٠-٩]\"",
        "\" \"",
        "\"\"",
        "\"\"",
        "\"|\"",
        "\"\"",
        "\"\"",
        "\"\"",
        "\"ـ\"",
        "\"\"",
        "\"<UNK>\"",
        "\"\"",
        "\"<PAD>\"",
        "\"\"",
        "\"ـ\"",
        "\"\"",
        "\" \"",
        "\"\"",
        "\"\"",
        "\"\"",
        "\"\"",
        "\"model_location cant be empty, send location of keras model\"",
        "'model'",
        "'second_model6'",
        "'.h5'",
        "'dictionary'",
        "'input_vocab_to_int'",
        "'output_int_to_vocab'",
        "\"input_vocab_to_int\"",
        "\"output_int_to_vocab\"",
        "'start load model'",
        "'end load model'",
        "\"max length for input_sent should be {} characters, you can split the sentence into multiple sentecens and call the function\"",
        "\"input_vocab_to_int\"",
        "'<UNK>'",
        "\"\"",
        "'output_int_to_vocab'",
        "'<PAD>'",
        "''",
        "'post'"
    ],
    "variables": [
        "harakat",
        "connector",
        "location",
        "location",
        "data",
        "text",
        "text",
        "text",
        "output",
        "current_haraka",
        "current_haraka",
        "current_haraka",
        "harakat_stack",
        "haraka",
        "combine",
        "input_length",
        "output_length",
        "text",
        "stack",
        "model_folder",
        "max_sentence",
        "model_location",
        "dictionary_folder",
        "input_vocab_to_int",
        "output_int_to_vocab",
        "dictionary",
        "model",
        "graph",
        "input_sent",
        "input_vocab_to_int",
        "input_letters_ids",
        "input_letters_ids",
        "text"
    ],
    "comments": [
        "!/usr/bin/env python3",
        "-*- coding: utf-8 -*-",
        "process harakat",
        "fix combine differences",
        "combine with text",
        "model",
        "input processing",
        "output processing",
        "common"
    ],
    "docstrings": [],
    "functions": [
        "save_binary",
        "load_binary",
        "get_sentences",
        "clear_punctuations",
        "clear_english_and_numbers",
        "is_tashkel",
        "clear_tashkel",
        "get_harakat",
        "get_taskel",
        "combine_text_with_harakat",
        "isEmpty",
        "push",
        "pop",
        "peek",
        "size",
        "to_array",
        "get_model",
        "prepare_input",
        "__preprocess",
        "logits_to_text",
        "get_final_text",
        "clean_harakat",
        "__pad_size"
    ],
    "classes": [
        "Shakkala"
    ]
}