{
    "identifiers": [
        "argparse",
        "logging",
        "torch",
        "numpy",
        "np",
        "pytorch_pretrained_bert",
        "GPT2LMHeadModel",
        "GPT2Tokenizer",
        "logging",
        "basicConfig",
        "format",
        "datefmt",
        "level",
        "logging",
        "INFO",
        "logging",
        "getLogger",
        "logits",
        "k",
        "k",
        "logits",
        "torch",
        "topk",
        "logits",
        "k",
        "values",
        "torch",
        "where",
        "logits",
        "min_values",
        "torch",
        "ones_like",
        "logits",
        "dtype",
        "logits",
        "dtype",
        "logits",
        "model",
        "length",
        "start_token",
        "batch_size",
        "context",
        "temperature",
        "top_k",
        "device",
        "start_token",
        "context",
        "torch",
        "tensor",
        "context",
        "device",
        "device",
        "context",
        "torch",
        "full",
        "batch_size",
        "start_token",
        "device",
        "device",
        "context",
        "context",
        "torch",
        "no_grad",
        "i",
        "length",
        "model",
        "prev",
        "past",
        "past",
        "logits",
        "temperature",
        "top_k_logits",
        "logits",
        "k",
        "top_k",
        "torch",
        "multinomial",
        "logits",
        "torch",
        "cat",
        "output",
        "prev",
        "dim",
        "output",
        "argparse",
        "ArgumentParser",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "parser",
        "add_argument",
        "parser",
        "add_argument",
        "parser",
        "add_argument",
        "parser",
        "add_argument",
        "parser",
        "add_argument",
        "parser",
        "parse_args",
        "args",
        "np",
        "random",
        "seed",
        "args",
        "seed",
        "torch",
        "random",
        "manual_seed",
        "args",
        "seed",
        "torch",
        "cuda",
        "manual_seed",
        "args",
        "seed",
        "torch",
        "device",
        "torch",
        "cuda",
        "is_available",
        "GPT2Tokenizer",
        "from_pretrained",
        "args",
        "model_name_or_path",
        "GPT2LMHeadModel",
        "from_pretrained",
        "args",
        "model_name_or_path",
        "args",
        "length",
        "model",
        "config",
        "n_ctx",
        "args",
        "length",
        "model",
        "config",
        "n_ctx",
        "ValueError",
        "model",
        "config",
        "n_ctx",
        "args",
        "nsamples",
        "generated",
        "args",
        "nsamples",
        "sample_sequence",
        "model",
        "model",
        "length",
        "args",
        "length",
        "start_token",
        "enc",
        "encoder",
        "batch_size",
        "args",
        "batch_size",
        "temperature",
        "args",
        "temperature",
        "top_k",
        "args",
        "top_k",
        "device",
        "device",
        "i",
        "args",
        "batch_size",
        "generated",
        "args",
        "batch_size",
        "enc",
        "decode",
        "i",
        "generated",
        "text",
        "sample_model"
    ],
    "literals": [
        "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'",
        "'%m/%d/%Y %H:%M:%S'",
        "'cuda'",
        "'Specify exactly one of start_token and context!'",
        "'Specify exactly one of start_token and context!'",
        "'--model_name_or_path'",
        "'gpt2'",
        "'pretrained model name or path to local checkpoint'",
        "\"--seed\"",
        "\"--nsamples\"",
        "\"--batch_size\"",
        "\"--length\"",
        "\"--temperature\"",
        "\"--top_k\"",
        "\"cuda\"",
        "\"cpu\"",
        "\"Can't get samples longer than window size: %s\"",
        "'<|endoftext|>'",
        "\"=\"",
        "\" SAMPLE \"",
        "\" \"",
        "\"=\"",
        "'__main__'"
    ],
    "variables": [
        "logger",
        "values",
        "_",
        "min_values",
        "context",
        "context",
        "prev",
        "output",
        "logits",
        "past",
        "logits",
        "logits",
        "prev",
        "output",
        "parser",
        "args",
        "device",
        "enc",
        "model",
        "args",
        "length",
        "generated",
        "text"
    ],
    "comments": [
        "!/usr/bin/env python3"
    ],
    "docstrings": [],
    "functions": [
        "top_k_logits",
        "sample_sequence",
        "sample_model"
    ],
    "classes": []
}