{
    "identifiers": [
        "nn",
        "Module",
        "d_model",
        "num_heads",
        "d_ff",
        "dropout",
        "EncoderLayer",
        "MultiHeadAttention",
        "d_model",
        "num_heads",
        "PositionWiseFeedForward",
        "d_model",
        "d_ff",
        "nn",
        "LayerNorm",
        "d_model",
        "nn",
        "LayerNorm",
        "d_model",
        "nn",
        "Dropout",
        "dropout",
        "x",
        "mask",
        "self_attn",
        "x",
        "x",
        "x",
        "mask",
        "norm1",
        "x",
        "dropout",
        "attn_output",
        "feed_forward",
        "x",
        "norm2",
        "x",
        "dropout",
        "ff_output",
        "x",
        "nn",
        "Module",
        "d_model",
        "num_heads",
        "d_ff",
        "dropout",
        "DecoderLayer",
        "MultiHeadAttention",
        "d_model",
        "num_heads",
        "MultiHeadAttention",
        "d_model",
        "num_heads",
        "PositionWiseFeedForward",
        "d_model",
        "d_ff",
        "nn",
        "LayerNorm",
        "d_model",
        "nn",
        "LayerNorm",
        "d_model",
        "nn",
        "LayerNorm",
        "d_model",
        "nn",
        "Dropout",
        "dropout",
        "x",
        "enc_output",
        "src_mask",
        "tgt_mask",
        "self_attn",
        "x",
        "x",
        "x",
        "tgt_mask",
        "norm1",
        "x",
        "dropout",
        "attn_output",
        "cross_attn",
        "x",
        "enc_output",
        "enc_output",
        "src_mask",
        "norm2",
        "x",
        "dropout",
        "attn_output",
        "feed_forward",
        "x",
        "norm3",
        "x",
        "dropout",
        "ff_output",
        "x"
    ],
    "literals": [],
    "variables": [
        "self_attn",
        "feed_forward",
        "norm1",
        "norm2",
        "dropout",
        "attn_output",
        "x",
        "ff_output",
        "x",
        "self_attn",
        "cross_attn",
        "feed_forward",
        "norm1",
        "norm2",
        "norm3",
        "dropout",
        "attn_output",
        "x",
        "attn_output",
        "x",
        "ff_output",
        "x"
    ],
    "comments": [],
    "docstrings": [],
    "functions": [
        "forward",
        "forward"
    ],
    "classes": [
        "EncoderLayer",
        "DecoderLayer"
    ]
}