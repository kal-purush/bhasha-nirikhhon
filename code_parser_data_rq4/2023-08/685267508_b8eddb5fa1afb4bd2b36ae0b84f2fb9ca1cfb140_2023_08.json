{
    "identifiers": [
        "Globalization",
        "IO",
        "MemoryMappedFiles",
        "Runtime",
        "Intrinsics",
        "Runtime",
        "Intrinsics",
        "X86",
        "Text",
        "BigMemory",
        "T",
        "T",
        "MemoryMappedViewAccessor",
        "view",
        "start",
        "length",
        "view",
        "SafeMemoryMappedViewHandle",
        "AcquirePointer",
        "_ptr",
        "_start",
        "start",
        "_length",
        "length",
        "ptr",
        "start",
        "length",
        "_ptr",
        "ptr",
        "_start",
        "start",
        "_length",
        "length",
        "T",
        "GetSpan",
        "T",
        "T",
        "_ptr",
        "_start",
        "_length",
        "BigMemory",
        "T",
        "start",
        "start",
        "_length",
        "ArgumentOutOfRangeException",
        "nameof",
        "start",
        "BigMemory",
        "T",
        "_ptr",
        "_start",
        "start",
        "_length",
        "start",
        "BigMemory",
        "T",
        "start",
        "length",
        "start",
        "_length",
        "length",
        "_length",
        "start",
        "ArgumentOutOfRangeException",
        "BigMemory",
        "T",
        "_ptr",
        "_start",
        "start",
        "length",
        "BinaryReader",
        "buffer",
        "dim",
        "buffer",
        "ReadInt32",
        "hidden_dim",
        "buffer",
        "ReadInt32",
        "n_layers",
        "buffer",
        "ReadInt32",
        "n_heads",
        "buffer",
        "ReadInt32",
        "n_kv_heads",
        "buffer",
        "ReadInt32",
        "buffer",
        "ReadInt32",
        "vocab_size",
        "Abs",
        "vocab_size",
        "seq_len",
        "buffer",
        "ReadInt32",
        "shared_weights",
        "vocab_size",
        "head_size",
        "dim",
        "n_heads",
        "dim",
        "hidden_dim",
        "n_layers",
        "n_heads",
        "n_kv_heads",
        "vocab_size",
        "seq_len",
        "shared_weights",
        "head_size",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "BigMemory",
        "memorySegment",
        "position",
        "dims",
        "d",
        "dims",
        "totalBytes",
        "d",
        "totalBytes",
        "memorySegment",
        "Slice",
        "position",
        "totalBytes",
        "position",
        "totalBytes",
        "BigMemory",
        "BigMemory",
        "memorySegment",
        "position",
        "dim0",
        "dims",
        "BigMemory",
        "BigMemory",
        "dim0",
        "i",
        "dim0",
        "i",
        "segments",
        "i",
        "takeFloats",
        "memorySegment",
        "position",
        "dims",
        "segments",
        "Config",
        "config",
        "BigMemory",
        "memorySegment",
        "token_embedding_table",
        "takeFloats",
        "memorySegment",
        "position",
        "config",
        "vocab_size",
        "config",
        "dim",
        "rms_att_weight",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "dim",
        "wq",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "dim",
        "config",
        "n_heads",
        "config",
        "head_size",
        "wk",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "dim",
        "config",
        "n_kv_heads",
        "config",
        "head_size",
        "wv",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "dim",
        "config",
        "n_kv_heads",
        "config",
        "head_size",
        "wo",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "n_heads",
        "config",
        "head_size",
        "config",
        "dim",
        "rms_ffn_weight",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "dim",
        "w1",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "hidden_dim",
        "config",
        "dim",
        "w2",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "dim",
        "config",
        "hidden_dim",
        "w3",
        "takeArray",
        "memorySegment",
        "position",
        "config",
        "n_layers",
        "config",
        "hidden_dim",
        "config",
        "dim",
        "rms_final_weight",
        "takeFloats",
        "memorySegment",
        "position",
        "config",
        "dim",
        "position",
        "config",
        "seq_len",
        "config",
        "head_size",
        "position",
        "config",
        "seq_len",
        "config",
        "head_size",
        "wcls",
        "config",
        "shared_weights",
        "token_embedding_table",
        "takeFloats",
        "memorySegment",
        "position",
        "config",
        "vocab_size",
        "config",
        "dim",
        "Config",
        "config",
        "config",
        "dim",
        "config",
        "n_kv_heads",
        "config",
        "n_heads",
        "x",
        "config",
        "dim",
        "xb",
        "config",
        "dim",
        "xb2",
        "config",
        "dim",
        "hb",
        "config",
        "hidden_dim",
        "hb2",
        "config",
        "hidden_dim",
        "q",
        "config",
        "dim",
        "k",
        "kv_dim",
        "v",
        "kv_dim",
        "att",
        "config",
        "n_heads",
        "config",
        "seq_len",
        "logits",
        "config",
        "vocab_size",
        "key_cache",
        "config",
        "n_layers",
        "config",
        "seq_len",
        "kv_dim",
        "value_cache",
        "config",
        "n_layers",
        "config",
        "seq_len",
        "kv_dim",
        "checkpoint_path",
        "mappedFile",
        "MemoryMappedFile",
        "CreateFromFile",
        "checkpoint_path",
        "mappedFile",
        "CreateViewStream",
        "configSize",
        "MemoryMappedFileAccess",
        "Read",
        "BinaryReader",
        "configBuffer",
        "Encoding",
        "UTF8",
        "config",
        "Config",
        "configReader",
        "WriteLine",
        "config",
        "state",
        "RunState",
        "config",
        "mappedFile",
        "CreateViewAccessor",
        "MemoryMappedFileAccess",
        "Read",
        "weights",
        "Weights",
        "config",
        "BigMemory",
        "accessor",
        "configSize",
        "accessor",
        "Capacity",
        "tokenizer_path",
        "vocab_size",
        "vocab_size",
        "vocab_size",
        "vocab",
        "vocab_size",
        "vocab_scores",
        "vocab_size",
        "MemoryMappedFile",
        "CreateFromFile",
        "tokenizer_path",
        "CreateViewStream",
        "MemoryMappedFileAccess",
        "Read",
        "BinaryReader",
        "accessor",
        "Encoding",
        "UTF8",
        "max_token_length",
        "reader",
        "ReadInt32",
        "i",
        "vocab_size",
        "i",
        "vocab_scores",
        "i",
        "reader",
        "ReadSingle",
        "reader",
        "ReadInt32",
        "reader",
        "ReadBytes",
        "len",
        "vocab",
        "i",
        "Encoding",
        "UTF8",
        "GetString",
        "vocab_size",
        "temperature",
        "topp",
        "rng_seed",
        "vocab_size",
        "vocab_size",
        "temperature",
        "temperature",
        "topp",
        "topp",
        "rng_seed",
        "rng_seed",
        "probindex",
        "vocab_size",
        "rng_seed",
        "rng_seed",
        "rng_seed",
        "rng_seed",
        "rng_seed",
        "rng_seed",
        "rng_seed",
        "random_u32",
        "o",
        "x",
        "BigMemory",
        "weight",
        "size",
        "j",
        "size",
        "j",
        "ss",
        "x",
        "j",
        "x",
        "j",
        "ss",
        "size",
        "ss",
        "ss",
        "Sqrt",
        "ss",
        "weight",
        "j",
        "size",
        "j",
        "o",
        "j",
        "w",
        "j",
        "ss",
        "x",
        "j",
        "x",
        "xOffset",
        "size",
        "x",
        "xOffset",
        "i",
        "size",
        "i",
        "x",
        "i",
        "xOffset",
        "max_val",
        "max_val",
        "x",
        "i",
        "xOffset",
        "i",
        "size",
        "i",
        "x",
        "i",
        "xOffset",
        "Exp",
        "x",
        "i",
        "xOffset",
        "max_val",
        "sum",
        "x",
        "i",
        "xOffset",
        "i",
        "size",
        "i",
        "x",
        "i",
        "xOffset",
        "sum",
        "xout",
        "x",
        "BigMemory",
        "wSegment",
        "n",
        "d",
        "Parallel",
        "For",
        "d",
        "wSegment",
        "Vector256",
        "IsHardwareAccelerated",
        "Fma",
        "IsSupported",
        "Vector256",
        "Vector256",
        "Zero",
        "Vector256",
        "Vector256",
        "Zero",
        "Vector256",
        "Vector256",
        "Zero",
        "Vector256",
        "Vector256",
        "Zero",
        "Vector256",
        "Count",
        "n",
        "n",
        "width",
        "j",
        "upperBound",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "w",
        "i",
        "n",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "w",
        "i",
        "n",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "w",
        "i",
        "n",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "w",
        "i",
        "n",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "x",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "x",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "x",
        "j",
        "width",
        "Vector256",
        "LoadUnsafe",
        "x",
        "j",
        "width",
        "sum0",
        "Fma",
        "MultiplyAdd",
        "wj0",
        "xj0",
        "sum0",
        "sum1",
        "Fma",
        "MultiplyAdd",
        "wj1",
        "xj1",
        "sum1",
        "sum2",
        "Fma",
        "MultiplyAdd",
        "wj2",
        "xj2",
        "sum2",
        "sum3",
        "Fma",
        "MultiplyAdd",
        "wj3",
        "xj3",
        "sum3",
        "val",
        "Vector256",
        "Sum",
        "sum0",
        "sum1",
        "sum2",
        "sum3",
        "j",
        "n",
        "j",
        "val",
        "w",
        "i",
        "n",
        "j",
        "x",
        "j",
        "xout",
        "i",
        "val",
        "Transformer",
        "transformer",
        "token",
        "pos",
        "transformer",
        "config",
        "transformer",
        "weights",
        "transformer",
        "state",
        "p",
        "dim",
        "p",
        "hidden_dim",
        "p",
        "head_size",
        "p",
        "dim",
        "p",
        "n_kv_heads",
        "p",
        "n_heads",
        "p",
        "n_heads",
        "p",
        "n_kv_heads",
        "w",
        "token_embedding_table",
        "Slice",
        "token",
        "dim",
        "dim",
        "CopyTo",
        "s",
        "x",
        "l",
        "p",
        "n_layers",
        "l",
        "rmsnorm",
        "s",
        "xb",
        "s",
        "x",
        "w",
        "rms_att_weight",
        "l",
        "dim",
        "matmul",
        "s",
        "q",
        "s",
        "xb",
        "w",
        "wq",
        "l",
        "dim",
        "dim",
        "matmul",
        "s",
        "k",
        "s",
        "xb",
        "w",
        "wk",
        "l",
        "dim",
        "kv_dim",
        "matmul",
        "s",
        "v",
        "s",
        "xb",
        "w",
        "wv",
        "l",
        "dim",
        "kv_dim",
        "i",
        "dim",
        "i",
        "i",
        "head_size",
        "Pow",
        "head_dim",
        "head_size",
        "pos",
        "freq",
        "Cos",
        "val",
        "Sin",
        "val",
        "i",
        "kv_dim",
        "v",
        "rotn",
        "v",
        "v",
        "s",
        "q",
        "s",
        "k",
        "vec",
        "i",
        "vec",
        "i",
        "vec",
        "i",
        "v0",
        "fcr",
        "v1",
        "fci",
        "vec",
        "i",
        "v0",
        "fci",
        "v1",
        "fcr",
        "l",
        "p",
        "seq_len",
        "kv_dim",
        "Copy",
        "s",
        "k",
        "s",
        "key_cache",
        "loff",
        "pos",
        "kv_dim",
        "kv_dim",
        "Copy",
        "s",
        "v",
        "s",
        "value_cache",
        "loff",
        "pos",
        "kv_dim",
        "kv_dim",
        "Parallel",
        "For",
        "p",
        "n_heads",
        "h",
        "head_size",
        "h",
        "p",
        "seq_len",
        "t",
        "pos",
        "t",
        "loff",
        "t",
        "kv_dim",
        "h",
        "kv_mul",
        "head_size",
        "i",
        "head_size",
        "i",
        "score",
        "s",
        "q",
        "qOffset",
        "i",
        "s",
        "key_cache",
        "keyCacheOffset",
        "i",
        "score",
        "Sqrt",
        "head_size",
        "s",
        "att",
        "attOffset",
        "t",
        "score",
        "softmax",
        "s",
        "att",
        "attOffset",
        "pos",
        "h",
        "head_size",
        "Fill",
        "s",
        "xb",
        "xbOffset",
        "head_size",
        "t",
        "pos",
        "t",
        "loff",
        "t",
        "kv_dim",
        "h",
        "kv_mul",
        "head_size",
        "s",
        "att",
        "attOffset",
        "t",
        "i",
        "head_size",
        "i",
        "s",
        "xb",
        "xbOffset",
        "i",
        "a",
        "s",
        "value_cache",
        "vOffset",
        "i",
        "matmul",
        "s",
        "xb2",
        "s",
        "xb",
        "w",
        "wo",
        "l",
        "dim",
        "dim",
        "i",
        "dim",
        "i",
        "s",
        "x",
        "i",
        "s",
        "xb2",
        "i",
        "rmsnorm",
        "s",
        "xb",
        "s",
        "x",
        "w",
        "rms_ffn_weight",
        "l",
        "dim",
        "matmul",
        "s",
        "hb",
        "s",
        "xb",
        "w",
        "w1",
        "l",
        "dim",
        "p",
        "hidden_dim",
        "matmul",
        "s",
        "hb2",
        "s",
        "xb",
        "w",
        "w3",
        "l",
        "dim",
        "p",
        "hidden_dim",
        "i",
        "hidden_dim",
        "i",
        "s",
        "hb",
        "i",
        "val",
        "Exp",
        "val",
        "s",
        "hb",
        "i",
        "val",
        "i",
        "hidden_dim",
        "i",
        "s",
        "hb",
        "i",
        "s",
        "hb",
        "i",
        "s",
        "hb2",
        "i",
        "matmul",
        "s",
        "xb",
        "s",
        "hb",
        "w",
        "w2",
        "l",
        "p",
        "hidden_dim",
        "dim",
        "i",
        "dim",
        "i",
        "s",
        "x",
        "i",
        "s",
        "xb",
        "i",
        "rmsnorm",
        "s",
        "x",
        "s",
        "x",
        "w",
        "rms_final_weight",
        "dim",
        "matmul",
        "s",
        "logits",
        "s",
        "x",
        "w",
        "wcls",
        "dim",
        "p",
        "vocab_size",
        "s",
        "logits",
        "Tokenizer",
        "t",
        "prev_token",
        "token",
        "t",
        "vocab",
        "token",
        "prev_token",
        "piece",
        "piece",
        "piece",
        "piece",
        "Int32",
        "Parse",
        "hex2",
        "NumberStyles",
        "HexNumber",
        "ch",
        "ch",
        "isPrintable",
        "IsWhiteSpace",
        "ch",
        "piece",
        "ch",
        "ToString",
        "piece",
        "sorted_vocab",
        "sorted_vocab",
        "GetValueOrDefault",
        "Tokenizer",
        "t",
        "text",
        "tokens",
        "t",
        "sorted_vocab",
        "t",
        "sorted_vocab",
        "i",
        "t",
        "vocab_size",
        "i",
        "t",
        "sorted_vocab",
        "Add",
        "t",
        "vocab",
        "i",
        "i",
        "tokens",
        "str_lookup",
        "t",
        "sorted_vocab",
        "singleCodepoint",
        "text",
        "EnumerateRunes",
        "str_lookup",
        "singleCodepoint",
        "ToString",
        "t",
        "sorted_vocab",
        "id",
        "tokens",
        "n_tokens",
        "id",
        "singleCodepoint",
        "EncodeToUtf8",
        "i",
        "usedBytes",
        "i",
        "tokens",
        "n_tokens",
        "i",
        "i",
        "n_tokens",
        "i",
        "t",
        "vocab",
        "tokens",
        "i",
        "t",
        "vocab",
        "tokens",
        "i",
        "str_lookup",
        "str_buffer",
        "t",
        "sorted_vocab",
        "id",
        "t",
        "vocab_scores",
        "id",
        "best_score",
        "best_score",
        "t",
        "vocab_scores",
        "id",
        "best_id",
        "id",
        "best_idx",
        "i",
        "best_idx",
        "tokens",
        "best_idx",
        "best_id",
        "best_idx",
        "i",
        "n_tokens",
        "i",
        "tokens",
        "i",
        "tokens",
        "i",
        "n_tokens",
        "n_tokens",
        "DateTimeOffset",
        "UtcNow",
        "ToUnixTimeMilliseconds",
        "Transformer",
        "transformer",
        "Tokenizer",
        "tokenizer",
        "Sampler",
        "sampler",
        "prompt",
        "steps",
        "prompt",
        "prompt_tokens",
        "prompt",
        "Length",
        "num_prompt_tokens",
        "encode",
        "tokenizer",
        "prompt",
        "prompt_tokens",
        "pos",
        "steps",
        "forward",
        "transformer",
        "token",
        "pos",
        "pos",
        "num_prompt_tokens",
        "next",
        "prompt_tokens",
        "pos",
        "next",
        "sample",
        "sampler",
        "logits",
        "pos",
        "next",
        "decode",
        "tokenizer",
        "token",
        "next",
        "Out",
        "Write",
        "piece",
        "token",
        "next",
        "start",
        "start",
        "time_in_ms",
        "WriteLine",
        "pos",
        "time_in_ms",
        "WriteLine",
        "pos",
        "end",
        "start",
        "probabilities",
        "n",
        "probabilities",
        "i",
        "n",
        "i",
        "probabilities",
        "i",
        "max_p",
        "max_i",
        "i",
        "max_p",
        "probabilities",
        "i",
        "max_i",
        "probabilities",
        "n",
        "coin",
        "i",
        "n",
        "i",
        "cdf",
        "probabilities",
        "i",
        "coin",
        "cdf",
        "i",
        "n",
        "array",
        "to",
        "array",
        "array",
        "array",
        "to",
        "array",
        "to",
        "tmp",
        "array",
        "n",
        "Comparison",
        "comparator",
        "next",
        "prev",
        "n",
        "prev",
        "r",
        "n",
        "comparator",
        "array",
        "r",
        "array",
        "next",
        "next",
        "r",
        "comparator",
        "array",
        "next",
        "array",
        "prev",
        "swap",
        "array",
        "prev",
        "next",
        "prev",
        "next",
        "probabilities",
        "n",
        "topp",
        "indices",
        "coin",
        "Comparison",
        "i",
        "j",
        "probabilities",
        "j",
        "probabilities",
        "i",
        "n",
        "topp",
        "n",
        "i",
        "indices",
        "Length",
        "i",
        "probabilities",
        "i",
        "cutoff",
        "indices",
        "head",
        "i",
        "indices",
        "tail",
        "i",
        "n0",
        "i",
        "i",
        "siftDown",
        "indices",
        "i",
        "n0",
        "comparator",
        "n0",
        "i",
        "i",
        "swap",
        "indices",
        "i",
        "cumulative_prob",
        "probabilities",
        "indices",
        "i",
        "cumulative_prob",
        "topp",
        "last_idx",
        "i",
        "siftDown",
        "indices",
        "i",
        "comparator",
        "coin",
        "cumulative_prob",
        "n0",
        "i",
        "last_idx",
        "i",
        "cdf",
        "probabilities",
        "indices",
        "i",
        "r",
        "cdf",
        "indices",
        "i",
        "indices",
        "last_idx",
        "Sampler",
        "sampler",
        "logits",
        "sampler",
        "temperature",
        "next",
        "sample_argmax",
        "logits",
        "sampler",
        "vocab_size",
        "q",
        "sampler",
        "vocab_size",
        "q",
        "logits",
        "q",
        "sampler",
        "temperature",
        "softmax",
        "logits",
        "sampler",
        "vocab_size",
        "sampler",
        "random_f32",
        "sampler",
        "topp",
        "sampler",
        "topp",
        "next",
        "sample_mult",
        "logits",
        "sampler",
        "vocab_size",
        "coin",
        "next",
        "sample_topp",
        "logits",
        "sampler",
        "vocab_size",
        "sampler",
        "topp",
        "sampler",
        "probindex",
        "coin",
        "next",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "WriteLine",
        "args",
        "args",
        "Length",
        "error_usage",
        "args",
        "i",
        "args",
        "Length",
        "i",
        "i",
        "args",
        "Length",
        "error_usage",
        "args",
        "i",
        "error_usage",
        "args",
        "i",
        "Length",
        "error_usage",
        "args",
        "i",
        "temperature",
        "Parse",
        "args",
        "i",
        "topp",
        "Parse",
        "args",
        "i",
        "rng_seed",
        "Parse",
        "args",
        "i",
        "steps",
        "Parse",
        "args",
        "i",
        "prompt",
        "args",
        "i",
        "tokenizer_path",
        "args",
        "i",
        "error_usage",
        "rng_seed",
        "rng_seed",
        "time_in_ms",
        "temperature",
        "temperature",
        "topp",
        "topp",
        "topp",
        "steps",
        "steps",
        "Transformer",
        "checkpoint_path",
        "steps",
        "steps",
        "transformer",
        "config",
        "seq_len",
        "Tokenizer",
        "tokenizer_path",
        "transformer",
        "config",
        "vocab_size",
        "Sampler",
        "transformer",
        "config",
        "vocab_size",
        "temperature",
        "topp",
        "rng_seed",
        "generate",
        "transformer",
        "tokenizer",
        "sampler",
        "prompt",
        "steps"
    ],
    "literals": [
        "\"Config{\"",
        "\"dim=\"",
        "\", hidden_dim=\"",
        "\", n_layers=\"",
        "\", n_heads=\"",
        "\", n_kv_heads=\"",
        "\", vocab_size=\"",
        "\", seq_len=\"",
        "\", shared_weights=\"",
        "\", head_size=\"",
        "\" \"",
        "\"\\nachieved tok/s: {0}\"",
        "\"Usage:   Llama2.net.exe <checkpoint> [options]\"",
        "\"Example: Lamma2.net.exe model.bin -n 256 -i \\\"Once upon a time\\\"\"",
        "\"Options:\"",
        "\"  -t <float>  temperature in [0,inf], default 1.0\"",
        "\"  -p <float>  p value in top-p (nucleus) sampling in [0,1] default 0.9\"",
        "\"  -s <int>    random seed, default time(NULL)\"",
        "\"  -n <int>    number of steps to run for, default 256. 0 = max_seq_len\"",
        "\"  -i <string> input prompt\"",
        "\"  -z <string> optional path to custom tokenizer\"",
        "\"tokenizer.bin\""
    ],
    "variables": [
        "_ptr",
        "_start",
        "_length",
        "dim",
        "hidden_dim",
        "n_layers",
        "n_heads",
        "n_kv_heads",
        "vocab_size",
        "seq_len",
        "shared_weights",
        "head_size",
        "vocab_size",
        "token_embedding_table",
        "rms_att_weight",
        "wq",
        "wk",
        "wv",
        "wo",
        "rms_ffn_weight",
        "w1",
        "w2",
        "w3",
        "rms_final_weight",
        "wcls",
        "totalBytes",
        "segments",
        "i",
        "position",
        "x",
        "xb",
        "xb2",
        "hb",
        "hb2",
        "q",
        "k",
        "v",
        "att",
        "logits",
        "key_cache",
        "value_cache",
        "kv_dim",
        "Config",
        "config",
        "Weights",
        "weights",
        "RunState",
        "state",
        "MemoryMappedFile",
        "mappedFile",
        "configSize",
        "configBuffer",
        "configReader",
        "accessor",
        "vocab",
        "vocab_scores",
        "vocab_size",
        "max_token_length",
        "sorted_vocab",
        "accessor",
        "reader",
        "i",
        "len",
        "vocab_size",
        "probindex",
        "temperature",
        "topp",
        "rng_seed",
        "ss",
        "j",
        "w",
        "j",
        "max_val",
        "i",
        "sum",
        "i",
        "i",
        "val",
        "j",
        "w",
        "sum0",
        "sum1",
        "sum2",
        "sum3",
        "width",
        "upperBound",
        "wj0",
        "wj1",
        "wj2",
        "wj3",
        "xj0",
        "xj1",
        "xj2",
        "xj3",
        "Config",
        "p",
        "Weights",
        "w",
        "RunState",
        "s",
        "dim",
        "hidden_dim",
        "head_size",
        "kv_dim",
        "kv_mul",
        "l",
        "i",
        "head_dim",
        "freq",
        "val",
        "fcr",
        "fci",
        "rotn",
        "v",
        "vec",
        "v0",
        "v1",
        "loff",
        "qOffset",
        "attOffset",
        "t",
        "keyCacheOffset",
        "score",
        "i",
        "xbOffset",
        "t",
        "vOffset",
        "a",
        "i",
        "i",
        "i",
        "val",
        "i",
        "i",
        "piece",
        "ch",
        "isPrintable",
        "i",
        "n_tokens",
        "id",
        "usedBytes",
        "i",
        "best_score",
        "best_id",
        "best_idx",
        "i",
        "str_buffer",
        "id",
        "i",
        "prompt_tokens",
        "num_prompt_tokens",
        "start",
        "next",
        "token",
        "pos",
        "logits",
        "piece",
        "end",
        "max_i",
        "max_p",
        "i",
        "cdf",
        "i",
        "tmp",
        "prev",
        "next",
        "r",
        "comparator",
        "head",
        "tail",
        "cutoff",
        "i",
        "n0",
        "head",
        "i",
        "cumulative_prob",
        "last_idx",
        "i",
        "r",
        "cdf",
        "i",
        "next",
        "q",
        "coin",
        "checkpoint_path",
        "tokenizer_path",
        "temperature",
        "topp",
        "rng_seed",
        "steps",
        "prompt",
        "i",
        "Transformer",
        "transformer",
        "Tokenizer",
        "tokenizer",
        "Sampler",
        "sampler"
    ],
    "comments": [
        "transformer dimension",
        "for ffn layers",
        "number of layers",
        "number of query heads",
        "number of key/value heads (can be < query heads because of multiquery)",
        "vocabulary size, usually 256 (byte-level)",
        "max sequence length",
        "token embedding table",
        "(vocab_size, dim)",
        "weights for rmsnorms",
        "(layer, dim) rmsnorm weights",
        "weights for matmuls. note dim == n_heads * head_size",
        "(layer, dim, n_heads * head_size)",
        "(layer, dim, n_kv_heads * head_size)",
        "(layer, dim, n_kv_heads * head_size)",
        "(layer, n_heads * head_size, dim)",
        "(layer, dim)",
        "weights for ffn",
        "(layer, hidden_dim, dim)",
        "(layer, dim, hidden_dim)",
        "(layer, hidden_dim, dim)",
        "readonly rmsnorm",
        "(dim,)",
        "(optional) classifier weights for the logits, on the last layer",
        "(vocab_size, dim)",
        "----------------------------------------------------------------------------",
        "initialization: read from checkpoint",
        "skip what used to be freq_cis_real (for RoPE)",
        "skip what used to be freq_cis_imag (for RoPE)",
        "current wave of activations",
        "activation at current time stamp (dim,)",
        "same, but inside a residual branch (dim,)",
        "an additional buffer just for convenience (dim,)",
        "buffer for hidden dimension in the ffn (hidden_dim,)",
        "buffer for hidden dimension in the ffn (hidden_dim,)",
        "query (dim,)",
        "key (dim,)",
        "value (dim,)",
        "buffer for scores/attention values (n_heads, seq_len)",
        "output logits",
        "kv cache",
        "(layer, seq_len, dim)",
        "(layer, seq_len, dim)",
        "the hyperparameters of the architecture (the blueprint)",
        "the weights of the model",
        "buffers for the \"wave\" of activations in the forward pass",
        "some more state needed to properly clean up the memory mapping (sigh)",
        "read in the config header",
        "i should have written the vocab_size into the tokenizer file... sigh",
        "malloc space to hold the scores and the strings",
        "read in the file",
        "buffer used in top-p sampling",
        "buffer only used with nucleus sampling; may not need but it's ~small",
        "xorshift rng: https://en.wikipedia.org/wiki/Xorshift#xorshift.2A",
        "random float32 in [0,1)",
        "----------------------------------------------------------------------------",
        "neural net blocks; the dynamics of the Transformer",
        "calculate sum of squares",
        "normalize and scale",
        "find max value (for numerical stability)",
        "exp and sum",
        "normalize",
        "W (d,n) @ x (n,) -> xout (d,)",
        "by far the most amount of time is spent inside this little function",
        "a few convenience variables",
        "integer multiplier of the kv sharing in multiquery",
        "copy the token embedding into x",
        "forward all the layers",
        "attention rmsnorm",
        "qkv matmuls for this position",
        "RoPE relative positional encoding: complex-valued rotate q and k in each head",
        "how many vectors? 2 = q & k, 1 = q only",
        "the vector to rotate (query or key)",
        "save key,value at this time step (pos) to our kv cache",
        "kv cache layer offset for convenience",
        "multihead attention. iterate over all heads",
        "get the query vector for this head",
        "float* q = s.q + h * head_size;",
        "attention scores for this head",
        "float* att = s.att + h * p.seq_len;",
        "iterate over all timesteps, including the current one",
        "get the key vector for this head and at this timestep",
        "float* k = s->key_cache + loff + t * kv_dim + (h / kv_mul) * head_size;",
        "calculate the attention score as the dot product of q and k",
        "save the score to the attention buffer",
        "softmax the scores to get attention weights, from 0..pos inclusively",
        "weighted sum of the values, store back into xb",
        "float* xb = s.xb + h * head_size;",
        "memset(xb, 0, head_size * sizeof(float));",
        "get the value vector for this head and at this timestep",
        "float* v = s->value_cache + loff + t * kv_dim + (h / kv_mul) * head_size;",
        "get the attention weight for this timestep",
        "accumulate the weighted value inconfigto xb",
        "final matmul to get the output of the attention",
        "residual connection back into x",
        "ffn rmsnorm",
        "Now for FFN in PyTorch we have: self.w2(F.silu(self.w1(x)) * self.w3(x))",
        "first calculate self.w1(x) and self.w3(x)",
        "SwiGLU non-linearity",
        "silu(x)=x*σ(x), where σ(x) is the logistic sigmoid",
        "elementwise multiply with w3(x)",
        "elementwise multiply with w3(x)",
        "final matmul to get the output of the ffn",
        "residual connection",
        "final rmsnorm",
        "classifier into logits",
        "----------------------------------------------------------------------------",
        "The Byte Pair Encoding (BPE) Tokenizer that translates strings <-> tokens",
        "following BOS (1) token, sentencepiece decoder strips any leading whitespace (see PR #89)",
        "careful, some tokens designate raw bytes, and look like e.g. '<0x01>'",
        "ok this token is a raw byte token, carefuly to only print printable chars or whitespace",
        "some of the other bytes can be various control codes, backspace, etc. => skip",
        "efficiently find the perfect match for str in vocab, return its index or -1 if not found",
        "encode the string text (input) into an upper-bound preallocated tokens[] array",
        "sort vocabulary",
        "add_dummy_prefix is true by default",
        "the number of tokens",
        "first encode every individual codepoint in the input string",
        "we found this codepoint in vocab, add it as a token",
        "byte_fallback encoding: just encode each byte as a token",
        "+3 is here because the first 3 vocab elements are <unk>, <s>, </s>",
        "so the individual bytes only start at index 3",
        "merge the best consecutive pair each iteration, according the scores in vocab_scores",
        "check if we can merge the pair (tokens[i], tokens[i+1])",
        "this merge pair exists in vocab! record its score and position",
        "we couldn't find any more pairs to merge, so we're done",
        "merge the consecutive pair (best_idx, best_idx+1) into new token best_id",
        "delete token at position best_idx+1, shift the entire sequence back 1",
        "token length decreased",
        "----------------------------------------------------------------------------",
        "utilities: time / rng",
        "return time in milliseconds, for benchmarking the model speed",
        "----------------------------------------------------------------------------",
        "generation loop",
        "encode the (string) prompt into tokens sequence, if any is given",
        "the sequence of prompt tokens",
        "the total number of prompt tokens",
        "start the main loop",
        "used to time our code, only initialized after first iteration",
        "will store the next token in the sequence",
        "init with token 1 (=BOS), as done in Llama-2 sentencepiece tokenizer",
        "position in the sequence",
        "forward the transformer to get logits for the next token",
        "advance the state machine",
        "if we are still processing the input prompt, force the next prompt token",
        "otherwise sample the next token from the logits",
        "data-dependent terminating condition: the BOS (1) token delimits sequences",
        "print the token as string, decode it with the Tokenizer object",
        "init the timer here because the first iteration can be slower",
        "report achieved tok/s (pos-1 because the timer starts after first iteration)",
        "----------------------------------------------------------------------------",
        "sampling can be done in a few ways: greedy argmax, sampling, top-p sampling",
        "return the index that has the highest probability",
        "sample index from probabilities (they must sum to 1!)",
        "in case of rounding errors",
        "top-p sampling (or \"nucleus sampling\") samples from the smallest set of",
        "tokens that exceed probability topp. This way we never sample tokens that",
        "have very low probabilities and are less likely to go \"off the rails\".",
        "coin is a random number in [0, 1), usually from random_f32()",
        "values smaller than (1 - topp) / (n - 1) cannot be part of the result",
        "so for efficiency we crop these out as candidates before sorting",
        "build heap O(n0)",
        "truncate the list where cumulative probability of the largest k elements exceeds topp",
        "O(k lg n0)",
        "we've exceeded topp by including last_idx",
        "sample from the truncated list",
        "in case of rounding errors",
        "sample the token given the logits and some hyperparameters",
        "greedy argmax sampling: take the token with the highest probability",
        "apply the temperature to the logits",
        "apply softmax to the logits to get the probabilities for next token",
        "flip a (float) coin (this is our source of entropy for sampling)",
        "we sample from this distribution to get the next token",
        "simply sample from the predicted probability distribution",
        "top-p (nucleus) sampling, clamping the least likely tokens to zero",
        "----------------------------------------------------------------------------",
        "int main",
        "default parameters",
        "e.g. out/model.bin",
        "0.0 = greedy deterministic. 1.0 = original. don't set higher",
        "top-p in nucleus sampling. 1.0 = off. 0.9 works well, but slower",
        "seed rng with time by default",
        "max number of steps to run for, 0: use seq_len",
        "prompt string",
        "do some basic validation",
        "must have arg after flag",
        "must start with dash",
        "must be -x (one dash, one letter)",
        "read in the args",
        "parameter validation/overrides",
        "build the Transformer via the model .bin file",
        "ovrerride to ~max length",
        "build the Tokenizer via the tokenizer .bin file",
        "build the Sampler",
        "run!"
    ],
    "docstrings": [],
    "functions": [
        "BigMemory",
        "BigMemory",
        "GetSpan",
        "Slice",
        "Slice",
        "Config",
        "ToString",
        "takeFloats",
        "takeArray",
        "Weights",
        "RunState",
        "Transformer",
        "Tokenizer",
        "Sampler",
        "random_u32",
        "random_f32",
        "rmsnorm",
        "softmax",
        "matmul",
        "forward",
        "decode",
        "str_lookup",
        "encode",
        "time_in_ms",
        "generate",
        "sample_argmax",
        "sample_mult",
        "swap",
        "siftDown",
        "sample_topp",
        "sample",
        "error_usage",
        "Main"
    ],
    "classes": [
        "Config",
        "Weights",
        "RunState",
        "Transformer",
        "Tokenizer",
        "Sampler",
        "Llama2"
    ]
}