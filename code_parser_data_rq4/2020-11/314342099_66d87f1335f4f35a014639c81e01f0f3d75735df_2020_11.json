{
    "identifiers": [
        "os",
        "math",
        "logging",
        "pprint",
        "pformat",
        "argparse",
        "ArgumentParser",
        "collections",
        "defaultdict",
        "itertools",
        "chain",
        "torch",
        "torch",
        "nn",
        "parallel",
        "DistributedDataParallel",
        "torch",
        "utils",
        "data",
        "DataLoader",
        "TensorDataset",
        "ignite",
        "engine",
        "Engine",
        "Events",
        "ignite",
        "handlers",
        "ModelCheckpoint",
        "global_step_from_engine",
        "ignite",
        "metrics",
        "Accuracy",
        "Loss",
        "MetricsLambda",
        "RunningAverage",
        "ignite",
        "contrib",
        "handlers",
        "ProgressBar",
        "PiecewiseLinear",
        "ignite",
        "contrib",
        "handlers",
        "tensorboard_logger",
        "TensorboardLogger",
        "OutputHandler",
        "OptimizerParamsHandler",
        "transformers",
        "AdamW",
        "OpenAIGPTDoubleHeadsModel",
        "OpenAIGPTTokenizer",
        "GPT2DoubleHeadsModel",
        "GPT2Tokenizer",
        "WEIGHTS_NAME",
        "CONFIG_NAME",
        "utils",
        "get_dataset",
        "make_logdir",
        "logging",
        "getLogger",
        "scalar",
        "args",
        "args",
        "local_rank",
        "scalar",
        "torch",
        "tensor",
        "scalar",
        "dtype",
        "torch",
        "device",
        "args",
        "device",
        "torch",
        "distributed",
        "get_world_size",
        "torch",
        "distributed",
        "all_reduce",
        "scalar_t",
        "op",
        "torch",
        "distributed",
        "ReduceOp",
        "SUM",
        "scalar_t",
        "item",
        "dataset",
        "padding",
        "max",
        "len",
        "x",
        "x",
        "dataset",
        "name",
        "PADDED_INPUTS",
        "x",
        "padding",
        "name",
        "max_l",
        "len",
        "x",
        "x",
        "dataset",
        "name",
        "dataset",
        "model",
        "tokenizer",
        "len",
        "tokenizer",
        "encoder",
        "tokenizer",
        "add_special_tokens",
        "ATTR_TO_SPECIAL_TOKEN",
        "num_added_tokens",
        "model",
        "resize_token_embeddings",
        "new_num_tokens",
        "orig_num_tokens",
        "num_added_tokens",
        "persona",
        "history",
        "reply",
        "tokenizer",
        "labels",
        "with_eos",
        "tokenizer",
        "convert_tokens_to_ids",
        "SPECIAL_TOKENS",
        "bos",
        "chain",
        "persona",
        "history",
        "reply",
        "eos",
        "with_eos",
        "sequence",
        "speaker2",
        "len",
        "sequence",
        "i",
        "speaker1",
        "s",
        "i",
        "s",
        "sequence",
        "chain",
        "sequence",
        "speaker2",
        "i",
        "speaker1",
        "i",
        "s",
        "sequence",
        "_",
        "s",
        "len",
        "instance",
        "len",
        "instance",
        "labels",
        "sum",
        "len",
        "s",
        "s",
        "sequence",
        "sequence",
        "instance",
        "args",
        "tokenizer",
        "get_dataset",
        "tokenizer",
        "args",
        "dataset_path",
        "args",
        "dataset_cache",
        "logger",
        "info",
        "defaultdict",
        "defaultdict",
        "dataset_name",
        "dataset",
        "personachat",
        "items",
        "len",
        "dataset",
        "args",
        "num_candidates",
        "dataset_name",
        "min",
        "args",
        "num_candidates",
        "num_candidates",
        "dialog",
        "dataset",
        "dialog",
        "copy",
        "_",
        "args",
        "personality_permutations",
        "utterance",
        "dialog",
        "utterance",
        "args",
        "max_history",
        "j",
        "candidate",
        "utterance",
        "num_candidates",
        "j",
        "num_candidates",
        "build_input_from_segments",
        "persona",
        "history",
        "candidate",
        "tokenizer",
        "labels",
        "input_name",
        "input_array",
        "instance",
        "items",
        "datasets",
        "dataset_name",
        "input_name",
        "append",
        "input_array",
        "datasets",
        "dataset_name",
        "append",
        "num_candidates",
        "datasets",
        "dataset_name",
        "num_candidates",
        "persona",
        "persona",
        "logger",
        "info",
        "dataset_name",
        "dataset",
        "datasets",
        "items",
        "pad_dataset",
        "dataset",
        "padding",
        "tokenizer",
        "convert_tokens_to_ids",
        "SPECIAL_TOKENS",
        "input_name",
        "MODEL_INPUTS",
        "torch",
        "tensor",
        "dataset",
        "input_name",
        "input_name",
        "tensor",
        "view",
        "datasets",
        "dataset_name",
        "tensor",
        "shape",
        "tensor_datasets",
        "dataset_name",
        "append",
        "tensor",
        "logger",
        "info",
        "TensorDataset",
        "tensor_datasets",
        "TensorDataset",
        "tensor_datasets",
        "torch",
        "utils",
        "data",
        "distributed",
        "DistributedSampler",
        "train_dataset",
        "args",
        "distributed",
        "torch",
        "utils",
        "data",
        "distributed",
        "DistributedSampler",
        "valid_dataset",
        "args",
        "distributed",
        "DataLoader",
        "train_dataset",
        "sampler",
        "train_sampler",
        "batch_size",
        "args",
        "train_batch_size",
        "shuffle",
        "args",
        "distributed",
        "DataLoader",
        "valid_dataset",
        "sampler",
        "valid_sampler",
        "batch_size",
        "args",
        "valid_batch_size",
        "shuffle",
        "logger",
        "info",
        "format",
        "train_dataset",
        "tensors",
        "shape",
        "logger",
        "info",
        "format",
        "valid_dataset",
        "tensors",
        "shape",
        "train_loader",
        "valid_loader",
        "train_sampler",
        "valid_sampler",
        "ArgumentParser",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "action",
        "help",
        "parser",
        "add_argument",
        "torch",
        "cuda",
        "is_available",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "add_argument",
        "help",
        "parser",
        "parse_args",
        "logging",
        "basicConfig",
        "level",
        "logging",
        "INFO",
        "args",
        "local_rank",
        "logging",
        "WARN",
        "logger",
        "warning",
        "args",
        "local_rank",
        "logger",
        "info",
        "pformat",
        "args",
        "args",
        "local_rank",
        "args",
        "distributed",
        "torch",
        "cuda",
        "set_device",
        "args",
        "local_rank",
        "torch",
        "device",
        "args",
        "local_rank",
        "torch",
        "distributed",
        "init_process_group",
        "backend",
        "init_method",
        "logger",
        "info",
        "GPT2Tokenizer",
        "args",
        "model_checkpoint",
        "OpenAIGPTTokenizer",
        "tokenizer_class",
        "from_pretrained",
        "args",
        "model_checkpoint",
        "GPT2DoubleHeadsModel",
        "args",
        "model_checkpoint",
        "OpenAIGPTDoubleHeadsModel",
        "model_class",
        "from_pretrained",
        "args",
        "model_checkpoint",
        "model",
        "to",
        "args",
        "device",
        "add_special_tokens_",
        "model",
        "tokenizer",
        "AdamW",
        "model",
        "parameters",
        "lr",
        "args",
        "lr",
        "correct_bias",
        "args",
        "fp16",
        "apex",
        "amp",
        "amp",
        "initialize",
        "model",
        "optimizer",
        "opt_level",
        "args",
        "fp16",
        "args",
        "distributed",
        "DistributedDataParallel",
        "model",
        "device_ids",
        "args",
        "local_rank",
        "output_device",
        "args",
        "local_rank",
        "logger",
        "info",
        "get_data_loaders",
        "args",
        "tokenizer",
        "engine",
        "batch",
        "model",
        "train",
        "input_tensor",
        "to",
        "args",
        "device",
        "input_tensor",
        "batch",
        "batch",
        "lm_loss",
        "mc_loss",
        "_",
        "model",
        "input_ids",
        "token_type_ids",
        "token_type_ids",
        "mc_token_ids",
        "mc_token_ids",
        "mc_labels",
        "mc_labels",
        "labels",
        "labels",
        "lm_loss",
        "args",
        "lm_coef",
        "mc_loss",
        "args",
        "mc_coef",
        "args",
        "gradient_accumulation_steps",
        "args",
        "fp16",
        "amp",
        "scale_loss",
        "loss",
        "optimizer",
        "scaled_loss",
        "scaled_loss",
        "backward",
        "torch",
        "nn",
        "utils",
        "clip_grad_norm_",
        "amp",
        "master_params",
        "optimizer",
        "args",
        "max_norm",
        "loss",
        "backward",
        "torch",
        "nn",
        "utils",
        "clip_grad_norm_",
        "model",
        "parameters",
        "args",
        "max_norm",
        "engine",
        "state",
        "iteration",
        "args",
        "gradient_accumulation_steps",
        "optimizer",
        "step",
        "optimizer",
        "zero_grad",
        "loss",
        "item",
        "Engine",
        "update",
        "engine",
        "batch",
        "model",
        "eval",
        "torch",
        "no_grad",
        "input_tensor",
        "to",
        "args",
        "device",
        "input_tensor",
        "batch",
        "batch",
        "tokenizer",
        "decode",
        "input_ids",
        "tolist",
        "_",
        "model",
        "input_ids",
        "token_type_ids",
        "token_type_ids",
        "mc_token_ids",
        "mc_token_ids",
        "lm_logits",
        "contiguous",
        "view",
        "lm_logits",
        "size",
        "labels",
        "contiguous",
        "view",
        "lm_logits_flat_shifted",
        "mc_logits",
        "labels_flat_shifted",
        "mc_labels",
        "Engine",
        "inference",
        "trainer",
        "add_event_handler",
        "Events",
        "EPOCH_COMPLETED",
        "_",
        "evaluator",
        "run",
        "val_loader",
        "args",
        "n_epochs",
        "trainer",
        "add_event_handler",
        "Events",
        "COMPLETED",
        "_",
        "evaluator",
        "run",
        "val_loader",
        "args",
        "eval_before_start",
        "trainer",
        "add_event_handler",
        "Events",
        "STARTED",
        "_",
        "evaluator",
        "run",
        "val_loader",
        "args",
        "distributed",
        "trainer",
        "add_event_handler",
        "Events",
        "EPOCH_STARTED",
        "engine",
        "train_sampler",
        "set_epoch",
        "engine",
        "state",
        "epoch",
        "evaluator",
        "add_event_handler",
        "Events",
        "EPOCH_STARTED",
        "engine",
        "valid_sampler",
        "set_epoch",
        "engine",
        "state",
        "epoch",
        "PiecewiseLinear",
        "optimizer",
        "args",
        "lr",
        "args",
        "n_epochs",
        "len",
        "train_loader",
        "trainer",
        "add_event_handler",
        "Events",
        "ITERATION_STARTED",
        "scheduler",
        "RunningAverage",
        "output_transform",
        "x",
        "x",
        "attach",
        "trainer",
        "Loss",
        "torch",
        "nn",
        "CrossEntropyLoss",
        "ignore_index",
        "output_transform",
        "x",
        "x",
        "x",
        "Accuracy",
        "output_transform",
        "x",
        "x",
        "x",
        "metrics",
        "update",
        "MetricsLambda",
        "average_distributed_scalar",
        "metrics",
        "args",
        "MetricsLambda",
        "average_distributed_scalar",
        "metrics",
        "args",
        "MetricsLambda",
        "math",
        "exp",
        "metrics",
        "name",
        "metric",
        "metrics",
        "items",
        "metric",
        "attach",
        "evaluator",
        "name",
        "args",
        "local_rank",
        "ProgressBar",
        "persist",
        "pbar",
        "attach",
        "trainer",
        "metric_names",
        "evaluator",
        "add_event_handler",
        "Events",
        "COMPLETED",
        "_",
        "pbar",
        "log_message",
        "pformat",
        "evaluator",
        "state",
        "metrics",
        "make_logdir",
        "args",
        "model_checkpoint",
        "TensorboardLogger",
        "log_dir",
        "tb_logger",
        "attach",
        "trainer",
        "log_handler",
        "OutputHandler",
        "tag",
        "metric_names",
        "event_name",
        "Events",
        "ITERATION_COMPLETED",
        "tb_logger",
        "attach",
        "trainer",
        "log_handler",
        "OptimizerParamsHandler",
        "optimizer",
        "event_name",
        "Events",
        "ITERATION_STARTED",
        "tb_logger",
        "attach",
        "evaluator",
        "log_handler",
        "OutputHandler",
        "tag",
        "metric_names",
        "metrics",
        "keys",
        "global_step_transform",
        "global_step_from_engine",
        "trainer",
        "event_name",
        "Events",
        "EPOCH_COMPLETED",
        "ModelCheckpoint",
        "log_dir",
        "save_interval",
        "n_saved",
        "trainer",
        "add_event_handler",
        "Events",
        "EPOCH_COMPLETED",
        "checkpoint_handler",
        "getattr",
        "model",
        "model",
        "torch",
        "save",
        "args",
        "log_dir",
        "getattr",
        "model",
        "model",
        "config",
        "to_json_file",
        "os",
        "path",
        "join",
        "log_dir",
        "CONFIG_NAME",
        "tokenizer",
        "save_pretrained",
        "log_dir",
        "trainer",
        "run",
        "train_loader",
        "max_epochs",
        "args",
        "n_epochs",
        "args",
        "local_rank",
        "args",
        "n_epochs",
        "os",
        "rename",
        "os",
        "path",
        "join",
        "log_dir",
        "checkpoint_handler",
        "_saved",
        "os",
        "path",
        "join",
        "log_dir",
        "WEIGHTS_NAME",
        "tb_logger",
        "close",
        "train"
    ],
    "literals": [
        "\"./chatbot_exec_log.txt\"",
        "\"<bos>\"",
        "\"<eos>\"",
        "\"<speaker1>\"",
        "\"<speaker2>\"",
        "\"<pad>\"",
        "'bos_token'",
        "'<bos>'",
        "'eos_token'",
        "'<eos>'",
        "'pad_token'",
        "'<pad>'",
        "'additional_special_tokens'",
        "'<speaker1>'",
        "'<speaker2>'",
        "\"input_ids\"",
        "\"mc_token_ids\"",
        "\"labels\"",
        "\"mc_labels\"",
        "\"token_type_ids\"",
        "\"input_ids\"",
        "\"labels\"",
        "\"token_type_ids\"",
        "\"input_ids\"",
        "\"labels\"",
        "\"input_ids\"",
        "\"token_type_ids\"",
        "\"mc_token_ids\"",
        "\"input_ids\"",
        "\"labels\"",
        "\"input_ids\"",
        "\"labels\"",
        "\"Build inputs and labels\"",
        "\"train\"",
        "\"valid\"",
        "\"utterances\"",
        "\"candidates\"",
        "'train'",
        "\"personality\"",
        "\"utterances\"",
        "\"history\"",
        "\"candidates\"",
        "\"mc_labels\"",
        "\"n_candidates\"",
        "\"Pad inputs and convert to Tensor\"",
        "\"train\"",
        "\"valid\"",
        "\"mc_labels\"",
        "\"n_candidates\"",
        "\"Build train and validation dataloaders\"",
        "\"train\"",
        "\"valid\"",
        "\"Train dataset (Batch, Candidates, Seq length): {}\"",
        "\"Valid dataset (Batch, Candidates, Seq length): {}\"",
        "\"--dataset_path\"",
        "\"\"",
        "\"Path or url of the dataset. If empty download from S3.\"",
        "\"--dataset_cache\"",
        "'./dataset_cache'",
        "\"Path or url of the dataset cache\"",
        "\"--model_checkpoint\"",
        "\"openai-gpt\"",
        "\"Path, url or short name of the model\"",
        "\"--num_candidates\"",
        "\"Number of candidates for training\"",
        "\"--max_history\"",
        "\"Number of previous exchanges to keep in history\"",
        "\"--train_batch_size\"",
        "\"Batch size for training\"",
        "\"--valid_batch_size\"",
        "\"Batch size for validation\"",
        "\"--gradient_accumulation_steps\"",
        "\"Accumulate gradients on several steps\"",
        "\"--lr\"",
        "\"Learning rate\"",
        "\"--lm_coef\"",
        "\"LM loss coefficient\"",
        "\"--mc_coef\"",
        "\"Multiple-choice loss coefficient\"",
        "\"--max_norm\"",
        "\"Clipping gradient norm\"",
        "\"--n_epochs\"",
        "\"Number of training epochs\"",
        "\"--personality_permutations\"",
        "\"Number of permutations of personality sentences\"",
        "\"--eval_before_start\"",
        "'store_true'",
        "\"If true start with a first evaluation before training\"",
        "\"--device\"",
        "\"cuda\"",
        "\"cpu\"",
        "\"Device (cuda or cpu)\"",
        "\"--fp16\"",
        "\"\"",
        "\"Set to O0, O1, O2 or O3 for fp16 training (see apex documentation)\"",
        "\"--local_rank\"",
        "\"Local rank for distributed training (-1: not distributed)\"",
        "\"Running process %d\"",
        "\"Arguments: %s\"",
        "\"cuda\"",
        "'nccl'",
        "'env://'",
        "\"Prepare tokenizer, pretrained model and optimizer.\"",
        "\"gpt2\"",
        "\"gpt2\"",
        "\"Prepare datasets\"",
        "\"lr\"",
        "\"loss\"",
        "\"nll\"",
        "\"accuracy\"",
        "\"average_nll\"",
        "\"nll\"",
        "\"average_accuracy\"",
        "\"accuracy\"",
        "\"average_ppl\"",
        "\"average_nll\"",
        "\"loss\"",
        "\"Validation: %s\"",
        "\"training\"",
        "\"loss\"",
        "\"validation\"",
        "'checkpoint'",
        "'mymodel'",
        "'module'",
        "'/model_training_args.bin'",
        "'module'",
        "\"__main__\""
    ],
    "variables": [
        "logger",
        "SPECIAL_TOKENS",
        "ATTR_TO_SPECIAL_TOKEN",
        "MODEL_INPUTS",
        "PADDED_INPUTS",
        "scalar_t",
        "max_l",
        "dataset",
        "name",
        "orig_num_tokens",
        "num_added_tokens",
        "bos",
        "eos",
        "speaker1",
        "speaker2",
        "sequence",
        "sequence",
        "instance",
        "instance",
        "instance",
        "instance",
        "instance",
        "instance",
        "personachat",
        "datasets",
        "num_candidates",
        "num_candidates",
        "persona",
        "history",
        "labels",
        "instance",
        "persona",
        "tensor_datasets",
        "dataset",
        "tensor",
        "tensor",
        "train_dataset",
        "valid_dataset",
        "train_sampler",
        "valid_sampler",
        "train_loader",
        "valid_loader",
        "parser",
        "args",
        "args",
        "distributed",
        "args",
        "device",
        "tokenizer_class",
        "tokenizer",
        "model_class",
        "model",
        "optimizer",
        "model",
        "optimizer",
        "model",
        "train_loader",
        "val_loader",
        "train_sampler",
        "valid_sampler",
        "batch",
        "input_ids",
        "mc_token_ids",
        "labels",
        "mc_labels",
        "token_type_ids",
        "loss",
        "trainer",
        "batch",
        "input_ids",
        "mc_token_ids",
        "labels",
        "mc_labels",
        "token_type_ids",
        "lm_logits",
        "mc_logits",
        "lm_logits_flat_shifted",
        "labels_flat_shifted",
        "evaluator",
        "scheduler",
        "metrics",
        "metrics",
        "pbar",
        "log_dir",
        "tb_logger",
        "checkpoint_handler"
    ],
    "comments": [
        "!/usr/bin/env python",
        "coding: utf-8",
        "# Import Packages",
        "In[1]:",
        "In[2]:",
        "# Global Variables",
        "In[3]:",
        "## Python Functions",
        "In[4]:",
        "doesn't add if they are already there",
        "## Python Function for Data",
        "In[5]:",
        "permuted personalities",
        "# Train",
        "In[6]:",
        "logging is set to INFO (resp. WARN) for main (resp. auxiliary) process. logger.info => log main process only, logger.warning => log all processes",
        "This is a logger.warning: it will be printed by all distributed processes",
        "Initialize distributed training if needed",
        "cant use Autotokenizer because checkpoint could be a Path",
        "Add special tokens if they are not already added",
        "Prepare model for FP16 and distributed training if needed (order is important, distributed should be the last)",
        "Apex is only required if we use fp16 training",
        "Training function and trainer",
        "Evaluation function and evaluator (evaluator output is the input of the metrics)",
        "if we dont send labels to model, it doesnt return losses",
        "Attach evaluation to trainer: we evaluate when we start the training and at the end of each epoch",
        "Make sure distributed data samplers split the dataset nicely between the distributed processes",
        "Linearly decrease the learning rate from lr to zero",
        "Prepare metrics - note how we compute distributed metrics",
        "On the main process: add progress bar, tensorboard, checkpoints and save model, configuration and tokenizer before we start to train",
        "\"getattr\" takes care of distributed encapsulation",
        "Run the training",
        "On the main process: close tensorboard logger and rename the last checkpoint (for easy re-loading with OpenAIGPTModel.from_pretrained method)",
        "TODO: PR in ignite to have better access to saved file paths (cleaner)",
        "# Run",
        "In[7]:"
    ],
    "docstrings": [
        "\"\"\" Average a scalar over the nodes if we are in distributed training. We use this for distributed evaluation. \"\"\"",
        "\"\"\" Pad the dataset. This could be optimized by defining a Dataset class and padding at the batch level, but this is simpler. \"\"\"",
        "\"\"\" Add special tokens to the tokenizer and the model if they have not already been added. \"\"\"",
        "\"\"\" Build a sequence of input from 3 segments: persona, history and last reply. \"\"\"",
        "\"\"\" Prepare the dataset for training and evaluation \"\"\""
    ],
    "functions": [
        "average_distributed_scalar",
        "pad_dataset",
        "add_special_tokens_",
        "build_input_from_segments",
        "get_data_loaders",
        "train",
        "update",
        "inference"
    ],
    "classes": []
}