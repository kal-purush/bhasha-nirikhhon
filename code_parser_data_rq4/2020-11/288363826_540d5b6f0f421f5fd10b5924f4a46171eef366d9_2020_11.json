{
    "identifiers": [
        "Azure",
        "Storage",
        "Blobs",
        "Specialized",
        "Collections",
        "Generic",
        "Configuration",
        "IO",
        "Linq",
        "StorageSamples",
        "BlobSamples",
        "filePath",
        "ConfigurationManager",
        "ConnectionStrings",
        "ConnectionString",
        "BlockBlobClient",
        "connectionString",
        "containerName",
        "blobName",
        "File",
        "ReadAllBytes",
        "filePath",
        "currentBlockSize",
        "MAX_BLOCK_SIZE",
        "contentProcessed",
        "currentBlockSize",
        "fileContents",
        "Length",
        "currentBlockSize",
        "fileContents",
        "Length",
        "contentProcessed",
        "currentBlockSize",
        "Copy",
        "fileContents",
        "contentProcessed",
        "byteBlock",
        "currentBlockSize",
        "Convert",
        "ToBase64String",
        "BitConverter",
        "GetBytes",
        "blockId",
        "blob",
        "StageBlock",
        "blockID",
        "MemoryStream",
        "byteBlock",
        "blockIds",
        "Add",
        "blockID",
        "contentProcessed",
        "currentBlockSize",
        "blockId",
        "blob",
        "CommitBlockList",
        "blockIds"
    ],
    "literals": [
        "\"StorageConnectionString\"",
        "\"testcontainer\"",
        "\"testblockBlob.txt\""
    ],
    "variables": [
        "MAX_BLOCK_SIZE",
        "connectionString",
        "containerName",
        "blobName",
        "BlockBlobClient",
        "blob",
        "blockIds",
        "blockId",
        "contentProcessed",
        "fileContents",
        "currentBlockSize",
        "MAX_BLOCK_SIZE",
        "byteBlock",
        "blockID"
    ],
    "comments": [
        "Set the max block size in bytes. There are a few supported block sizes 64kb, 128kb, 256kb, 512kb, 1Mb, 2Mb, 4Mb, 100Mb",
        "Smaller block size will result in faster processing of write request, but will increase total no. of write operations",
        "512kb",
        "Get the connection string to storage account",
        "Set the container name",
        "Set the complete block blob path and name. You can also use just the name if you want to upload to root",
        "We are using the Blobs.Specialized.BlockBlobClient to quickly create block blob object with minimal code",
        "Maintain a list of block Ids to commit",
        "variable to compute block id",
        "variable to maintain blocks/content processed",
        "Get the file/data contents in bytes",
        "Set current block size to MAX size",
        "If content processed + current block size exceeds file length,",
        "then set current block size to difference of file length - content processed",
        "this is done to capture the last block that is smaller than MAX block size",
        "Create an array consisting only the subset/block of the file content",
        "Create a Base64 string for block ID. We can use any Base64 string, but be sure to hold the value to commit",
        "We are staging/adding a new block to a blob in storage account, to be committed later",
        "Adding block IDs to list",
        "Increase total blocks created",
        "Commit all the blocks to storage account. Unless committed, we will not see the file in storage account"
    ],
    "docstrings": [],
    "functions": [
        "Upload"
    ],
    "classes": [
        "UploadBlockBlob"
    ]
}