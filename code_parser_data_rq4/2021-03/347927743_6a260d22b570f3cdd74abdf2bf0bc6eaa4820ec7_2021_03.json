{
    "identifiers": [
        "it",
        "cnr",
        "asfa",
        "textprocessing",
        "java",
        "io",
        "BufferedReader",
        "java",
        "io",
        "BufferedWriter",
        "java",
        "io",
        "File",
        "java",
        "io",
        "FileInputStream",
        "java",
        "io",
        "FileOutputStream",
        "java",
        "io",
        "FileReader",
        "java",
        "io",
        "FileWriter",
        "java",
        "io",
        "java",
        "io",
        "InputStreamReader",
        "java",
        "io",
        "OutputStreamWriter",
        "java",
        "io",
        "PrintWriter",
        "java",
        "util",
        "Arrays",
        "java",
        "util",
        "LinkedHashMap",
        "org",
        "json",
        "JSONObject",
        "it",
        "cnr",
        "asfa",
        "textprocessing",
        "utils",
        "EfficientSearchInText",
        "puretext",
        "matches",
        "category",
        "annotationstext",
        "jsonAnnotations",
        "filename",
        "file",
        "filename",
        "reader",
        "file",
        "key",
        "line",
        "reader",
        "readLine",
        "line",
        "key",
        "line",
        "line",
        "reader",
        "readLine",
        "jsonString",
        "key",
        "obj",
        "jsonString",
        "puretext",
        "obj",
        "getString",
        "TokenizedjsonText",
        "puretext",
        "split",
        "i",
        "i",
        "TokenizedjsonText",
        "length",
        "i",
        "TokenizedjsonText",
        "i",
        "TokenizedjsonText",
        "i",
        "replaceAll",
        "toLowerCase",
        "est",
        "referenceTaxa",
        "nthreads",
        "found",
        "est",
        "searchParallel",
        "TokenizedjsonText",
        "referenceTaxa",
        "nthreads",
        "Arrays",
        "toString",
        "found",
        "matches",
        "found",
        "annotationName",
        "category",
        "annotationName",
        "TokenizedjsonText",
        "puretext",
        "split",
        "sb",
        "annotation",
        "s0",
        "s1",
        "annotation",
        "append",
        "annotationName",
        "i",
        "i",
        "TokenizedjsonText",
        "length",
        "i",
        "matches",
        "i",
        "sb",
        "append",
        "TokenizedjsonText",
        "i",
        "s1",
        "s1",
        "TokenizedjsonText",
        "i",
        "length",
        "annotation",
        "append",
        "s0",
        "s1",
        "s0",
        "s0",
        "TokenizedjsonText",
        "i",
        "length",
        "s1",
        "s1",
        "sb",
        "append",
        "TokenizedjsonText",
        "i",
        "s1",
        "s1",
        "TokenizedjsonText",
        "i",
        "length",
        "s0",
        "s0",
        "TokenizedjsonText",
        "i",
        "length",
        "speciesAnnotation",
        "sb",
        "toString",
        "category",
        "speciesAnnotation",
        "annotationstext",
        "put",
        "annotationName",
        "speciesAnnotation",
        "jsonAnnotations",
        "put",
        "annotationName",
        "annotation",
        "toString",
        "filename",
        "file",
        "filename",
        "temp",
        "File",
        "createTempFile",
        "file",
        "getParentFile",
        "charset",
        "reader",
        "file",
        "charset",
        "writer",
        "temp",
        "charset",
        "count",
        "line",
        "line",
        "reader",
        "readLine",
        "line",
        "contains",
        "count",
        "count",
        "count",
        "writer",
        "line",
        "writer",
        "append",
        "category",
        "toUpperCase",
        "writer",
        "annotationstext",
        "get",
        "category",
        "reader",
        "close",
        "writer",
        "close",
        "file",
        "temp",
        "renameTo",
        "file",
        "filename",
        "file",
        "filename",
        "reader",
        "file",
        "key",
        "line",
        "reader",
        "readLine",
        "line",
        "key",
        "line",
        "line",
        "reader",
        "readLine",
        "jsonString",
        "key",
        "obj",
        "jsonString",
        "obj",
        "remove",
        "obj",
        "remove",
        "obj",
        "remove",
        "obj",
        "remove",
        "obj",
        "remove",
        "obj",
        "remove",
        "obj",
        "remove",
        "writer",
        "filename",
        "writer",
        "append",
        "writer",
        "append",
        "obj",
        "toString",
        "substring",
        "obj",
        "toString",
        "length",
        "writer",
        "append",
        "jsonAnnotations",
        "get",
        "category",
        "toString",
        "writer",
        "close"
    ],
    "literals": [
        "\"\"",
        "\"text\"",
        "\"\\\\s+\"",
        "\"[^a-zA-Z ]\"",
        "\"\"",
        "\"taxon.csv\"",
        "\"Found \"",
        "\"\\\\s+\"",
        "\"\\\"\"",
        "\"\\\":\"",
        "\" [\"",
        "\"]\"",
        "\"{\\\"indices\\\":[\"",
        "\",\"",
        "\"]}\"",
        "\" \"",
        "\"file\"",
        "\".txt\"",
        "\"UTF-8\"",
        "\"##\"",
        "\"##\"",
        "\"##\"",
        "\"\"",
        "\"prova\"",
        "\"org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.ENGLISH_NER_CORENLP\"",
        "\"org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.OPEN_NLP_ENGLISH_PIPELINE\"",
        "\"org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.TAGME_ENGLISH_NER\"",
        "\"org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.ANNIE_PLUS_MEASUREMENTS\"",
        "\"org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.ENGLISH_NAMED_ENTITY_RECOGNIZER\"",
        "\"org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.KEYWORDS_NER_ENGLISH\"",
        "\"\"",
        "\",\""
    ],
    "variables": [
        "puretext",
        "matches",
        "category",
        "line"
    ],
    "comments": [
        "Testo pulito estratto dal file JSON",
        "Lista di corrispondenze riscontrate nel testo espresse in booleani",
        "Stringa che descrive la tipologia della annotazioni richieste, nel caso specifico Taxon ma che potrebbe diventare Worms o Gibf",
        "le dichiarazioni precedenti \"LinkedHashMap<String,String> annotationstext;\"",
        "causavano l'errore \"Exception in thread \"main\"",
        "java.lang.NullPointerException \"",
        "Metodo che ottiene il testo pulito dal file JSON ricavato dall'output di",
        "NLPHub",
        "Metodo identifica le tassonomie e nel testo e le salva nella",
        "variabile \"matches\"",
        "Per migliorare il match rimuovo i segni di punteggiatura e trasformo il testo",
        "in minuscolo. Questo passaggio viene effettuato dopo la suddivisione del",
        "testo in tokens per eviare che si verifichino delle incogruenze a livello di",
        "match di tokens nel metodo \"enrich\" dove il testo deve essere quello",
        "originale",
        "dell'output del json e non quello trasformato per effettuare al meglio il",
        "match",
        "Salvo la stringa che indica la categoria delle annotazioni in una variabile che utilizzerò successiamente",
        "Variabile per il file TXT",
        "Variabile per il file JSON",
        "Coppia di variabili per il conteggio degli indici delle posizioni di inizio e",
        "fine delle parole nel testo (quelli che servono per il file JSON)",
        "Rimuovo le annotazioni superflue (tutte tranne quella di merge dal file .JSON",
        "e aggiung quelle di Taxon)",
        "Stampo le nuove annotazioni successivamente a quelle di MERGE e chiudo",
        "Rimuovo le annotazioni superflue (tutte tranne quella di merge dal file .JSON",
        "e aggiung quelle di Taxon)",
        "Questo elemento mancante dal file json non causa errore",
        "Salvo il JSON rimuovando l'ultimo carattere che è una parentesi",
        "Aggiungo quelle di Taxon"
    ],
    "docstrings": [],
    "functions": [
        "capture",
        "get",
        "enrich",
        "materializeText",
        "materializeJSON"
    ],
    "classes": [
        "ASFAResearchObject"
    ]
}