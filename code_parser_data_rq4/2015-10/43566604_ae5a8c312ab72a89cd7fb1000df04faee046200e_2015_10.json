{
    "identifiers": [
        "bs4",
        "BeautifulSoup",
        "urlparse",
        "urlparse",
        "urljoin",
        "sys",
        "argv",
        "re",
        "urllib2",
        "argv",
        "url",
        "urlparse",
        "url",
        "format",
        "scheme",
        "uri",
        "scheme",
        "host",
        "uri",
        "netloc",
        "url",
        "urljoin",
        "domain",
        "url",
        "url",
        "get_domain_from_url",
        "url",
        "domain",
        "result",
        "url",
        "visited",
        "result",
        "text",
        "visited",
        "BeautifulSoup",
        "text",
        "soup",
        "find_all",
        "soup",
        "get_text",
        "word",
        "rendered",
        "split",
        "addresses",
        "re",
        "findall",
        "word",
        "a",
        "anchors",
        "get_full_url",
        "a",
        "get",
        "should_visit",
        "url",
        "url",
        "visited",
        "add",
        "url",
        "urllib2",
        "urlopen",
        "url",
        "read",
        "addresses",
        "extract_emails_from_text",
        "html",
        "addresses",
        "get_domain_from_url",
        "filename",
        "domain",
        "urllib2",
        "urlopen",
        "filename",
        "read",
        "extract_emails_from_text",
        "main"
    ],
    "literals": [
        "'{scheme}://{host}'",
        "\"http\"",
        "\"localhost\"",
        "\"html.parser\"",
        "'a'",
        "' '",
        "' '",
        "r'[a-z]+[A-Za-z0-9._%+-]+@\\S+\\.com'",
        "'href'"
    ],
    "variables": [
        "script",
        "filename",
        "visited",
        "uri",
        "result",
        "result",
        "addresses",
        "soup",
        "anchors",
        "rendered",
        "url",
        "html",
        "domain",
        "main"
    ],
    "comments": [
        "domain = \"\"",
        "More intelligent checking to ensure no duplicate or leaked visits",
        "Domain should match",
        "Should not have been visited",
        "Deal with JS",
        "Step 1",
        "Extract all anchor tags from text using BS4",
        "Step 2",
        "Get list of emails from text",
        "Step 3",
        "the recursion starts here"
    ],
    "docstrings": [],
    "functions": [
        "get_domain_from_url",
        "get_full_url",
        "should_visit",
        "extract_emails_from_text"
    ],
    "classes": []
}