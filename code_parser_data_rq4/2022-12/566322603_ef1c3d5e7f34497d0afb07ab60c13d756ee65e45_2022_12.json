{
    "identifiers": [
        "pathlib",
        "Path",
        "abc",
        "ABC",
        "abstractmethod",
        "pandas",
        "pd",
        "utils",
        "_time_it_",
        "typing",
        "Optional",
        "Union",
        "errors",
        "ImportCanceledError",
        "ActivityProductionValueError",
        "IncompatibleDatabaseNamingError",
        "InvalidSDFEntryValue",
        "ABC",
        "abstractmethod",
        "path",
        "Optional",
        "Union",
        "Path",
        "kwargs",
        "staticmethod",
        "data",
        "pd",
        "DataFrame",
        "ds",
        "data",
        "data",
        "data",
        "data",
        "data",
        "data",
        "ds",
        "ds",
        "split",
        "ds",
        "ds",
        "split",
        "IncompatibleDatabaseNamingError",
        "format",
        "ds",
        "ds",
        "staticmethod",
        "data",
        "pd",
        "DataFrame",
        "scenario_names",
        "pd",
        "DataFrame",
        "scenario",
        "scenario_names",
        "pd",
        "concat",
        "data",
        "loc",
        "data",
        "loc",
        "data",
        "loc",
        "scenario",
        "failed",
        "failed",
        "empty",
        "ActivityProductionValueError",
        "format",
        "failed",
        "failed",
        "staticmethod",
        "data",
        "pd",
        "DataFrame",
        "fields",
        "pd",
        "DataFrame",
        "field",
        "fields",
        "pd",
        "concat",
        "data",
        "loc",
        "data",
        "field",
        "isna",
        "hasNA",
        "hasNA",
        "empty",
        "InvalidSDFEntryValue",
        "format",
        "hasNA",
        "hasNA",
        "staticmethod",
        "data",
        "pd",
        "DataFrame",
        "ABFileImporter",
        "ABStandardProcessColumns",
        "difference",
        "ABFileImporter",
        "ABScenarioColumnsErrorIfNA",
        "ABFileImporter",
        "ABStandardProcessColumns",
        "union",
        "ABFileImporter",
        "ABStandardBiosphereColumns",
        "difference",
        "ABFileImporter",
        "ABScenarioColumnsErrorIfNA",
        "data",
        "loc",
        "data",
        "loc",
        "fillna",
        "fromkeys",
        "not_bio_cols",
        "data",
        "loc",
        "data",
        "loc",
        "fillna",
        "fromkeys",
        "bio_cols",
        "pd",
        "concat",
        "non_bio",
        "bio",
        "staticmethod",
        "data",
        "pd",
        "DataFrame",
        "fields",
        "scenario_names",
        "ABFileImporter",
        "fill_nas",
        "data",
        "ABFileImporter",
        "database_and_key_check",
        "data",
        "ABFileImporter",
        "na_value_check",
        "data",
        "fields",
        "scenario_names",
        "ABFileImporter",
        "production_process_check",
        "data",
        "scenario_names",
        "staticmethod",
        "data",
        "pd",
        "DataFrame",
        "data",
        "columns",
        "difference",
        "ABFileImporter",
        "ABStandardProcessColumns",
        "union",
        "ABFileImporter",
        "ABStandardBiosphereColumns",
        "ABFileImporter",
        "ABPickleImporter",
        "staticmethod",
        "path",
        "Optional",
        "Union",
        "Path",
        "kwargs",
        "kwargs",
        "pd",
        "read_pickle",
        "path",
        "compresion",
        "kwargs",
        "pd",
        "read_pickle",
        "path",
        "ABPickleImporter",
        "all_checks",
        "df",
        "ABPickleImporter",
        "ABScenarioColumnsErrorIfNA",
        "ABPickleImporter",
        "scenario_names",
        "df",
        "df",
        "ABFileImporter",
        "ABFeatherImporter",
        "staticmethod",
        "path",
        "Optional",
        "Union",
        "Path",
        "kwargs",
        "pd",
        "read_feather",
        "path",
        "ABPickleImporter",
        "all_checks",
        "df",
        "ABPickleImporter",
        "ABScenarioColumnsErrorIfNA",
        "ABPickleImporter",
        "scenario_names",
        "df",
        "df",
        "ABFileImporter",
        "ABCSVImporter",
        "staticmethod",
        "path",
        "Optional",
        "Union",
        "Path",
        "kwargs",
        "kwargs",
        "kwargs",
        "kwargs",
        "kwargs",
        "pd",
        "read_csv",
        "path",
        "compression",
        "compression",
        "sep",
        "separator",
        "index_col",
        "ABPickleImporter",
        "all_checks",
        "df",
        "ABPickleImporter",
        "ABScenarioColumnsErrorIfNA",
        "ABPickleImporter",
        "scenario_names",
        "df",
        "df",
        "staticmethod",
        "_time_it_",
        "file",
        "Optional",
        "Union",
        "Path",
        "pd",
        "DataFrame",
        "pd",
        "read_pickle",
        "file",
        "staticmethod",
        "_time_it_",
        "file",
        "Optional",
        "Union",
        "Path",
        "key",
        "Optional",
        "Union",
        "pd",
        "DataFrame",
        "pd",
        "read_hdf",
        "file",
        "key",
        "key",
        "staticmethod",
        "_time_it_",
        "file",
        "Optional",
        "Union",
        "Path",
        "sep",
        "pd",
        "DataFrame",
        "pd",
        "read_csv",
        "file",
        "sep",
        "sep",
        "staticmethod",
        "_time_it_",
        "file",
        "Optional",
        "Union",
        "Path",
        "compression",
        "pd",
        "DataFrame",
        "compression",
        "pd",
        "read_feather",
        "file",
        "pd",
        "read_feather",
        "file",
        "compression",
        "compression"
    ],
    "literals": [
        "'from activity name'",
        "'from reference product'",
        "'to reference product'",
        "'to location'",
        "'from location'",
        "'to activity name'",
        "'from key'",
        "'flow type'",
        "'from database'",
        "'to database'",
        "'to key'",
        "'from unit'",
        "'to unit'",
        "'from key'",
        "'flow type'",
        "'to key'",
        "'from categories'",
        "'to categories'",
        "'from database'",
        "'from key'",
        "'to database'",
        "'to key'",
        "'from activity name'",
        "'to activity name'",
        "','",
        "','",
        "\"Error in importing file with activity {} and {}\"",
        "'flow type'",
        "'production'",
        "\"Error with the production value in the exchange between activity {} and {}\"",
        "'from activity name'",
        "'to activity name'",
        "\"Error with NA's in the exchange between activity {} and {}\"",
        "'from activity name'",
        "'to activity name'",
        "'flow type'",
        "'biosphere'",
        "'NA'",
        "'flow type'",
        "'biosphere'",
        "'NA'",
        "'compression'",
        "'-'",
        "'compression'",
        "'compression'",
        "'-'",
        "'compression'",
        "'infer'",
        "'sep'",
        "'sep'",
        "\";\"",
        "';'"
    ],
    "variables": [
        "ABStandardProcessColumns",
        "ABScenarioColumnsErrorIfNA",
        "ABStandardBiosphereColumns",
        "failed",
        "failed",
        "hasNA",
        "hasNA",
        "not_bio_cols",
        "bio_cols",
        "non_bio",
        "bio",
        "df",
        "df",
        "df",
        "compression",
        "compression",
        "separator",
        "separator",
        "df"
    ],
    "comments": [
        "Check all following uses of fields has the same requirements",
        "... execute code",
        "... execute code",
        "... execute code"
    ],
    "docstrings": [
        "\"\"\"\n    Activity Browser abstract base class for scenario file imports\n\n    Contains a set of static methods for checking the file contents\n    to conform to the desired standard. These include:\n    - correct spelling of key and database names (checking they match)\n    - correct spelling of databases (if few instances are found)\n    - that all production exchanges do not have a value of 0\n    - that NAs are properly interpreted\n    \"\"\"",
        "\"\"\"Abstract method must be implemented in child classes.\"\"\"",
        "\"\"\"Will check the values in the 'xxxx database' and the 'xxxx key' fields.\n        If the database names are incongruent an IncompatibleDatabaseNamingError is raised.\n        The source and destination keys are provided for the first exchange where\n        this error occurs.\n        \"\"\"",
        "\"\"\" Runs a check on a dataframe over the scenario names (provided by the second argument)\n        If for a production exchange a value of 0 is observed for one of the scenarios an\n        ActivityProductionValueError is thrown with the source and destination activity names of the\n        exchanges being provided\n        \"\"\"",
        "\"\"\" Runs checks on the dataframe to ensure that those fields specified by the field argument do not\n        contain NaNs.\n        If an NaN is discovered an InvalidSDFEntryValue Error is thrown that contains two lists:\n        The first contains the list of the source activity names, the second the destination activity names\n        of the exchange\n        \"\"\"",
        "\"\"\" Will replace NaNs in the dataframe with a string holding \"NA\" for the following subsection of columns:\n            'from activity name', 'from reference product', 'to reference product', 'to location',\n            'from location', 'to activity name', 'from database', 'to database', 'from unit', 'to unit',\n            'from categories' and 'to categories'\n\n            Note: How NaNs are treated depends on the 'flow type'\n        \"\"\""
    ],
    "functions": [
        "read_file",
        "database_and_key_check",
        "production_process_check",
        "na_value_check",
        "fill_nas",
        "all_checks",
        "scenario_names",
        "read_file",
        "read_file",
        "read_file",
        "pickle",
        "hd5",
        "csv_zipped",
        "feather"
    ],
    "classes": [
        "ABFileImporter",
        "ABPickleImporter",
        "ABFeatherImporter",
        "ABCSVImporter",
        "FileImports"
    ]
}