{
    "identifiers": [
        "torch",
        "torch",
        "nn",
        "nn",
        "torch",
        "distributions",
        "dist",
        "torch",
        "nn",
        "functional",
        "F",
        "nn",
        "Module",
        "input_size",
        "num_layers",
        "hidden_size",
        "latent_dimension",
        "num_layers",
        "hidden_size",
        "latent_dimension",
        "nn",
        "LSTM",
        "input_size",
        "input_size",
        "hidden_size",
        "hidden_size",
        "num_layers",
        "num_layers",
        "bidirectional",
        "batch_first",
        "nn",
        "Linear",
        "in_features",
        "hidden_size",
        "out_features",
        "latent_dimension",
        "nn",
        "Linear",
        "in_features",
        "hidden_size",
        "out_features",
        "latent_dimension",
        "x",
        "h_t",
        "_",
        "lstm",
        "x",
        "h_t",
        "view",
        "num_layers",
        "hidden_size",
        "h_t",
        "torch",
        "cat",
        "h_t_forward",
        "h_t_backward",
        "dim",
        "fc_mean",
        "h_t",
        "F",
        "softplus",
        "fc_std",
        "h_t",
        "dist",
        "Normal",
        "loc",
        "mean",
        "scale",
        "std",
        "z_dist",
        "nn",
        "Module",
        "latent_dimension",
        "u_size",
        "hidden_size",
        "conductor_input_size",
        "num_layers",
        "num_layers",
        "hidden_size",
        "u_size",
        "conductor_input_size",
        "nn",
        "Linear",
        "in_features",
        "latent_dimension",
        "out_features",
        "hidden_size",
        "num_layers",
        "nn",
        "LSTM",
        "input_size",
        "conductor_input_size",
        "hidden_size",
        "hidden_size",
        "num_layers",
        "num_layers",
        "batch_first",
        "z",
        "torch",
        "tanh",
        "fc",
        "z",
        "t",
        "hidden_size",
        "num_layers",
        "t",
        "hidden_size",
        "num_layers",
        "hidden_states",
        "reshape",
        "num_layers",
        "hidden_size",
        "cell_states",
        "reshape",
        "num_layers",
        "hidden_size",
        "torch",
        "zeros",
        "size",
        "z",
        "shape",
        "u_size",
        "conductor_input_size",
        "lstm",
        "conductor_input",
        "hidden_states",
        "cell_states",
        "torch",
        "unbind",
        "embeddings",
        "dim",
        "embeddings"
    ],
    "literals": [],
    "variables": [
        "num_layers",
        "hidden_size",
        "latent_dimension",
        "lstm",
        "fc_mean",
        "fc_std",
        "_",
        "h_t",
        "h_t_forward",
        "h_t_backward",
        "h_t",
        "mean",
        "std",
        "z_dist",
        "num_layers",
        "hidden_size",
        "u_size",
        "conductor_input_size",
        "fc",
        "lstm",
        "t",
        "hidden_states",
        "cell_states",
        "hidden_states",
        "cell_states",
        "conductor_input",
        "embeddings",
        "_",
        "embeddings"
    ],
    "comments": [
        "tensor shape of initial hidden state: (num_directionsâˆ—num_layers, batch_size, hidden_size)",
        "ref: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html",
        "h, c -> 2",
        "embedding: (B, u_size, conductor_hidden_size) -> u_size * (B, hidden_size)"
    ],
    "docstrings": [],
    "functions": [
        "forward",
        "forward"
    ],
    "classes": [
        "LSTMEncoder",
        "Conductor"
    ]
}