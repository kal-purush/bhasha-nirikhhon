{
    "identifiers": [
        "os",
        "unittest",
        "nlgeval",
        "nlgeval",
        "NLGEval",
        "unittest",
        "TestCase",
        "classmethod",
        "cls",
        "NLGEval",
        "n",
        "compute_individual_metrics",
        "hyp",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertEqual",
        "len",
        "scores",
        "os",
        "path",
        "join",
        "os",
        "path",
        "dirname",
        "os",
        "path",
        "join",
        "root_dir",
        "os",
        "path",
        "join",
        "root_dir",
        "os",
        "path",
        "join",
        "root_dir",
        "nlgeval",
        "compute_metrics",
        "hypothesis",
        "references",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertEqual",
        "len",
        "scores",
        "n",
        "compute_metrics",
        "ref_list",
        "hyp_list",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertAlmostEqual",
        "scores",
        "places",
        "assertEqual",
        "len",
        "scores"
    ],
    "literals": [
        "\"this is a test\"",
        "\"this is also a test\"",
        "\"this is a good test\"",
        "'Bleu_1'",
        "'Bleu_2'",
        "'Bleu_3'",
        "'Bleu_4'",
        "'METEOR'",
        "'ROUGE_L'",
        "'CIDEr'",
        "'SkipThoughtCS'",
        "'EmbeddingAverageCosineSimilairty'",
        "'VectorExtremaCosineSimilarity'",
        "'GreedyMatchingScore'",
        "'..'",
        "'..'",
        "'examples/hyp.txt'",
        "'examples/ref1.txt'",
        "'examples/ref2.txt'",
        "'Bleu_1'",
        "'Bleu_2'",
        "'Bleu_3'",
        "'Bleu_4'",
        "'METEOR'",
        "'ROUGE_L'",
        "'CIDEr'",
        "'SkipThoughtCS'",
        "'EmbeddingAverageCosineSimilairty'",
        "'VectorExtremaCosineSimilarity'",
        "'GreedyMatchingScore'",
        "\"this is one reference sentence for sentence1\"",
        "\"this is the second reference sentence for sentence2\"",
        "\"this is one more reference sentence for sentence1\"",
        "\"this is a reference sentence for sentence2 which was generated by your model\"",
        "\"this is the model generated sentence1 which seems good enough\"",
        "\"this is sentence2 which has been generated by your model\"",
        "'Bleu_1'",
        "'Bleu_2'",
        "'Bleu_3'",
        "'Bleu_4'",
        "'METEOR'",
        "'ROUGE_L'",
        "'CIDEr'",
        "'SkipThoughtCS'",
        "'EmbeddingAverageCosineSimilairty'",
        "'VectorExtremaCosineSimilarity'",
        "'GreedyMatchingScore'"
    ],
    "variables": [
        "cls",
        "n",
        "scores",
        "root_dir",
        "hypothesis",
        "references",
        "scores",
        "scores"
    ],
    "comments": [
        "The example from the README."
    ],
    "docstrings": [],
    "functions": [
        "setUpClass",
        "test_compute_individual_metrics",
        "test_compute_metrics",
        "test_compute_metrics_oo"
    ],
    "classes": [
        "TestNlgEval"
    ]
}